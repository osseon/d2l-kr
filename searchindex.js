Search.setIndex({"docnames": ["chapter_appendix-mathematics-for-deep-learning/distributions", "chapter_appendix-mathematics-for-deep-learning/eigendecomposition", "chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops", "chapter_appendix-mathematics-for-deep-learning/index", "chapter_appendix-mathematics-for-deep-learning/information-theory", "chapter_appendix-mathematics-for-deep-learning/integral-calculus", "chapter_appendix-mathematics-for-deep-learning/maximum-likelihood", "chapter_appendix-mathematics-for-deep-learning/multivariable-calculus", "chapter_appendix-mathematics-for-deep-learning/naive-bayes", "chapter_appendix-mathematics-for-deep-learning/random-variables", "chapter_appendix-mathematics-for-deep-learning/single-variable-calculus", "chapter_appendix-mathematics-for-deep-learning/statistics", "chapter_appendix-tools-for-deep-learning/aws", "chapter_appendix-tools-for-deep-learning/colab", "chapter_appendix-tools-for-deep-learning/contributing", "chapter_appendix-tools-for-deep-learning/d2l", "chapter_appendix-tools-for-deep-learning/index", "chapter_appendix-tools-for-deep-learning/jupyter", "chapter_appendix-tools-for-deep-learning/sagemaker", "chapter_appendix-tools-for-deep-learning/selecting-servers-gpus", "chapter_appendix-tools-for-deep-learning/utils", "chapter_attention-mechanisms-and-transformers/attention-pooling", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions", "chapter_attention-mechanisms-and-transformers/bahdanau-attention", "chapter_attention-mechanisms-and-transformers/index", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers", "chapter_attention-mechanisms-and-transformers/multihead-attention", "chapter_attention-mechanisms-and-transformers/queries-keys-values", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding", "chapter_attention-mechanisms-and-transformers/transformer", "chapter_attention-mechanisms-and-transformers/vision-transformer", "chapter_builders-guide/custom-layer", "chapter_builders-guide/index", "chapter_builders-guide/init-param", "chapter_builders-guide/lazy-init", "chapter_builders-guide/model-construction", "chapter_builders-guide/parameters", "chapter_builders-guide/read-write", "chapter_builders-guide/use-gpu", "chapter_computational-performance/async-computation", "chapter_computational-performance/auto-parallelism", "chapter_computational-performance/hardware", "chapter_computational-performance/hybridize", "chapter_computational-performance/index", "chapter_computational-performance/multiple-gpus", "chapter_computational-performance/multiple-gpus-concise", "chapter_computational-performance/parameterserver", "chapter_computer-vision/anchor", "chapter_computer-vision/bounding-box", "chapter_computer-vision/fcn", "chapter_computer-vision/fine-tuning", "chapter_computer-vision/image-augmentation", "chapter_computer-vision/index", "chapter_computer-vision/kaggle-cifar10", "chapter_computer-vision/kaggle-dog", "chapter_computer-vision/multiscale-object-detection", "chapter_computer-vision/neural-style", "chapter_computer-vision/object-detection-dataset", "chapter_computer-vision/rcnn", "chapter_computer-vision/semantic-segmentation-and-dataset", "chapter_computer-vision/ssd", "chapter_computer-vision/transposed-conv", "chapter_convolutional-modern/alexnet", "chapter_convolutional-modern/batch-norm", "chapter_convolutional-modern/cnn-design", "chapter_convolutional-modern/densenet", "chapter_convolutional-modern/googlenet", "chapter_convolutional-modern/index", "chapter_convolutional-modern/nin", "chapter_convolutional-modern/resnet", "chapter_convolutional-modern/vgg", "chapter_convolutional-neural-networks/channels", "chapter_convolutional-neural-networks/conv-layer", "chapter_convolutional-neural-networks/index", "chapter_convolutional-neural-networks/lenet", "chapter_convolutional-neural-networks/padding-and-strides", "chapter_convolutional-neural-networks/pooling", "chapter_convolutional-neural-networks/why-conv", "chapter_gaussian-processes/gp-inference", "chapter_gaussian-processes/gp-intro", "chapter_gaussian-processes/gp-priors", "chapter_gaussian-processes/index", "chapter_generative-adversarial-networks/dcgan", "chapter_generative-adversarial-networks/gan", "chapter_generative-adversarial-networks/index", "chapter_hyperparameter-optimization/hyperopt-api", "chapter_hyperparameter-optimization/hyperopt-intro", "chapter_hyperparameter-optimization/index", "chapter_hyperparameter-optimization/rs-async", "chapter_hyperparameter-optimization/sh-async", "chapter_hyperparameter-optimization/sh-intro", "chapter_installation/index", "chapter_introduction/index", "chapter_linear-classification/classification", "chapter_linear-classification/environment-and-distribution-shift", "chapter_linear-classification/generalization-classification", "chapter_linear-classification/image-classification-dataset", "chapter_linear-classification/index", "chapter_linear-classification/softmax-regression", "chapter_linear-classification/softmax-regression-concise", "chapter_linear-classification/softmax-regression-scratch", "chapter_linear-regression/generalization", "chapter_linear-regression/index", "chapter_linear-regression/linear-regression", "chapter_linear-regression/linear-regression-concise", "chapter_linear-regression/linear-regression-scratch", "chapter_linear-regression/oo-design", "chapter_linear-regression/synthetic-regression-data", "chapter_linear-regression/weight-decay", "chapter_multilayer-perceptrons/backprop", "chapter_multilayer-perceptrons/dropout", "chapter_multilayer-perceptrons/generalization-deep", "chapter_multilayer-perceptrons/index", "chapter_multilayer-perceptrons/kaggle-house-price", "chapter_multilayer-perceptrons/mlp", "chapter_multilayer-perceptrons/mlp-implementation", "chapter_multilayer-perceptrons/numerical-stability-and-init", "chapter_natural-language-processing-applications/finetuning-bert", "chapter_natural-language-processing-applications/index", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset", "chapter_natural-language-processing-applications/natural-language-inference-attention", "chapter_natural-language-processing-applications/natural-language-inference-bert", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset", "chapter_natural-language-processing-applications/sentiment-analysis-cnn", "chapter_natural-language-processing-applications/sentiment-analysis-rnn", "chapter_natural-language-processing-pretraining/approx-training", "chapter_natural-language-processing-pretraining/bert", "chapter_natural-language-processing-pretraining/bert-dataset", "chapter_natural-language-processing-pretraining/bert-pretraining", "chapter_natural-language-processing-pretraining/glove", "chapter_natural-language-processing-pretraining/index", "chapter_natural-language-processing-pretraining/similarity-analogy", "chapter_natural-language-processing-pretraining/subword-embedding", "chapter_natural-language-processing-pretraining/word-embedding-dataset", "chapter_natural-language-processing-pretraining/word2vec", "chapter_natural-language-processing-pretraining/word2vec-pretraining", "chapter_notation/index", "chapter_optimization/adadelta", "chapter_optimization/adagrad", "chapter_optimization/adam", "chapter_optimization/convexity", "chapter_optimization/gd", "chapter_optimization/index", "chapter_optimization/lr-scheduler", "chapter_optimization/minibatch-sgd", "chapter_optimization/momentum", "chapter_optimization/optimization-intro", "chapter_optimization/rmsprop", "chapter_optimization/sgd", "chapter_preface/index", "chapter_preliminaries/autograd", "chapter_preliminaries/calculus", "chapter_preliminaries/index", "chapter_preliminaries/linear-algebra", "chapter_preliminaries/lookup-api", "chapter_preliminaries/ndarray", "chapter_preliminaries/pandas", "chapter_preliminaries/probability", "chapter_recommender-systems/autorec", "chapter_recommender-systems/ctr", "chapter_recommender-systems/deepfm", "chapter_recommender-systems/fm", "chapter_recommender-systems/index", "chapter_recommender-systems/mf", "chapter_recommender-systems/movielens", "chapter_recommender-systems/neumf", "chapter_recommender-systems/ranking", "chapter_recommender-systems/recsys-intro", "chapter_recommender-systems/seqrec", "chapter_recurrent-modern/beam-search", "chapter_recurrent-modern/bi-rnn", "chapter_recurrent-modern/deep-rnn", "chapter_recurrent-modern/encoder-decoder", "chapter_recurrent-modern/gru", "chapter_recurrent-modern/index", "chapter_recurrent-modern/lstm", "chapter_recurrent-modern/machine-translation-and-dataset", "chapter_recurrent-modern/seq2seq", "chapter_recurrent-neural-networks/bptt", "chapter_recurrent-neural-networks/index", "chapter_recurrent-neural-networks/language-model", "chapter_recurrent-neural-networks/rnn", "chapter_recurrent-neural-networks/rnn-concise", "chapter_recurrent-neural-networks/rnn-scratch", "chapter_recurrent-neural-networks/sequence", "chapter_recurrent-neural-networks/text-sequence", "chapter_references/zreferences", "chapter_reinforcement-learning/index", "chapter_reinforcement-learning/mdp", "chapter_reinforcement-learning/qlearning", "chapter_reinforcement-learning/value-iter", "index"], "filenames": ["chapter_appendix-mathematics-for-deep-learning/distributions.rst", "chapter_appendix-mathematics-for-deep-learning/eigendecomposition.rst", "chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.rst", "chapter_appendix-mathematics-for-deep-learning/index.rst", "chapter_appendix-mathematics-for-deep-learning/information-theory.rst", "chapter_appendix-mathematics-for-deep-learning/integral-calculus.rst", "chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.rst", "chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.rst", "chapter_appendix-mathematics-for-deep-learning/naive-bayes.rst", "chapter_appendix-mathematics-for-deep-learning/random-variables.rst", "chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.rst", "chapter_appendix-mathematics-for-deep-learning/statistics.rst", "chapter_appendix-tools-for-deep-learning/aws.rst", "chapter_appendix-tools-for-deep-learning/colab.rst", "chapter_appendix-tools-for-deep-learning/contributing.rst", "chapter_appendix-tools-for-deep-learning/d2l.rst", "chapter_appendix-tools-for-deep-learning/index.rst", "chapter_appendix-tools-for-deep-learning/jupyter.rst", "chapter_appendix-tools-for-deep-learning/sagemaker.rst", "chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.rst", "chapter_appendix-tools-for-deep-learning/utils.rst", "chapter_attention-mechanisms-and-transformers/attention-pooling.rst", "chapter_attention-mechanisms-and-transformers/attention-scoring-functions.rst", "chapter_attention-mechanisms-and-transformers/bahdanau-attention.rst", "chapter_attention-mechanisms-and-transformers/index.rst", "chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.rst", "chapter_attention-mechanisms-and-transformers/multihead-attention.rst", "chapter_attention-mechanisms-and-transformers/queries-keys-values.rst", "chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.rst", "chapter_attention-mechanisms-and-transformers/transformer.rst", "chapter_attention-mechanisms-and-transformers/vision-transformer.rst", "chapter_builders-guide/custom-layer.rst", "chapter_builders-guide/index.rst", "chapter_builders-guide/init-param.rst", "chapter_builders-guide/lazy-init.rst", "chapter_builders-guide/model-construction.rst", "chapter_builders-guide/parameters.rst", "chapter_builders-guide/read-write.rst", "chapter_builders-guide/use-gpu.rst", "chapter_computational-performance/async-computation.rst", "chapter_computational-performance/auto-parallelism.rst", "chapter_computational-performance/hardware.rst", "chapter_computational-performance/hybridize.rst", "chapter_computational-performance/index.rst", "chapter_computational-performance/multiple-gpus.rst", "chapter_computational-performance/multiple-gpus-concise.rst", "chapter_computational-performance/parameterserver.rst", "chapter_computer-vision/anchor.rst", "chapter_computer-vision/bounding-box.rst", "chapter_computer-vision/fcn.rst", "chapter_computer-vision/fine-tuning.rst", "chapter_computer-vision/image-augmentation.rst", "chapter_computer-vision/index.rst", "chapter_computer-vision/kaggle-cifar10.rst", "chapter_computer-vision/kaggle-dog.rst", "chapter_computer-vision/multiscale-object-detection.rst", "chapter_computer-vision/neural-style.rst", "chapter_computer-vision/object-detection-dataset.rst", "chapter_computer-vision/rcnn.rst", "chapter_computer-vision/semantic-segmentation-and-dataset.rst", "chapter_computer-vision/ssd.rst", "chapter_computer-vision/transposed-conv.rst", "chapter_convolutional-modern/alexnet.rst", "chapter_convolutional-modern/batch-norm.rst", "chapter_convolutional-modern/cnn-design.rst", "chapter_convolutional-modern/densenet.rst", "chapter_convolutional-modern/googlenet.rst", "chapter_convolutional-modern/index.rst", "chapter_convolutional-modern/nin.rst", "chapter_convolutional-modern/resnet.rst", "chapter_convolutional-modern/vgg.rst", "chapter_convolutional-neural-networks/channels.rst", "chapter_convolutional-neural-networks/conv-layer.rst", "chapter_convolutional-neural-networks/index.rst", "chapter_convolutional-neural-networks/lenet.rst", "chapter_convolutional-neural-networks/padding-and-strides.rst", "chapter_convolutional-neural-networks/pooling.rst", "chapter_convolutional-neural-networks/why-conv.rst", "chapter_gaussian-processes/gp-inference.rst", "chapter_gaussian-processes/gp-intro.rst", "chapter_gaussian-processes/gp-priors.rst", "chapter_gaussian-processes/index.rst", "chapter_generative-adversarial-networks/dcgan.rst", "chapter_generative-adversarial-networks/gan.rst", "chapter_generative-adversarial-networks/index.rst", "chapter_hyperparameter-optimization/hyperopt-api.rst", "chapter_hyperparameter-optimization/hyperopt-intro.rst", "chapter_hyperparameter-optimization/index.rst", "chapter_hyperparameter-optimization/rs-async.rst", "chapter_hyperparameter-optimization/sh-async.rst", "chapter_hyperparameter-optimization/sh-intro.rst", "chapter_installation/index.rst", "chapter_introduction/index.rst", "chapter_linear-classification/classification.rst", "chapter_linear-classification/environment-and-distribution-shift.rst", "chapter_linear-classification/generalization-classification.rst", "chapter_linear-classification/image-classification-dataset.rst", "chapter_linear-classification/index.rst", "chapter_linear-classification/softmax-regression.rst", "chapter_linear-classification/softmax-regression-concise.rst", "chapter_linear-classification/softmax-regression-scratch.rst", "chapter_linear-regression/generalization.rst", "chapter_linear-regression/index.rst", "chapter_linear-regression/linear-regression.rst", "chapter_linear-regression/linear-regression-concise.rst", "chapter_linear-regression/linear-regression-scratch.rst", "chapter_linear-regression/oo-design.rst", "chapter_linear-regression/synthetic-regression-data.rst", "chapter_linear-regression/weight-decay.rst", "chapter_multilayer-perceptrons/backprop.rst", "chapter_multilayer-perceptrons/dropout.rst", "chapter_multilayer-perceptrons/generalization-deep.rst", "chapter_multilayer-perceptrons/index.rst", "chapter_multilayer-perceptrons/kaggle-house-price.rst", "chapter_multilayer-perceptrons/mlp.rst", "chapter_multilayer-perceptrons/mlp-implementation.rst", "chapter_multilayer-perceptrons/numerical-stability-and-init.rst", "chapter_natural-language-processing-applications/finetuning-bert.rst", "chapter_natural-language-processing-applications/index.rst", "chapter_natural-language-processing-applications/natural-language-inference-and-dataset.rst", "chapter_natural-language-processing-applications/natural-language-inference-attention.rst", "chapter_natural-language-processing-applications/natural-language-inference-bert.rst", "chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.rst", "chapter_natural-language-processing-applications/sentiment-analysis-cnn.rst", "chapter_natural-language-processing-applications/sentiment-analysis-rnn.rst", "chapter_natural-language-processing-pretraining/approx-training.rst", "chapter_natural-language-processing-pretraining/bert.rst", "chapter_natural-language-processing-pretraining/bert-dataset.rst", "chapter_natural-language-processing-pretraining/bert-pretraining.rst", "chapter_natural-language-processing-pretraining/glove.rst", "chapter_natural-language-processing-pretraining/index.rst", "chapter_natural-language-processing-pretraining/similarity-analogy.rst", "chapter_natural-language-processing-pretraining/subword-embedding.rst", "chapter_natural-language-processing-pretraining/word-embedding-dataset.rst", "chapter_natural-language-processing-pretraining/word2vec.rst", "chapter_natural-language-processing-pretraining/word2vec-pretraining.rst", "chapter_notation/index.rst", "chapter_optimization/adadelta.rst", "chapter_optimization/adagrad.rst", "chapter_optimization/adam.rst", "chapter_optimization/convexity.rst", "chapter_optimization/gd.rst", "chapter_optimization/index.rst", "chapter_optimization/lr-scheduler.rst", "chapter_optimization/minibatch-sgd.rst", "chapter_optimization/momentum.rst", "chapter_optimization/optimization-intro.rst", "chapter_optimization/rmsprop.rst", "chapter_optimization/sgd.rst", "chapter_preface/index.rst", "chapter_preliminaries/autograd.rst", "chapter_preliminaries/calculus.rst", "chapter_preliminaries/index.rst", "chapter_preliminaries/linear-algebra.rst", "chapter_preliminaries/lookup-api.rst", "chapter_preliminaries/ndarray.rst", "chapter_preliminaries/pandas.rst", "chapter_preliminaries/probability.rst", "chapter_recommender-systems/autorec.rst", "chapter_recommender-systems/ctr.rst", "chapter_recommender-systems/deepfm.rst", "chapter_recommender-systems/fm.rst", "chapter_recommender-systems/index.rst", "chapter_recommender-systems/mf.rst", "chapter_recommender-systems/movielens.rst", "chapter_recommender-systems/neumf.rst", "chapter_recommender-systems/ranking.rst", "chapter_recommender-systems/recsys-intro.rst", "chapter_recommender-systems/seqrec.rst", "chapter_recurrent-modern/beam-search.rst", "chapter_recurrent-modern/bi-rnn.rst", "chapter_recurrent-modern/deep-rnn.rst", "chapter_recurrent-modern/encoder-decoder.rst", "chapter_recurrent-modern/gru.rst", "chapter_recurrent-modern/index.rst", "chapter_recurrent-modern/lstm.rst", "chapter_recurrent-modern/machine-translation-and-dataset.rst", "chapter_recurrent-modern/seq2seq.rst", "chapter_recurrent-neural-networks/bptt.rst", "chapter_recurrent-neural-networks/index.rst", "chapter_recurrent-neural-networks/language-model.rst", "chapter_recurrent-neural-networks/rnn.rst", "chapter_recurrent-neural-networks/rnn-concise.rst", "chapter_recurrent-neural-networks/rnn-scratch.rst", "chapter_recurrent-neural-networks/sequence.rst", "chapter_recurrent-neural-networks/text-sequence.rst", "chapter_references/zreferences.rst", "chapter_reinforcement-learning/index.rst", "chapter_reinforcement-learning/mdp.rst", "chapter_reinforcement-learning/qlearning.rst", "chapter_reinforcement-learning/value-iter.rst", "index.rst"], "titles": ["<span class=\"section-number\">22.8. </span>Distributions", "<span class=\"section-number\">22.2. </span>Eigendecompositions", "<span class=\"section-number\">22.1. </span>Geometry and Linear Algebraic Operations", "<span class=\"section-number\">22. </span>Appendix: Mathematics for Deep Learning", "<span class=\"section-number\">22.11. </span>Information Theory", "<span class=\"section-number\">22.5. </span>Integral Calculus", "<span class=\"section-number\">22.7. </span>Maximum Likelihood", "<span class=\"section-number\">22.4. </span>Multivariable Calculus", "<span class=\"section-number\">22.9. </span>Naive Bayes", "<span class=\"section-number\">22.6. </span>Random Variables", "<span class=\"section-number\">22.3. </span>Single Variable Calculus", "<span class=\"section-number\">22.10. </span>Statistics", "<span class=\"section-number\">23.3. </span>Using AWS EC2 Instances", "<span class=\"section-number\">23.4. </span>Using Google Colab", "<span class=\"section-number\">23.6. </span>Contributing to This Book", "<span class=\"section-number\">23.8. </span>The <code class=\"docutils literal notranslate\"><span class=\"pre\">d2l</span></code> API Document", "<span class=\"section-number\">23. </span>Appendix: Tools for Deep Learning", "<span class=\"section-number\">23.1. </span>Using Jupyter Notebooks", "<span class=\"section-number\">23.2. </span>Using Amazon SageMaker", "<span class=\"section-number\">23.5. </span>Selecting Servers and GPUs", "<span class=\"section-number\">23.7. </span>Utility Functions and Classes", "<span class=\"section-number\">11.2. </span>Attention Pooling by Similarity", "<span class=\"section-number\">11.3. </span>Attention Scoring Functions", "<span class=\"section-number\">11.4. </span>The Bahdanau Attention Mechanism", "<span class=\"section-number\">11. </span>Attention Mechanisms and Transformers", "<span class=\"section-number\">11.9. </span>Large-Scale Pretraining with Transformers", "<span class=\"section-number\">11.5. </span>Multi-Head Attention", "<span class=\"section-number\">11.1. </span>Queries, Keys, and Values", "<span class=\"section-number\">11.6. </span>Self-Attention and Positional Encoding", "<span class=\"section-number\">11.7. </span>The Transformer Architecture", "<span class=\"section-number\">11.8. </span>Transformers for Vision", "<span class=\"section-number\">6.5. </span>Custom Layers", "<span class=\"section-number\">6. </span>Builders\u2019 Guide", "<span class=\"section-number\">6.3. </span>Parameter Initialization", "<span class=\"section-number\">6.4. </span>Lazy Initialization", "<span class=\"section-number\">6.1. </span>Layers and Modules", "<span class=\"section-number\">6.2. </span>Parameter Management", "<span class=\"section-number\">6.6. </span>File I/O", "<span class=\"section-number\">6.7. </span>GPUs", "<span class=\"section-number\">13.2. </span>Asynchronous Computation", "<span class=\"section-number\">13.3. </span>Automatic Parallelism", "<span class=\"section-number\">13.4. </span>Hardware", "<span class=\"section-number\">13.1. </span>Compilers and Interpreters", "<span class=\"section-number\">13. </span>Computational Performance", "<span class=\"section-number\">13.5. </span>Training on Multiple GPUs", "<span class=\"section-number\">13.6. </span>Concise Implementation for Multiple GPUs", "<span class=\"section-number\">13.7. </span>Parameter Servers", "<span class=\"section-number\">14.4. </span>Anchor Boxes", "<span class=\"section-number\">14.3. </span>Object Detection and Bounding Boxes", "<span class=\"section-number\">14.11. </span>Fully Convolutional Networks", "<span class=\"section-number\">14.2. </span>Fine-Tuning", "<span class=\"section-number\">14.1. </span>Image Augmentation", "<span class=\"section-number\">14. </span>Computer Vision", "<span class=\"section-number\">14.13. </span>Image Classification (CIFAR-10) on Kaggle", "<span class=\"section-number\">14.14. </span>Dog Breed Identification (ImageNet Dogs) on Kaggle", "<span class=\"section-number\">14.5. </span>Multiscale Object Detection", "<span class=\"section-number\">14.12. </span>Neural Style Transfer", "<span class=\"section-number\">14.6. </span>The Object Detection Dataset", "<span class=\"section-number\">14.8. </span>Region-based CNNs (R-CNNs)", "<span class=\"section-number\">14.9. </span>Semantic Segmentation and the Dataset", "<span class=\"section-number\">14.7. </span>Single Shot Multibox Detection", "<span class=\"section-number\">14.10. </span>Transposed Convolution", "<span class=\"section-number\">8.1. </span>Deep Convolutional Neural Networks (AlexNet)", "<span class=\"section-number\">8.5. </span>Batch Normalization", "<span class=\"section-number\">8.8. </span>Designing Convolution Network Architectures", "<span class=\"section-number\">8.7. </span>Densely Connected Networks (DenseNet)", "<span class=\"section-number\">8.4. </span>Multi-Branch Networks (GoogLeNet)", "<span class=\"section-number\">8. </span>Modern Convolutional Neural Networks", "<span class=\"section-number\">8.3. </span>Network in Network (NiN)", "<span class=\"section-number\">8.6. </span>Residual Networks (ResNet) and ResNeXt", "<span class=\"section-number\">8.2. </span>Networks Using Blocks (VGG)", "<span class=\"section-number\">7.4. </span>Multiple Input and Multiple Output Channels", "<span class=\"section-number\">7.2. </span>Convolutions for Images", "<span class=\"section-number\">7. </span>Convolutional Neural Networks", "<span class=\"section-number\">7.6. </span>Convolutional Neural Networks (LeNet)", "<span class=\"section-number\">7.3. </span>Padding and Stride", "<span class=\"section-number\">7.5. </span>Pooling", "<span class=\"section-number\">7.1. </span>From Fully Connected Layers to Convolutions", "<span class=\"section-number\">18.3. </span>Gaussian Process Inference", "<span class=\"section-number\">18.1. </span>Introduction to Gaussian Processes", "<span class=\"section-number\">18.2. </span>Gaussian Process Priors", "<span class=\"section-number\">18. </span>Gaussian Processes", "<span class=\"section-number\">20.2. </span>Deep Convolutional Generative Adversarial Networks", "<span class=\"section-number\">20.1. </span>Generative Adversarial Networks", "<span class=\"section-number\">20. </span>Generative Adversarial Networks", "<span class=\"section-number\">19.2. </span>Hyperparameter Optimization API", "<span class=\"section-number\">19.1. </span>What Is Hyperparameter Optimization?", "<span class=\"section-number\">19. </span>Hyperparameter Optimization", "<span class=\"section-number\">19.3. </span>Asynchronous Random Search", "<span class=\"section-number\">19.5. </span>Asynchronous Successive Halving", "<span class=\"section-number\">19.4. </span>Multi-Fidelity Hyperparameter Optimization", "Installation", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">4.3. </span>The Base Classification Model", "<span class=\"section-number\">4.7. </span>Environment and Distribution Shift", "<span class=\"section-number\">4.6. </span>Generalization in Classification", "<span class=\"section-number\">4.2. </span>The Image Classification Dataset", "<span class=\"section-number\">4. </span>Linear Neural Networks for Classification", "<span class=\"section-number\">4.1. </span>Softmax Regression", "<span class=\"section-number\">4.5. </span>Concise Implementation of Softmax Regression", "<span class=\"section-number\">4.4. </span>Softmax Regression Implementation from Scratch", "<span class=\"section-number\">3.6. </span>Generalization", "<span class=\"section-number\">3. </span>Linear Neural Networks for Regression", "<span class=\"section-number\">3.1. </span>Linear Regression", "<span class=\"section-number\">3.5. </span>Concise Implementation of Linear Regression", "<span class=\"section-number\">3.4. </span>Linear Regression Implementation from Scratch", "<span class=\"section-number\">3.2. </span>Object-Oriented Design for Implementation", "<span class=\"section-number\">3.3. </span>Synthetic Regression Data", "<span class=\"section-number\">3.7. </span>Weight Decay", "<span class=\"section-number\">5.3. </span>Forward Propagation, Backward Propagation, and Computational Graphs", "<span class=\"section-number\">5.6. </span>Dropout", "<span class=\"section-number\">5.5. </span>Generalization in Deep Learning", "<span class=\"section-number\">5. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.7. </span>Predicting House Prices on Kaggle", "<span class=\"section-number\">5.1. </span>Multilayer Perceptrons", "<span class=\"section-number\">5.2. </span>Implementation of Multilayer Perceptrons", "<span class=\"section-number\">5.4. </span>Numerical Stability and Initialization", "<span class=\"section-number\">16.6. </span>Fine-Tuning BERT for Sequence-Level and Token-Level Applications", "<span class=\"section-number\">16. </span>Natural Language Processing: Applications", "<span class=\"section-number\">16.4. </span>Natural Language Inference and the Dataset", "<span class=\"section-number\">16.5. </span>Natural Language Inference: Using Attention", "<span class=\"section-number\">16.7. </span>Natural Language Inference: Fine-Tuning BERT", "<span class=\"section-number\">16.1. </span>Sentiment Analysis and the Dataset", "<span class=\"section-number\">16.3. </span>Sentiment Analysis: Using Convolutional Neural Networks", "<span class=\"section-number\">16.2. </span>Sentiment Analysis: Using Recurrent Neural Networks", "<span class=\"section-number\">15.2. </span>Approximate Training", "<span class=\"section-number\">15.8. </span>Bidirectional Encoder Representations from Transformers (BERT)", "<span class=\"section-number\">15.9. </span>The Dataset for Pretraining BERT", "<span class=\"section-number\">15.10. </span>Pretraining BERT", "<span class=\"section-number\">15.5. </span>Word Embedding with Global Vectors (GloVe)", "<span class=\"section-number\">15. </span>Natural Language Processing: Pretraining", "<span class=\"section-number\">15.7. </span>Word Similarity and Analogy", "<span class=\"section-number\">15.6. </span>Subword Embedding", "<span class=\"section-number\">15.3. </span>The Dataset for Pretraining Word Embeddings", "<span class=\"section-number\">15.1. </span>Word Embedding (word2vec)", "<span class=\"section-number\">15.4. </span>Pretraining word2vec", "Notation", "<span class=\"section-number\">12.9. </span>Adadelta", "<span class=\"section-number\">12.7. </span>Adagrad", "<span class=\"section-number\">12.10. </span>Adam", "<span class=\"section-number\">12.2. </span>Convexity", "<span class=\"section-number\">12.3. </span>Gradient Descent", "<span class=\"section-number\">12. </span>Optimization Algorithms", "<span class=\"section-number\">12.11. </span>Learning Rate Scheduling", "<span class=\"section-number\">12.5. </span>Minibatch Stochastic Gradient Descent", "<span class=\"section-number\">12.6. </span>Momentum", "<span class=\"section-number\">12.1. </span>Optimization and Deep Learning", "<span class=\"section-number\">12.8. </span>RMSProp", "<span class=\"section-number\">12.4. </span>Stochastic Gradient Descent", "Preface", "<span class=\"section-number\">2.5. </span>Automatic Differentiation", "<span class=\"section-number\">2.4. </span>Calculus", "<span class=\"section-number\">2. </span>Preliminaries", "<span class=\"section-number\">2.3. </span>Linear Algebra", "<span class=\"section-number\">2.7. </span>Documentation", "<span class=\"section-number\">2.1. </span>Data Manipulation", "<span class=\"section-number\">2.2. </span>Data Preprocessing", "<span class=\"section-number\">2.6. </span>Probability and Statistics", "<span class=\"section-number\">21.4. </span>AutoRec: Rating Prediction with Autoencoders", "<span class=\"section-number\">21.8. </span>Feature-Rich Recommender Systems", "<span class=\"section-number\">21.10. </span>Deep Factorization Machines", "<span class=\"section-number\">21.9. </span>Factorization Machines", "<span class=\"section-number\">21. </span>Recommender Systems", "<span class=\"section-number\">21.3. </span>Matrix Factorization", "<span class=\"section-number\">21.2. </span>The MovieLens Dataset", "<span class=\"section-number\">21.6. </span>Neural Collaborative Filtering for Personalized Ranking", "<span class=\"section-number\">21.5. </span>Personalized Ranking for Recommender Systems", "<span class=\"section-number\">21.1. </span>Overview of Recommender Systems", "<span class=\"section-number\">21.7. </span>Sequence-Aware Recommender Systems", "<span class=\"section-number\">10.8. </span>Beam Search", "<span class=\"section-number\">10.4. </span>Bidirectional Recurrent Neural Networks", "<span class=\"section-number\">10.3. </span>Deep Recurrent Neural Networks", "<span class=\"section-number\">10.6. </span>The Encoder\u2013Decoder Architecture", "<span class=\"section-number\">10.2. </span>Gated Recurrent Units (GRU)", "<span class=\"section-number\">10. </span>Modern Recurrent Neural Networks", "<span class=\"section-number\">10.1. </span>Long Short-Term Memory (LSTM)", "<span class=\"section-number\">10.5. </span>Machine Translation and the Dataset", "<span class=\"section-number\">10.7. </span>Sequence-to-Sequence Learning for Machine Translation", "<span class=\"section-number\">9.7. </span>Backpropagation Through Time", "<span class=\"section-number\">9. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.3. </span>Language Models", "<span class=\"section-number\">9.4. </span>Recurrent Neural Networks", "<span class=\"section-number\">9.6. </span>Concise Implementation of Recurrent Neural Networks", "<span class=\"section-number\">9.5. </span>Recurrent Neural Network Implementation from Scratch", "<span class=\"section-number\">9.1. </span>Working with Sequences", "<span class=\"section-number\">9.2. </span>Converting Raw Text into Sequence Data", "References", "<span class=\"section-number\">17. </span>Reinforcement Learning", "<span class=\"section-number\">17.1. </span>Markov Decision Process (MDP)", "<span class=\"section-number\">17.3. </span>Q-Learning", "<span class=\"section-number\">17.2. </span>Value Iteration", "Dive into Deep Learning"], "terms": {"now": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 44, 46, 47, 49, 51, 53, 54, 55, 56, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 83, 85, 88, 89, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 108, 109, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 163, 165, 168, 169, 170, 171, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 189, 190], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "have": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 126, 129, 132, 133, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "learn": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 121, 126, 130, 132, 134, 137, 139, 140, 142, 144, 145, 147, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 174, 175, 179, 181, 182, 183, 185, 186, 188, 190], "how": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 129, 130, 131, 132, 133, 134, 135, 137, 138, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 162, 163, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "work": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 22, 24, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 55, 58, 61, 62, 63, 64, 66, 67, 69, 71, 72, 73, 74, 76, 79, 81, 82, 85, 86, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 123, 132, 135, 137, 138, 139, 140, 141, 143, 145, 148, 149, 150, 151, 153, 155, 156, 157, 170, 171, 173, 176, 178, 179, 180, 182, 183, 185, 186, 189, 191], "probabl": [0, 1, 3, 4, 6, 8, 11, 19, 20, 27, 33, 47, 51, 56, 58, 60, 63, 64, 74, 79, 83, 85, 86, 91, 92, 93, 94, 95, 98, 99, 100, 110, 113, 114, 116, 117, 120, 125, 130, 133, 134, 143, 146, 148, 149, 152, 153, 155, 164, 166, 167, 168, 169, 177, 178, 180, 181, 184, 186, 188, 189, 190, 191], "both": [0, 1, 4, 7, 8, 9, 11, 22, 23, 25, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 85, 86, 88, 92, 93, 94, 95, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 132, 134, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 157, 160, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 185, 189, 190], "set": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 14, 18, 20, 21, 22, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56, 57, 59, 62, 64, 65, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 133, 134, 135, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 171, 173, 174, 175, 180, 181, 183, 184, 185, 186, 188, 189, 190], "let": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 88, 90, 93, 94, 95, 96, 98, 100, 103, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 119, 122, 123, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 163, 164, 166, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 188, 189, 190], "": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 163, 164, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "get": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 19, 20, 21, 31, 32, 34, 36, 37, 38, 39, 41, 42, 45, 47, 51, 53, 54, 56, 58, 61, 63, 64, 65, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 83, 85, 88, 89, 90, 91, 92, 94, 95, 98, 99, 100, 101, 102, 103, 104, 107, 109, 111, 113, 114, 115, 116, 117, 119, 120, 121, 124, 126, 127, 129, 131, 132, 137, 138, 140, 141, 145, 146, 148, 149, 150, 152, 153, 154, 156, 157, 159, 162, 163, 168, 169, 171, 178, 179, 180, 183, 184, 185, 188, 190], "know": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 28, 31, 33, 34, 35, 36, 38, 41, 42, 47, 48, 49, 60, 63, 69, 72, 75, 77, 79, 80, 92, 94, 95, 96, 98, 99, 100, 101, 104, 105, 108, 109, 113, 114, 115, 116, 119, 133, 140, 141, 150, 153, 154, 155, 156, 157, 180, 181, 184, 187, 188, 189, 190], "some": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 19, 21, 22, 23, 24, 25, 27, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 49, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118, 126, 127, 129, 130, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 162, 163, 164, 165, 168, 169, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190], "common": [0, 3, 4, 6, 7, 9, 11, 14, 21, 22, 25, 27, 34, 35, 46, 47, 50, 52, 56, 63, 64, 68, 69, 70, 78, 92, 93, 94, 98, 100, 101, 103, 104, 106, 108, 110, 111, 113, 114, 116, 117, 121, 126, 130, 132, 138, 139, 140, 141, 142, 143, 145, 148, 149, 150, 151, 153, 155, 156, 157, 162, 165, 167, 170, 171, 177, 180, 181, 182, 183, 184, 185], "encount": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 23, 42, 44, 45, 46, 49, 50, 66, 69, 71, 74, 77, 81, 92, 94, 95, 98, 101, 103, 105, 107, 116, 128, 139, 140, 144, 145, 146, 147, 148, 149, 157, 171, 174, 175, 179, 184, 185], "depend": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 21, 22, 25, 26, 28, 29, 38, 39, 40, 41, 42, 44, 46, 51, 58, 63, 64, 65, 76, 77, 78, 79, 85, 86, 87, 88, 90, 92, 94, 95, 98, 101, 103, 105, 108, 109, 110, 111, 113, 114, 125, 126, 132, 138, 139, 141, 144, 148, 149, 150, 151, 153, 156, 157, 170, 171, 173, 175, 177, 178, 180, 181, 183, 184, 185, 186, 188, 189, 190], "area": [0, 2, 5, 7, 9, 22, 29, 41, 47, 49, 50, 51, 53, 54, 59, 62, 64, 69, 72, 75, 76, 88, 92, 94, 98, 103, 116, 138, 149, 151, 162, 165, 179], "machin": [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 17, 18, 20, 23, 24, 25, 27, 29, 30, 32, 38, 40, 41, 42, 43, 44, 58, 62, 63, 74, 77, 78, 79, 80, 81, 83, 86, 87, 88, 91, 95, 96, 97, 98, 101, 103, 105, 106, 107, 108, 111, 113, 117, 118, 119, 120, 121, 122, 130, 139, 140, 147, 149, 150, 153, 155, 156, 157, 162, 169, 171, 172, 173, 174, 175, 178, 179, 181, 182, 183, 184, 185, 186, 187, 191], "mai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 38, 39, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 67, 69, 71, 72, 74, 75, 77, 78, 79, 80, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 116, 117, 120, 123, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 138, 139, 140, 141, 143, 146, 149, 150, 153, 155, 156, 157, 158, 159, 164, 166, 167, 169, 172, 176, 177, 180, 181, 184, 187, 188], "need": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 119, 120, 123, 124, 127, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 163, 167, 168, 169, 170, 173, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190], "familiar": [0, 5, 7, 9, 10, 11, 14, 31, 37, 44, 56, 57, 80, 99, 106, 111, 153, 178, 184], "vastli": [0, 1, 6, 10, 76], "more": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 88, 89, 90, 91, 92, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 118, 119, 120, 124, 125, 126, 127, 129, 130, 132, 133, 134, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 158, 160, 162, 164, 165, 166, 167, 168, 169, 170, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189], "deep": [0, 1, 2, 4, 5, 7, 8, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 58, 60, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 84, 86, 88, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 126, 130, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 156, 162, 167, 170, 174, 179, 180, 182, 183, 184, 185, 186, 187, 189], "potenti": [0, 2, 7, 9, 25, 41, 42, 44, 47, 64, 68, 78, 83, 85, 92, 94, 99, 103, 105, 111, 114, 122, 145, 149, 160, 178, 181, 190], "none": [0, 4, 20, 21, 22, 23, 26, 27, 29, 30, 33, 34, 36, 37, 40, 44, 47, 49, 50, 51, 53, 54, 60, 69, 85, 86, 90, 96, 99, 105, 106, 107, 108, 113, 119, 120, 121, 123, 124, 126, 127, 128, 135, 141, 143, 144, 150, 151, 159, 163, 165, 166, 168, 170, 171, 173, 175, 176, 182, 183, 184, 185], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 121, 123, 124, 125, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 163, 164, 165, 166, 167, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 188, 189, 190], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], "howev": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 22, 24, 25, 28, 29, 30, 33, 35, 36, 37, 38, 39, 42, 44, 46, 48, 50, 53, 55, 56, 57, 59, 60, 62, 63, 65, 69, 71, 72, 74, 75, 76, 77, 78, 80, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 101, 103, 105, 106, 108, 109, 110, 111, 113, 114, 115, 117, 118, 119, 121, 125, 126, 129, 130, 132, 133, 138, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 155, 156, 157, 161, 164, 166, 169, 170, 171, 174, 175, 177, 178, 179, 180, 181, 183, 184, 185, 189], "good": [0, 1, 2, 7, 12, 14, 18, 19, 21, 27, 29, 36, 41, 42, 44, 62, 64, 69, 70, 74, 77, 78, 80, 83, 87, 88, 92, 94, 95, 96, 99, 100, 101, 103, 104, 105, 107, 110, 113, 114, 120, 129, 134, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 157, 164, 171, 176, 180, 183, 184, 189, 190], "basic": [0, 2, 3, 7, 9, 10, 24, 31, 32, 35, 41, 44, 45, 48, 49, 52, 66, 67, 69, 70, 73, 74, 78, 82, 85, 87, 90, 95, 97, 102, 104, 108, 109, 113, 114, 115, 118, 130, 134, 141, 142, 143, 148, 149, 150, 152, 155, 159, 173, 179, 180, 184, 185], "list": [0, 1, 2, 5, 9, 12, 20, 23, 30, 34, 35, 36, 37, 38, 40, 44, 45, 47, 49, 51, 53, 54, 55, 57, 60, 63, 70, 78, 90, 92, 93, 94, 96, 100, 105, 106, 107, 117, 119, 120, 127, 129, 131, 132, 133, 144, 149, 151, 154, 155, 157, 162, 163, 164, 165, 166, 168, 175, 176, 182, 183, 184, 185], "first": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 135, 138, 139, 140, 141, 143, 144, 146, 148, 149, 150, 151, 153, 155, 156, 157, 159, 161, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 190], "import": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 132, 133, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "librari": [0, 16, 19, 22, 31, 32, 41, 42, 46, 78, 85, 91, 92, 103, 104, 106, 107, 110, 139, 144, 149, 150, 151, 152, 153, 154, 155, 156, 166, 168, 182, 183, 186], "pytorchmxnettensorflow": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 15, 18, 20, 23, 36, 42, 48, 66, 82, 83, 103, 104, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 182], "matplotlib": [0, 1, 2, 5, 6, 7, 8, 9, 10, 44, 47, 48, 49, 50, 51, 55, 56, 57, 59, 60, 78, 83, 89, 96, 103, 105, 107, 108, 113, 114, 116, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 156, 157, 183, 184, 189, 190], "inlin": [0, 1, 2, 5, 6, 7, 8, 9, 10, 44, 47, 48, 49, 50, 51, 55, 56, 57, 59, 60, 83, 96, 103, 105, 107, 108, 113, 114, 116, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 151, 157, 183, 184, 189, 190], "from": [0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 109, 112, 113, 116, 117, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 172, 174, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191], "math": [0, 4, 5, 6, 7, 8, 11, 20, 22, 26, 28, 29, 35, 53, 62, 63, 78, 98, 100, 103, 113, 115, 133, 135, 137, 138, 139, 143, 144, 147, 148, 177, 183, 186], "erf": [0, 80], "factori": [0, 35, 42], "torch": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 189, 190], "ipython": [0, 1, 2, 5, 7, 9, 10, 20, 149], "displai": [0, 1, 2, 5, 7, 9, 10, 14, 15, 17, 19, 20, 27, 55, 60, 70, 74, 91, 92, 106, 113, 149, 151, 154, 159], "d2l": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 80, 82, 83, 85, 86, 88, 89, 90, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 157, 158, 159, 160, 161, 163, 164, 165, 168, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 189, 190, 191], "pi": [0, 2, 4, 5, 7, 9, 10, 11, 20, 24, 78, 80, 103, 140, 141, 143, 146, 151, 189, 190], "aco": [0, 2, 9, 10, 11], "zero": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 37, 44, 47, 49, 55, 59, 60, 61, 63, 65, 69, 72, 74, 75, 76, 78, 79, 80, 82, 83, 86, 92, 94, 100, 101, 103, 105, 108, 110, 111, 113, 114, 115, 116, 123, 128, 129, 133, 137, 138, 139, 143, 144, 145, 146, 147, 148, 151, 153, 155, 157, 158, 159, 161, 164, 165, 166, 168, 173, 175, 177, 183, 184, 186, 188, 189, 190], "1": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "2": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 98, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 160, 162, 163, 164, 165, 166, 168, 169, 170, 171, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "defin": [0, 1, 2, 4, 6, 7, 9, 10, 11, 15, 20, 21, 24, 26, 27, 31, 33, 34, 35, 36, 38, 39, 40, 42, 44, 46, 47, 48, 51, 52, 55, 57, 59, 61, 63, 65, 66, 70, 72, 75, 76, 77, 79, 80, 81, 83, 85, 86, 88, 89, 90, 92, 93, 94, 97, 98, 100, 101, 102, 103, 106, 107, 109, 114, 115, 116, 120, 121, 124, 125, 126, 128, 130, 131, 132, 133, 140, 141, 143, 144, 146, 148, 150, 151, 153, 157, 158, 161, 163, 164, 165, 168, 171, 175, 176, 177, 179, 180, 181, 183, 185, 188, 190], "numpi": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 47, 53, 54, 59, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 76, 78, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 135, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 153, 154, 155, 156, 157, 170, 171, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 189, 190], "np": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 80, 82, 83, 86, 90, 93, 96, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 189, 190], "mxnet": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 83, 91, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185, 186], "tensorflow": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 14, 18, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 42, 48, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 83, 91, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "tf": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 42, 48, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 83, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "tensorflow_prob": [0, 157], "tfp": 0, "simplest": [0, 5, 6, 11, 24, 27, 44, 51, 78, 83, 90, 91, 92, 103, 106, 107, 108, 111, 112, 148], "random": [0, 3, 4, 5, 6, 7, 8, 11, 20, 21, 22, 25, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 50, 51, 53, 54, 57, 59, 61, 65, 69, 71, 72, 74, 75, 76, 78, 80, 81, 82, 83, 85, 87, 89, 90, 92, 94, 95, 98, 100, 101, 103, 105, 106, 107, 108, 110, 113, 115, 116, 126, 127, 133, 136, 140, 143, 144, 146, 148, 149, 150, 152, 153, 154, 155, 164, 165, 166, 168, 170, 171, 173, 175, 180, 181, 182, 183, 184, 185, 189, 190, 191], "variabl": [0, 3, 4, 7, 8, 11, 20, 22, 23, 27, 28, 29, 33, 35, 37, 38, 39, 40, 42, 45, 46, 47, 50, 53, 54, 55, 56, 60, 63, 64, 65, 70, 71, 72, 74, 76, 78, 79, 80, 82, 83, 86, 92, 95, 98, 100, 101, 103, 105, 106, 108, 109, 110, 111, 113, 114, 115, 116, 129, 132, 133, 135, 136, 137, 138, 139, 140, 141, 144, 145, 147, 148, 151, 152, 153, 155, 156, 159, 161, 169, 171, 172, 173, 175, 177, 178, 180, 181, 183, 184, 186, 187, 189, 191], "usual": [0, 1, 7, 11, 14, 17, 19, 29, 33, 42, 43, 47, 48, 50, 51, 56, 57, 58, 59, 63, 64, 77, 86, 89, 92, 94, 95, 99, 101, 103, 105, 119, 126, 134, 138, 140, 146, 148, 149, 153, 154, 157, 158, 159, 160, 161, 166, 169, 185], "encod": [0, 2, 4, 5, 8, 9, 10, 20, 21, 23, 24, 74, 75, 78, 80, 98, 100, 111, 113, 117, 121, 123, 124, 127, 128, 130, 134, 153, 157, 158, 169, 170, 174, 175, 176, 180, 186, 188, 191], "coin": [0, 4, 6, 9, 152, 167], "flip": [0, 1, 2, 4, 5, 6, 9, 53, 62, 72, 77, 92, 94, 146, 153, 157, 175], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 17, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 121, 122, 123, 124, 125, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190], "come": [0, 2, 4, 6, 10, 12, 22, 24, 27, 28, 29, 35, 41, 42, 46, 47, 53, 61, 62, 63, 64, 69, 71, 72, 77, 78, 83, 86, 92, 94, 96, 98, 99, 103, 105, 110, 111, 114, 117, 118, 125, 132, 134, 141, 144, 145, 148, 149, 150, 151, 157, 169, 170, 175, 180, 184, 188], "up": [0, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 16, 19, 20, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 38, 40, 41, 42, 44, 45, 46, 49, 51, 53, 55, 56, 58, 60, 62, 64, 65, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 83, 85, 86, 88, 90, 91, 92, 94, 95, 98, 100, 101, 103, 104, 105, 108, 110, 111, 113, 114, 116, 120, 122, 125, 126, 129, 132, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 153, 155, 156, 157, 160, 163, 164, 167, 169, 171, 173, 178, 179, 180, 181, 183, 184, 186, 188, 189, 190], "p": [0, 4, 6, 8, 9, 20, 21, 23, 27, 28, 29, 30, 44, 47, 60, 62, 63, 64, 72, 75, 76, 78, 80, 92, 93, 94, 95, 98, 101, 103, 108, 110, 125, 129, 132, 133, 134, 136, 137, 138, 139, 140, 144, 145, 146, 147, 148, 153, 157, 163, 165, 166, 168, 169, 177, 178, 180, 181, 183, 184, 186, 188, 189, 190], "0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 36, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 188, 189, 190], "If": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 22, 24, 27, 38, 39, 40, 41, 42, 46, 47, 49, 50, 53, 54, 55, 56, 61, 62, 63, 64, 69, 71, 72, 74, 75, 78, 79, 80, 82, 83, 88, 89, 90, 91, 92, 94, 95, 98, 99, 101, 103, 105, 106, 113, 114, 116, 129, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 153, 155, 157, 161, 165, 167, 169, 170, 175, 176, 177, 178, 179, 180, 181, 184, 185, 188, 189, 190], "x": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 86, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 119, 120, 122, 123, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 156, 157, 159, 160, 161, 164, 165, 168, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186], "write": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 19, 20, 25, 31, 32, 34, 35, 37, 38, 39, 41, 42, 44, 54, 62, 63, 78, 80, 91, 92, 99, 103, 107, 111, 116, 139, 140, 141, 147, 149, 150, 151, 153, 155, 156, 157, 182, 183, 184, 188, 189, 190], "sim": [0, 4, 11, 33, 51, 64, 78, 79, 80, 83, 86, 94, 95, 98, 101, 103, 108, 110, 125, 131, 135, 136, 140, 157, 180, 190], "textrm": [0, 1, 2, 4, 5, 7, 8, 9, 11, 21, 22, 27, 28, 29, 33, 38, 41, 46, 47, 60, 63, 64, 69, 71, 72, 75, 76, 78, 79, 80, 82, 83, 86, 90, 92, 93, 94, 95, 98, 99, 101, 103, 104, 108, 109, 110, 113, 116, 125, 128, 129, 131, 133, 134, 135, 136, 138, 139, 140, 141, 144, 145, 146, 148, 151, 153, 155, 157, 158, 159, 160, 161, 163, 165, 166, 168, 170, 171, 173, 175, 176, 177, 178, 180, 181, 183, 184, 185, 188, 189, 190], "The": [0, 2, 3, 4, 9, 10, 12, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 87, 88, 89, 90, 91, 94, 97, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 124, 125, 126, 128, 130, 131, 136, 140, 141, 142, 143, 144, 146, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 190, 191], "cumul": [0, 64, 114, 138, 153, 165, 166], "function": [0, 3, 5, 6, 7, 8, 10, 11, 16, 17, 19, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 55, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 87, 90, 91, 93, 94, 95, 96, 97, 99, 100, 101, 102, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 138, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 153, 155, 157, 158, 160, 161, 163, 164, 165, 168, 170, 171, 173, 174, 175, 178, 181, 182, 183, 184, 186, 187, 188, 189, 191], "f": [0, 1, 4, 5, 7, 9, 10, 11, 20, 21, 23, 26, 28, 29, 30, 31, 35, 37, 38, 42, 44, 45, 49, 51, 53, 54, 57, 59, 60, 61, 64, 65, 66, 69, 72, 77, 78, 79, 80, 82, 83, 85, 86, 90, 91, 94, 95, 96, 99, 101, 103, 104, 105, 108, 109, 113, 114, 119, 120, 122, 126, 127, 128, 129, 131, 132, 133, 135, 136, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 163, 164, 165, 168, 170, 173, 175, 176, 177, 178, 181, 182, 183, 184, 185, 186, 189, 190], "begin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 21, 23, 25, 26, 28, 29, 33, 34, 35, 38, 42, 45, 46, 48, 52, 53, 60, 61, 64, 66, 67, 69, 72, 77, 78, 79, 80, 82, 86, 90, 92, 94, 95, 98, 100, 101, 103, 104, 105, 108, 110, 114, 115, 116, 119, 120, 125, 126, 127, 130, 132, 133, 134, 137, 138, 139, 140, 141, 143, 145, 147, 148, 151, 153, 155, 157, 161, 164, 165, 166, 169, 170, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 189, 190], "case": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 19, 21, 22, 23, 27, 28, 29, 31, 33, 34, 38, 39, 40, 41, 42, 44, 46, 50, 51, 60, 62, 63, 64, 65, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 88, 89, 92, 93, 94, 95, 98, 99, 101, 103, 104, 105, 108, 110, 111, 112, 114, 116, 118, 119, 123, 127, 129, 132, 134, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 154, 155, 157, 164, 166, 169, 173, 175, 176, 177, 179, 180, 181, 183, 184, 188, 189, 190], "le": [0, 4, 9, 62, 64, 74, 104, 149, 186], "end": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 33, 41, 42, 44, 45, 52, 54, 55, 57, 58, 60, 61, 62, 64, 65, 68, 71, 76, 77, 78, 79, 82, 83, 87, 88, 92, 93, 94, 98, 101, 103, 104, 105, 108, 110, 111, 112, 114, 116, 117, 118, 125, 127, 132, 134, 137, 138, 139, 140, 141, 143, 145, 147, 148, 149, 151, 153, 154, 155, 157, 161, 165, 166, 169, 170, 171, 173, 175, 176, 177, 178, 180, 184, 186, 189, 190], "mass": [0, 4, 80, 92, 117, 184], "plot": [0, 1, 2, 5, 6, 7, 9, 10, 11, 20, 21, 28, 47, 60, 63, 69, 78, 79, 80, 82, 85, 88, 89, 93, 96, 100, 103, 104, 106, 108, 109, 110, 111, 114, 115, 116, 122, 128, 133, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 157, 164, 176, 177, 183, 184, 185], "below": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 19, 21, 26, 28, 29, 30, 33, 34, 35, 36, 40, 41, 42, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 69, 70, 71, 75, 76, 78, 79, 80, 85, 86, 88, 90, 92, 93, 94, 96, 98, 100, 103, 104, 105, 107, 108, 110, 112, 114, 115, 119, 120, 123, 124, 131, 135, 141, 143, 145, 146, 149, 150, 151, 153, 155, 156, 160, 161, 163, 165, 166, 168, 171, 175, 176, 177, 183, 185], "3": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 81, 82, 83, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 163, 164, 165, 167, 168, 169, 171, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 190], "set_figs": [0, 2, 5, 7, 9, 47, 48, 49, 51, 55, 56, 60, 78, 80, 82, 83, 88, 89, 90, 122, 140, 141, 144, 145, 146, 147, 151, 157, 176], "plt": [0, 2, 5, 7, 9, 11, 20, 21, 27, 47, 48, 49, 51, 55, 56, 60, 78, 80, 83, 88, 89, 90, 122, 140, 141, 144, 145, 146, 147, 149, 151, 157, 164, 176], "stem": [0, 9, 30, 64, 66, 68, 140, 174, 178], "use_line_collect": [0, 9], "true": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 27, 29, 33, 37, 40, 41, 42, 45, 47, 49, 50, 51, 53, 54, 56, 57, 59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 78, 79, 82, 83, 85, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 116, 119, 120, 121, 122, 124, 125, 126, 127, 128, 133, 135, 136, 140, 143, 144, 149, 150, 151, 153, 156, 157, 158, 160, 161, 163, 164, 165, 166, 167, 168, 170, 171, 172, 173, 175, 176, 177, 178, 182, 183, 184, 185], "xlabel": [0, 5, 7, 9, 20, 22, 23, 27, 28, 29, 51, 53, 54, 56, 60, 78, 80, 82, 83, 85, 88, 89, 90, 103, 106, 122, 128, 135, 141, 143, 144, 145, 146, 147, 151, 163, 164, 165, 176, 185], "ylabel": [0, 5, 7, 9, 20, 22, 23, 27, 28, 29, 56, 78, 80, 82, 83, 85, 88, 89, 90, 103, 106, 122, 128, 135, 141, 144, 146, 151, 164, 176, 185], "m": [0, 2, 4, 7, 9, 14, 20, 21, 22, 23, 27, 29, 30, 41, 46, 47, 57, 63, 78, 79, 80, 86, 92, 94, 109, 116, 120, 124, 125, 129, 132, 134, 138, 140, 144, 146, 151, 153, 157, 158, 163, 164, 165, 166, 168, 177, 178, 180, 181, 186], "show": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 41, 44, 45, 47, 51, 52, 53, 54, 55, 56, 58, 59, 62, 64, 67, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 89, 90, 92, 93, 94, 96, 98, 100, 103, 104, 106, 110, 111, 114, 119, 120, 121, 123, 126, 130, 131, 135, 137, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 158, 164, 167, 173, 176, 178, 180, 182, 183, 189, 190], "22": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 98, 144, 153, 186], "8": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 22, 23, 25, 28, 29, 30, 31, 33, 36, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 79, 82, 83, 85, 86, 89, 90, 92, 93, 96, 98, 103, 104, 110, 114, 116, 117, 118, 121, 122, 123, 125, 126, 127, 128, 129, 132, 134, 137, 139, 141, 144, 146, 147, 148, 149, 155, 157, 168, 169, 171, 176, 177, 186, 189, 190], "arang": [0, 1, 5, 6, 7, 9, 10, 11, 20, 21, 22, 28, 29, 37, 44, 47, 49, 58, 60, 61, 76, 82, 90, 103, 106, 110, 114, 116, 126, 140, 141, 143, 145, 146, 147, 150, 151, 153, 155, 184], "01": [0, 5, 7, 8, 9, 10, 11, 20, 33, 44, 45, 50, 54, 60, 62, 64, 65, 66, 69, 70, 78, 95, 100, 103, 104, 105, 107, 108, 113, 115, 124, 128, 139, 140, 141, 143, 144, 145, 146, 147, 157, 158, 160, 163, 165, 168, 170, 171, 173, 175, 183, 184], "def": [0, 2, 4, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 80, 82, 83, 85, 86, 88, 89, 90, 93, 94, 96, 98, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 182, 183, 184, 185, 189, 190], "return": [0, 2, 4, 5, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 51, 53, 54, 56, 57, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 115, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 132, 133, 135, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 182, 183, 184, 185, 187, 189, 190], "els": [0, 9, 20, 21, 22, 29, 38, 39, 45, 47, 49, 50, 51, 53, 54, 57, 59, 60, 63, 64, 69, 85, 88, 89, 93, 94, 95, 96, 99, 101, 105, 106, 107, 108, 110, 113, 119, 120, 121, 122, 124, 126, 127, 132, 141, 143, 150, 151, 155, 158, 163, 164, 165, 168, 170, 171, 173, 175, 176, 180, 183, 184, 189], "tensor": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 20, 22, 26, 27, 28, 29, 31, 32, 33, 36, 39, 41, 47, 48, 49, 53, 55, 56, 57, 58, 59, 60, 61, 66, 68, 71, 72, 75, 76, 77, 78, 82, 83, 93, 96, 99, 100, 104, 105, 107, 109, 110, 113, 115, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 136, 140, 141, 150, 151, 152, 154, 155, 157, 168, 176, 177, 180, 183, 186], "y": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 20, 21, 25, 26, 28, 29, 31, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 71, 72, 75, 76, 78, 79, 80, 82, 83, 86, 91, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 116, 119, 120, 122, 123, 132, 134, 136, 140, 143, 144, 146, 148, 150, 151, 153, 155, 156, 157, 159, 160, 161, 165, 166, 168, 169, 173, 175, 177, 180, 183, 184, 186, 189], "c": [0, 2, 4, 5, 9, 10, 11, 17, 20, 22, 23, 30, 35, 39, 41, 42, 44, 47, 53, 54, 55, 56, 58, 63, 64, 69, 70, 71, 74, 76, 77, 78, 80, 90, 92, 94, 95, 96, 103, 105, 106, 113, 114, 116, 123, 126, 129, 131, 132, 133, 134, 138, 141, 144, 145, 150, 151, 153, 155, 157, 159, 168, 169, 175, 177, 181, 184, 185, 186], "d": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 22, 27, 28, 29, 42, 44, 58, 60, 64, 70, 72, 77, 78, 80, 82, 83, 86, 92, 94, 95, 98, 101, 103, 108, 109, 111, 114, 120, 123, 125, 131, 132, 134, 138, 140, 141, 146, 150, 151, 153, 155, 157, 161, 166, 168, 169, 170, 171, 173, 175, 177, 178, 180, 181, 184, 186], "arrai": [0, 1, 2, 4, 6, 7, 8, 9, 20, 22, 26, 27, 28, 29, 31, 33, 35, 38, 41, 47, 48, 49, 55, 56, 57, 58, 59, 60, 61, 63, 66, 71, 72, 76, 78, 83, 92, 100, 103, 104, 105, 107, 113, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 133, 135, 140, 141, 142, 144, 153, 155, 156, 158, 159, 163, 164, 165, 168, 171, 175, 176, 180, 183, 189, 190], "rang": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 72, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 95, 98, 99, 100, 101, 103, 106, 107, 110, 113, 114, 116, 117, 118, 119, 122, 123, 126, 127, 132, 133, 135, 138, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 153, 155, 157, 159, 163, 164, 165, 167, 168, 171, 175, 177, 178, 180, 183, 184, 189, 190], "constant": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 26, 28, 29, 31, 33, 35, 38, 46, 47, 48, 49, 56, 59, 61, 63, 64, 71, 72, 76, 77, 79, 83, 88, 90, 92, 94, 95, 98, 100, 103, 104, 105, 107, 108, 113, 116, 129, 133, 138, 140, 141, 143, 144, 147, 148, 150, 151, 153, 155, 156, 165, 175, 176, 180, 183, 184, 185], "mu_x": [0, 9, 47], "sigma_x": [0, 9, 47, 136], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "sampl": [0, 2, 6, 9, 11, 25, 33, 47, 48, 51, 53, 54, 55, 59, 62, 63, 64, 71, 72, 73, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 100, 101, 103, 110, 116, 117, 120, 126, 129, 130, 134, 135, 142, 143, 144, 154, 155, 157, 159, 161, 162, 164, 166, 177, 180, 183, 184, 189, 190], "an": [0, 2, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190], "arbitrari": [0, 1, 2, 5, 7, 23, 25, 31, 35, 37, 46, 63, 66, 76, 78, 80, 83, 92, 94, 95, 101, 109, 111, 132, 149, 150, 153, 155, 156, 166, 184, 190], "shape": [0, 2, 4, 7, 8, 20, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 44, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 92, 93, 96, 99, 100, 104, 105, 107, 109, 110, 113, 114, 115, 119, 120, 122, 123, 124, 126, 127, 128, 133, 135, 138, 143, 144, 145, 150, 151, 153, 154, 155, 157, 163, 164, 165, 168, 170, 171, 172, 173, 175, 176, 177, 178, 181, 182, 183], "follow": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 85, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 148, 149, 150, 151, 152, 153, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "rand": [0, 21, 22, 31, 33, 34, 35, 36, 38, 40, 47, 49, 56, 61, 72, 75, 100, 110], "10": [0, 2, 4, 5, 7, 8, 9, 10, 11, 12, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 77, 78, 79, 80, 82, 85, 86, 88, 89, 90, 91, 92, 95, 96, 99, 100, 103, 104, 106, 108, 110, 113, 114, 115, 116, 117, 118, 121, 122, 123, 126, 127, 130, 132, 133, 134, 135, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 149, 151, 153, 157, 160, 163, 164, 165, 168, 169, 170, 171, 172, 173, 175, 176, 177, 179, 180, 185, 186, 190, 191], "cast": [0, 2, 8, 11, 20, 21, 22, 29, 33, 62, 63, 87, 93, 96, 98, 100, 101, 110, 149, 176, 177], "dtype": [0, 1, 2, 8, 11, 20, 22, 23, 28, 29, 33, 47, 49, 59, 60, 63, 76, 93, 96, 100, 110, 113, 114, 121, 127, 135, 144, 150, 153, 155, 156, 159, 163, 168, 183, 184], "float32": [0, 2, 8, 11, 20, 21, 22, 28, 29, 33, 47, 49, 53, 56, 57, 59, 60, 76, 83, 93, 110, 113, 114, 127, 144, 150, 153, 155, 157, 159, 177, 183, 184], "next": [0, 1, 2, 3, 4, 7, 10, 11, 12, 13, 17, 18, 20, 23, 26, 27, 28, 31, 34, 35, 37, 38, 41, 42, 44, 45, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 78, 79, 80, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 109, 110, 111, 113, 115, 120, 121, 122, 128, 133, 141, 144, 146, 147, 148, 149, 150, 157, 164, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "commonli": [0, 1, 3, 6, 9, 11, 22, 33, 41, 42, 48, 49, 52, 56, 60, 63, 66, 69, 70, 73, 75, 83, 92, 96, 98, 101, 108, 109, 114, 129, 140, 146, 149, 150, 153, 163, 178], "For": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 161, 163, 165, 167, 168, 169, 170, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190], "our": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 22, 24, 25, 26, 27, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 44, 45, 46, 47, 49, 51, 52, 54, 55, 57, 60, 62, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 125, 135, 138, 139, 140, 141, 144, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 162, 164, 169, 170, 171, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190], "discuss": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68, 70, 72, 73, 74, 76, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 152, 154, 155, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 189, 190], "here": [0, 1, 2, 4, 7, 8, 10, 11, 12, 19, 20, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 62, 63, 65, 69, 71, 72, 74, 75, 77, 78, 79, 80, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 119, 127, 129, 131, 133, 137, 138, 139, 140, 141, 143, 145, 146, 148, 150, 151, 153, 155, 156, 157, 158, 163, 165, 166, 169, 170, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 190], "assum": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 14, 21, 22, 35, 37, 38, 39, 41, 44, 46, 47, 48, 49, 50, 55, 56, 63, 64, 69, 71, 72, 75, 76, 77, 78, 79, 83, 86, 89, 90, 91, 92, 93, 94, 95, 98, 100, 101, 103, 105, 107, 108, 109, 113, 114, 116, 125, 134, 140, 141, 143, 146, 148, 149, 150, 157, 166, 173, 178, 179, 180, 181, 183, 184, 189, 190], "support": [0, 2, 3, 4, 14, 17, 19, 20, 25, 38, 41, 42, 44, 46, 51, 58, 62, 63, 64, 74, 77, 78, 79, 89, 91, 92, 93, 96, 104, 106, 107, 113, 122, 128, 149, 155, 161, 175, 186], "integ": [0, 2, 5, 8, 9, 19, 38, 41, 47, 49, 53, 85, 98, 113, 133, 134, 136, 156], "ldot": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 22, 26, 27, 28, 46, 47, 56, 64, 65, 83, 94, 98, 103, 110, 120, 125, 129, 134, 140, 141, 145, 147, 148, 151, 153, 157, 169, 171, 177, 178, 180, 181, 183, 184, 188, 189, 190], "n": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 20, 21, 22, 28, 30, 41, 44, 46, 47, 48, 49, 53, 54, 56, 58, 59, 63, 64, 75, 78, 79, 80, 82, 83, 86, 89, 90, 94, 95, 98, 100, 101, 103, 106, 107, 108, 109, 110, 113, 114, 116, 119, 120, 122, 123, 125, 132, 133, 134, 136, 140, 141, 144, 148, 151, 153, 155, 157, 159, 163, 164, 165, 167, 168, 170, 171, 173, 175, 176, 177, 178, 181, 183, 185, 186, 189], "ani": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 41, 42, 44, 45, 46, 47, 49, 55, 56, 57, 58, 59, 60, 62, 63, 64, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 125, 126, 127, 128, 129, 132, 133, 134, 135, 140, 141, 143, 144, 145, 146, 148, 149, 151, 153, 155, 156, 157, 158, 166, 169, 170, 171, 172, 173, 174, 177, 178, 179, 180, 181, 183, 184, 185, 188, 189, 190], "other": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 22, 23, 24, 25, 27, 28, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 169, 170, 171, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "valu": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 20, 21, 22, 23, 24, 26, 28, 29, 30, 33, 34, 35, 36, 39, 42, 43, 44, 45, 47, 50, 51, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 85, 86, 87, 89, 90, 92, 93, 94, 95, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 121, 123, 125, 129, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 166, 167, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 183, 184, 185, 186, 187, 188, 189, 191], "freeli": [0, 5, 6, 7, 92, 149], "chosen": [0, 2, 5, 7, 9, 22, 25, 36, 41, 64, 66, 88, 92, 95, 98, 101, 103, 140, 185, 189, 190], "mean": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 19, 20, 21, 22, 24, 27, 29, 31, 33, 38, 41, 42, 45, 46, 47, 49, 50, 54, 56, 59, 60, 62, 63, 65, 66, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 126, 128, 134, 135, 136, 138, 140, 141, 143, 144, 145, 148, 151, 153, 155, 156, 157, 158, 159, 163, 165, 166, 170, 175, 178, 180, 183, 185, 186, 189, 190], "word": [0, 1, 2, 4, 7, 8, 10, 20, 23, 24, 46, 58, 62, 63, 64, 69, 74, 77, 79, 83, 92, 94, 95, 98, 100, 109, 110, 116, 117, 118, 119, 120, 122, 125, 126, 127, 130, 132, 138, 140, 141, 144, 145, 149, 150, 153, 157, 170, 175, 176, 179, 181, 183, 184, 185, 186, 190, 191], "context": [0, 1, 2, 4, 10, 23, 24, 25, 31, 36, 37, 38, 45, 46, 63, 64, 76, 83, 90, 92, 93, 95, 102, 108, 111, 114, 125, 128, 129, 130, 134, 135, 138, 140, 142, 143, 145, 149, 153, 156, 157, 159, 167, 169, 170, 172, 177, 180, 184, 186], "everi": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 19, 22, 24, 28, 29, 31, 35, 38, 41, 42, 45, 47, 53, 54, 55, 60, 63, 69, 71, 76, 78, 79, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 98, 99, 103, 104, 105, 107, 110, 111, 114, 115, 116, 117, 120, 126, 132, 143, 145, 149, 150, 154, 155, 157, 170, 171, 172, 175, 176, 177, 179, 182, 184, 186, 189], "possibl": [0, 1, 4, 5, 7, 8, 9, 10, 11, 12, 14, 19, 25, 28, 29, 30, 39, 41, 42, 44, 46, 47, 50, 55, 57, 62, 63, 64, 68, 70, 72, 73, 74, 75, 77, 78, 79, 83, 86, 89, 92, 94, 95, 96, 98, 100, 101, 103, 105, 111, 114, 116, 118, 120, 127, 129, 132, 138, 139, 144, 148, 149, 154, 155, 157, 160, 167, 169, 177, 180, 181, 183, 184, 188, 190], "equal": [0, 2, 4, 5, 7, 9, 10, 11, 19, 24, 27, 28, 36, 41, 47, 62, 63, 64, 68, 75, 86, 92, 93, 94, 98, 100, 101, 103, 108, 110, 114, 122, 125, 126, 133, 135, 136, 138, 143, 144, 147, 150, 151, 153, 155, 157, 165, 180, 183, 184, 189, 190], "like": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 14, 19, 25, 30, 31, 34, 35, 38, 39, 41, 42, 44, 52, 55, 56, 60, 62, 63, 64, 68, 69, 70, 76, 77, 78, 79, 80, 82, 83, 85, 86, 92, 94, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 111, 113, 114, 116, 118, 123, 124, 127, 129, 138, 143, 145, 146, 148, 149, 153, 155, 156, 157, 165, 166, 167, 168, 169, 170, 172, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], "each": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 34, 35, 36, 39, 41, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 137, 138, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190], "p_i": [0, 4, 6, 9, 117], "frac": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 21, 22, 27, 28, 33, 47, 62, 63, 64, 65, 66, 72, 75, 78, 79, 80, 89, 90, 94, 95, 98, 99, 100, 101, 103, 104, 105, 108, 109, 110, 113, 114, 116, 120, 125, 129, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 150, 151, 153, 157, 159, 161, 163, 165, 169, 177, 178, 180, 183, 185, 189], "denot": [0, 5, 8, 10, 11, 21, 27, 28, 29, 31, 47, 49, 56, 60, 63, 64, 65, 69, 71, 72, 76, 77, 89, 92, 93, 94, 98, 103, 109, 113, 114, 120, 125, 129, 131, 132, 134, 136, 140, 141, 145, 148, 153, 155, 157, 158, 160, 161, 163, 165, 166, 168, 169, 177, 178, 180, 181, 190], "u": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 27, 31, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 51, 56, 57, 64, 65, 66, 69, 71, 72, 74, 77, 78, 79, 80, 81, 83, 85, 86, 88, 90, 92, 94, 95, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 113, 114, 115, 116, 119, 125, 129, 132, 134, 135, 138, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 153, 155, 157, 163, 164, 165, 166, 167, 168, 169, 171, 173, 177, 178, 180, 183, 184, 185, 186, 187, 188, 189, 190], "k": [0, 1, 2, 4, 7, 9, 20, 21, 22, 23, 26, 27, 28, 29, 44, 46, 47, 61, 64, 71, 72, 77, 78, 79, 80, 88, 89, 90, 92, 94, 95, 98, 101, 103, 105, 108, 111, 112, 120, 123, 125, 129, 131, 132, 133, 135, 138, 141, 146, 153, 155, 157, 160, 161, 163, 164, 165, 168, 169, 177, 178, 184, 186, 189, 190], "5": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 103, 104, 105, 106, 108, 109, 110, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 151, 153, 155, 156, 157, 158, 160, 161, 163, 164, 165, 168, 169, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 36, 37, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 86, 88, 89, 90, 91, 92, 94, 98, 99, 100, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 120, 121, 123, 124, 125, 126, 128, 129, 131, 132, 133, 134, 135, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 159, 164, 168, 169, 170, 173, 175, 177, 178, 179, 180, 181, 183, 184, 186, 189, 190], "6": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 38, 41, 44, 45, 46, 47, 51, 53, 58, 60, 61, 62, 63, 64, 65, 66, 69, 71, 72, 74, 75, 76, 77, 78, 82, 83, 85, 86, 88, 89, 92, 95, 100, 101, 106, 108, 110, 111, 113, 114, 115, 116, 117, 121, 123, 126, 127, 132, 135, 138, 139, 143, 144, 145, 146, 147, 149, 151, 153, 155, 157, 169, 172, 176, 177, 184, 186, 190], "floor": [0, 8, 53], "12": [0, 2, 5, 7, 9, 12, 21, 25, 41, 44, 56, 63, 66, 77, 82, 86, 88, 89, 91, 98, 121, 128, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 153, 155, 186], "randint": [0, 85, 88, 89, 90, 126, 133, 165, 168], "size": [0, 1, 2, 4, 9, 10, 11, 12, 19, 20, 22, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 90, 92, 93, 95, 96, 100, 103, 105, 107, 108, 109, 110, 111, 116, 119, 120, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 140, 141, 144, 145, 147, 148, 150, 151, 153, 155, 157, 161, 163, 164, 165, 166, 169, 175, 176, 177, 178, 180, 181, 182, 183, 185, 186, 189, 190], "int32": [0, 8, 20, 23, 29, 47, 49, 53, 59, 96, 121, 127, 135, 168, 176, 177, 183], "idea": [0, 4, 5, 7, 10, 11, 18, 23, 24, 29, 36, 39, 41, 42, 46, 49, 52, 62, 63, 64, 65, 67, 68, 69, 70, 76, 77, 80, 82, 83, 86, 89, 90, 92, 94, 95, 96, 98, 100, 101, 103, 104, 108, 110, 111, 113, 115, 116, 118, 125, 132, 133, 137, 138, 141, 149, 150, 151, 157, 163, 171, 173, 174, 175, 176, 178, 185, 186, 187, 189, 190], "behind": [0, 24, 31, 35, 46, 68, 81, 82, 92, 143, 144, 149, 150, 174, 189, 190], "increas": [0, 4, 6, 8, 10, 21, 24, 25, 26, 38, 39, 40, 41, 44, 46, 49, 50, 53, 54, 55, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 75, 79, 82, 90, 92, 98, 99, 101, 103, 104, 105, 108, 110, 111, 113, 114, 121, 124, 129, 138, 140, 141, 143, 144, 145, 148, 151, 157, 171, 177, 178, 180, 181, 184, 189, 190], "scale": [0, 1, 2, 4, 5, 9, 10, 11, 12, 19, 20, 21, 23, 24, 26, 28, 29, 30, 38, 41, 44, 46, 47, 49, 50, 51, 53, 54, 55, 57, 58, 62, 63, 64, 66, 67, 69, 70, 78, 79, 80, 81, 86, 88, 92, 95, 96, 98, 101, 105, 108, 113, 116, 117, 122, 124, 138, 139, 141, 144, 147, 150, 151, 153, 157, 167, 171, 180, 186, 191], "fit": [0, 6, 7, 20, 23, 25, 29, 30, 41, 47, 59, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 83, 85, 86, 88, 89, 92, 94, 95, 99, 100, 103, 104, 105, 106, 108, 110, 111, 113, 115, 127, 129, 143, 144, 149, 151, 158, 163, 171, 173, 175, 177, 179, 180, 182, 183, 184], "within": [0, 6, 9, 11, 19, 21, 22, 26, 28, 29, 35, 41, 44, 46, 63, 64, 68, 69, 72, 74, 75, 77, 78, 79, 92, 95, 98, 108, 109, 129, 132, 140, 144, 145, 148, 155, 157, 166, 183, 187, 188], "interv": [0, 3, 4, 5, 9, 51, 60, 62, 78, 79, 92, 95, 99, 114, 129, 140, 141, 151, 155, 157, 173, 175, 186], "b": [0, 2, 4, 5, 7, 8, 9, 10, 11, 17, 20, 22, 39, 42, 44, 47, 51, 63, 64, 69, 71, 72, 76, 77, 79, 80, 83, 85, 86, 91, 92, 93, 98, 100, 103, 104, 105, 106, 107, 108, 114, 120, 126, 131, 132, 136, 138, 140, 141, 144, 145, 150, 151, 153, 155, 157, 158, 160, 163, 165, 168, 169, 170, 171, 173, 175, 177, 181, 186], "approach": [0, 4, 5, 21, 24, 27, 28, 42, 44, 46, 54, 58, 63, 64, 70, 73, 74, 77, 78, 80, 81, 86, 87, 92, 94, 95, 98, 111, 113, 114, 116, 126, 132, 140, 141, 144, 146, 148, 149, 151, 166, 167, 171, 172, 173, 176, 177, 180, 184, 186], "just": [0, 1, 2, 3, 5, 7, 8, 9, 10, 12, 13, 21, 23, 25, 27, 30, 31, 32, 35, 36, 38, 39, 41, 42, 44, 46, 47, 51, 53, 55, 56, 57, 60, 61, 62, 63, 64, 66, 69, 70, 71, 72, 74, 76, 77, 80, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 120, 123, 125, 128, 138, 139, 140, 141, 143, 145, 146, 148, 149, 150, 151, 152, 153, 155, 157, 162, 168, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 189], "pick": [0, 4, 7, 8, 9, 10, 21, 22, 24, 27, 41, 45, 64, 75, 76, 77, 85, 95, 98, 100, 101, 103, 113, 116, 129, 139, 140, 141, 143, 144, 145, 148, 156, 169, 171, 180, 181, 183, 185, 189, 190], "densiti": [0, 4, 6, 11, 19, 21, 41, 78, 79, 92, 95, 101, 105, 136, 157, 184, 186], "type": [0, 2, 4, 5, 8, 11, 12, 18, 19, 20, 21, 33, 35, 36, 41, 42, 44, 45, 47, 50, 53, 59, 60, 61, 63, 64, 69, 72, 74, 78, 79, 80, 85, 86, 89, 92, 93, 97, 98, 99, 100, 106, 107, 113, 117, 118, 119, 123, 124, 126, 135, 136, 144, 145, 149, 153, 155, 156, 159, 164, 166, 167, 168, 169, 170, 172, 175, 176, 177, 183], "7": [0, 1, 2, 4, 6, 8, 9, 11, 12, 14, 17, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 38, 41, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 82, 85, 86, 91, 92, 94, 98, 100, 103, 106, 110, 111, 113, 121, 123, 125, 126, 129, 133, 135, 137, 138, 139, 140, 143, 146, 147, 149, 156, 157, 169, 176, 177, 178, 179, 180, 185, 186], "note": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 47, 49, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 121, 123, 124, 126, 127, 128, 129, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 148, 150, 151, 153, 155, 157, 159, 160, 161, 164, 165, 167, 169, 170, 172, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190], "default": [0, 2, 11, 12, 17, 24, 31, 33, 34, 35, 36, 38, 39, 40, 42, 47, 69, 74, 75, 76, 82, 85, 86, 87, 92, 93, 94, 98, 100, 104, 106, 108, 113, 114, 126, 137, 143, 148, 150, 153, 155, 158, 159, 160, 161, 164, 165, 171, 173, 179], "so": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 50, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 91, 92, 94, 95, 96, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 123, 124, 129, 132, 133, 137, 138, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 164, 167, 168, 169, 170, 176, 177, 178, 180, 181, 183, 184, 185, 188, 189], "want": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 20, 21, 22, 26, 27, 33, 35, 36, 37, 38, 39, 40, 41, 44, 46, 48, 49, 50, 57, 63, 65, 69, 72, 75, 76, 77, 78, 79, 80, 83, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 120, 129, 138, 140, 143, 144, 146, 147, 148, 149, 150, 153, 155, 157, 163, 170, 171, 173, 177, 178, 180, 181, 182, 183, 184, 185, 188], "differ": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 98, 99, 101, 103, 105, 106, 107, 108, 110, 111, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 153, 155, 157, 158, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 180, 181, 183, 184, 188, 189, 190], "make": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 20, 22, 24, 25, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 41, 42, 44, 46, 51, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 74, 75, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 111, 113, 114, 115, 122, 125, 127, 129, 130, 138, 140, 141, 143, 144, 146, 148, 149, 150, 155, 157, 158, 159, 161, 166, 167, 168, 177, 179, 180, 181, 182, 183, 184, 185, 187, 189, 190], "thing": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 17, 19, 21, 27, 34, 38, 39, 40, 41, 62, 71, 77, 78, 83, 92, 94, 95, 96, 98, 99, 101, 103, 105, 106, 107, 108, 111, 113, 114, 126, 129, 138, 141, 143, 144, 145, 151, 153, 155, 156, 157, 163, 171, 178, 180, 184, 185, 190], "littl": [0, 1, 2, 3, 4, 5, 9, 10, 14, 21, 24, 25, 39, 78, 95, 99, 101, 133, 140, 141, 144, 145, 157, 180, 184], "complex": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 23, 25, 27, 28, 30, 31, 32, 35, 36, 40, 41, 42, 44, 45, 46, 47, 56, 60, 62, 63, 65, 66, 69, 70, 71, 74, 77, 78, 86, 89, 90, 92, 94, 95, 103, 104, 106, 108, 111, 113, 114, 115, 120, 125, 126, 127, 132, 134, 142, 148, 149, 150, 158, 160, 161, 166, 171, 173, 174, 176, 179, 186, 190], "examin": [0, 1, 2, 3, 6, 9, 10, 36, 117, 149], "origin": [0, 2, 4, 7, 8, 9, 10, 11, 14, 17, 21, 23, 24, 25, 29, 30, 37, 41, 44, 47, 48, 49, 51, 53, 54, 56, 59, 60, 61, 62, 63, 64, 66, 69, 70, 74, 75, 77, 80, 86, 87, 92, 94, 95, 96, 101, 103, 106, 108, 110, 113, 114, 117, 119, 121, 123, 124, 125, 126, 127, 128, 133, 137, 140, 144, 145, 149, 150, 153, 157, 160, 177, 179, 180, 181, 183, 185], "perform": [0, 1, 6, 7, 8, 9, 10, 11, 12, 19, 21, 22, 24, 25, 26, 27, 29, 31, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 52, 53, 54, 56, 58, 60, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 82, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 99, 100, 101, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 119, 123, 132, 137, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 153, 155, 158, 160, 161, 163, 165, 167, 171, 173, 177, 180, 181, 182, 183, 184, 186, 190, 191], "sequenc": [0, 1, 4, 6, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 38, 39, 41, 42, 46, 65, 68, 70, 73, 77, 83, 86, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 142, 148, 157, 162, 164, 167, 169, 170, 171, 172, 173, 174, 175, 178, 179, 181, 183, 186, 187, 188, 191], "independ": [0, 1, 2, 4, 6, 7, 8, 9, 11, 22, 26, 29, 40, 41, 42, 44, 46, 58, 63, 64, 68, 69, 71, 77, 78, 79, 80, 86, 88, 92, 98, 101, 103, 107, 116, 117, 125, 130, 134, 136, 138, 144, 147, 148, 155, 157, 184, 186], "experi": [0, 1, 4, 5, 8, 9, 11, 12, 23, 25, 26, 29, 40, 41, 44, 46, 49, 50, 51, 53, 54, 55, 56, 59, 60, 62, 63, 64, 66, 72, 74, 76, 85, 88, 89, 92, 96, 100, 101, 104, 105, 106, 108, 110, 119, 126, 128, 133, 138, 141, 142, 143, 144, 147, 148, 151, 157, 158, 162, 164, 167, 173, 175, 177, 178, 183, 184, 185, 186, 187, 189], "ha": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 86, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 110, 111, 113, 114, 116, 117, 119, 121, 122, 123, 125, 126, 128, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 156, 157, 158, 159, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 188, 189, 190], "succeed": [0, 92], "ask": [0, 2, 4, 7, 9, 11, 25, 63, 76, 92, 94, 104, 108, 113, 114, 149, 153, 157, 180, 186], "mani": [0, 1, 2, 4, 5, 6, 7, 9, 11, 12, 19, 21, 23, 24, 25, 27, 34, 35, 38, 39, 40, 41, 42, 46, 47, 48, 50, 51, 52, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 88, 90, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 110, 111, 113, 114, 116, 120, 125, 129, 130, 132, 133, 138, 139, 140, 141, 143, 144, 146, 148, 149, 150, 151, 153, 157, 162, 163, 164, 165, 166, 167, 170, 171, 174, 175, 176, 179, 180, 181, 183, 184, 185, 186, 187, 189, 190], "success": [0, 8, 9, 24, 25, 31, 35, 41, 51, 63, 64, 66, 70, 72, 75, 82, 83, 87, 94, 101, 105, 111, 149, 150, 157, 160, 174, 175, 177, 189, 191], "expect": [0, 2, 4, 5, 6, 9, 10, 11, 21, 22, 27, 35, 38, 39, 40, 46, 69, 72, 74, 76, 78, 79, 92, 93, 94, 95, 98, 101, 103, 106, 107, 108, 109, 110, 113, 114, 115, 122, 129, 133, 136, 139, 140, 143, 144, 145, 146, 148, 149, 150, 152, 155, 159, 164, 175, 178, 183, 184, 186, 189, 190], "see": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 113, 114, 115, 116, 117, 121, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 138, 140, 141, 143, 144, 145, 146, 148, 150, 151, 153, 154, 155, 157, 158, 161, 164, 172, 175, 177, 178, 180, 181, 183, 184, 185, 188, 189, 190], "express": [0, 4, 5, 6, 7, 8, 9, 10, 26, 36, 40, 41, 46, 56, 58, 63, 69, 71, 72, 76, 77, 79, 80, 92, 93, 95, 98, 101, 103, 104, 108, 111, 114, 116, 129, 134, 140, 145, 151, 153, 155, 157, 158, 159, 165, 169, 171, 177, 178, 181, 189], "mathemat": [0, 1, 2, 4, 5, 6, 9, 10, 11, 25, 26, 28, 35, 45, 46, 63, 65, 67, 69, 77, 92, 95, 98, 99, 100, 103, 108, 109, 110, 111, 114, 116, 129, 140, 145, 146, 149, 151, 153, 155, 157, 169, 173, 175, 178, 181, 186, 188, 190, 191], "x_i": [0, 4, 6, 7, 8, 9, 11, 21, 31, 63, 78, 79, 80, 98, 103, 108, 129, 136, 140, 141, 145, 148, 151, 153, 157, 161], "where": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 33, 35, 36, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 98, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 123, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190], "us": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], "failur": [0, 41, 92, 94], "sinc": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 22, 23, 25, 28, 29, 30, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 80, 82, 83, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 114, 115, 116, 122, 124, 125, 128, 129, 132, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 161, 165, 167, 169, 172, 173, 175, 176, 177, 178, 180, 181, 184, 185, 190], "sai": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 22, 25, 33, 35, 37, 40, 41, 42, 47, 49, 55, 57, 58, 63, 64, 72, 76, 77, 79, 83, 90, 92, 94, 95, 98, 101, 108, 110, 111, 114, 117, 141, 144, 146, 150, 151, 153, 157, 169, 180, 181, 183, 184, 188], "Then": [0, 1, 4, 6, 8, 9, 11, 14, 17, 22, 23, 24, 26, 27, 30, 35, 38, 41, 47, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 65, 69, 78, 80, 89, 91, 92, 93, 94, 98, 101, 103, 105, 110, 111, 112, 113, 119, 120, 123, 124, 126, 127, 131, 132, 134, 135, 140, 143, 148, 149, 151, 163, 164, 165, 169, 173, 177, 178], "sum_": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 22, 23, 27, 31, 46, 56, 63, 64, 77, 80, 94, 95, 98, 101, 103, 105, 108, 113, 116, 120, 125, 129, 132, 134, 138, 139, 140, 144, 145, 148, 153, 157, 158, 161, 163, 165, 166, 169, 178, 180, 188, 189, 190], "In": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190], "To": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 77, 78, 79, 83, 85, 86, 89, 91, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 119, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 180, 181, 183, 184, 185, 189, 190], "notic": [0, 2, 4, 5, 6, 7, 9, 10, 30, 35, 38, 54, 71, 79, 92, 93, 104, 106, 109, 113, 115, 134, 145, 155, 156, 157, 161, 184, 185, 190], "exactli": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 27, 30, 64, 71, 76, 78, 86, 92, 93, 94, 101, 103, 105, 108, 111, 114, 115, 138, 148, 157, 161, 173, 188], "occur": [0, 2, 4, 6, 7, 8, 19, 35, 39, 40, 41, 46, 63, 64, 71, 75, 76, 92, 94, 98, 99, 129, 133, 138, 144, 145, 148, 157, 159, 169, 176, 177, 178, 180, 184, 185, 186], "binom": 0, "wai": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 24, 27, 30, 31, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 50, 51, 54, 55, 58, 60, 61, 62, 63, 64, 66, 69, 70, 75, 76, 77, 79, 83, 85, 86, 87, 89, 90, 92, 94, 95, 98, 99, 100, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 120, 123, 130, 131, 134, 135, 140, 141, 143, 144, 145, 146, 147, 148, 149, 153, 155, 156, 157, 160, 162, 164, 167, 176, 177, 178, 179, 180, 181, 183, 184, 186, 187, 188, 189], "thu": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 19, 21, 22, 24, 25, 26, 27, 29, 35, 36, 37, 39, 41, 42, 44, 47, 50, 56, 57, 60, 61, 62, 63, 66, 69, 71, 72, 74, 75, 77, 78, 85, 92, 94, 95, 98, 99, 100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 116, 117, 119, 120, 121, 126, 127, 129, 130, 132, 133, 138, 140, 141, 143, 144, 145, 146, 148, 150, 151, 153, 155, 157, 158, 170, 171, 172, 173, 175, 178, 179, 180, 181, 184, 189], "comput": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 44, 45, 46, 47, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 120, 121, 123, 125, 126, 128, 129, 130, 132, 133, 134, 135, 138, 139, 140, 141, 143, 144, 145, 148, 149, 151, 152, 153, 155, 156, 157, 160, 161, 166, 167, 169, 170, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 186, 190, 191], "coeffici": [0, 2, 4, 9, 31, 41, 44, 63, 77, 113, 136, 147, 151, 177], "comb": 0, "min": [0, 11, 38, 47, 83, 88, 89, 90, 94, 114, 133, 140, 141, 143, 146, 177, 183], "pmf": 0, "11": [0, 1, 2, 4, 6, 7, 9, 12, 21, 22, 23, 25, 26, 27, 28, 29, 30, 49, 62, 64, 66, 67, 68, 70, 82, 91, 92, 98, 108, 109, 111, 118, 123, 126, 135, 148, 149, 153, 176, 177, 178, 179, 180, 186], "cmf": 0, "cumsum": [0, 144, 153, 157, 159], "dim": [0, 8, 20, 22, 23, 26, 29, 47, 49, 50, 53, 54, 60, 63, 65, 66, 76, 82, 120, 123, 124, 135, 155, 157, 160], "int": [0, 5, 8, 9, 20, 22, 23, 26, 28, 29, 30, 31, 47, 53, 62, 63, 64, 65, 66, 69, 70, 72, 74, 77, 78, 86, 88, 89, 90, 94, 95, 96, 99, 100, 101, 105, 106, 108, 110, 115, 131, 132, 136, 140, 155, 157, 159, 160, 161, 163, 164, 165, 168, 170, 171, 173, 175, 177, 182, 183, 185], "tolist": [0, 1, 2, 5, 9, 20, 29, 144], "linear": [0, 1, 3, 4, 5, 6, 8, 9, 11, 20, 22, 26, 27, 28, 30, 31, 33, 35, 38, 41, 42, 44, 45, 50, 54, 56, 58, 62, 65, 71, 74, 78, 80, 81, 83, 86, 88, 92, 93, 94, 95, 96, 99, 100, 101, 106, 107, 110, 111, 113, 115, 116, 120, 123, 124, 126, 138, 140, 141, 143, 144, 145, 149, 150, 151, 152, 155, 157, 158, 160, 161, 165, 177, 178, 179, 182, 184, 186, 191], "over": [0, 2, 4, 5, 6, 7, 8, 9, 10, 19, 20, 21, 23, 27, 28, 31, 32, 36, 37, 38, 40, 41, 44, 45, 46, 52, 55, 56, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 88, 89, 90, 92, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 113, 114, 115, 116, 118, 119, 125, 127, 129, 132, 133, 135, 136, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 153, 157, 158, 160, 161, 163, 164, 166, 173, 175, 176, 177, 178, 179, 180, 183, 184, 185, 189, 190], "sum": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 24, 27, 28, 29, 30, 35, 38, 39, 40, 44, 45, 46, 51, 53, 54, 56, 60, 61, 64, 71, 72, 76, 77, 78, 79, 80, 82, 83, 92, 93, 94, 98, 100, 101, 103, 105, 108, 113, 114, 120, 123, 125, 126, 128, 129, 131, 132, 133, 135, 136, 140, 143, 144, 147, 148, 150, 151, 152, 155, 157, 158, 160, 161, 163, 165, 166, 168, 176, 177, 178, 183, 190], "fact": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 19, 21, 25, 27, 31, 39, 40, 41, 45, 46, 47, 50, 51, 54, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 76, 77, 78, 80, 92, 95, 98, 99, 101, 103, 105, 106, 107, 108, 111, 113, 114, 115, 116, 118, 119, 125, 126, 137, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 157, 169, 178, 180, 184], "varianc": [0, 1, 6, 21, 22, 29, 56, 63, 78, 79, 80, 95, 98, 103, 105, 110, 113, 116, 136, 138, 139, 143, 144, 145, 148, 157, 166, 178, 184], "sample_shap": 0, "thought": [0, 4, 6, 9, 25, 46, 55, 56, 63, 68, 69, 78, 83, 92, 103, 126, 149, 153, 179, 185, 186], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], "stand": [0, 11, 21, 92, 104, 143, 164, 184, 186], "bu": [0, 19, 40, 41, 46, 59, 115], "stop": [0, 2, 7, 10, 12, 16, 20, 23, 41, 42, 44, 45, 51, 53, 54, 60, 79, 82, 83, 86, 88, 89, 90, 94, 103, 112, 114, 128, 135, 141, 143, 144, 148, 155, 163, 165, 177, 185], "buse": [0, 19, 43, 44, 46, 62], "arriv": [0, 7, 8, 9, 22, 28, 46, 64, 65, 66, 69, 94, 103, 108, 138, 140, 141, 144, 148, 153, 156, 157, 175, 178, 184, 187, 189], "minut": [0, 18, 41, 74, 88, 89, 92, 94, 153, 169, 186], "start": [0, 1, 2, 4, 5, 7, 9, 10, 11, 12, 14, 20, 21, 22, 24, 29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 44, 45, 46, 47, 49, 51, 53, 54, 56, 60, 62, 63, 64, 67, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 88, 89, 90, 91, 92, 95, 98, 100, 103, 104, 106, 109, 111, 113, 117, 118, 128, 132, 141, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 157, 163, 164, 167, 175, 177, 178, 180, 183, 186, 188, 189, 190], "consid": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 19, 22, 25, 27, 28, 30, 39, 41, 42, 46, 47, 55, 58, 61, 62, 63, 64, 66, 69, 72, 75, 77, 78, 79, 80, 85, 86, 88, 90, 92, 95, 96, 98, 100, 101, 103, 108, 111, 115, 116, 117, 122, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 138, 140, 141, 143, 144, 145, 146, 148, 150, 153, 156, 157, 158, 164, 165, 166, 168, 169, 170, 177, 178, 180, 181, 184, 188, 189], "simpli": [0, 2, 11, 13, 14, 18, 21, 22, 23, 25, 27, 31, 35, 38, 39, 42, 44, 54, 56, 60, 62, 63, 66, 69, 70, 71, 72, 75, 77, 78, 79, 80, 83, 86, 91, 92, 94, 95, 98, 99, 101, 103, 105, 106, 108, 109, 110, 111, 113, 114, 115, 116, 123, 137, 138, 140, 143, 144, 148, 151, 153, 156, 157, 166, 169, 170, 171, 173, 178, 180, 181, 183, 184, 188], "one": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 31, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 123, 125, 126, 127, 129, 131, 132, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 151, 153, 155, 156, 157, 158, 159, 161, 163, 164, 165, 167, 168, 169, 171, 172, 173, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 190], "window": [0, 17, 20, 21, 58, 61, 62, 64, 66, 67, 68, 71, 72, 74, 75, 76, 77, 91, 92, 123, 125, 129, 133, 134, 154, 184, 186], "far": [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 19, 21, 25, 27, 32, 34, 37, 38, 41, 42, 44, 53, 61, 62, 66, 69, 71, 73, 74, 75, 77, 78, 79, 85, 86, 88, 92, 94, 95, 100, 101, 103, 104, 108, 109, 111, 112, 116, 137, 141, 143, 144, 145, 148, 149, 150, 151, 153, 156, 157, 169, 170, 178, 180, 181, 183, 184, 188], "urban": 0, "center": [0, 1, 9, 12, 19, 20, 24, 33, 41, 47, 48, 49, 54, 55, 58, 60, 62, 63, 75, 77, 92, 95, 113, 125, 129, 130, 132, 134, 135, 157, 164, 167], "might": [0, 2, 3, 5, 7, 8, 9, 11, 14, 19, 21, 23, 24, 27, 30, 33, 34, 35, 36, 37, 38, 41, 42, 45, 46, 54, 62, 63, 69, 70, 72, 74, 75, 76, 77, 78, 79, 82, 83, 86, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 161, 162, 163, 165, 166, 169, 173, 178, 179, 180, 183, 184, 185, 188], "pretti": [0, 8, 9, 41, 78, 92, 139, 157, 184], "approxim": [0, 1, 5, 7, 9, 11, 27, 39, 41, 46, 58, 63, 64, 70, 72, 78, 80, 86, 90, 92, 94, 95, 98, 99, 103, 111, 130, 133, 138, 140, 141, 144, 146, 158, 166, 178, 180, 181, 184, 186, 188, 189, 191], "never": [0, 2, 5, 8, 9, 10, 11, 27, 35, 41, 42, 62, 63, 92, 94, 95, 98, 99, 101, 103, 114, 116, 126, 140, 146, 157, 162, 178, 183, 184], "than": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 19, 22, 24, 25, 26, 28, 29, 30, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 50, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 119, 120, 121, 122, 126, 127, 128, 129, 133, 134, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 153, 154, 155, 156, 157, 158, 165, 166, 168, 169, 171, 173, 175, 176, 178, 180, 181, 183, 184, 185, 186], "busi": [0, 12, 35, 42, 46, 86, 88, 90, 92, 95, 98, 101, 157, 167], "even": [0, 2, 5, 6, 7, 8, 9, 10, 19, 21, 22, 23, 25, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 56, 58, 60, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 108, 109, 111, 113, 114, 115, 116, 127, 132, 133, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 155, 157, 159, 167, 175, 176, 180, 181, 183, 184, 185, 187, 188, 189], "two": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 22, 23, 25, 26, 28, 29, 31, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 89, 92, 94, 95, 98, 101, 103, 105, 106, 107, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 137, 138, 140, 141, 143, 144, 145, 146, 149, 153, 154, 155, 156, 157, 158, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 176, 177, 180, 181, 183, 184, 185, 190], "model": [0, 1, 2, 3, 4, 6, 9, 10, 11, 19, 20, 22, 24, 27, 28, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 55, 56, 57, 58, 59, 62, 63, 64, 67, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 94, 95, 96, 97, 102, 107, 109, 111, 112, 116, 117, 118, 119, 121, 122, 125, 128, 130, 131, 133, 137, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 153, 155, 156, 157, 159, 162, 166, 167, 169, 170, 171, 172, 174, 176, 177, 178, 179, 185, 186, 187, 188, 191], "split": [0, 5, 9, 20, 23, 30, 38, 41, 43, 45, 46, 50, 53, 54, 59, 60, 92, 100, 101, 105, 106, 107, 119, 120, 124, 127, 131, 132, 133, 159, 162, 165, 168, 176, 177, 185], "part": [0, 1, 2, 3, 4, 5, 20, 21, 23, 24, 26, 37, 40, 41, 42, 46, 53, 56, 58, 59, 62, 63, 69, 70, 74, 86, 92, 94, 98, 99, 100, 101, 105, 106, 108, 109, 111, 114, 117, 119, 121, 130, 139, 140, 141, 143, 147, 149, 150, 160, 170, 171, 173, 176, 184, 189, 190], "30": [0, 8, 12, 23, 24, 29, 41, 46, 58, 74, 75, 90, 92, 126, 141, 143, 157, 160, 161, 163, 177, 184, 185, 186], "second": [0, 2, 4, 6, 7, 9, 10, 11, 19, 21, 22, 28, 29, 30, 33, 34, 36, 38, 41, 42, 44, 46, 47, 56, 60, 62, 63, 64, 66, 68, 69, 70, 72, 74, 75, 76, 77, 83, 85, 86, 92, 93, 94, 98, 99, 100, 102, 103, 105, 106, 109, 110, 113, 115, 116, 117, 123, 126, 132, 137, 138, 139, 141, 144, 146, 150, 151, 153, 155, 157, 160, 165, 166, 169, 170, 174, 177, 178, 180, 184, 185, 186, 189, 190], "_1": [0, 2, 22, 27, 28, 46, 56, 64, 69, 83, 94, 98, 120, 138, 148, 153, 157, 160, 170, 177, 178, 184], "_2": [0, 2, 7, 22, 125, 138, 140, 151, 153, 157, 160, 178], "total": [0, 4, 5, 8, 9, 11, 22, 39, 40, 41, 44, 46, 47, 53, 60, 61, 62, 64, 66, 69, 75, 77, 88, 89, 90, 94, 103, 133, 144, 153, 155, 157, 166, 178, 180, 184, 188], "_i": [0, 1, 2, 4, 21, 22, 26, 27, 28, 46, 56, 94, 98, 100, 111, 113, 120, 129, 134, 136, 138, 140, 145, 148, 157, 160, 161, 163, 165, 168, 178, 179], "why": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 21, 25, 29, 35, 36, 38, 39, 41, 42, 44, 45, 46, 48, 51, 55, 61, 62, 63, 65, 66, 68, 69, 71, 72, 76, 77, 79, 80, 85, 86, 92, 93, 95, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 115, 116, 126, 127, 128, 129, 134, 137, 138, 139, 141, 143, 145, 146, 147, 148, 149, 150, 151, 153, 157, 169, 170, 171, 175, 176, 177, 181, 183, 184, 186, 189], "By": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 17, 25, 27, 33, 35, 38, 39, 41, 42, 43, 44, 46, 55, 56, 57, 59, 62, 63, 64, 69, 71, 72, 74, 75, 76, 77, 78, 80, 92, 93, 95, 96, 99, 100, 101, 104, 108, 109, 110, 119, 120, 121, 127, 140, 141, 145, 146, 149, 150, 153, 154, 155, 157, 162, 173, 178, 183], "same": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 119, 123, 124, 126, 128, 129, 130, 132, 134, 135, 136, 137, 138, 141, 143, 144, 145, 147, 150, 151, 153, 155, 157, 158, 160, 163, 167, 168, 170, 171, 172, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 188, 189, 190], "reason": [0, 1, 2, 4, 6, 7, 9, 10, 11, 23, 25, 35, 37, 41, 46, 62, 63, 64, 66, 69, 71, 77, 78, 79, 80, 81, 92, 93, 94, 95, 98, 99, 101, 102, 103, 108, 109, 113, 114, 116, 119, 129, 134, 137, 140, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 155, 157, 161, 169, 180, 183, 184, 186], "abov": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 17, 21, 25, 26, 27, 28, 29, 35, 39, 40, 41, 42, 47, 50, 51, 53, 54, 59, 60, 61, 62, 63, 64, 71, 72, 75, 77, 78, 79, 80, 83, 86, 88, 92, 94, 95, 96, 98, 100, 101, 106, 107, 109, 110, 112, 114, 116, 117, 122, 123, 129, 133, 134, 135, 138, 140, 141, 145, 146, 148, 157, 163, 164, 168, 173, 175, 176, 177, 178, 180, 181, 183, 184, 185, 188, 189, 190], "previou": [0, 1, 2, 4, 6, 7, 8, 9, 10, 23, 29, 34, 35, 37, 41, 42, 43, 44, 45, 50, 52, 53, 59, 60, 62, 64, 65, 69, 71, 72, 74, 75, 78, 85, 86, 88, 90, 92, 94, 101, 104, 107, 108, 110, 114, 116, 117, 135, 137, 144, 145, 148, 149, 153, 157, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 180, 181, 183, 184, 185, 188, 189, 190], "section": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 82, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 160, 161, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190], "mu_": [0, 9], "sigma_": [0, 9, 11, 63, 166], "take": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 25, 27, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 123, 124, 125, 126, 127, 128, 129, 133, 134, 136, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 156, 157, 165, 168, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 183, 184, 187, 188, 189, 190], "rightarrow": [0, 5, 7, 9, 10, 11, 12, 17, 63, 86, 140, 141, 151, 155, 157, 177, 189, 190], "infti": [0, 4, 5, 9, 10, 11, 63, 80, 92, 95, 98, 140, 145, 157, 188, 189, 190], "number": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 20, 22, 25, 26, 27, 28, 29, 30, 31, 33, 38, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 189, 190], "stabil": [0, 1, 6, 63, 66, 99, 112, 131, 135, 137, 139, 161, 178, 186, 191], "indic": [0, 2, 4, 5, 7, 9, 10, 11, 12, 20, 22, 34, 38, 41, 47, 55, 56, 57, 59, 64, 69, 71, 75, 76, 77, 78, 85, 92, 94, 95, 96, 100, 101, 107, 113, 114, 119, 121, 122, 125, 126, 127, 129, 131, 133, 135, 136, 137, 138, 141, 143, 144, 149, 151, 153, 155, 157, 159, 165, 166, 167, 168, 176, 178, 180, 183, 185, 188, 189, 190], "could": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 21, 24, 25, 28, 34, 35, 40, 41, 44, 45, 46, 60, 62, 63, 64, 69, 70, 71, 73, 76, 77, 78, 79, 83, 86, 88, 90, 92, 94, 95, 96, 98, 99, 101, 103, 105, 107, 108, 114, 115, 116, 134, 137, 138, 139, 141, 143, 144, 145, 146, 148, 149, 150, 153, 155, 156, 157, 161, 169, 171, 178, 180, 181, 183, 184, 185, 190], "infinit": [0, 2, 4, 5, 9, 10, 77, 79, 80, 81, 95, 98, 101, 111, 114, 141, 157, 188, 189], "subdivis": 0, "limit": [0, 10, 11, 20, 21, 22, 23, 25, 27, 38, 41, 44, 46, 49, 50, 58, 60, 62, 69, 70, 71, 77, 78, 80, 88, 89, 92, 95, 98, 99, 100, 103, 108, 111, 118, 121, 126, 140, 143, 145, 147, 148, 149, 151, 153, 156, 157, 158, 167, 180, 183, 186], "should": [0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 19, 21, 24, 27, 29, 31, 34, 35, 37, 38, 41, 45, 47, 48, 53, 63, 64, 66, 69, 71, 72, 74, 76, 77, 78, 79, 83, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 98, 100, 101, 103, 104, 105, 108, 110, 113, 114, 117, 120, 129, 137, 140, 141, 143, 148, 149, 150, 153, 154, 155, 156, 157, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 188, 189, 190], "too": [0, 2, 3, 7, 8, 10, 11, 12, 19, 21, 23, 27, 36, 41, 42, 44, 46, 47, 55, 62, 65, 78, 83, 86, 89, 92, 94, 95, 96, 101, 107, 108, 109, 110, 111, 114, 116, 129, 132, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 153, 157, 178], "much": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 18, 19, 21, 22, 23, 25, 38, 39, 41, 42, 46, 50, 57, 58, 60, 62, 63, 64, 66, 69, 70, 71, 74, 77, 78, 80, 81, 83, 86, 89, 92, 94, 95, 96, 98, 100, 101, 103, 104, 106, 108, 113, 114, 115, 119, 120, 121, 129, 130, 137, 138, 139, 140, 141, 144, 145, 148, 149, 150, 151, 152, 153, 156, 157, 173, 175, 176, 178, 179, 180, 183, 184, 185], "surpris": [0, 2, 4, 5, 18, 34, 42, 68, 72, 94, 95, 101, 110, 111, 114, 141, 149, 162, 180, 184], "real": [0, 1, 2, 5, 9, 10, 11, 35, 46, 49, 57, 58, 63, 77, 79, 80, 84, 92, 94, 95, 101, 103, 107, 111, 112, 113, 114, 134, 136, 137, 140, 141, 146, 147, 149, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 166, 169, 180, 184, 185, 186, 187, 188, 189], "world": [0, 3, 17, 22, 25, 35, 57, 58, 71, 79, 83, 92, 94, 101, 103, 111, 114, 130, 144, 149, 153, 156, 160, 162, 163, 164, 166, 183, 187], "count": [0, 2, 8, 11, 25, 41, 47, 71, 103, 119, 122, 127, 128, 129, 133, 138, 144, 157, 159, 164, 165, 176, 180, 184, 185], "nice": [0, 1, 2, 6, 7, 24, 63, 94, 98, 103, 107, 108, 140, 145, 157, 180, 186], "well": [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 22, 24, 25, 27, 29, 31, 34, 35, 39, 40, 41, 44, 46, 47, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 89, 90, 92, 94, 95, 96, 98, 101, 103, 104, 105, 110, 111, 113, 114, 115, 116, 119, 123, 126, 137, 140, 141, 142, 143, 145, 146, 148, 149, 150, 151, 157, 162, 163, 166, 168, 178, 180, 183, 184, 185, 186, 189, 190], "made": [0, 8, 9, 14, 24, 30, 41, 62, 63, 65, 69, 74, 77, 81, 92, 94, 95, 98, 99, 116, 149, 155, 156, 170, 173, 175, 183, 187], "formal": [0, 10, 11, 26, 77, 90, 92, 94, 101, 103, 110, 114, 126, 138, 140, 149, 150, 151, 152, 153, 161, 165, 166, 169, 170, 171, 178, 183], "law": [0, 1, 2, 25, 92, 105, 149, 157, 185, 186, 188], "rare": [0, 7, 11, 62, 74, 94, 99, 101, 129, 132, 133, 138, 141, 178, 180, 183, 185, 186], "event": [0, 4, 8, 11, 92, 98, 103, 125, 129, 136, 157, 179, 183, 184, 186, 187], "through": [0, 1, 2, 4, 7, 9, 10, 11, 14, 16, 17, 27, 31, 34, 35, 36, 40, 41, 42, 45, 46, 47, 55, 56, 58, 60, 62, 63, 64, 66, 69, 70, 71, 72, 73, 74, 76, 78, 79, 81, 82, 85, 86, 91, 92, 94, 95, 97, 98, 100, 103, 104, 105, 106, 108, 109, 110, 113, 114, 116, 123, 125, 130, 133, 134, 144, 148, 150, 155, 157, 159, 160, 162, 164, 167, 171, 177, 179, 180, 181, 183, 184, 186, 188, 191], "carefulli": [0, 2, 11, 19, 41, 94, 116], "lambda": [0, 1, 8, 20, 21, 34, 36, 38, 44, 47, 53, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 82, 90, 96, 98, 103, 105, 106, 108, 109, 113, 116, 127, 138, 140, 144, 145, 146, 148, 150, 158, 159, 163, 164, 165, 168, 173, 175, 176, 183, 185], "p_k": [0, 4, 26], "ke": 0, "known": [0, 1, 2, 4, 5, 6, 9, 10, 11, 25, 29, 34, 41, 47, 62, 63, 69, 76, 77, 78, 79, 81, 86, 92, 94, 98, 101, 103, 107, 108, 111, 119, 139, 145, 148, 150, 153, 157, 163, 175, 185, 189, 190], "rate": [0, 8, 9, 10, 11, 24, 41, 44, 45, 50, 53, 54, 62, 63, 64, 65, 69, 72, 74, 78, 79, 80, 82, 85, 86, 92, 94, 95, 96, 99, 100, 101, 103, 104, 105, 115, 116, 133, 137, 139, 142, 144, 145, 147, 151, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 171, 183, 186, 189, 191], "paramet": [0, 6, 7, 8, 9, 10, 11, 19, 20, 22, 24, 25, 26, 27, 30, 32, 34, 35, 38, 40, 41, 42, 43, 44, 45, 49, 50, 51, 53, 54, 56, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 92, 93, 94, 95, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 118, 120, 121, 123, 124, 126, 128, 129, 132, 134, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 155, 157, 163, 165, 166, 170, 171, 177, 178, 179, 180, 181, 183, 186, 189, 191], "averag": [0, 1, 2, 4, 6, 9, 11, 22, 25, 26, 27, 30, 49, 50, 63, 64, 65, 66, 68, 69, 73, 74, 79, 82, 85, 88, 92, 93, 94, 95, 99, 100, 101, 103, 104, 105, 106, 110, 113, 120, 134, 135, 137, 139, 143, 144, 146, 147, 148, 153, 157, 177, 180, 186, 190], "unit": [0, 2, 4, 9, 21, 22, 29, 30, 31, 33, 35, 37, 41, 42, 44, 55, 58, 60, 62, 63, 64, 69, 74, 76, 77, 80, 81, 86, 92, 94, 98, 103, 110, 113, 114, 115, 116, 124, 126, 128, 134, 140, 144, 153, 157, 160, 168, 170, 171, 174, 175, 177, 181, 182, 183, 185, 186, 191], "time": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 120, 122, 124, 125, 126, 127, 129, 132, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 159, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], "e": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 54, 56, 58, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 83, 85, 86, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 120, 122, 123, 126, 129, 132, 134, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 159, 160, 162, 163, 164, 165, 168, 169, 171, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190], "13": [0, 4, 6, 11, 39, 40, 41, 42, 44, 45, 46, 51, 53, 54, 91, 98, 114, 120, 148, 149, 157, 178, 186], "lam": [0, 145], "20": [0, 4, 9, 11, 20, 22, 34, 35, 36, 37, 41, 44, 53, 56, 58, 60, 61, 62, 78, 80, 82, 83, 85, 91, 92, 95, 104, 108, 126, 133, 135, 141, 143, 145, 160, 161, 163, 164, 171, 173, 175, 176, 182, 183], "exp": [0, 4, 5, 7, 9, 10, 11, 21, 22, 27, 47, 78, 79, 80, 94, 95, 98, 99, 100, 103, 105, 113, 114, 116, 120, 125, 129, 134, 135, 136, 140, 141, 148, 155, 177, 180, 183], "14": [0, 7, 9, 47, 49, 50, 53, 54, 55, 56, 58, 59, 60, 61, 79, 82, 98, 128, 149, 153, 156, 177, 178, 186], "21": [0, 4, 49, 82, 98, 153, 186], "As": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 21, 22, 25, 26, 27, 28, 29, 31, 34, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 159, 160, 162, 163, 164, 165, 167, 169, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 188, 189, 190], "saw": [0, 2, 4, 7, 9, 10, 41, 42, 47, 72, 77, 80, 98, 110, 114, 138, 139, 143, 145, 146, 157, 176, 180], "particularli": [0, 7, 27, 41, 42, 45, 46, 56, 75, 79, 98, 114, 138, 140, 143, 144, 148, 157, 161, 173, 180, 184, 185], "concis": [0, 2, 7, 9, 27, 43, 44, 47, 60, 64, 67, 69, 83, 93, 97, 98, 102, 105, 106, 112, 137, 139, 142, 174, 179, 191], "try": [0, 1, 4, 5, 7, 9, 10, 11, 14, 19, 20, 35, 38, 41, 44, 45, 48, 49, 56, 62, 64, 65, 66, 69, 70, 72, 74, 78, 86, 90, 92, 94, 98, 100, 101, 103, 104, 105, 107, 108, 113, 114, 115, 116, 127, 135, 138, 139, 144, 145, 147, 150, 153, 156, 158, 163, 165, 176, 178, 184, 189, 190], "relat": [0, 2, 3, 4, 7, 9, 11, 17, 21, 23, 28, 41, 42, 50, 52, 63, 64, 70, 72, 73, 78, 92, 94, 95, 101, 103, 105, 111, 112, 114, 115, 121, 129, 138, 153, 156, 157, 159, 173, 180, 184, 186, 190], "again": [0, 1, 2, 4, 5, 7, 9, 10, 12, 33, 42, 45, 54, 62, 64, 65, 69, 70, 78, 79, 90, 92, 94, 95, 98, 99, 103, 113, 114, 115, 140, 143, 148, 150, 157, 175, 189, 190], "measur": [0, 1, 2, 3, 4, 5, 6, 9, 11, 14, 26, 38, 39, 40, 41, 42, 47, 53, 54, 56, 74, 77, 78, 92, 93, 94, 95, 98, 101, 103, 105, 106, 108, 110, 111, 112, 114, 115, 117, 119, 129, 144, 153, 156, 157, 158, 159, 162, 165, 166, 177, 179, 180, 186], "rather": [0, 1, 4, 5, 7, 8, 9, 10, 11, 19, 21, 22, 23, 24, 27, 35, 36, 37, 38, 39, 41, 44, 46, 47, 50, 58, 59, 60, 62, 63, 65, 69, 70, 71, 72, 76, 77, 78, 82, 83, 92, 94, 95, 96, 98, 101, 102, 103, 104, 105, 107, 108, 110, 111, 113, 114, 115, 119, 120, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 153, 154, 156, 157, 158, 171, 173, 175, 178, 180, 181, 183, 184, 186], "decreas": [0, 4, 7, 9, 10, 28, 64, 69, 70, 79, 82, 90, 98, 99, 101, 108, 111, 114, 137, 138, 141, 143, 144, 145, 147, 148, 151, 152, 161], "fix": [0, 2, 7, 8, 9, 10, 11, 14, 23, 24, 27, 28, 29, 35, 41, 59, 63, 64, 71, 74, 76, 79, 80, 82, 86, 89, 90, 92, 94, 95, 99, 100, 101, 103, 105, 110, 114, 115, 116, 122, 123, 124, 132, 134, 138, 139, 141, 143, 147, 153, 168, 171, 172, 174, 175, 177, 179, 180, 184, 190], "send": [0, 2, 4, 10, 14, 31, 41, 44, 46, 144, 187], "think": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 14, 22, 25, 32, 35, 55, 59, 63, 65, 69, 70, 71, 76, 77, 79, 83, 92, 94, 96, 98, 100, 101, 103, 105, 110, 111, 114, 115, 123, 146, 149, 153, 156, 157, 167, 172, 178, 180, 183, 184, 187, 188, 190], "hope": [0, 1, 4, 9, 36, 59, 70, 74, 92, 94, 95, 111, 113, 138, 140, 149, 157, 173, 183, 185], "lost": [0, 23, 29, 46, 63, 77, 157, 177, 185], "behav": [0, 7, 10, 30, 31, 36, 63, 92, 98, 103, 106, 107, 111, 114, 116, 138, 141, 145, 146, 148, 153, 157, 177, 185, 187], "seen": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 19, 61, 64, 72, 78, 79, 82, 86, 88, 89, 90, 92, 94, 96, 101, 114, 118, 126, 129, 140, 141, 143, 144, 148, 159, 175, 178, 180, 184, 185, 187], "plausibl": [0, 7, 78, 92, 114, 116, 157, 170, 176, 180], "believ": [0, 7, 9, 11, 62, 63, 77, 78, 79, 94, 100, 101, 103, 149, 153, 157, 184], "converg": [0, 9, 21, 62, 63, 64, 78, 86, 95, 99, 103, 111, 116, 126, 137, 138, 139, 142, 143, 144, 145, 147, 151, 157, 160, 171, 183, 186, 189, 190], "what": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 51, 53, 54, 55, 57, 58, 59, 62, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 89, 91, 92, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 127, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 160, 164, 167, 169, 170, 171, 173, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191], "look": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 14, 19, 21, 28, 31, 33, 34, 35, 38, 39, 41, 42, 44, 46, 49, 57, 59, 62, 63, 64, 66, 69, 71, 72, 75, 77, 78, 79, 80, 83, 85, 86, 88, 92, 94, 95, 96, 98, 100, 103, 106, 107, 108, 111, 113, 114, 116, 126, 127, 138, 140, 141, 143, 144, 145, 146, 148, 157, 160, 163, 169, 178, 179, 180, 181, 184, 185, 186, 189], "becom": [0, 1, 2, 4, 5, 6, 7, 10, 14, 19, 25, 27, 30, 34, 38, 39, 41, 42, 46, 56, 62, 63, 64, 65, 69, 70, 71, 74, 77, 78, 79, 80, 85, 86, 88, 90, 92, 94, 95, 101, 103, 108, 110, 111, 114, 119, 121, 126, 130, 134, 139, 141, 145, 146, 149, 150, 153, 154, 156, 157, 159, 167, 174, 177, 183, 184], "convinc": [0, 74, 86], "100": [0, 1, 2, 4, 6, 9, 11, 19, 25, 26, 28, 29, 30, 36, 38, 41, 46, 50, 51, 53, 62, 63, 69, 70, 82, 83, 90, 92, 96, 100, 101, 108, 113, 116, 120, 123, 124, 129, 131, 135, 144, 150, 153, 157, 159, 164, 171, 180, 182, 183, 184, 186], "1000": [0, 10, 11, 19, 20, 25, 28, 38, 39, 42, 50, 53, 54, 57, 62, 77, 78, 82, 83, 85, 94, 96, 104, 105, 107, 122, 126, 148, 150, 157, 171, 178, 184, 186, 188], "figur": [0, 1, 2, 5, 7, 9, 20, 25, 58, 64, 69, 72, 77, 79, 80, 89, 92, 95, 103, 106, 146, 148, 149, 151, 165, 168, 185], "figsiz": [0, 9, 20, 21, 27, 28, 29, 56, 78, 82, 83, 103, 106, 114, 116, 140, 151, 184], "subplot": [0, 9, 20, 21, 27, 78, 140], "sqrt": [0, 1, 2, 5, 9, 11, 20, 22, 29, 47, 60, 63, 78, 80, 95, 103, 113, 116, 131, 133, 135, 137, 138, 139, 147, 148, 153, 157, 158, 163, 183], "xlim": [0, 9, 20, 38, 44, 45, 51, 53, 54, 56, 60, 82, 83, 90, 106, 128, 135, 143, 144, 151, 163, 165, 184], "titl": [0, 8, 9, 11, 17, 20, 27, 29, 92, 94, 96, 164, 165], "format": [0, 4, 7, 14, 17, 18, 38, 42, 47, 48, 49, 51, 53, 56, 59, 60, 62, 72, 78, 98, 99, 123, 127, 132, 133, 136, 151, 152, 164, 176], "One": [0, 1, 2, 3, 4, 5, 6, 7, 8, 21, 22, 23, 27, 31, 33, 35, 38, 39, 41, 42, 47, 50, 56, 58, 59, 62, 63, 64, 65, 69, 70, 71, 74, 75, 78, 83, 90, 92, 94, 95, 96, 98, 101, 103, 106, 107, 108, 109, 110, 113, 114, 116, 118, 130, 139, 140, 142, 143, 145, 147, 150, 153, 157, 160, 163, 170, 175, 177, 178, 179, 180, 184, 185], "compar": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 17, 19, 24, 25, 27, 29, 38, 41, 42, 44, 45, 46, 48, 50, 51, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 78, 82, 86, 87, 88, 89, 90, 92, 93, 95, 96, 98, 99, 100, 101, 103, 104, 105, 110, 111, 113, 114, 115, 117, 121, 123, 125, 127, 132, 135, 137, 138, 144, 145, 148, 153, 157, 160, 168, 169, 171, 173, 175, 177, 180, 181, 182, 183, 184, 185, 189, 190], "divid": [0, 2, 6, 8, 9, 10, 11, 20, 35, 45, 47, 50, 53, 54, 55, 56, 58, 59, 63, 92, 98, 105, 107, 108, 110, 138, 141, 144, 149, 153, 157, 180, 186], "standard": [0, 5, 7, 8, 14, 32, 33, 35, 36, 41, 49, 50, 53, 54, 56, 59, 62, 63, 64, 70, 71, 72, 78, 79, 82, 85, 86, 89, 91, 92, 95, 96, 99, 101, 103, 104, 105, 107, 108, 110, 113, 114, 116, 136, 143, 144, 145, 155, 157, 161, 169, 170, 171, 172, 173, 175, 179, 182, 183, 184, 185, 187], "deviat": [0, 25, 33, 49, 50, 54, 62, 63, 78, 79, 82, 85, 95, 103, 105, 107, 108, 113, 136, 139, 144, 155, 157, 173, 175], "squeez": [0, 8, 20, 22, 27, 47, 60, 63, 64, 83, 96, 123, 163, 168, 186], "outcom": [0, 4, 5, 6, 7, 21, 22, 42, 64, 69, 74, 92, 98, 109, 114, 140, 148, 157, 178], "smaller": [0, 4, 7, 8, 9, 10, 11, 14, 19, 25, 35, 41, 45, 50, 55, 56, 59, 60, 62, 64, 65, 69, 70, 71, 72, 75, 77, 96, 100, 103, 108, 109, 125, 127, 129, 138, 139, 141, 143, 144, 146, 148, 178, 180, 183, 185, 186], "longer": [0, 1, 2, 3, 5, 6, 14, 23, 25, 26, 41, 42, 48, 62, 63, 66, 68, 70, 77, 89, 90, 92, 96, 103, 110, 113, 114, 115, 119, 121, 132, 138, 139, 140, 141, 145, 150, 153, 155, 168, 169, 177, 180, 185], "A": [0, 2, 3, 4, 8, 9, 10, 17, 19, 20, 21, 25, 27, 30, 32, 38, 39, 41, 43, 46, 47, 49, 57, 58, 59, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 91, 95, 96, 97, 98, 99, 101, 103, 104, 106, 110, 111, 114, 116, 117, 119, 120, 126, 134, 136, 138, 139, 140, 141, 143, 144, 146, 148, 151, 152, 153, 155, 156, 158, 161, 164, 167, 168, 169, 174, 175, 177, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191], "deriv": [0, 2, 4, 5, 6, 7, 9, 11, 21, 25, 27, 63, 67, 69, 71, 72, 76, 77, 78, 79, 80, 94, 95, 98, 101, 103, 105, 108, 109, 114, 136, 138, 141, 145, 146, 150, 152, 157, 158, 166, 178, 186], "beyond": [0, 1, 2, 4, 5, 8, 11, 17, 18, 19, 22, 24, 30, 62, 65, 67, 76, 77, 78, 85, 86, 92, 107, 109, 110, 111, 138, 139, 143, 144, 145, 149, 154, 155, 156, 157, 165, 169, 180, 184, 185, 186, 189], "scope": [0, 1, 2, 4, 8, 11, 20, 38, 39, 64, 86, 94, 106, 138, 143, 150, 157], "document": [0, 2, 8, 12, 14, 16, 17, 33, 51, 96, 100, 104, 114, 144, 149, 152, 156, 170, 179, 180, 183, 184, 186, 191], "central": [0, 1, 7, 41, 46, 47, 50, 80, 88, 93, 95, 98, 101, 119, 157, 162, 189], "theorem": [0, 3, 8, 63, 80, 95, 98, 111, 138, 140, 145, 149, 157, 186], "state": [0, 4, 9, 11, 12, 20, 23, 24, 25, 27, 28, 29, 30, 34, 36, 40, 42, 56, 62, 63, 64, 74, 75, 78, 80, 81, 83, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 101, 104, 105, 106, 108, 110, 111, 113, 115, 117, 124, 126, 137, 138, 139, 141, 144, 145, 147, 151, 155, 157, 170, 171, 172, 174, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 188, 189, 190], "yield": [0, 2, 7, 9, 21, 22, 23, 41, 46, 61, 62, 64, 66, 68, 71, 72, 75, 76, 77, 92, 93, 94, 98, 101, 103, 106, 107, 109, 110, 111, 114, 137, 139, 141, 145, 147, 148, 150, 155, 157, 168, 177, 178], "sometim": [0, 3, 5, 10, 12, 17, 21, 24, 33, 35, 36, 41, 45, 56, 63, 71, 72, 75, 76, 77, 87, 92, 94, 98, 106, 108, 111, 113, 114, 138, 149, 150, 153, 155, 157, 177, 179, 183, 184], "normal": [0, 4, 8, 9, 10, 11, 20, 21, 22, 24, 25, 27, 30, 31, 33, 37, 38, 39, 42, 44, 45, 50, 51, 53, 54, 56, 59, 65, 66, 67, 69, 71, 74, 79, 80, 82, 83, 92, 93, 95, 98, 100, 102, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 120, 129, 135, 139, 140, 144, 147, 148, 150, 153, 154, 155, 157, 158, 163, 164, 165, 166, 168, 173, 175, 177, 181, 183, 184, 186, 191], "explicitli": [0, 4, 7, 10, 11, 36, 42, 66, 78, 92, 101, 103, 104, 107, 110, 114, 126, 143, 145, 158, 171, 178], "lim_": [0, 10, 11, 72, 80, 140, 151, 190], "mathcal": [0, 1, 4, 5, 8, 9, 10, 11, 27, 28, 46, 47, 63, 64, 69, 71, 78, 79, 80, 83, 86, 90, 95, 98, 103, 105, 108, 110, 125, 129, 132, 134, 136, 138, 140, 141, 143, 144, 145, 147, 148, 157, 158, 161, 163, 165, 169, 181, 183, 188, 189, 190], "given": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 24, 25, 26, 27, 28, 33, 40, 41, 44, 46, 47, 49, 50, 55, 56, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 77, 78, 79, 81, 82, 83, 85, 86, 92, 93, 94, 95, 98, 100, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118, 123, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 163, 165, 166, 169, 170, 171, 172, 173, 175, 177, 178, 180, 181, 182, 183, 184, 186, 188, 189, 190], "mu": [0, 11, 27, 63, 78, 79, 80, 92, 94, 95, 103, 107, 113, 157, 158], "sigma": [0, 1, 9, 11, 21, 33, 45, 60, 63, 78, 79, 80, 86, 95, 98, 100, 103, 104, 105, 107, 108, 110, 113, 114, 115, 116, 125, 136, 144, 157, 160, 165, 166, 170, 171, 173, 175, 183], "written": [0, 2, 4, 5, 6, 9, 10, 22, 38, 41, 65, 80, 92, 130, 140, 141, 153, 175, 183, 190], "p_x": [0, 4, 9], "17": [0, 41, 64, 114, 155, 186, 188, 190], "It": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 14, 18, 21, 23, 24, 27, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 79, 80, 82, 83, 85, 86, 92, 93, 94, 95, 96, 98, 99, 100, 103, 104, 105, 106, 107, 109, 110, 113, 114, 117, 118, 123, 129, 130, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 175, 178, 179, 180, 181, 183, 188, 189, 190], "appendix": [0, 2, 10, 11, 17, 149, 191], "doe": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 36, 39, 40, 41, 42, 44, 46, 49, 50, 51, 54, 56, 59, 62, 63, 64, 66, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 101, 103, 104, 105, 107, 108, 109, 111, 113, 114, 115, 116, 118, 123, 124, 125, 126, 133, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 157, 163, 165, 167, 168, 169, 170, 175, 176, 177, 178, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190], "close": [0, 1, 2, 3, 4, 5, 6, 10, 11, 16, 21, 25, 50, 52, 55, 56, 62, 63, 64, 69, 70, 72, 78, 79, 80, 81, 86, 91, 92, 94, 95, 101, 103, 104, 105, 110, 111, 113, 114, 116, 129, 146, 159, 173, 175, 183, 190], "form": [0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 19, 21, 27, 35, 41, 42, 53, 57, 63, 64, 67, 69, 70, 74, 77, 78, 79, 80, 83, 86, 92, 94, 97, 101, 103, 105, 110, 114, 117, 119, 121, 123, 124, 129, 131, 132, 133, 138, 139, 140, 141, 143, 145, 149, 150, 153, 155, 157, 165, 166, 167, 172, 174, 175, 178, 180, 183, 184, 185, 187, 188], "formula": [0, 2, 4, 5, 9, 11, 101, 103, 141, 159, 180], "term": [0, 2, 4, 5, 6, 7, 8, 9, 10, 19, 21, 22, 27, 32, 35, 38, 39, 41, 42, 44, 46, 55, 62, 63, 64, 65, 66, 69, 70, 72, 78, 85, 86, 92, 93, 94, 95, 98, 99, 100, 103, 106, 108, 109, 111, 114, 116, 129, 138, 139, 140, 141, 143, 144, 145, 147, 148, 150, 151, 153, 157, 161, 163, 167, 168, 169, 173, 174, 176, 177, 178, 180, 181, 182, 184, 186, 189, 191], "elementari": [0, 10, 149, 153, 157, 186], "provid": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 18, 19, 21, 24, 26, 27, 29, 31, 33, 34, 35, 37, 41, 42, 44, 45, 46, 49, 51, 53, 54, 58, 59, 60, 62, 63, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81, 83, 85, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 121, 133, 139, 141, 143, 144, 146, 149, 150, 152, 154, 155, 157, 159, 163, 164, 165, 166, 167, 169, 172, 173, 180, 182, 183], "integr": [0, 3, 9, 14, 35, 41, 63, 68, 70, 77, 78, 81, 94, 101, 108, 136, 140, 145, 149, 151, 157, 158, 159, 160, 173, 191], "numer": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 36, 41, 62, 63, 71, 73, 76, 78, 79, 81, 92, 95, 96, 98, 99, 100, 103, 109, 111, 112, 113, 131, 135, 137, 139, 146, 149, 151, 155, 156, 160, 161, 167, 174, 178, 179, 183, 185, 187, 191], "phi": [0, 5, 63, 80, 109, 111, 114, 165, 168, 170, 178, 181], "keen": [0, 5, 92], "ei": [0, 2, 5], "reader": [0, 5, 14, 21, 41, 63, 64, 77, 78, 86, 88, 92, 94, 100, 108, 113, 127, 138, 143, 145, 149, 157, 160, 179, 184], "recogn": [0, 5, 8, 9, 11, 34, 48, 50, 54, 59, 66, 71, 74, 76, 77, 80, 92, 101, 114, 119, 179, 180], "inde": [0, 1, 2, 4, 5, 6, 7, 9, 10, 24, 27, 41, 42, 46, 63, 64, 72, 78, 81, 92, 93, 94, 95, 98, 105, 106, 108, 113, 116, 126, 142, 145, 148, 151, 157], "valid": [0, 4, 8, 11, 21, 22, 23, 25, 27, 29, 52, 57, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 85, 86, 87, 88, 90, 93, 94, 95, 98, 99, 100, 103, 105, 106, 107, 108, 111, 112, 114, 117, 123, 133, 153, 164, 172, 184, 186], "choic": [0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 19, 21, 22, 30, 38, 40, 41, 42, 44, 45, 63, 64, 66, 67, 69, 70, 76, 77, 78, 85, 90, 92, 93, 94, 95, 97, 98, 103, 104, 108, 110, 111, 113, 114, 115, 116, 123, 124, 127, 129, 130, 133, 138, 139, 141, 143, 145, 147, 148, 149, 150, 157, 167, 169, 170, 180, 184, 185, 190], "shorter": [0, 1, 2, 22, 26, 28, 92, 119, 134, 144, 176, 177, 180], "noth": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 34, 50, 63, 92, 95, 114, 116, 125, 184], "about": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 17, 19, 20, 22, 23, 25, 28, 32, 34, 35, 37, 38, 46, 47, 59, 62, 63, 67, 75, 76, 78, 79, 80, 81, 83, 86, 88, 89, 92, 93, 94, 95, 98, 101, 102, 103, 104, 106, 107, 109, 110, 111, 113, 114, 116, 117, 119, 121, 124, 132, 138, 148, 153, 156, 157, 163, 164, 175, 178, 179, 180, 183, 184, 185], "wa": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 19, 23, 24, 25, 27, 29, 30, 35, 38, 41, 42, 44, 46, 50, 51, 62, 63, 64, 66, 67, 68, 70, 73, 74, 76, 77, 78, 80, 85, 92, 93, 94, 95, 96, 98, 100, 101, 103, 108, 111, 113, 114, 116, 126, 131, 132, 134, 135, 137, 138, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 157, 159, 163, 166, 167, 172, 175, 176, 178, 179, 182, 184, 185, 188, 190], "fundament": [0, 1, 2, 3, 4, 8, 9, 10, 11, 46, 78, 92, 94, 95, 98, 100, 101, 108, 113, 114, 116, 146, 149, 153, 157, 162, 167, 179, 183, 186, 187, 189], "collect": [0, 1, 2, 4, 6, 9, 11, 20, 27, 39, 50, 53, 57, 62, 63, 64, 73, 77, 78, 79, 80, 82, 86, 89, 90, 92, 94, 95, 101, 103, 108, 111, 113, 119, 120, 132, 133, 136, 149, 153, 157, 159, 165, 166, 167, 177, 184, 185, 189], "ident": [0, 2, 4, 6, 11, 22, 27, 29, 35, 38, 44, 45, 50, 62, 63, 64, 69, 70, 78, 80, 82, 85, 92, 94, 101, 103, 107, 114, 136, 140, 143, 144, 146, 150, 154, 155, 157, 165, 168, 178, 181, 186, 189, 190], "There": [0, 1, 2, 4, 5, 6, 7, 9, 11, 19, 21, 22, 27, 36, 38, 39, 40, 41, 44, 46, 47, 54, 57, 59, 60, 62, 69, 75, 77, 78, 81, 86, 92, 98, 103, 106, 108, 114, 116, 120, 133, 140, 143, 144, 145, 146, 148, 151, 153, 155, 157, 158, 159, 164, 166, 167, 171, 179, 180, 181, 182, 184, 187, 189], "addit": [0, 1, 2, 4, 6, 8, 9, 11, 14, 18, 19, 21, 23, 24, 25, 26, 28, 29, 35, 36, 38, 39, 41, 42, 49, 50, 51, 55, 58, 59, 62, 63, 64, 65, 69, 71, 72, 73, 74, 75, 78, 80, 82, 86, 88, 89, 90, 92, 94, 96, 99, 101, 103, 106, 107, 108, 110, 114, 115, 116, 117, 121, 126, 129, 138, 139, 143, 144, 145, 146, 148, 153, 154, 155, 157, 164, 165, 171, 172, 180, 183, 184, 186, 190], "requir": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 21, 22, 25, 27, 29, 31, 34, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 53, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 113, 114, 116, 117, 118, 121, 124, 125, 126, 129, 134, 137, 138, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 155, 156, 157, 161, 164, 167, 168, 171, 172, 175, 177, 178, 179, 181, 184, 186, 189, 190], "most": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 18, 19, 22, 23, 24, 25, 27, 33, 35, 36, 38, 39, 40, 41, 42, 44, 46, 50, 51, 52, 59, 62, 64, 67, 71, 72, 73, 75, 78, 80, 83, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 105, 106, 108, 109, 110, 111, 113, 114, 117, 121, 123, 127, 131, 132, 135, 138, 140, 143, 144, 145, 146, 149, 150, 152, 153, 155, 156, 157, 159, 161, 162, 164, 166, 169, 174, 175, 176, 177, 178, 182, 183, 184, 185, 186, 189], "philosophi": 0, "clear": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 14, 20, 21, 23, 33, 63, 66, 75, 78, 92, 108, 110, 114, 139, 149, 150, 153, 157, 161, 183], "statist": [0, 3, 4, 8, 9, 21, 23, 41, 46, 63, 72, 75, 77, 78, 83, 85, 87, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 108, 111, 114, 115, 130, 132, 137, 144, 146, 149, 150, 152, 162, 176, 179, 180, 184, 186, 191], "whenev": [0, 7, 17, 22, 38, 39, 41, 42, 64, 69, 73, 77, 85, 91, 92, 93, 95, 96, 98, 99, 101, 103, 104, 111, 138, 139, 140, 141, 143, 144, 145, 148, 149, 150, 154, 155, 156, 157, 173, 175, 177, 178, 184, 185], "someth": [0, 1, 2, 5, 7, 8, 9, 10, 11, 14, 35, 38, 39, 41, 63, 83, 86, 92, 95, 99, 113, 114, 117, 138, 140, 144, 155, 157, 159], "small": [0, 1, 2, 5, 7, 8, 9, 10, 11, 12, 19, 25, 30, 31, 38, 39, 40, 41, 42, 44, 50, 53, 54, 55, 57, 60, 62, 63, 64, 65, 70, 72, 75, 77, 78, 79, 80, 82, 83, 86, 92, 95, 98, 100, 101, 103, 105, 108, 109, 110, 111, 113, 116, 117, 121, 128, 131, 137, 138, 140, 141, 143, 144, 145, 148, 149, 151, 157, 169, 180, 183, 186, 188], "contribut": [0, 4, 7, 10, 11, 16, 17, 22, 66, 78, 92, 95, 103, 116, 149, 158, 191], "being": [0, 1, 2, 4, 5, 8, 9, 11, 12, 14, 18, 27, 29, 34, 39, 40, 41, 44, 47, 61, 67, 69, 78, 80, 85, 92, 94, 95, 98, 103, 107, 113, 114, 116, 117, 125, 126, 129, 132, 133, 134, 143, 144, 145, 155, 157, 173, 175, 178, 187], "fascin": [0, 1, 111], "properti": [0, 2, 9, 21, 23, 27, 29, 62, 63, 70, 78, 79, 80, 81, 92, 95, 107, 111, 113, 126, 141, 142, 144, 145, 146, 149, 151, 152, 154, 155, 156, 157, 178, 180, 183, 185, 186, 187], "would": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 14, 21, 27, 29, 30, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 108, 110, 113, 114, 116, 138, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 156, 157, 163, 169, 171, 173, 175, 178, 180, 181, 183, 184, 185, 188, 189], "maximum": [0, 1, 2, 3, 4, 7, 9, 10, 11, 21, 28, 29, 41, 52, 58, 60, 73, 86, 90, 94, 98, 101, 103, 114, 115, 121, 123, 127, 128, 133, 134, 143, 146, 166, 169, 191], "entropi": [0, 3, 6, 20, 25, 44, 60, 74, 83, 92, 94, 95, 97, 99, 126, 129, 136, 161, 177, 180, 181, 186], "deepli": [0, 1, 2, 73, 151], "point": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 19, 20, 24, 31, 34, 35, 37, 38, 41, 42, 46, 47, 51, 56, 62, 63, 64, 65, 66, 67, 69, 70, 74, 78, 79, 80, 82, 83, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 101, 103, 106, 110, 111, 113, 114, 140, 142, 143, 144, 145, 149, 150, 151, 153, 155, 156, 157, 160, 167, 168, 174, 175, 179, 186, 187], "rigor": [0, 6, 9, 62, 63, 114, 149, 151, 153], "sens": [0, 1, 2, 4, 5, 6, 9, 10, 11, 67, 69, 71, 78, 79, 92, 94, 95, 98, 100, 108, 111, 113, 114, 140, 143, 150, 157, 167, 171, 183], "conserv": [0, 95, 111], "recal": [0, 1, 2, 5, 6, 7, 9, 11, 12, 21, 23, 24, 25, 31, 35, 41, 49, 51, 54, 55, 59, 60, 63, 64, 65, 68, 72, 75, 95, 96, 99, 100, 101, 103, 104, 105, 108, 109, 110, 111, 113, 114, 115, 121, 125, 126, 127, 128, 132, 135, 140, 141, 144, 145, 146, 147, 150, 153, 156, 157, 165, 167, 174, 176, 177, 178, 181, 183, 184, 189], "shown": [0, 1, 2, 4, 7, 9, 10, 12, 13, 14, 17, 25, 29, 30, 38, 39, 42, 47, 49, 50, 51, 53, 54, 58, 60, 65, 66, 71, 72, 80, 92, 94, 98, 117, 123, 134, 140, 163, 168, 170, 175, 178, 188, 190], "share": [0, 4, 7, 12, 14, 23, 25, 31, 35, 36, 41, 46, 58, 62, 64, 68, 69, 92, 103, 113, 116, 123, 132, 144, 147, 149, 155, 157, 160, 165, 179], "thei": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 55, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 123, 126, 133, 134, 135, 139, 140, 141, 142, 143, 144, 145, 149, 150, 153, 155, 156, 157, 161, 162, 164, 168, 172, 173, 175, 176, 178, 179, 181, 183, 184, 185, 189], "belong": [0, 4, 47, 59, 62, 92, 98, 107, 117, 136, 153], "whose": [0, 1, 5, 9, 22, 25, 28, 29, 30, 35, 47, 50, 53, 54, 58, 63, 66, 73, 74, 76, 91, 92, 95, 101, 109, 114, 116, 120, 125, 126, 127, 131, 133, 135, 149, 150, 153, 155, 156, 177, 178, 181, 182, 183, 184, 189], "mathbf": [0, 1, 2, 4, 5, 7, 8, 9, 10, 17, 21, 22, 23, 26, 27, 28, 29, 35, 46, 47, 56, 61, 63, 64, 65, 69, 72, 77, 78, 82, 83, 86, 90, 94, 95, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 114, 116, 120, 125, 126, 129, 132, 134, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 150, 151, 153, 155, 157, 158, 160, 161, 163, 165, 168, 169, 170, 171, 173, 175, 177, 178, 179, 180, 181, 183, 184], "mid": [0, 4, 6, 8, 11, 93, 94, 98, 103, 108, 125, 129, 134, 136, 140, 157, 163, 166, 169, 175, 177, 180, 181, 183, 184, 188, 189, 190], "boldsymbol": [0, 1, 4, 5, 6, 7, 63, 98, 107, 120, 138, 141, 145, 148, 157], "eta": [0, 50, 89, 90, 103, 105, 108, 138, 139, 141, 143, 145, 147, 148, 183], "h": [0, 4, 6, 7, 10, 20, 22, 23, 26, 30, 47, 48, 55, 56, 58, 60, 61, 63, 71, 72, 75, 76, 77, 80, 94, 96, 98, 105, 109, 110, 114, 115, 116, 120, 129, 132, 136, 140, 141, 145, 151, 155, 157, 158, 165, 168, 170, 171, 173, 175, 177, 178, 181, 182, 183, 185, 186, 189, 190], "cdot": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 35, 44, 46, 63, 65, 69, 70, 71, 90, 101, 103, 105, 114, 116, 120, 125, 134, 136, 138, 140, 141, 143, 144, 146, 148, 150, 151, 153, 157, 158, 161, 168, 178, 184, 188], "left": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 20, 21, 22, 25, 28, 44, 46, 47, 48, 49, 51, 53, 56, 57, 58, 62, 64, 65, 69, 72, 75, 76, 77, 78, 79, 80, 87, 92, 95, 103, 105, 108, 109, 113, 114, 116, 123, 125, 126, 128, 129, 133, 134, 136, 138, 139, 140, 141, 143, 145, 147, 148, 149, 151, 153, 155, 157, 165, 168, 169, 173, 177, 178, 179, 180, 183, 184, 187, 188, 189, 190], "top": [0, 1, 2, 7, 11, 12, 17, 22, 27, 35, 41, 46, 56, 60, 61, 69, 72, 75, 76, 77, 78, 80, 85, 86, 90, 91, 92, 103, 107, 108, 109, 114, 120, 125, 129, 131, 134, 136, 138, 140, 141, 145, 150, 151, 153, 157, 163, 165, 167, 168, 171, 178, 186], "t": [0, 2, 6, 7, 8, 9, 11, 20, 23, 27, 28, 41, 47, 56, 59, 61, 69, 72, 74, 78, 80, 83, 92, 94, 95, 96, 98, 103, 105, 107, 114, 116, 119, 124, 125, 132, 133, 134, 137, 138, 139, 143, 144, 145, 147, 148, 150, 153, 157, 159, 163, 164, 165, 168, 169, 170, 171, 173, 175, 176, 177, 178, 180, 181, 183, 184, 186, 188, 189, 190], "right": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 20, 21, 22, 25, 28, 30, 41, 44, 46, 47, 48, 51, 56, 57, 58, 62, 63, 64, 65, 69, 72, 75, 76, 77, 78, 79, 80, 92, 94, 95, 103, 105, 108, 109, 111, 113, 114, 116, 123, 125, 126, 129, 133, 134, 138, 139, 140, 141, 143, 145, 147, 148, 151, 153, 157, 165, 169, 173, 177, 178, 179, 180, 183, 184, 188, 189, 190], "definit": [0, 1, 2, 5, 7, 9, 10, 22, 28, 34, 42, 51, 55, 66, 77, 78, 81, 82, 88, 90, 94, 98, 100, 106, 109, 113, 114, 125, 127, 135, 136, 139, 142, 145, 147, 149, 151, 153, 157, 165, 177, 178, 181, 186, 187], "subtl": [0, 1, 7, 9, 10, 11, 56, 94, 114, 144, 157, 178], "underli": [0, 1, 2, 24, 36, 41, 63, 66, 69, 75, 78, 87, 92, 95, 101, 103, 105, 108, 111, 116, 141, 144, 151, 155, 157, 169, 170, 179, 184, 187], "base": [0, 4, 5, 11, 12, 14, 22, 23, 24, 25, 26, 28, 29, 30, 31, 35, 40, 42, 44, 47, 48, 49, 50, 51, 52, 53, 55, 56, 62, 63, 64, 65, 67, 68, 72, 73, 74, 77, 78, 79, 82, 85, 86, 88, 90, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 108, 111, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 134, 135, 136, 144, 146, 149, 151, 153, 154, 155, 156, 157, 158, 159, 162, 164, 165, 166, 167, 168, 169, 171, 172, 177, 178, 179, 180, 182, 184, 185, 186, 189, 190, 191], "view": [0, 2, 4, 6, 8, 10, 12, 20, 27, 38, 52, 59, 65, 69, 80, 92, 95, 98, 110, 111, 113, 120, 129, 134, 140, 153, 167, 168, 169, 179, 180, 181, 183, 186], "modifi": [0, 7, 12, 14, 17, 22, 23, 25, 30, 34, 41, 45, 47, 54, 56, 58, 62, 65, 69, 70, 78, 85, 92, 107, 122, 125, 138, 143, 144, 149, 151, 183, 189], "weight": [0, 1, 2, 7, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 44, 45, 46, 49, 50, 56, 60, 61, 62, 63, 69, 71, 72, 74, 75, 77, 78, 79, 81, 82, 85, 86, 94, 97, 98, 100, 101, 102, 103, 104, 105, 109, 110, 111, 113, 114, 115, 116, 120, 123, 124, 126, 127, 129, 133, 135, 139, 140, 143, 144, 147, 153, 157, 158, 160, 161, 163, 165, 166, 168, 170, 171, 173, 174, 175, 177, 178, 181, 182, 183, 186, 191], "vector": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 21, 22, 24, 26, 28, 29, 30, 35, 37, 44, 46, 56, 58, 61, 62, 63, 64, 68, 72, 73, 74, 76, 77, 78, 79, 80, 82, 92, 94, 96, 99, 100, 102, 104, 105, 107, 108, 109, 110, 111, 113, 115, 116, 118, 120, 125, 126, 130, 132, 135, 136, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 155, 157, 160, 161, 165, 168, 170, 177, 178, 179, 181, 183, 184, 186, 191], "eta_1": 0, "eta_2": 0, "eta_l": 0, "mathbb": [0, 5, 8, 9, 17, 21, 22, 26, 27, 28, 29, 47, 56, 77, 82, 83, 86, 90, 94, 98, 103, 107, 109, 114, 120, 134, 136, 138, 140, 141, 144, 148, 151, 153, 155, 160, 161, 163, 165, 168, 170, 171, 173, 175, 178, 181, 184, 188, 189], "r": [0, 2, 4, 5, 7, 8, 9, 17, 20, 21, 22, 26, 27, 28, 29, 39, 42, 47, 52, 53, 56, 59, 64, 77, 82, 83, 86, 89, 90, 92, 94, 95, 98, 101, 103, 107, 109, 114, 119, 120, 127, 131, 132, 134, 136, 138, 140, 141, 144, 145, 148, 151, 153, 155, 158, 160, 161, 163, 165, 168, 170, 171, 173, 175, 178, 181, 184, 186, 188, 189, 190, 191], "l": [0, 4, 7, 10, 12, 17, 20, 22, 42, 44, 45, 47, 51, 53, 54, 56, 60, 69, 72, 77, 78, 80, 86, 92, 93, 94, 98, 99, 101, 103, 104, 105, 106, 108, 109, 114, 116, 125, 128, 129, 132, 133, 135, 138, 140, 143, 144, 148, 160, 161, 163, 165, 168, 169, 171, 176, 177, 178, 183, 186], "call": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 47, 50, 51, 55, 56, 59, 61, 62, 63, 65, 66, 69, 70, 72, 73, 76, 77, 78, 79, 82, 83, 85, 90, 92, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 120, 129, 132, 134, 135, 138, 139, 140, 141, 144, 145, 149, 150, 151, 153, 154, 155, 156, 157, 164, 167, 168, 172, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 189, 190], "natur": [0, 4, 8, 9, 11, 22, 24, 25, 27, 29, 30, 35, 37, 63, 69, 72, 77, 78, 88, 92, 94, 98, 103, 108, 111, 114, 117, 123, 125, 126, 128, 131, 132, 134, 136, 138, 140, 141, 146, 148, 149, 150, 153, 156, 157, 160, 166, 170, 174, 176, 179, 180, 184, 186, 188, 191], "canon": 0, "These": [0, 1, 2, 3, 7, 9, 10, 11, 19, 22, 24, 25, 28, 29, 32, 35, 41, 47, 50, 56, 58, 60, 62, 63, 64, 66, 69, 73, 74, 76, 78, 79, 81, 86, 92, 93, 94, 104, 109, 113, 114, 115, 117, 121, 123, 126, 127, 135, 144, 145, 149, 153, 155, 156, 157, 160, 162, 163, 166, 171, 175, 179, 181, 182, 184, 185, 187], "enter": [0, 4, 7, 12, 14, 17, 19, 59, 62, 92, 94, 149], "new": [0, 4, 5, 8, 10, 11, 12, 14, 17, 19, 21, 23, 24, 31, 32, 35, 37, 38, 41, 42, 45, 47, 50, 54, 56, 58, 61, 62, 64, 67, 69, 70, 76, 78, 81, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 98, 99, 101, 103, 104, 106, 107, 108, 110, 111, 113, 117, 119, 124, 127, 130, 132, 134, 138, 140, 145, 149, 150, 153, 154, 155, 157, 159, 167, 168, 173, 175, 176, 181, 183, 184, 185, 186, 187, 188, 189], "dot": [0, 1, 3, 7, 20, 21, 23, 24, 26, 28, 29, 31, 35, 39, 40, 44, 56, 61, 69, 71, 72, 78, 79, 80, 83, 90, 100, 103, 105, 107, 108, 115, 116, 125, 131, 134, 135, 136, 144, 148, 150, 152, 155, 161, 165, 173, 175, 179, 181, 183, 184], "product": [0, 1, 3, 4, 5, 6, 7, 9, 10, 21, 23, 24, 25, 26, 28, 29, 39, 42, 56, 62, 67, 74, 79, 80, 86, 92, 94, 98, 103, 105, 108, 116, 117, 122, 125, 130, 134, 135, 136, 144, 148, 149, 150, 151, 152, 154, 155, 157, 159, 161, 162, 163, 165, 167, 173, 175, 178, 181, 182, 183, 184], "against": [0, 1, 11, 41, 69, 85, 89, 96, 100, 105, 107, 113, 117], "x_1": [0, 4, 5, 6, 7, 8, 9, 11, 78, 79, 80, 83, 98, 103, 108, 133, 138, 141, 145, 147, 148, 151, 153, 177, 178, 179, 180, 181, 183, 184], "x_2": [0, 6, 7, 8, 11, 79, 98, 103, 108, 133, 138, 141, 145, 147, 148, 151, 153, 180], "x_n": [0, 4, 5, 6, 7, 9, 11, 78, 79, 80, 83, 103, 148, 151, 153], "t_1": [0, 8, 39], "t_2": [0, 8, 39], "t_l": 0, "suffici": [0, 2, 6, 9, 19, 23, 40, 44, 45, 62, 64, 70, 92, 93, 94, 95, 96, 100, 101, 103, 111, 114, 117, 138, 140, 141, 143, 149, 178, 180, 181, 183, 184, 185, 186], "name": [0, 1, 5, 7, 9, 12, 14, 18, 20, 21, 22, 23, 25, 27, 31, 32, 33, 35, 36, 37, 41, 46, 49, 50, 52, 53, 54, 59, 61, 62, 63, 65, 69, 70, 72, 74, 76, 77, 85, 86, 88, 89, 91, 92, 94, 96, 98, 106, 110, 111, 115, 116, 126, 133, 134, 137, 142, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 160, 162, 164, 166, 168, 173, 175, 181, 188, 189], "inform": [0, 2, 3, 6, 7, 10, 12, 14, 23, 27, 34, 36, 38, 41, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 69, 70, 73, 75, 76, 77, 79, 83, 92, 94, 95, 97, 103, 107, 113, 114, 117, 119, 120, 121, 129, 131, 132, 141, 153, 154, 157, 159, 164, 167, 168, 170, 171, 173, 174, 175, 176, 177, 179, 180, 181, 182, 184, 185, 186, 190, 191], "repres": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 25, 27, 28, 29, 31, 35, 36, 38, 48, 52, 55, 56, 57, 59, 60, 62, 72, 73, 74, 77, 78, 79, 80, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 100, 103, 104, 110, 111, 113, 114, 115, 117, 118, 119, 120, 123, 125, 126, 127, 129, 130, 132, 133, 134, 136, 145, 149, 150, 153, 155, 156, 157, 158, 159, 160, 161, 163, 164, 166, 167, 168, 169, 176, 178, 179, 181, 183, 184, 185, 186], "calcul": [0, 1, 4, 8, 10, 11, 31, 35, 38, 44, 47, 49, 54, 56, 60, 62, 63, 68, 71, 72, 75, 76, 92, 94, 95, 97, 98, 99, 101, 103, 104, 109, 110, 112, 113, 114, 125, 126, 129, 132, 133, 134, 135, 137, 144, 145, 150, 151, 153, 157, 158, 159, 163, 165, 171, 175, 177, 178, 179, 180, 181, 183, 190], "third": [0, 4, 6, 7, 9, 10, 11, 17, 21, 28, 29, 36, 41, 46, 47, 56, 63, 64, 66, 76, 77, 92, 100, 105, 119, 153, 155, 157, 161, 170, 178, 180, 183, 184, 185], "refer": [0, 2, 4, 6, 8, 9, 10, 11, 14, 19, 25, 27, 28, 29, 36, 38, 40, 41, 42, 47, 48, 51, 56, 58, 64, 65, 69, 71, 72, 75, 76, 77, 78, 82, 85, 86, 92, 96, 98, 100, 103, 105, 109, 126, 132, 136, 137, 138, 144, 146, 150, 153, 155, 157, 160, 167, 176, 178, 180, 181, 191], "ensur": [0, 9, 19, 22, 27, 29, 33, 37, 40, 41, 46, 62, 63, 71, 74, 75, 86, 88, 92, 95, 98, 100, 108, 110, 116, 138, 140, 141, 143, 145, 147, 151, 158, 165, 171, 175, 179, 183, 187, 189, 190], "log": [0, 3, 4, 5, 7, 8, 9, 10, 12, 18, 20, 38, 41, 47, 53, 54, 60, 78, 80, 83, 86, 88, 89, 90, 95, 99, 100, 103, 108, 113, 116, 117, 122, 125, 129, 134, 135, 136, 140, 141, 144, 150, 151, 166, 168, 169, 180, 185, 186], "concret": [0, 1, 7, 9, 10, 14, 47, 50, 53, 55, 56, 58, 60, 77, 80, 94, 103, 118, 123, 124, 134, 140, 148, 177, 180, 188], "univari": [0, 141], "had": [0, 8, 9, 24, 25, 38, 41, 44, 62, 66, 68, 69, 70, 74, 75, 79, 83, 92, 94, 96, 98, 106, 109, 116, 145, 149, 157, 175, 176, 183, 184, 185], "align": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 21, 23, 25, 28, 33, 41, 58, 76, 77, 78, 82, 92, 94, 95, 98, 103, 108, 110, 114, 115, 116, 120, 125, 134, 137, 138, 139, 140, 144, 145, 147, 148, 151, 157, 161, 165, 166, 169, 170, 173, 175, 178, 180, 183, 184, 186, 189], "match": [0, 6, 7, 9, 10, 22, 25, 27, 28, 35, 41, 44, 46, 62, 64, 68, 70, 74, 75, 76, 77, 78, 82, 83, 92, 93, 98, 100, 107, 113, 119, 145, 150, 151, 155, 157, 159, 173, 177, 186], "bmatrix": [0, 1, 2, 5, 7, 26, 28, 78, 79, 145, 153], "worth": [0, 2, 5, 7, 8, 9, 10, 11, 37, 41, 42, 45, 58, 63, 64, 74, 80, 86, 92, 93, 98, 101, 103, 104, 106, 114, 157, 159, 160, 161, 181, 186], "exact": [0, 7, 9, 27, 36, 63, 78, 79, 92, 95, 103, 138, 140, 141, 155, 157, 164], "somewhat": [0, 2, 5, 11, 38, 40, 46, 62, 63, 64, 76, 79, 86, 138, 140, 145, 180], "featur": [0, 8, 11, 21, 22, 23, 28, 29, 35, 38, 42, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 79, 88, 92, 94, 95, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 111, 113, 114, 115, 120, 123, 126, 134, 135, 139, 142, 149, 155, 157, 160, 161, 162, 164, 165, 167, 171, 173, 174, 177, 179, 181, 183, 184, 186, 189, 191], "itself": [0, 2, 5, 6, 8, 9, 10, 11, 12, 25, 27, 28, 35, 77, 78, 85, 91, 92, 98, 104, 107, 108, 110, 114, 137, 138, 139, 144, 153, 157, 178], "allud": [0, 4, 63], "wide": [0, 1, 8, 9, 11, 19, 24, 29, 31, 41, 48, 50, 51, 54, 58, 60, 62, 63, 68, 70, 71, 74, 78, 92, 94, 96, 102, 108, 111, 113, 114, 116, 117, 118, 119, 122, 123, 126, 144, 148, 149, 153, 160, 161, 162, 163, 164, 166, 175, 183, 186], "techniqu": [0, 1, 3, 4, 7, 21, 32, 34, 42, 48, 49, 50, 51, 52, 60, 62, 63, 67, 73, 75, 78, 87, 92, 98, 101, 103, 104, 108, 109, 110, 111, 113, 127, 130, 134, 139, 141, 147, 148, 149, 150, 152, 162, 167, 169, 170, 175, 176, 180, 184, 186, 187], "final": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 22, 23, 26, 29, 30, 34, 35, 38, 41, 45, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75, 76, 78, 85, 90, 92, 93, 94, 95, 98, 100, 101, 103, 105, 106, 108, 109, 113, 114, 115, 120, 123, 124, 126, 128, 140, 144, 146, 148, 149, 150, 155, 156, 157, 160, 161, 163, 165, 169, 171, 173, 175, 176, 177, 178, 179, 183, 187], "output": [0, 1, 4, 6, 7, 8, 10, 11, 12, 14, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 44, 47, 49, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 109, 110, 114, 115, 116, 117, 119, 120, 121, 123, 124, 126, 127, 129, 131, 132, 135, 141, 146, 150, 151, 153, 155, 158, 160, 163, 165, 166, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 191], "power": [0, 1, 10, 12, 18, 19, 24, 25, 28, 32, 37, 41, 45, 52, 62, 63, 69, 72, 73, 77, 78, 81, 83, 91, 92, 95, 101, 103, 104, 106, 107, 108, 111, 113, 114, 115, 116, 126, 133, 144, 149, 150, 151, 160, 162, 167, 178, 181, 184, 185, 186, 190], "frequent": [0, 2, 3, 4, 11, 39, 63, 75, 86, 91, 92, 94, 103, 106, 114, 116, 129, 132, 138, 144, 149, 180, 184, 185], "ye": [0, 5, 9, 12, 86, 92, 149, 167, 186], "select": [0, 4, 8, 11, 12, 14, 16, 23, 24, 27, 40, 47, 51, 53, 54, 56, 58, 63, 64, 66, 78, 85, 86, 92, 93, 95, 100, 102, 105, 108, 112, 118, 126, 140, 141, 149, 155, 156, 169, 171, 186, 188, 189, 191], "finit": [0, 2, 4, 9, 10, 11, 46, 72, 80, 83, 94, 95, 98, 101, 103, 104, 111, 140, 142, 146, 157], "seri": [0, 4, 9, 19, 25, 41, 47, 51, 58, 66, 72, 73, 80, 81, 92, 95, 111, 149, 151, 168, 175, 179, 186], "result": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 17, 21, 22, 24, 25, 26, 28, 29, 30, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 52, 56, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 85, 88, 89, 92, 93, 94, 95, 99, 100, 101, 103, 105, 107, 110, 111, 113, 114, 115, 117, 119, 120, 123, 125, 126, 128, 129, 131, 132, 133, 135, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 153, 155, 157, 163, 164, 165, 168, 169, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190], "ad": [0, 2, 5, 7, 8, 9, 11, 25, 28, 29, 34, 35, 36, 40, 41, 42, 44, 46, 48, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 77, 78, 93, 94, 98, 103, 105, 106, 107, 110, 111, 113, 114, 115, 126, 137, 139, 140, 148, 150, 153, 155, 159, 160, 165, 175, 181, 186], "larg": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 14, 19, 21, 22, 24, 27, 30, 38, 41, 42, 43, 44, 46, 47, 50, 51, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 75, 77, 78, 79, 80, 83, 86, 88, 92, 94, 95, 96, 98, 99, 100, 103, 104, 105, 107, 108, 109, 111, 113, 114, 116, 117, 120, 122, 124, 125, 128, 129, 130, 131, 133, 138, 140, 141, 143, 144, 145, 147, 148, 149, 151, 153, 156, 157, 167, 173, 176, 178, 180, 183, 185, 186, 188, 189, 191], "togeth": [0, 3, 4, 5, 7, 9, 10, 24, 35, 36, 44, 47, 63, 64, 65, 67, 69, 71, 74, 77, 79, 92, 94, 98, 105, 108, 111, 116, 118, 123, 127, 129, 130, 149, 153, 157, 163, 164, 167, 168, 170, 171, 174, 176, 177, 179, 181, 183, 188, 189, 190], "16": [0, 9, 12, 19, 23, 30, 35, 41, 44, 45, 46, 49, 55, 58, 60, 61, 62, 63, 64, 66, 68, 69, 70, 74, 76, 82, 85, 86, 92, 110, 117, 118, 119, 120, 121, 123, 124, 126, 128, 130, 131, 143, 144, 149, 153, 168, 177, 183, 184, 186], "element": [0, 1, 3, 4, 7, 8, 10, 17, 22, 23, 27, 28, 39, 41, 47, 51, 56, 57, 58, 61, 62, 63, 67, 69, 70, 71, 72, 75, 76, 90, 92, 94, 98, 100, 103, 110, 114, 116, 123, 128, 129, 133, 134, 135, 136, 141, 144, 148, 152, 153, 154, 155, 157, 161, 163, 168, 169, 183, 184, 185, 186], "often": [1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 19, 22, 24, 25, 28, 29, 32, 33, 35, 36, 38, 39, 41, 42, 46, 47, 48, 49, 53, 60, 62, 63, 64, 66, 70, 73, 75, 76, 77, 78, 79, 80, 83, 85, 87, 88, 89, 92, 93, 94, 95, 96, 98, 101, 102, 103, 105, 107, 108, 109, 110, 111, 113, 114, 116, 125, 129, 133, 134, 135, 136, 138, 140, 143, 144, 146, 148, 149, 150, 151, 153, 155, 156, 157, 159, 160, 166, 167, 168, 170, 171, 173, 176, 179, 182, 183, 184, 185, 187, 189, 190], "notion": [1, 2, 4, 5, 9, 10, 11, 21, 39, 63, 69, 71, 78, 92, 95, 101, 108, 110, 131, 151, 153, 170, 171, 178, 183, 188], "when": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 83, 85, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 159, 167, 169, 170, 171, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190], "studi": [1, 3, 4, 5, 6, 10, 11, 25, 27, 43, 52, 59, 64, 74, 88, 92, 94, 101, 103, 114, 117, 119, 122, 130, 132, 145, 146, 153, 154, 157, 162, 164, 168, 187], "algebra": [1, 3, 4, 7, 9, 10, 22, 41, 42, 62, 78, 103, 104, 149, 151, 152, 155, 186, 191], "beginn": [1, 12, 19, 146, 149], "easi": [1, 7, 34, 35, 41, 42, 45, 64, 70, 73, 79, 80, 81, 82, 88, 92, 94, 95, 98, 103, 106, 108, 110, 120, 134, 138, 140, 141, 146, 149, 155, 157, 165, 178, 184, 186, 189], "overlook": [1, 94], "introduc": [1, 2, 3, 4, 5, 6, 8, 10, 11, 13, 18, 21, 22, 23, 24, 25, 27, 32, 35, 44, 45, 46, 47, 48, 49, 50, 53, 55, 58, 60, 61, 63, 64, 66, 69, 70, 73, 74, 76, 78, 79, 80, 81, 82, 83, 86, 87, 90, 92, 94, 95, 98, 100, 101, 103, 104, 105, 107, 108, 109, 111, 112, 113, 114, 116, 117, 118, 120, 123, 125, 126, 134, 140, 141, 143, 144, 146, 149, 151, 153, 154, 157, 158, 159, 160, 163, 165, 166, 167, 168, 169, 171, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 188], "convei": [1, 4, 63, 67, 92, 109, 148, 150, 157], "suppos": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 17, 23, 26, 27, 28, 47, 50, 56, 58, 59, 60, 61, 72, 77, 78, 79, 80, 91, 94, 95, 98, 103, 107, 116, 117, 120, 126, 129, 134, 140, 146, 148, 150, 151, 157, 168, 169, 171, 172, 173, 175, 176, 177, 180, 184, 188], "matrix": [1, 2, 3, 5, 8, 21, 27, 28, 34, 38, 39, 40, 41, 44, 47, 52, 56, 62, 63, 68, 69, 71, 72, 73, 74, 75, 78, 79, 80, 83, 92, 93, 94, 98, 100, 103, 104, 105, 107, 109, 110, 114, 115, 116, 126, 135, 136, 138, 140, 141, 144, 145, 146, 150, 151, 152, 155, 157, 158, 161, 162, 164, 165, 166, 167, 168, 170, 177, 178, 181, 183, 186, 191], "entri": [1, 2, 4, 7, 20, 22, 35, 72, 78, 90, 92, 93, 98, 99, 100, 103, 105, 107, 136, 138, 141, 146, 150, 153, 155, 156, 158, 159, 164, 165, 173, 177, 180, 183], "appli": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 20, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 82, 83, 86, 87, 92, 95, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 123, 124, 126, 130, 132, 138, 140, 141, 143, 144, 147, 149, 150, 151, 152, 153, 155, 156, 157, 158, 161, 169, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 188], "v": [1, 2, 7, 9, 19, 20, 21, 22, 26, 27, 41, 72, 77, 78, 92, 93, 101, 116, 120, 125, 126, 127, 129, 132, 134, 135, 138, 139, 140, 143, 144, 145, 146, 149, 150, 152, 153, 155, 157, 158, 159, 161, 163, 165, 168, 169, 178, 181, 186, 189, 190], "obtain": [1, 2, 4, 5, 6, 7, 9, 10, 11, 17, 21, 23, 25, 30, 35, 39, 40, 41, 42, 44, 47, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 69, 72, 76, 77, 80, 82, 83, 88, 92, 93, 94, 95, 98, 104, 107, 109, 110, 116, 120, 123, 124, 126, 129, 132, 134, 135, 137, 139, 141, 143, 144, 145, 146, 148, 151, 153, 157, 169, 170, 177, 180, 181, 183, 187, 188, 189, 190], "2x": [1, 2, 7, 10, 114, 141, 151], "intuit": [1, 2, 4, 5, 7, 9, 10, 11, 21, 24, 27, 35, 42, 47, 55, 62, 63, 64, 66, 67, 71, 77, 78, 79, 80, 81, 92, 98, 101, 107, 108, 110, 111, 113, 114, 129, 133, 138, 140, 141, 143, 145, 148, 149, 151, 153, 156, 157, 163, 173, 174, 175, 178, 184, 190], "interpret": [1, 2, 3, 6, 7, 9, 10, 19, 22, 24, 27, 38, 43, 63, 64, 71, 79, 81, 91, 92, 95, 98, 103, 108, 111, 114, 130, 144, 150, 151, 154, 157, 186, 191], "stretch": [1, 5, 92, 145], "twice": [1, 2, 5, 10, 42, 48, 95, 104, 127, 129, 140, 144, 157, 176], "direct": [1, 2, 3, 5, 7, 9, 10, 11, 23, 25, 39, 41, 46, 48, 56, 63, 71, 72, 74, 92, 103, 105, 109, 113, 114, 140, 141, 143, 145, 150, 151, 152, 157, 166, 170, 171, 178, 183, 184], "remain": [1, 2, 6, 7, 21, 22, 24, 25, 30, 34, 35, 41, 42, 44, 46, 47, 53, 57, 58, 60, 62, 63, 64, 67, 70, 72, 74, 77, 86, 89, 90, 92, 94, 95, 97, 98, 101, 110, 111, 116, 126, 127, 130, 139, 140, 143, 144, 149, 151, 154, 160, 164, 168, 175, 176, 179, 183, 185], "unchang": [1, 2, 21, 41, 42, 44, 58, 60, 61, 64, 69, 70, 72, 76, 94, 99, 110, 126, 127, 140, 144, 147, 153, 160, 175, 183], "sent": [1, 38, 46, 92, 103], "still": [1, 2, 4, 7, 8, 9, 10, 11, 12, 19, 21, 22, 25, 29, 31, 32, 35, 38, 39, 40, 41, 42, 44, 45, 46, 50, 60, 62, 64, 66, 71, 74, 76, 77, 78, 79, 80, 86, 89, 90, 92, 93, 95, 98, 99, 100, 103, 105, 106, 108, 111, 114, 116, 126, 127, 129, 138, 141, 144, 145, 146, 148, 149, 150, 155, 157, 158, 171, 173, 176, 179, 180, 183, 184, 185, 186, 188], "line": [1, 2, 5, 7, 9, 10, 12, 14, 17, 20, 25, 38, 40, 41, 42, 53, 56, 60, 62, 69, 72, 74, 78, 79, 80, 85, 91, 92, 95, 99, 100, 103, 104, 106, 110, 111, 114, 115, 119, 122, 127, 131, 133, 138, 140, 151, 153, 156, 157, 159, 164, 176, 185, 186], "onli": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 33, 34, 35, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 85, 86, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 123, 125, 126, 127, 129, 132, 133, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 153, 155, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181, 183, 184, 185, 186, 188, 189, 190], "modif": [1, 12, 32, 44, 66, 70, 88, 92, 107, 127, 155, 185], "them": [1, 2, 4, 7, 8, 9, 10, 11, 12, 14, 21, 22, 25, 27, 29, 30, 33, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 79, 80, 82, 86, 89, 90, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 113, 114, 115, 116, 120, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 138, 139, 140, 141, 144, 146, 149, 150, 153, 155, 156, 157, 164, 167, 168, 169, 176, 177, 180, 183, 184, 185, 189], "factor": [1, 2, 5, 7, 9, 10, 18, 19, 24, 25, 31, 33, 38, 43, 49, 51, 63, 64, 69, 71, 74, 78, 92, 94, 95, 98, 103, 104, 111, 144, 149, 153, 158, 162, 165, 166, 167, 177, 178, 184, 186, 187, 189, 190, 191], "respect": [1, 2, 4, 5, 7, 8, 21, 22, 25, 28, 30, 31, 35, 36, 37, 39, 41, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 86, 88, 92, 94, 96, 97, 98, 100, 101, 103, 105, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 129, 132, 133, 134, 135, 136, 138, 140, 141, 144, 146, 148, 149, 150, 151, 153, 155, 156, 157, 159, 164, 165, 166, 168, 169, 170, 177, 178, 180, 181, 184, 190], "gener": [1, 2, 4, 6, 7, 8, 9, 10, 12, 14, 17, 19, 20, 22, 23, 24, 25, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 66, 67, 69, 70, 72, 75, 76, 77, 78, 79, 80, 81, 85, 86, 87, 88, 90, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 105, 106, 108, 110, 112, 113, 114, 116, 117, 118, 121, 125, 126, 128, 129, 130, 133, 134, 136, 138, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 159, 160, 161, 162, 165, 166, 167, 168, 169, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191], "out": [1, 2, 4, 5, 7, 8, 9, 10, 12, 16, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 35, 37, 38, 41, 42, 44, 45, 46, 47, 53, 54, 59, 60, 63, 64, 66, 71, 72, 74, 75, 77, 78, 80, 85, 86, 91, 92, 94, 95, 96, 98, 100, 101, 103, 105, 107, 108, 109, 110, 111, 113, 114, 115, 116, 121, 122, 124, 127, 128, 130, 132, 135, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 164, 165, 168, 169, 170, 171, 173, 175, 176, 177, 182, 184, 185, 190], "subtract": [1, 2, 4, 5, 31, 50, 63, 99, 103, 136, 155, 183], "off": [1, 4, 5, 12, 39, 41, 62, 64, 66, 67, 69, 70, 71, 75, 77, 79, 83, 92, 94, 95, 98, 108, 111, 113, 116, 117, 127, 136, 139, 144, 150, 153, 157, 165, 169], "side": [1, 2, 4, 5, 9, 48, 61, 63, 75, 79, 98, 111, 114, 129, 136, 140, 141, 145, 149, 151, 155, 157, 159, 164, 183], "equival": [1, 2, 4, 5, 7, 21, 22, 35, 38, 42, 60, 71, 77, 80, 98, 103, 108, 110, 111, 114, 116, 117, 119, 123, 129, 134, 140, 146, 148, 151, 153, 155, 180, 181, 183, 185, 186, 190], "happen": [1, 2, 4, 5, 6, 7, 8, 9, 10, 21, 34, 35, 36, 38, 39, 42, 44, 45, 46, 62, 63, 68, 69, 71, 72, 74, 77, 78, 79, 80, 82, 83, 92, 94, 95, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 116, 137, 139, 141, 143, 144, 145, 146, 147, 149, 150, 151, 153, 155, 156, 157, 173, 181, 183, 184, 188, 189, 190], "must": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 25, 31, 34, 35, 39, 40, 42, 55, 60, 63, 69, 74, 92, 93, 94, 95, 96, 98, 101, 103, 104, 105, 108, 109, 110, 111, 114, 115, 119, 129, 146, 149, 153, 155, 156, 157, 176, 178, 179, 180, 183, 184, 185], "compress": [1, 2, 24, 27, 41, 63, 74, 98, 99, 132, 177, 180], "down": [1, 2, 3, 5, 7, 8, 9, 10, 20, 41, 48, 51, 66, 71, 74, 75, 78, 92, 96, 99, 101, 126, 130, 138, 141, 143, 144, 145, 157, 167, 170, 182, 183, 184, 185, 189, 190], "henc": [1, 4, 8, 10, 11, 12, 21, 22, 33, 34, 37, 39, 40, 41, 46, 61, 62, 63, 76, 83, 85, 86, 88, 89, 92, 94, 96, 98, 103, 104, 105, 108, 113, 126, 138, 139, 140, 141, 144, 145, 147, 148, 157, 170, 178, 180, 181, 183, 184], "invert": [1, 3, 4, 94, 103, 114, 141, 151], "determin": [1, 3, 4, 5, 7, 11, 21, 24, 34, 42, 47, 48, 55, 58, 60, 63, 64, 72, 77, 78, 79, 90, 91, 92, 94, 95, 98, 103, 105, 107, 111, 113, 115, 116, 117, 119, 120, 138, 141, 145, 147, 151, 152, 157, 170, 173, 174, 175, 181, 183, 185, 187], "det": [1, 2, 5, 78], "onc": [1, 2, 4, 5, 9, 12, 14, 20, 31, 34, 35, 38, 41, 42, 45, 46, 63, 79, 83, 85, 88, 89, 90, 92, 94, 95, 99, 101, 103, 104, 105, 106, 108, 109, 111, 141, 144, 146, 148, 149, 150, 153, 155, 157, 169, 177, 183, 186], "solv": [1, 2, 4, 5, 9, 10, 25, 64, 66, 68, 69, 78, 83, 92, 94, 95, 98, 100, 101, 103, 105, 114, 138, 139, 140, 145, 149, 153, 157, 161, 162, 181, 186, 187], "associ": [1, 5, 7, 12, 27, 28, 35, 38, 39, 46, 62, 70, 72, 78, 79, 80, 92, 94, 95, 96, 98, 103, 109, 114, 116, 120, 136, 138, 146, 148, 149, 151, 153, 157, 158, 161, 168, 170, 181, 185, 186, 190], "challeng": [1, 2, 9, 29, 46, 62, 66, 67, 68, 69, 74, 83, 85, 86, 92, 94, 95, 96, 98, 103, 106, 110, 111, 114, 115, 142, 149, 159, 164, 179, 184, 186], "polynomi": [1, 7, 10, 80, 81, 95, 108, 143, 148, 161], "equat": [1, 2, 7, 10, 11, 14, 21, 79, 80, 81, 92, 98, 105, 107, 108, 109, 114, 139, 141, 143, 145, 147, 149, 153, 157, 173, 175, 177, 184, 186], "4x": [1, 7, 10, 78, 151], "4y": 1, "check": [1, 2, 6, 7, 8, 12, 14, 19, 20, 22, 27, 31, 36, 41, 48, 71, 75, 78, 85, 90, 91, 92, 96, 98, 105, 107, 111, 113, 140, 148, 153, 156, 157, 160, 161, 163, 165, 180, 183, 184], "code": [1, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 22, 25, 27, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 50, 51, 53, 54, 61, 62, 63, 69, 70, 72, 74, 75, 76, 77, 78, 79, 81, 85, 86, 89, 90, 92, 93, 95, 98, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 119, 124, 126, 127, 133, 143, 144, 150, 151, 153, 154, 155, 158, 159, 161, 165, 168, 171, 173, 175, 176, 177, 181, 182, 183, 186, 189, 190], "built": [1, 2, 4, 8, 19, 31, 32, 37, 42, 44, 67, 72, 76, 92, 96, 99, 100, 103, 104, 105, 106, 107, 111, 115, 126, 143, 145, 153, 155, 171, 175], "linalg": [1, 2, 78, 150, 153, 186], "eig": 1, "routin": [1, 31, 45, 63, 78, 92, 108, 138, 151, 155, 156], "float64": [1, 2], "length": [1, 2, 4, 7, 8, 9, 22, 23, 24, 25, 28, 29, 30, 55, 56, 57, 58, 61, 63, 74, 78, 79, 80, 82, 92, 98, 100, 103, 107, 109, 115, 119, 120, 121, 122, 124, 125, 126, 127, 128, 132, 133, 134, 139, 140, 150, 153, 155, 157, 169, 171, 172, 174, 175, 177, 178, 179, 180, 183, 184, 185], "wherea": [1, 4, 9, 11, 41, 63, 68, 70, 90, 92, 95, 107, 108, 138, 140, 141, 144, 145, 146, 150, 153, 155, 157, 175, 180, 184, 189], "took": [1, 57, 62, 92, 94, 95, 98, 99, 105, 116, 144, 151, 157, 161, 187, 188], "addition": [1, 4, 36, 37, 46, 58, 63, 79, 90, 94, 104, 110, 157, 175], "sign": [1, 2, 3, 4, 9, 14, 16, 92, 98, 139, 141, 146, 153, 158, 188], "parallel": [1, 2, 24, 26, 28, 29, 35, 38, 39, 43, 45, 62, 66, 70, 73, 86, 88, 89, 90, 92, 106, 121, 139, 144, 150, 158, 160, 186, 191], "ones": [1, 2, 6, 7, 9, 11, 14, 20, 22, 23, 26, 28, 29, 30, 38, 39, 41, 44, 47, 55, 63, 64, 69, 71, 72, 83, 85, 89, 90, 95, 96, 102, 103, 108, 110, 114, 119, 127, 133, 135, 138, 140, 146, 147, 150, 153, 154, 155, 157, 164, 165, 169, 176, 180, 183, 184, 188, 189], "found": [1, 2, 4, 11, 19, 25, 38, 41, 45, 46, 62, 64, 72, 78, 85, 91, 92, 101, 104, 111, 114, 143, 148, 149, 164, 190], "hand": [1, 2, 4, 5, 7, 10, 11, 21, 41, 42, 47, 62, 66, 69, 78, 79, 86, 89, 90, 92, 94, 95, 101, 103, 109, 111, 113, 114, 117, 120, 126, 127, 129, 136, 138, 141, 142, 144, 148, 149, 150, 151, 153, 155, 157, 158, 160, 162, 167, 169, 187], "continu": [1, 3, 4, 5, 7, 12, 14, 25, 28, 39, 47, 51, 56, 60, 62, 63, 72, 75, 78, 80, 81, 88, 89, 90, 92, 94, 95, 96, 108, 109, 111, 113, 114, 116, 117, 120, 125, 127, 130, 132, 133, 138, 141, 142, 149, 153, 157, 158, 159, 169, 178, 180, 183, 184, 188], "step": [1, 2, 7, 9, 10, 12, 14, 17, 18, 20, 23, 24, 25, 28, 29, 37, 39, 42, 45, 46, 47, 51, 52, 53, 54, 56, 58, 60, 62, 63, 64, 68, 70, 75, 78, 80, 83, 91, 92, 94, 99, 100, 103, 105, 108, 109, 113, 115, 120, 121, 122, 123, 124, 125, 126, 128, 134, 135, 137, 139, 141, 143, 144, 145, 147, 148, 150, 151, 155, 156, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186, 188, 189], "further": [1, 5, 7, 8, 9, 10, 11, 18, 22, 23, 25, 30, 36, 41, 42, 43, 46, 49, 50, 53, 54, 55, 58, 60, 62, 63, 64, 66, 68, 69, 75, 79, 80, 82, 88, 89, 92, 95, 98, 101, 111, 114, 115, 116, 117, 121, 123, 126, 129, 143, 145, 150, 155, 156, 157, 164, 165, 172, 177, 178, 183, 184, 185, 189], "w": [1, 2, 7, 9, 10, 20, 30, 33, 34, 35, 47, 48, 49, 54, 55, 56, 57, 58, 60, 61, 63, 71, 72, 75, 76, 77, 80, 82, 83, 96, 98, 100, 103, 104, 105, 107, 108, 109, 114, 116, 123, 125, 131, 132, 133, 134, 135, 138, 140, 144, 145, 148, 153, 155, 156, 158, 160, 161, 165, 168, 170, 171, 173, 175, 178, 181, 186], "column": [1, 2, 5, 7, 9, 21, 22, 27, 28, 47, 53, 55, 56, 61, 72, 73, 74, 75, 77, 92, 94, 100, 103, 113, 135, 136, 144, 150, 153, 155, 156, 157, 158, 159, 164, 177, 179, 181], "diagon": [1, 2, 63, 69, 71, 72, 78, 79, 136, 138, 141, 145, 153, 157], "tell": [1, 2, 4, 5, 6, 7, 9, 10, 34, 41, 56, 62, 78, 79, 83, 92, 95, 101, 104, 116, 138, 144, 149, 150, 151, 153, 155, 157, 184], "multipli": [1, 2, 5, 6, 7, 8, 9, 11, 17, 21, 22, 28, 29, 39, 41, 53, 54, 58, 61, 71, 72, 83, 103, 108, 109, 116, 123, 140, 144, 145, 151, 153, 157, 178, 181, 184], "consequ": [1, 19, 23, 27, 34, 40, 41, 62, 63, 64, 69, 70, 73, 76, 77, 92, 94, 96, 100, 104, 109, 110, 114, 116, 125, 138, 141, 145, 146, 157, 178, 184], "decomposit": [1, 2, 3, 7, 11, 46, 78, 98, 120, 153, 190], "exist": [1, 2, 4, 5, 7, 9, 11, 20, 31, 34, 38, 42, 45, 51, 62, 64, 69, 83, 86, 92, 94, 104, 105, 107, 113, 114, 116, 126, 130, 135, 140, 142, 146, 148, 151, 164, 166, 167, 171, 173], "full": [1, 2, 3, 8, 9, 10, 28, 41, 42, 44, 46, 47, 53, 54, 63, 66, 69, 73, 78, 88, 89, 90, 92, 103, 105, 106, 141, 144, 146, 147, 148, 149, 150, 168, 184, 187, 189], "linearli": [1, 2, 19, 26, 28, 30, 44, 46, 64, 103, 104, 105, 114, 125, 138, 147, 148], "9": [1, 2, 4, 6, 8, 9, 10, 11, 12, 25, 28, 41, 47, 49, 53, 54, 56, 58, 59, 60, 61, 63, 64, 66, 70, 71, 77, 79, 82, 91, 92, 95, 118, 121, 123, 125, 126, 128, 129, 130, 131, 133, 134, 135, 137, 139, 140, 143, 144, 145, 147, 148, 149, 153, 155, 168, 169, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189], "cleanli": [1, 2, 4, 111], "overbrac": 1, "posit": [1, 4, 5, 6, 9, 10, 11, 23, 24, 29, 30, 41, 47, 48, 49, 50, 51, 55, 57, 58, 60, 61, 62, 63, 71, 72, 75, 77, 78, 86, 92, 94, 98, 99, 103, 109, 114, 117, 122, 123, 124, 125, 126, 127, 133, 134, 136, 140, 141, 145, 146, 148, 153, 155, 157, 162, 165, 166, 167, 180, 183, 186, 191], "rais": [1, 20, 21, 23, 85, 92, 94, 96, 106, 116, 133, 172, 182], "neg": [1, 2, 3, 4, 5, 7, 9, 10, 11, 22, 47, 50, 60, 64, 77, 78, 82, 92, 95, 98, 99, 100, 103, 114, 117, 122, 124, 130, 135, 141, 146, 155, 157, 162, 166, 183], "non": [1, 2, 4, 5, 6, 7, 9, 11, 20, 23, 27, 40, 41, 42, 52, 53, 58, 60, 61, 62, 69, 78, 80, 82, 92, 94, 101, 111, 125, 126, 129, 133, 135, 145, 148, 152, 157, 158, 160, 161, 164, 165, 166, 176, 184, 186, 188, 190], "lambda_1": 1, "lambda_n": 1, "becaus": [1, 2, 4, 6, 7, 9, 22, 25, 28, 29, 30, 31, 34, 36, 38, 42, 47, 49, 50, 51, 54, 58, 60, 62, 63, 64, 71, 72, 73, 74, 75, 77, 78, 79, 82, 86, 88, 89, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 108, 110, 111, 113, 114, 116, 119, 124, 129, 135, 144, 148, 149, 150, 151, 153, 155, 157, 166, 169, 175, 178, 179, 181, 184, 185, 188, 189, 190], "whatev": [1, 2, 4, 5, 7, 23, 77, 103, 181, 184], "undo": [1, 2, 183], "multipl": [1, 2, 3, 6, 8, 9, 11, 12, 14, 18, 19, 20, 25, 26, 28, 29, 35, 36, 38, 39, 40, 41, 42, 43, 46, 48, 49, 50, 52, 55, 56, 58, 62, 63, 64, 65, 66, 69, 70, 72, 73, 74, 77, 85, 86, 88, 89, 95, 98, 99, 101, 103, 104, 106, 107, 109, 112, 113, 114, 115, 120, 123, 127, 129, 131, 134, 135, 143, 144, 145, 148, 150, 151, 152, 155, 156, 167, 170, 171, 173, 174, 175, 176, 177, 178, 181, 186, 189, 191], "volum": [1, 2, 5], "rank": [1, 3, 53, 63, 89, 92, 98, 103, 113, 117, 161, 162, 163, 167, 185, 186, 191], "your": [1, 3, 11, 12, 13, 14, 17, 18, 19, 21, 35, 38, 40, 41, 54, 62, 63, 64, 67, 71, 78, 85, 87, 88, 91, 92, 94, 95, 96, 98, 99, 100, 101, 104, 105, 106, 107, 109, 110, 112, 113, 114, 115, 116, 121, 143, 144, 149, 151, 152, 153, 154, 155, 156, 157, 167, 169, 182, 187], "hopefulli": [1, 37, 98, 178], "simplifi": [1, 6, 8, 21, 22, 23, 27, 30, 34, 35, 39, 47, 56, 62, 65, 66, 71, 74, 75, 77, 92, 93, 103, 106, 109, 112, 113, 117, 134, 138, 145, 153, 157, 173, 178, 181, 185, 186], "algorithm": [1, 2, 3, 4, 8, 10, 19, 23, 25, 41, 44, 45, 46, 47, 49, 51, 53, 54, 60, 62, 63, 64, 66, 71, 77, 81, 86, 87, 88, 90, 94, 96, 98, 99, 101, 102, 103, 106, 107, 108, 109, 111, 112, 114, 115, 116, 117, 127, 132, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 156, 158, 159, 161, 163, 180, 184, 186, 187, 188, 190, 191], "analysi": [1, 11, 25, 39, 70, 71, 73, 88, 92, 95, 103, 108, 111, 114, 117, 118, 119, 126, 132, 138, 140, 142, 149, 179, 186, 191], "do": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 22, 28, 29, 30, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 50, 51, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 76, 77, 78, 79, 80, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 120, 125, 127, 128, 131, 132, 136, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 163, 167, 172, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188], "alwai": [1, 2, 4, 5, 7, 8, 9, 10, 11, 21, 24, 25, 29, 33, 34, 48, 62, 69, 71, 76, 77, 82, 89, 92, 93, 95, 98, 100, 101, 106, 108, 111, 113, 114, 115, 126, 141, 153, 155, 163, 167, 175, 180, 181, 183, 184], "enough": [1, 2, 9, 10, 11, 18, 19, 23, 28, 34, 35, 37, 41, 62, 63, 72, 91, 92, 95, 96, 98, 101, 103, 111, 113, 114, 126, 138, 140, 141, 143, 144, 145, 152, 157, 180], "process": [1, 4, 5, 7, 9, 11, 12, 14, 20, 22, 24, 25, 27, 28, 29, 30, 35, 36, 37, 39, 41, 42, 44, 47, 49, 56, 62, 64, 66, 68, 69, 70, 72, 74, 76, 77, 83, 85, 86, 87, 90, 92, 94, 96, 98, 101, 103, 104, 105, 107, 111, 113, 115, 117, 120, 121, 122, 123, 126, 128, 131, 132, 134, 139, 143, 144, 145, 149, 150, 155, 156, 157, 158, 160, 167, 168, 169, 174, 176, 177, 179, 180, 181, 183, 184, 186, 187, 189, 190, 191], "instanc": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 19, 21, 22, 23, 27, 29, 30, 31, 35, 36, 37, 38, 40, 41, 42, 44, 45, 46, 49, 50, 51, 52, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 86, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 126, 129, 130, 131, 132, 133, 138, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 159, 170, 171, 175, 176, 180, 184, 185, 191], "singl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 19, 22, 24, 25, 26, 29, 30, 35, 38, 39, 40, 41, 42, 44, 45, 46, 52, 58, 62, 63, 64, 65, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 83, 88, 89, 90, 92, 95, 98, 99, 101, 103, 104, 106, 108, 109, 110, 114, 115, 116, 118, 119, 120, 123, 126, 128, 132, 141, 144, 146, 149, 151, 154, 155, 156, 157, 166, 168, 169, 171, 177, 178, 179, 180, 181, 183, 184, 185, 186, 191], "handl": [1, 7, 9, 31, 34, 35, 41, 44, 47, 68, 74, 75, 77, 92, 102, 106, 108, 110, 113, 114, 126, 140, 150, 156, 167, 170, 172, 175, 177, 178, 179, 184, 189], "advanc": [1, 16, 22, 25, 32, 41, 42, 52, 67, 74, 78, 81, 86, 87, 88, 92, 95, 96, 98, 113, 141, 143, 148, 149, 150, 153, 156, 157, 159, 162, 167, 176, 179, 182, 183, 186, 187], "cover": [1, 20, 27, 34, 36, 41, 47, 49, 51, 52, 53, 59, 62, 63, 64, 67, 76, 77, 78, 98, 99, 103, 105, 111, 113, 118, 130, 131, 143, 145, 149, 153, 162, 176, 177, 179, 184, 186], "jordan": 1, "singular": [1, 2, 78, 92, 117], "restrict": [1, 2, 12, 37, 77, 94, 95, 101, 103, 108, 111, 157, 186, 188], "attent": [1, 2, 20, 25, 27, 29, 30, 64, 74, 76, 78, 92, 95, 114, 117, 118, 121, 126, 128, 146, 149, 156, 157, 159, 163, 175, 177, 184, 186, 191], "those": [1, 2, 7, 9, 11, 19, 25, 27, 29, 30, 32, 35, 36, 42, 43, 47, 49, 50, 54, 56, 57, 58, 60, 62, 63, 65, 68, 69, 70, 74, 75, 77, 79, 80, 92, 94, 98, 100, 101, 103, 105, 109, 110, 111, 112, 114, 117, 118, 121, 125, 127, 128, 133, 136, 143, 146, 147, 149, 150, 156, 157, 159, 163, 171, 180, 181], "guarante": [1, 9, 10, 35, 59, 63, 69, 78, 92, 94, 95, 98, 101, 111, 138, 141, 143, 146, 148, 157, 169, 186], "famili": [1, 2, 3, 27, 64, 68, 70, 73, 77, 92, 96, 98], "orthogon": [1, 2, 72, 115, 138, 145], "angl": [1, 3, 7, 9, 50, 134, 153], "anoth": [1, 2, 4, 5, 7, 9, 13, 22, 25, 26, 28, 36, 39, 41, 46, 47, 48, 50, 51, 56, 61, 62, 63, 64, 69, 75, 76, 77, 79, 83, 86, 90, 92, 94, 98, 101, 103, 110, 111, 114, 115, 116, 117, 119, 129, 132, 137, 138, 141, 143, 146, 150, 154, 156, 157, 159, 165, 167, 168, 169, 170, 172, 175, 176, 178, 179, 183, 185, 188, 190], "special": [1, 2, 4, 22, 25, 27, 30, 34, 35, 41, 62, 66, 67, 69, 72, 76, 77, 81, 92, 94, 95, 98, 108, 113, 114, 116, 117, 119, 121, 123, 126, 127, 128, 131, 132, 141, 151, 153, 154, 155, 156, 157, 169, 175, 176, 177, 178, 183, 184, 185, 190], "difficult": [1, 4, 5, 8, 10, 17, 27, 38, 41, 44, 55, 60, 63, 68, 77, 86, 88, 92, 93, 94, 95, 98, 99, 101, 103, 105, 114, 115, 138, 140, 148, 149, 151, 161, 177, 180, 184, 186], "present": [1, 4, 19, 24, 25, 29, 35, 41, 44, 48, 63, 65, 67, 76, 87, 92, 95, 103, 106, 111, 131, 149, 151, 159, 171, 176, 180], "said": [1, 6, 19, 41, 42, 44, 52, 64, 68, 70, 72, 76, 78, 92, 95, 101, 103, 151, 157, 181, 183], "without": [1, 2, 3, 5, 6, 9, 11, 12, 22, 23, 25, 27, 29, 30, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 54, 58, 60, 62, 63, 64, 69, 70, 75, 77, 78, 80, 81, 83, 86, 88, 92, 94, 95, 98, 99, 103, 104, 105, 106, 107, 114, 116, 118, 120, 125, 126, 130, 132, 134, 137, 139, 141, 143, 144, 145, 147, 148, 149, 151, 153, 155, 157, 164, 168, 171, 175, 177, 178, 179, 180, 183, 184, 186, 188, 189], "largest": [1, 2, 9, 25, 47, 57, 58, 62, 66, 92, 93, 95, 98, 99, 100, 101, 138, 169, 188, 190], "a_": [1, 2, 7, 47, 78, 132, 153, 178], "ij": [1, 2, 4, 5, 7, 9, 47, 56, 78, 79, 80, 94, 100, 103, 116, 120, 129, 136, 138, 141, 144, 146, 153], "squar": [1, 2, 5, 7, 9, 17, 20, 22, 25, 29, 33, 41, 53, 54, 56, 60, 63, 72, 77, 78, 92, 98, 101, 102, 104, 105, 108, 109, 113, 117, 129, 136, 137, 138, 139, 144, 147, 148, 151, 153, 157, 158, 163], "r_i": [1, 90], "j": [1, 2, 4, 5, 7, 9, 22, 23, 24, 27, 29, 31, 46, 47, 56, 60, 61, 64, 72, 75, 76, 77, 79, 80, 82, 94, 98, 99, 103, 107, 109, 113, 116, 117, 120, 125, 129, 132, 134, 136, 138, 144, 149, 153, 155, 157, 161, 165, 166, 168, 177, 178, 186], "neq": [1, 4, 63, 94, 95, 98, 125, 134, 138, 141, 151, 153, 157], "disc": 1, "plane": [1, 2, 5, 77, 117], "ii": [1, 2, 8, 11, 23, 25, 35, 56, 60, 62, 63, 64, 68, 70, 74, 80, 92, 98, 100, 103, 104, 105, 106, 111, 116, 117, 126, 127, 138, 149, 150, 151, 152, 155, 157, 169, 175, 181, 184, 185, 190], "radiu": [1, 63, 140, 151, 183], "contain": [1, 2, 4, 5, 7, 8, 9, 11, 17, 20, 27, 28, 29, 34, 35, 36, 37, 41, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 61, 62, 63, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 88, 91, 92, 93, 94, 95, 96, 98, 99, 101, 103, 104, 105, 106, 109, 110, 113, 114, 115, 119, 121, 122, 123, 125, 127, 131, 132, 133, 134, 136, 138, 140, 149, 150, 151, 153, 155, 156, 164, 168, 169, 173, 175, 177, 180, 182, 184, 185, 187, 189, 190], "bit": [1, 3, 4, 5, 6, 7, 8, 9, 10, 14, 19, 21, 22, 28, 36, 38, 39, 41, 46, 47, 51, 62, 64, 69, 71, 74, 83, 96, 98, 99, 103, 114, 116, 140, 141, 143, 144, 148, 150, 159, 178, 180], "unpack": [1, 34, 105], "r_1": [1, 47, 188, 190], "r_2": [1, 47, 188], "r_3": 1, "r_4": 1, "33": [1, 60, 98, 186], "44": [1, 4, 92, 98, 186], "99": [1, 9, 41, 86, 95, 157, 186, 188], "97": [1, 157, 186], "95": [1, 11, 47, 78, 79, 85, 95, 96, 145, 146, 147, 186, 189, 190], "08": [1, 47, 54, 79], "comfort": [1, 9, 11, 92, 111], "insid": [1, 5, 7, 9, 11, 35, 38, 45, 48, 53, 63, 74, 88, 90, 94, 99, 100, 140, 148, 150, 151, 155, 190], "_": [1, 2, 5, 6, 7, 8, 9, 11, 20, 21, 23, 27, 29, 30, 31, 33, 39, 40, 46, 47, 51, 53, 56, 57, 59, 60, 63, 64, 65, 69, 70, 74, 75, 77, 78, 82, 86, 90, 93, 95, 100, 103, 104, 105, 109, 116, 120, 124, 125, 126, 128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 144, 145, 147, 148, 151, 153, 154, 157, 158, 160, 161, 163, 164, 165, 166, 168, 169, 170, 171, 173, 175, 176, 177, 178, 181, 182, 183, 184, 188, 189, 190], "eigh": 1, "fairli": [1, 7, 9, 21, 62, 69, 89, 92, 103, 106, 113, 137, 139, 141, 143, 157, 178, 180], "accur": [1, 9, 11, 47, 48, 58, 62, 64, 69, 72, 73, 92, 94, 99, 101, 103, 105, 111, 113, 134, 138, 157, 178, 180, 184, 186], "significantli": [1, 7, 9, 19, 25, 41, 46, 50, 62, 63, 64, 65, 66, 68, 70, 74, 78, 90, 92, 94, 101, 103, 109, 112, 114, 121, 125, 126, 128, 133, 138, 144, 145, 148, 157, 173, 175, 176, 184, 185], "larger": [1, 2, 9, 11, 19, 25, 30, 35, 38, 41, 44, 45, 49, 50, 53, 54, 55, 56, 60, 61, 62, 63, 64, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 88, 90, 91, 95, 98, 99, 101, 103, 108, 109, 111, 113, 115, 121, 124, 127, 129, 132, 138, 139, 145, 148, 155, 157, 176, 178, 185, 189], "topic": [1, 2, 3, 9, 11, 24, 66, 78, 92, 94, 95, 98, 103, 111, 116, 119, 149, 151, 184, 186], "grasp": [1, 112, 149], "understand": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 25, 36, 39, 41, 42, 59, 63, 65, 67, 69, 71, 72, 74, 79, 80, 81, 85, 92, 96, 98, 99, 101, 102, 105, 109, 111, 119, 126, 130, 139, 140, 141, 142, 145, 149, 153, 173, 180, 186], "principl": [1, 3, 4, 10, 30, 60, 63, 64, 77, 86, 92, 94, 95, 101, 103, 111, 142, 148, 149, 151, 177, 178, 184, 186, 187], "problem": [1, 2, 3, 4, 5, 6, 7, 8, 11, 22, 25, 27, 35, 39, 41, 43, 50, 54, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 75, 76, 77, 78, 80, 82, 83, 85, 87, 93, 95, 96, 97, 98, 99, 100, 101, 103, 105, 107, 108, 111, 113, 114, 115, 116, 117, 118, 119, 121, 122, 137, 138, 139, 140, 141, 142, 146, 147, 148, 149, 150, 151, 153, 154, 156, 157, 159, 161, 162, 163, 168, 169, 172, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 186, 187, 188, 190, 191], "neural": [1, 2, 4, 7, 10, 24, 27, 32, 34, 35, 36, 49, 50, 51, 52, 53, 55, 60, 63, 64, 69, 70, 71, 72, 77, 78, 79, 81, 83, 86, 87, 88, 90, 92, 95, 98, 100, 101, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 118, 134, 141, 143, 149, 151, 153, 155, 158, 160, 162, 167, 168, 172, 175, 176, 178, 180, 184, 185, 186, 189, 191], "network": [1, 2, 4, 7, 8, 10, 12, 19, 24, 27, 30, 31, 32, 34, 35, 36, 37, 40, 42, 43, 46, 50, 51, 52, 53, 54, 55, 56, 58, 71, 72, 75, 76, 77, 78, 79, 81, 86, 87, 88, 89, 90, 92, 94, 95, 96, 98, 99, 100, 101, 104, 105, 106, 108, 110, 112, 113, 114, 115, 116, 118, 126, 134, 138, 141, 143, 144, 147, 148, 149, 150, 151, 153, 155, 158, 160, 165, 167, 168, 172, 175, 176, 178, 180, 184, 186, 187, 189, 191], "proper": [1, 8, 25, 26, 33, 41, 63, 85, 91, 92, 101, 117, 138, 139, 145, 156, 157, 171, 175], "initi": [1, 6, 7, 10, 11, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 40, 42, 43, 44, 47, 51, 52, 53, 54, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 78, 79, 82, 83, 85, 86, 88, 89, 90, 91, 92, 95, 99, 100, 103, 104, 105, 106, 108, 109, 110, 111, 112, 120, 121, 123, 124, 126, 128, 129, 132, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 150, 153, 155, 157, 158, 160, 161, 163, 165, 168, 171, 177, 178, 182, 183, 184, 186, 190, 191], "investig": [1, 4, 9, 51, 52, 64, 80, 95, 105, 119, 123, 150, 157, 167], "text": [1, 2, 4, 10, 14, 17, 20, 21, 23, 25, 27, 28, 29, 30, 31, 47, 56, 59, 73, 77, 92, 94, 96, 100, 111, 118, 119, 120, 121, 122, 123, 125, 126, 129, 130, 133, 134, 146, 149, 150, 156, 162, 169, 170, 171, 176, 178, 179, 180, 181, 183, 184, 186, 191], "toi": [1, 4, 22, 26, 39, 43, 86, 142, 148, 150], "version": [1, 2, 4, 7, 8, 14, 18, 25, 29, 30, 31, 38, 41, 62, 63, 65, 66, 69, 76, 91, 92, 96, 98, 99, 104, 107, 108, 114, 117, 121, 128, 131, 140, 141, 143, 148, 149, 157, 163, 164, 165, 169, 173, 174, 186, 187, 189, 190], "help": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 17, 27, 39, 40, 41, 50, 56, 75, 78, 79, 81, 82, 85, 92, 94, 102, 105, 107, 108, 109, 111, 113, 114, 117, 126, 132, 138, 140, 141, 146, 149, 154, 156, 157, 158, 159, 162, 167, 173, 174, 175, 180, 182, 186], "interspers": [1, 38, 106], "layer": [1, 2, 7, 22, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 50, 51, 52, 54, 55, 56, 58, 61, 62, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 80, 82, 83, 85, 86, 88, 89, 92, 93, 97, 98, 99, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 115, 116, 117, 120, 121, 123, 124, 126, 128, 143, 144, 146, 149, 153, 158, 160, 165, 168, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 183, 186, 191], "transform": [1, 3, 5, 8, 20, 22, 23, 26, 27, 35, 36, 42, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 74, 82, 92, 96, 98, 103, 105, 107, 108, 113, 114, 115, 116, 117, 121, 122, 123, 124, 128, 130, 133, 135, 149, 150, 153, 155, 158, 160, 165, 170, 172, 175, 177, 178, 179, 184, 185, 186, 191], "simplic": [1, 4, 5, 6, 9, 11, 21, 47, 49, 60, 72, 78, 86, 90, 92, 94, 104, 106, 109, 110, 113, 114, 127, 141, 143, 144, 168, 185], "repeat": [1, 2, 6, 7, 10, 22, 23, 26, 29, 35, 42, 47, 58, 66, 67, 70, 79, 85, 90, 92, 105, 126, 144, 148, 151, 157, 177, 178, 183], "taken": [1, 2, 3, 5, 7, 8, 9, 25, 30, 38, 39, 41, 44, 50, 56, 64, 72, 74, 77, 79, 92, 94, 98, 101, 103, 108, 110, 114, 129, 149, 150, 157, 188, 190], "gaussian": [1, 3, 4, 6, 21, 22, 30, 33, 74, 82, 83, 86, 92, 100, 103, 108, 110, 114, 116, 126, 153, 155, 157, 173, 175, 186, 191], "distribut": [1, 3, 4, 6, 11, 20, 21, 25, 27, 33, 34, 38, 40, 43, 46, 47, 54, 55, 60, 63, 67, 69, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 92, 93, 95, 97, 98, 101, 102, 105, 107, 108, 110, 111, 114, 116, 117, 125, 129, 133, 136, 140, 143, 146, 147, 148, 154, 155, 157, 164, 166, 173, 175, 177, 180, 181, 184, 185, 186, 188, 190, 191], "manual_se": [1, 4, 11], "42": [1, 25, 33, 41, 115], "randn": [1, 9, 11, 21, 30, 31, 37, 39, 42, 44, 65, 69, 74, 78, 107, 108, 115, 126, 144, 150, 155, 173, 175, 181, 183, 184], "seed": [1, 4, 11, 20, 85, 110, 189, 190], "8675309": [1, 6, 11], "feed": [1, 24, 25, 28, 30, 31, 61, 62, 73, 74, 83, 85, 92, 113, 114, 120, 121, 123, 124, 126, 153, 155, 156, 170, 175, 177, 181, 183], "five": [1, 47, 55, 58, 59, 60, 62, 66, 70, 92, 101, 110, 114, 127, 164, 168, 169, 180, 183], "dimension": [1, 2, 3, 4, 5, 8, 11, 21, 22, 23, 28, 29, 34, 35, 48, 49, 55, 59, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 82, 86, 92, 94, 95, 98, 99, 102, 103, 104, 107, 109, 111, 114, 115, 118, 120, 124, 131, 134, 136, 140, 142, 146, 151, 152, 153, 155, 158, 161, 181, 183], "ml": [1, 2, 7, 18, 81, 86, 164, 186], "turn": [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 17, 22, 23, 35, 41, 42, 46, 63, 64, 66, 71, 72, 77, 83, 92, 94, 95, 98, 100, 101, 103, 105, 109, 111, 112, 114, 116, 140, 146, 148, 151, 157, 169, 171, 173, 178, 180, 186, 188, 190], "input": [1, 2, 6, 7, 8, 10, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 41, 42, 44, 45, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 86, 89, 90, 92, 94, 95, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 119, 120, 121, 123, 124, 127, 128, 130, 131, 132, 133, 135, 141, 144, 146, 150, 151, 153, 155, 156, 157, 158, 160, 161, 165, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 191], "imag": [1, 2, 4, 8, 9, 12, 14, 20, 21, 24, 25, 27, 28, 30, 31, 34, 41, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 60, 62, 63, 64, 66, 68, 71, 73, 74, 75, 76, 77, 78, 80, 82, 83, 92, 94, 95, 97, 98, 99, 100, 101, 107, 110, 111, 114, 115, 120, 123, 144, 149, 151, 153, 156, 168, 179, 184, 186, 191], "predict": [1, 2, 4, 8, 10, 11, 19, 20, 23, 25, 26, 29, 35, 36, 37, 41, 45, 46, 51, 52, 53, 54, 55, 58, 59, 65, 66, 68, 75, 77, 79, 80, 81, 82, 83, 92, 93, 94, 95, 97, 98, 101, 102, 105, 108, 109, 110, 111, 112, 114, 117, 120, 121, 123, 124, 128, 129, 130, 134, 135, 149, 153, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 179, 180, 181, 183, 186, 187, 191], "pictur": [1, 2, 9, 30, 74, 92, 94, 95, 101, 103, 111, 130, 190], "cat": [1, 2, 20, 23, 29, 30, 47, 48, 51, 53, 59, 60, 65, 66, 74, 76, 77, 82, 83, 86, 91, 92, 94, 98, 111, 113, 114, 120, 123, 124, 132, 155, 170, 177, 180, 181, 186], "veri": [1, 2, 9, 11, 17, 19, 21, 22, 23, 28, 29, 31, 37, 41, 42, 44, 46, 60, 62, 63, 64, 68, 69, 70, 74, 77, 78, 79, 80, 83, 86, 92, 94, 96, 98, 99, 100, 101, 103, 105, 106, 113, 114, 116, 124, 128, 130, 133, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 156, 157, 160, 170, 171, 178, 180, 181, 183, 185, 186, 188, 190], "chang": [1, 2, 3, 6, 7, 9, 10, 12, 16, 17, 18, 20, 22, 24, 27, 29, 30, 33, 34, 35, 36, 39, 42, 44, 47, 49, 50, 54, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 74, 76, 78, 79, 80, 82, 83, 88, 91, 92, 94, 98, 100, 103, 104, 106, 107, 108, 109, 110, 111, 115, 117, 118, 119, 126, 129, 133, 137, 138, 141, 143, 144, 145, 148, 149, 150, 151, 153, 155, 157, 158, 160, 167, 169, 170, 175, 178, 183, 184, 185, 186, 188, 190], "amplifi": 1, "tini": [1, 2, 5, 10, 41, 45, 62, 63, 183, 186], "lead": [1, 2, 7, 8, 9, 10, 11, 21, 22, 25, 27, 30, 31, 39, 42, 44, 47, 50, 54, 56, 58, 63, 64, 65, 69, 71, 72, 77, 78, 80, 86, 87, 88, 89, 92, 94, 98, 99, 101, 103, 104, 105, 108, 109, 111, 113, 114, 120, 129, 132, 133, 138, 139, 140, 141, 143, 145, 148, 150, 153, 157, 161, 167, 168, 173, 175, 178, 180, 182, 183, 184, 186], "seem": [1, 2, 5, 8, 10, 11, 19, 34, 42, 46, 62, 63, 71, 77, 78, 79, 80, 92, 95, 103, 109, 111, 116, 141, 145, 149, 169, 170, 179, 188], "On": [1, 4, 7, 9, 11, 14, 22, 26, 39, 41, 42, 44, 47, 59, 62, 63, 69, 79, 85, 86, 89, 90, 91, 92, 94, 95, 101, 109, 111, 113, 116, 117, 126, 127, 129, 138, 142, 144, 148, 149, 157, 158, 167, 169, 179, 183, 186], "shrink": [1, 21, 27, 65, 108, 111, 151, 183], "after": [1, 2, 6, 9, 10, 11, 12, 14, 17, 18, 21, 22, 23, 25, 26, 29, 30, 34, 36, 37, 39, 41, 42, 44, 46, 47, 48, 50, 51, 53, 54, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 85, 86, 88, 89, 90, 92, 94, 95, 99, 101, 103, 106, 107, 109, 110, 111, 113, 114, 116, 119, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 138, 140, 141, 143, 144, 145, 148, 149, 150, 153, 155, 157, 158, 164, 168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 189, 190], "run": [1, 2, 9, 11, 13, 14, 16, 19, 25, 34, 36, 37, 38, 40, 41, 42, 45, 46, 51, 62, 63, 64, 66, 72, 74, 75, 77, 78, 79, 81, 85, 86, 88, 89, 90, 92, 95, 96, 100, 103, 105, 106, 108, 109, 110, 112, 119, 127, 128, 133, 137, 144, 150, 153, 154, 155, 157, 164, 168, 169, 171, 173, 175, 177, 181, 182, 183, 186, 189, 190], "essenti": [1, 2, 7, 9, 10, 11, 12, 29, 41, 45, 49, 55, 71, 76, 78, 79, 80, 92, 111, 115, 138, 143, 144, 147, 153, 158, 159, 178], "also": [1, 2, 4, 5, 7, 8, 9, 10, 11, 15, 17, 18, 19, 21, 24, 25, 27, 28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 101, 103, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 123, 124, 126, 128, 129, 131, 132, 133, 134, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 171, 173, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 187, 188, 189, 190], "clearli": [1, 6, 8, 9, 21, 24, 27, 39, 41, 64, 69, 79, 92, 95, 111, 139, 140, 148, 149, 158, 164, 166, 180, 184], "either": [1, 2, 4, 6, 7, 8, 9, 11, 21, 22, 28, 29, 40, 41, 42, 44, 50, 60, 61, 62, 69, 72, 75, 76, 77, 79, 86, 88, 89, 91, 92, 94, 98, 101, 103, 111, 113, 114, 116, 118, 121, 122, 126, 138, 140, 144, 156, 157, 164, 167, 176, 183, 184], "walk": [1, 9, 14, 73, 78, 81, 92, 106, 113, 133, 141, 157], "narrow": [1, 11, 19, 21, 41, 70, 78, 79, 92, 145, 149], "between": [1, 2, 4, 5, 7, 8, 9, 11, 14, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 76, 77, 79, 83, 85, 86, 88, 90, 92, 94, 95, 96, 98, 101, 103, 106, 108, 110, 111, 113, 114, 115, 119, 120, 125, 126, 127, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 143, 144, 145, 146, 148, 151, 153, 157, 161, 163, 165, 166, 168, 169, 171, 175, 176, 177, 178, 180, 181, 184, 186, 187, 189], "decai": [1, 62, 63, 86, 95, 101, 102, 109, 110, 111, 113, 138, 140, 143, 144, 148, 163, 165, 184, 185, 191], "sure": [1, 11, 12, 14, 17, 19, 36, 38, 41, 71, 85, 88, 90, 92, 95, 100, 101, 105, 106, 115], "repeatedli": [1, 35, 42, 63, 77, 80, 92, 95, 104, 140, 151], "keep": [1, 2, 4, 5, 7, 9, 10, 11, 12, 14, 22, 23, 27, 35, 36, 38, 39, 41, 42, 44, 47, 50, 53, 54, 56, 61, 63, 65, 70, 72, 76, 85, 88, 90, 92, 93, 94, 95, 98, 99, 101, 103, 104, 106, 108, 110, 115, 116, 121, 127, 133, 137, 138, 141, 143, 144, 145, 147, 149, 153, 155, 157, 158, 160, 165, 171, 174, 175, 176, 178, 183, 184, 188, 189, 190], "track": [1, 7, 9, 10, 11, 24, 27, 36, 39, 41, 63, 66, 67, 72, 85, 92, 114, 115, 138, 148, 150, 186], "norm": [1, 2, 4, 9, 20, 22, 29, 30, 35, 38, 60, 63, 64, 70, 94, 99, 100, 102, 105, 106, 109, 110, 111, 136, 140, 148, 150, 152, 183], "v_in": 1, "norm_list": 1, "item": [1, 4, 7, 8, 9, 10, 11, 12, 20, 26, 39, 47, 78, 85, 90, 92, 98, 125, 132, 148, 155, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 183, 184, 185, 186, 189, 190], "append": [1, 2, 10, 12, 20, 23, 29, 35, 45, 47, 53, 54, 56, 57, 59, 60, 64, 65, 69, 70, 85, 86, 90, 93, 103, 113, 116, 119, 120, 122, 123, 127, 128, 131, 132, 133, 141, 144, 159, 163, 164, 165, 168, 171, 173, 175, 176, 177, 183, 184], "matmul": [1, 2, 20, 22, 31, 35, 56, 61, 71, 83, 100, 105, 107, 108, 115, 116, 153, 173, 175, 181, 183], "grow": [1, 19, 35, 36, 46, 62, 77, 78, 79, 89, 92, 94, 95, 101, 104, 106, 108, 111, 113, 138, 140, 144, 147, 148, 149, 150, 153, 157, 177, 181, 186, 189], "uncontrol": [1, 187], "quotient": [1, 10, 151], "pattern": [1, 2, 5, 7, 8, 24, 25, 30, 35, 41, 63, 64, 65, 66, 68, 70, 71, 76, 77, 92, 94, 95, 101, 103, 107, 110, 111, 149, 157, 161, 167, 168, 171, 175, 186], "norm_ratio_list": 1, "ratio": [1, 10, 19, 47, 49, 50, 51, 53, 54, 55, 58, 60, 64, 66, 76, 94, 121, 130, 133, 138, 143, 151, 157, 177], "last": [1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 17, 20, 22, 23, 24, 27, 32, 38, 39, 41, 44, 46, 49, 50, 56, 60, 61, 62, 65, 68, 69, 76, 77, 78, 81, 82, 83, 85, 91, 92, 93, 120, 121, 122, 123, 124, 133, 138, 139, 143, 144, 145, 148, 155, 160, 161, 165, 167, 168, 170, 171, 175, 178, 180], "portion": [1, 2, 9, 14, 41, 44, 45, 55, 57, 61, 69, 71, 72, 75, 76, 92, 108, 114, 123, 169], "974459321485": 1, "shift": [1, 2, 4, 5, 6, 10, 21, 24, 25, 63, 64, 67, 69, 72, 75, 76, 77, 83, 92, 97, 101, 103, 114, 116, 176, 177, 180, 181, 186, 191], "stabl": [1, 2, 8, 63, 98, 99, 116, 145, 149, 178, 186], "correspond": [1, 2, 4, 5, 8, 9, 11, 19, 21, 24, 27, 28, 35, 36, 38, 45, 47, 49, 50, 55, 59, 60, 61, 62, 63, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 88, 89, 92, 94, 95, 96, 98, 100, 101, 103, 108, 109, 110, 113, 114, 119, 123, 125, 126, 133, 134, 138, 140, 141, 153, 155, 156, 157, 159, 161, 163, 165, 170, 171, 176, 177, 178, 179, 180, 181, 183, 184, 185, 188, 189, 190], "amount": [1, 4, 7, 8, 10, 12, 19, 21, 25, 27, 39, 41, 42, 44, 46, 50, 60, 62, 63, 64, 66, 68, 69, 70, 71, 74, 77, 78, 79, 80, 86, 89, 90, 92, 94, 95, 98, 101, 103, 104, 107, 108, 111, 113, 130, 133, 137, 139, 140, 141, 143, 144, 145, 146, 149, 150, 151, 157, 167, 171, 174, 180, 184, 188, 189], "specif": [1, 2, 4, 6, 7, 8, 9, 11, 13, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 34, 36, 38, 39, 41, 44, 46, 47, 48, 58, 59, 60, 63, 64, 66, 69, 70, 78, 92, 93, 94, 96, 98, 100, 103, 110, 111, 114, 117, 118, 124, 125, 127, 130, 131, 133, 134, 136, 138, 140, 144, 146, 148, 150, 152, 153, 157, 162, 163, 165, 168, 171, 175, 176, 177, 178, 181, 182, 184, 185, 189], "caveat": [1, 41, 83, 141], "go": [1, 2, 4, 6, 7, 8, 10, 11, 12, 14, 18, 23, 29, 34, 35, 37, 39, 41, 42, 44, 54, 57, 62, 64, 66, 70, 71, 74, 75, 76, 77, 79, 83, 92, 94, 95, 98, 100, 101, 103, 104, 106, 109, 111, 114, 115, 116, 130, 131, 135, 138, 139, 141, 143, 144, 146, 148, 149, 153, 157, 164, 171, 177, 178, 183, 184, 185, 186, 187, 188, 190], "you": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 127, 128, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], "rotat": [1, 2, 21, 25, 41, 57, 138, 141, 145, 147, 153, 186], "root": [1, 2, 8, 9, 11, 20, 29, 33, 41, 51, 63, 78, 96, 106, 108, 113, 125, 148, 151, 153, 157, 163, 176, 185, 186, 191], "imaginari": 1, "sort": [1, 4, 5, 15, 21, 47, 53, 54, 90, 92, 95, 96, 98, 104, 113, 127, 157, 164, 165, 168, 171, 172, 184, 185], "norm_eig": 1, "ab": [1, 4, 7, 21, 33, 35, 49, 56, 60, 71, 72, 105, 141, 149, 153, 169, 186], "print": [1, 2, 4, 7, 8, 10, 14, 20, 22, 23, 28, 29, 33, 34, 36, 38, 39, 42, 44, 45, 47, 49, 51, 53, 54, 56, 57, 59, 60, 72, 74, 78, 82, 83, 85, 86, 96, 104, 105, 106, 107, 108, 110, 113, 116, 119, 121, 122, 124, 127, 128, 131, 132, 133, 135, 141, 143, 144, 149, 151, 154, 155, 156, 157, 159, 163, 164, 165, 173, 176, 177, 180, 185], "eigval": 1, "absolut": [1, 9, 39, 41, 60, 105, 113, 141, 153, 157, 166], "unexpect": 1, "identifi": [1, 2, 5, 7, 34, 50, 62, 64, 66, 85, 86, 90, 92, 108, 111, 113, 119, 158, 160, 161, 169], "befor": [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 23, 25, 26, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 54, 56, 58, 60, 63, 64, 66, 68, 69, 70, 71, 73, 76, 77, 78, 80, 85, 86, 88, 89, 91, 92, 94, 95, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 123, 124, 127, 128, 133, 135, 138, 140, 141, 143, 145, 146, 147, 148, 149, 150, 155, 156, 157, 171, 175, 176, 177, 178, 180, 181, 182, 184, 187, 189], "thirteen": 1, "decim": [1, 4, 9], "place": [1, 4, 6, 28, 30, 42, 53, 57, 63, 70, 76, 92, 94, 95, 98, 103, 104, 105, 108, 111, 113, 114, 127, 137, 139, 140, 144, 149, 150, 155, 157, 178, 184, 186, 187], "coincid": [1, 24, 46, 94, 98], "But": [1, 3, 7, 8, 9, 38, 39, 46, 51, 77, 78, 83, 92, 94, 95, 99, 101, 104, 108, 111, 113, 114, 138, 153, 177, 179, 182, 183, 184, 185, 189], "geometr": [1, 2, 3, 4, 7, 10, 145, 180], "particular": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 19, 22, 23, 24, 27, 31, 35, 39, 41, 42, 44, 45, 46, 62, 63, 64, 68, 69, 70, 71, 77, 79, 80, 88, 90, 92, 94, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 111, 115, 138, 139, 141, 143, 145, 148, 149, 151, 153, 157, 174, 179, 180, 183, 184, 188, 189, 190], "least": [1, 5, 9, 11, 19, 38, 39, 40, 41, 45, 51, 53, 62, 63, 64, 71, 74, 77, 78, 83, 86, 87, 88, 89, 90, 92, 95, 98, 101, 106, 107, 114, 116, 127, 133, 138, 140, 143, 144, 145, 146, 148, 157, 164, 180, 184, 186], "closer": [1, 9, 10, 11, 35, 55, 56, 60, 63, 69, 77, 79, 83, 92, 95, 101, 110, 116, 143, 178, 184, 186], "until": [1, 8, 10, 34, 35, 39, 41, 42, 46, 47, 57, 62, 64, 69, 70, 71, 75, 79, 83, 86, 89, 90, 92, 101, 103, 105, 107, 109, 111, 114, 116, 119, 121, 133, 141, 143, 145, 147, 169, 171, 175, 176, 179, 184], "practic": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 14, 19, 22, 24, 26, 29, 35, 37, 39, 41, 42, 44, 45, 46, 47, 50, 51, 53, 54, 57, 58, 62, 63, 64, 71, 72, 75, 77, 78, 79, 80, 85, 86, 87, 88, 89, 92, 94, 95, 98, 100, 101, 103, 104, 105, 107, 108, 111, 112, 113, 115, 116, 117, 126, 129, 130, 131, 138, 139, 140, 141, 142, 143, 144, 147, 148, 149, 154, 158, 160, 164, 169, 170, 174, 175, 178, 179, 181, 185, 186], "purpos": [1, 7, 12, 22, 27, 30, 35, 36, 41, 46, 50, 62, 63, 72, 73, 74, 76, 78, 83, 86, 90, 91, 92, 95, 100, 107, 108, 113, 137, 140, 141, 143, 150, 153, 157, 158, 164, 169, 173, 186, 189], "been": [1, 2, 4, 7, 9, 11, 14, 17, 21, 24, 25, 27, 29, 34, 35, 38, 39, 41, 42, 44, 47, 48, 50, 51, 52, 53, 55, 56, 60, 62, 63, 64, 65, 67, 68, 69, 74, 78, 79, 83, 86, 90, 92, 94, 95, 98, 101, 103, 104, 106, 107, 109, 111, 114, 117, 119, 122, 126, 130, 132, 140, 143, 144, 145, 149, 150, 151, 155, 156, 157, 158, 164, 166, 167, 170, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 189], "basi": [1, 2, 5, 7, 21, 45, 47, 63, 77, 79, 81, 101, 103, 110, 111, 114, 130, 138, 139, 140, 145, 147, 158, 172, 180, 187], "detail": [1, 2, 5, 6, 7, 8, 11, 12, 14, 15, 17, 18, 22, 23, 25, 32, 35, 36, 37, 41, 42, 44, 46, 51, 56, 58, 60, 62, 63, 64, 66, 68, 69, 70, 71, 73, 74, 92, 95, 96, 98, 104, 105, 106, 109, 113, 115, 116, 120, 133, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 150, 156, 160, 161, 163, 164, 168, 171, 173, 175, 177, 179, 181, 188], "golub": [1, 103, 186], "van": [1, 4, 103, 149, 186], "loan": [1, 94, 103, 114, 153, 186], "1996": [1, 62, 80, 96, 103, 186], "conclud": [1, 5, 7, 9, 10, 11, 25, 40, 52, 66, 73, 94, 95, 101], "squish": [1, 98], "stai": [1, 44, 58, 92, 94, 103, 184, 188], "throughout": [1, 7, 8, 9, 10, 25, 35, 37, 42, 46, 47, 48, 62, 63, 67, 74, 83, 91, 92, 94, 101, 103, 106, 107, 108, 110, 111, 112, 113, 116, 136, 144, 148, 149, 151, 156, 178, 179, 184, 185], "entir": [1, 2, 4, 5, 7, 9, 10, 17, 18, 21, 22, 24, 25, 27, 29, 35, 36, 37, 41, 42, 47, 50, 53, 54, 58, 62, 63, 64, 66, 69, 70, 76, 77, 78, 79, 80, 86, 90, 92, 94, 95, 98, 99, 101, 103, 105, 106, 107, 108, 117, 124, 125, 126, 128, 129, 138, 141, 143, 144, 146, 149, 153, 155, 157, 166, 175, 177, 180, 181, 183, 184, 187], "rescal": [1, 22, 29, 56, 59, 63, 110, 113, 137, 138, 139, 144], "instead": [1, 4, 5, 6, 8, 11, 12, 19, 22, 23, 24, 26, 27, 30, 34, 36, 37, 38, 41, 42, 44, 46, 51, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 76, 77, 78, 79, 80, 85, 86, 87, 89, 90, 92, 93, 94, 95, 98, 99, 100, 103, 104, 106, 107, 108, 116, 118, 119, 128, 132, 137, 139, 141, 143, 145, 146, 148, 150, 151, 155, 157, 158, 165, 166, 173, 175, 184, 187, 188, 190], "consecut": [1, 25, 119, 126, 132, 180, 185], "princip": [1, 6, 92], "explod": [1, 86, 112, 174, 175, 178, 183], "eventu": [1, 9, 63, 64, 74, 77, 92, 111, 141, 153, 183, 187], "equilibr": 1, "abl": [1, 2, 4, 8, 9, 11, 12, 19, 22, 36, 39, 41, 42, 46, 62, 63, 74, 77, 83, 85, 87, 90, 91, 92, 98, 101, 106, 107, 109, 111, 116, 119, 126, 140, 141, 144, 146, 149, 150, 157, 174, 175, 180, 184, 187], "approx": [1, 5, 6, 7, 9, 10, 46, 63, 64, 78, 83, 98, 129, 148, 177, 181], "due": [1, 6, 7, 8, 9, 11, 14, 19, 28, 31, 35, 41, 44, 49, 50, 58, 60, 62, 63, 64, 66, 67, 74, 76, 77, 86, 89, 92, 94, 95, 99, 103, 104, 114, 115, 120, 121, 125, 126, 133, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 157, 159, 160, 163, 170, 175, 178, 182], "circular": [1, 4], "ginibr": [1, 186], "1965": [1, 114, 186], "relationship": [1, 2, 4, 6, 9, 11, 24, 25, 77, 92, 95, 101, 103, 108, 114, 118, 119, 120, 126, 129, 132, 134, 146, 157, 158, 171, 181, 186], "object": [1, 2, 3, 6, 11, 24, 25, 34, 35, 36, 37, 47, 49, 50, 51, 52, 56, 58, 59, 60, 62, 63, 64, 67, 73, 74, 76, 77, 78, 80, 83, 85, 87, 90, 93, 94, 98, 101, 102, 103, 105, 107, 108, 109, 110, 113, 117, 125, 138, 140, 141, 142, 143, 144, 145, 146, 150, 152, 153, 154, 157, 158, 163, 166, 169, 178, 183, 184, 185, 186, 189, 190, 191], "connect": [1, 2, 7, 9, 13, 23, 24, 25, 26, 28, 30, 31, 35, 36, 41, 44, 46, 49, 50, 52, 54, 58, 60, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 80, 81, 83, 98, 99, 101, 102, 103, 104, 110, 111, 112, 114, 115, 116, 117, 121, 123, 124, 126, 140, 143, 158, 165, 168, 173, 175, 177, 179, 181, 182, 183, 186, 191], "pennington": [1, 129, 186], "et": [1, 8, 10, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 35, 40, 41, 44, 45, 46, 47, 49, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 94, 95, 96, 98, 101, 103, 104, 110, 111, 114, 116, 117, 119, 120, 123, 124, 126, 127, 128, 129, 132, 133, 134, 138, 139, 140, 143, 145, 149, 150, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 173, 174, 175, 176, 177, 179, 180, 181, 184, 186, 187, 189], "al": [1, 8, 10, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 35, 40, 41, 44, 45, 46, 47, 49, 56, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 94, 95, 96, 98, 101, 103, 104, 110, 111, 114, 116, 117, 119, 120, 123, 124, 126, 127, 128, 129, 132, 133, 134, 138, 139, 140, 143, 145, 149, 150, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 173, 174, 175, 176, 177, 179, 180, 181, 184, 186, 187, 189], "2017": [1, 19, 22, 23, 24, 26, 28, 29, 41, 44, 47, 58, 60, 63, 65, 66, 67, 69, 71, 86, 92, 96, 111, 114, 116, 117, 126, 132, 144, 145, 160, 165, 175, 178, 184, 186], "subsequ": [1, 8, 12, 21, 25, 30, 34, 35, 41, 42, 44, 58, 60, 63, 64, 68, 69, 70, 72, 74, 77, 85, 92, 94, 95, 96, 109, 110, 111, 112, 114, 134, 138, 144, 145, 149, 150, 155, 163, 168, 169, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184], "allow": [1, 2, 4, 5, 7, 8, 9, 11, 18, 19, 22, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 51, 56, 57, 62, 63, 64, 65, 66, 69, 71, 75, 77, 83, 85, 86, 90, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 113, 114, 121, 123, 129, 132, 138, 139, 140, 141, 142, 145, 148, 149, 151, 153, 155, 157, 171, 173, 174, 175, 177, 180, 183, 184, 187, 189], "reduc": [1, 2, 5, 6, 10, 11, 12, 21, 25, 39, 40, 41, 43, 47, 49, 50, 51, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 74, 75, 76, 77, 78, 79, 82, 88, 90, 92, 95, 96, 98, 101, 103, 105, 108, 111, 114, 119, 121, 123, 124, 125, 138, 139, 141, 143, 144, 145, 146, 148, 150, 153, 155, 157, 158, 160, 161, 162, 167, 173, 183, 184, 186, 189], "primarili": [1, 19, 24, 25, 39, 44, 68, 69, 70, 74, 92, 93, 109, 114, 143, 146, 148, 178, 179], "theori": [1, 2, 3, 5, 6, 8, 9, 11, 62, 72, 73, 92, 94, 97, 101, 108, 110, 111, 138, 143, 149, 157, 163, 178, 180, 186, 191], "strang": [1, 5, 10, 33, 95, 111, 153, 186], "smallest": [1, 7, 85, 90, 95, 98, 99, 103, 138, 157], "less": [1, 4, 5, 8, 9, 11, 12, 19, 21, 25, 26, 29, 30, 40, 41, 45, 50, 51, 54, 56, 63, 68, 69, 74, 78, 79, 86, 89, 92, 94, 95, 105, 108, 113, 114, 116, 122, 126, 127, 133, 134, 135, 138, 140, 143, 144, 145, 146, 149, 150, 153, 157, 176, 180, 185, 188, 190], "done": [1, 2, 5, 6, 7, 9, 10, 14, 20, 22, 34, 37, 39, 41, 42, 74, 80, 85, 86, 90, 94, 105, 113, 114, 155, 186, 189], "head": [1, 6, 7, 9, 24, 25, 28, 29, 30, 41, 42, 64, 66, 67, 92, 128, 157, 164, 191], "data": [2, 3, 4, 6, 7, 8, 10, 11, 12, 17, 19, 20, 23, 24, 25, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 114, 115, 118, 119, 120, 121, 123, 124, 125, 126, 127, 130, 133, 134, 135, 137, 138, 139, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 170, 171, 172, 173, 175, 176, 177, 179, 180, 181, 182, 183, 184, 186, 189, 191], "kei": [2, 3, 4, 5, 6, 7, 10, 12, 21, 22, 23, 24, 26, 28, 29, 32, 33, 34, 35, 36, 38, 41, 43, 52, 53, 62, 63, 65, 66, 70, 72, 74, 75, 78, 89, 90, 93, 94, 95, 96, 98, 103, 105, 106, 107, 110, 112, 114, 115, 116, 127, 132, 139, 141, 143, 145, 147, 149, 151, 153, 155, 164, 165, 167, 168, 173, 174, 175, 178, 179, 184, 185, 186, 187, 189, 190, 191], "pillar": [2, 5], "broadli": [2, 39, 40, 81, 95, 98, 103, 146, 157, 176, 179], "while": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 20, 23, 24, 25, 27, 28, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 85, 86, 88, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 116, 117, 119, 120, 121, 124, 126, 127, 128, 132, 133, 134, 136, 138, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 153, 154, 155, 156, 157, 158, 168, 169, 170, 171, 175, 177, 178, 179, 180, 183, 184, 185, 187, 189], "machineri": [2, 92, 186], "commun": [2, 4, 30, 41, 43, 44, 46, 62, 77, 92, 98, 130, 149, 167, 179, 186], "mechan": [2, 7, 10, 19, 21, 22, 26, 27, 28, 29, 34, 46, 62, 76, 78, 79, 80, 92, 94, 97, 98, 100, 105, 108, 109, 114, 118, 120, 123, 139, 149, 153, 155, 157, 163, 173, 174, 175, 177, 186, 191], "modern": [2, 3, 4, 8, 11, 21, 22, 24, 27, 29, 40, 41, 46, 62, 63, 64, 66, 69, 70, 73, 74, 92, 95, 96, 98, 104, 105, 111, 114, 116, 143, 149, 150, 153, 155, 161, 176, 178, 179, 183, 184, 185, 191], "lot": [2, 4, 17, 19, 35, 38, 41, 43, 50, 56, 58, 61, 62, 67, 77, 78, 92, 94, 98, 103, 107, 121, 138, 141, 143, 145, 150, 153, 163, 178, 180, 184, 185], "subject": [2, 11, 12, 38, 41, 69, 91, 92, 94, 98, 103, 140, 145, 148, 150, 153, 157], "deeper": [2, 3, 5, 9, 10, 29, 32, 34, 54, 62, 63, 64, 65, 66, 69, 70, 71, 72, 76, 77, 95, 101, 103, 109, 114, 130, 142, 145, 186], "highlight": [2, 7, 25, 103, 106, 120, 130], "few": [2, 4, 7, 8, 9, 10, 18, 20, 22, 23, 24, 25, 29, 35, 38, 40, 41, 42, 44, 46, 48, 49, 54, 62, 64, 67, 69, 75, 77, 78, 79, 80, 81, 86, 89, 90, 91, 92, 94, 96, 99, 101, 102, 103, 106, 108, 110, 114, 115, 118, 140, 141, 143, 148, 149, 151, 152, 153, 155, 162, 177, 178, 179, 180, 184, 185, 186, 188, 189], "concept": [2, 3, 4, 5, 6, 7, 11, 27, 32, 35, 41, 63, 69, 70, 79, 85, 90, 92, 108, 112, 141, 149, 151, 153, 155, 157, 167, 179, 181, 187, 188], "includ": [2, 7, 9, 11, 12, 17, 22, 23, 24, 25, 28, 32, 35, 39, 40, 42, 49, 53, 54, 57, 58, 60, 62, 63, 64, 66, 67, 71, 72, 73, 75, 78, 79, 80, 81, 85, 86, 92, 94, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 111, 113, 114, 117, 119, 125, 126, 133, 135, 142, 149, 151, 153, 154, 155, 156, 157, 158, 164, 165, 167, 168, 169, 170, 171, 175, 176, 177, 181, 184], "eigenvalu": [2, 3, 116, 138, 145, 146, 178], "eigenvector": [2, 138, 145, 146, 178], "space": [2, 4, 9, 12, 19, 20, 22, 23, 27, 28, 49, 58, 60, 67, 69, 71, 72, 74, 78, 79, 81, 85, 88, 89, 90, 92, 98, 101, 108, 114, 116, 117, 118, 119, 127, 132, 133, 138, 140, 149, 153, 155, 157, 158, 169, 176, 186, 188, 189], "python": [2, 8, 17, 19, 35, 36, 38, 39, 40, 42, 44, 63, 70, 88, 91, 92, 100, 103, 104, 105, 106, 107, 124, 144, 149, 152, 153, 154, 156, 157, 164, 173, 175], "mathematician": [2, 5, 10, 92, 114, 151], "row": [2, 12, 21, 22, 27, 28, 29, 47, 49, 55, 56, 60, 61, 74, 75, 77, 92, 93, 94, 98, 100, 103, 107, 114, 119, 126, 131, 135, 136, 144, 153, 155, 156, 157, 158, 161, 163, 165, 168, 177, 178, 179, 181], "benefici": [2, 26, 63, 64, 116, 143, 145, 146, 165], "flexibl": [2, 10, 11, 31, 32, 35, 41, 42, 63, 69, 71, 78, 80, 85, 92, 95, 165, 167, 169, 175, 184, 186], "describ": [2, 4, 7, 9, 10, 14, 17, 18, 25, 26, 27, 28, 29, 35, 44, 46, 47, 48, 49, 50, 52, 53, 54, 56, 58, 60, 63, 66, 67, 69, 70, 71, 72, 75, 76, 77, 79, 92, 94, 98, 103, 104, 107, 109, 110, 111, 114, 115, 117, 118, 120, 121, 123, 125, 127, 135, 140, 145, 146, 148, 149, 153, 157, 161, 163, 168, 175, 178, 179, 181, 184, 188, 190], "though": [2, 19, 22, 27, 29, 36, 38, 41, 42, 44, 46, 60, 62, 63, 66, 69, 70, 71, 72, 77, 86, 92, 95, 96, 98, 99, 103, 114, 115, 116, 118, 120, 123, 126, 129, 138, 139, 140, 143, 146, 149, 150, 153, 157, 177, 181, 183, 184], "orient": [2, 62, 92, 102, 105, 107, 186, 191], "tabular": [2, 77, 156, 179], "dataset": [2, 4, 6, 8, 10, 11, 20, 25, 29, 30, 32, 41, 43, 44, 45, 47, 51, 52, 56, 58, 62, 63, 64, 66, 69, 74, 77, 78, 79, 80, 83, 84, 86, 90, 92, 94, 95, 97, 98, 100, 102, 103, 104, 105, 106, 108, 110, 111, 112, 115, 117, 118, 124, 128, 130, 131, 132, 135, 141, 142, 146, 148, 149, 152, 153, 157, 158, 160, 162, 163, 171, 173, 174, 175, 177, 179, 180, 182, 183, 184, 186, 189, 191], "treat": [2, 9, 23, 30, 56, 69, 73, 77, 92, 94, 98, 100, 101, 106, 113, 122, 130, 133, 142, 151, 156, 161, 165, 169, 171, 176, 181, 183, 184], "convent": [2, 3, 7, 10, 63, 64, 67, 75, 78, 82, 92, 94, 96, 99, 108, 114, 136, 146, 151, 157, 169, 179], "give": [2, 4, 5, 6, 7, 8, 9, 10, 11, 23, 28, 32, 35, 36, 41, 47, 61, 66, 70, 72, 74, 75, 77, 78, 79, 80, 82, 83, 86, 92, 94, 95, 98, 99, 101, 104, 108, 112, 113, 114, 115, 116, 123, 126, 143, 144, 148, 149, 151, 153, 155, 156, 157, 159, 160, 162, 163, 165, 169, 175, 178, 184, 185, 189, 190], "three": [2, 4, 6, 9, 10, 11, 12, 19, 21, 22, 25, 29, 39, 42, 47, 50, 53, 54, 56, 59, 60, 63, 64, 65, 66, 68, 70, 71, 74, 75, 77, 81, 83, 92, 95, 96, 98, 100, 101, 105, 106, 114, 117, 119, 120, 121, 126, 128, 129, 131, 140, 141, 149, 151, 153, 160, 165, 166, 168, 169, 173, 175, 178, 180, 181, 183, 185], "dimens": [2, 5, 7, 8, 20, 22, 23, 28, 29, 33, 34, 35, 47, 48, 49, 54, 55, 58, 60, 61, 63, 64, 65, 66, 70, 71, 72, 74, 75, 76, 77, 80, 92, 93, 94, 95, 99, 100, 101, 104, 107, 110, 111, 115, 120, 123, 124, 131, 135, 136, 141, 146, 153, 155, 158, 163, 170, 175, 177, 181, 183, 186], "visual": [2, 3, 5, 7, 8, 9, 10, 11, 20, 21, 23, 24, 25, 26, 29, 36, 47, 49, 62, 69, 70, 72, 78, 79, 80, 82, 83, 85, 87, 90, 92, 97, 100, 103, 105, 109, 141, 147, 152, 153, 156, 178, 185, 186, 189], "compon": [2, 4, 7, 11, 21, 27, 29, 31, 32, 35, 36, 41, 42, 46, 52, 59, 65, 70, 72, 83, 85, 94, 96, 98, 99, 100, 103, 104, 105, 106, 108, 139, 149, 150, 153, 155, 157, 160, 165, 168, 172, 179, 182, 186, 188, 191], "locat": [2, 7, 9, 11, 14, 21, 27, 36, 38, 41, 47, 48, 59, 63, 64, 68, 71, 72, 75, 76, 77, 78, 79, 80, 91, 92, 94, 106, 114, 144, 146, 151, 153, 155, 156, 167, 184, 188, 189, 190], "fig": [2, 4, 5, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 53, 54, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 82, 83, 88, 89, 90, 92, 94, 98, 101, 103, 104, 106, 109, 110, 111, 113, 114, 117, 118, 120, 121, 123, 124, 125, 126, 130, 134, 140, 149, 151, 167, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 184, 188], "illustr": [2, 5, 6, 7, 9, 10, 11, 12, 22, 25, 35, 38, 39, 40, 41, 42, 44, 46, 47, 56, 58, 61, 62, 68, 69, 72, 80, 83, 85, 92, 94, 96, 100, 101, 105, 107, 108, 109, 113, 114, 116, 117, 118, 120, 121, 123, 124, 125, 126, 129, 132, 140, 141, 143, 144, 145, 146, 149, 150, 153, 155, 160, 163, 165, 167, 168, 169, 171, 173, 175, 177, 178, 181, 184], "mathit": [2, 9, 22, 27, 30, 64, 69, 169], "coordin": [2, 5, 9, 11, 21, 47, 48, 49, 55, 56, 57, 58, 67, 77, 98, 103, 114, 137, 138, 139, 141, 144, 145, 147, 148, 153, 157, 179], "higher": [2, 3, 5, 11, 12, 19, 25, 28, 30, 41, 46, 47, 54, 62, 64, 65, 77, 80, 89, 92, 95, 98, 101, 109, 113, 114, 121, 128, 132, 133, 141, 143, 145, 146, 148, 150, 153, 157, 160, 161, 163, 165, 168, 177, 180], "analog": [2, 4, 23, 69, 92, 95, 98, 153, 157, 181, 190], "although": [2, 24, 25, 29, 42, 47, 50, 57, 58, 60, 62, 65, 69, 70, 78, 92, 93, 103, 108, 112, 114, 126, 134, 141, 144, 146, 158, 163, 175, 177, 184], "harder": [2, 7, 94], "abstract": [2, 4, 5, 9, 27, 32, 35, 46, 55, 70, 80, 92, 107, 115, 140, 168, 186, 188], "level": [2, 5, 11, 19, 24, 25, 29, 32, 41, 42, 44, 45, 49, 52, 53, 54, 55, 58, 59, 61, 62, 63, 66, 72, 74, 76, 77, 78, 79, 80, 83, 88, 89, 90, 92, 94, 95, 96, 98, 99, 103, 104, 106, 110, 111, 114, 115, 118, 120, 121, 132, 137, 149, 153, 157, 168, 170, 171, 173, 175, 176, 179, 180, 182, 183, 185, 186, 191], "No": [2, 4, 20, 25, 38, 41, 45, 95, 106, 149, 153, 157, 186], "face": [2, 29, 83, 86, 92, 94, 95, 99, 101, 116, 138, 145, 151, 153, 156, 174, 175, 179], "insurmount": 2, "classifi": [2, 3, 4, 6, 30, 44, 49, 52, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 74, 77, 83, 92, 94, 95, 96, 97, 99, 100, 101, 110, 114, 115, 117, 119, 126, 157, 166, 172, 183, 184, 185], "dog": [2, 47, 48, 52, 53, 59, 62, 77, 83, 92, 94, 98, 111, 114, 132, 180, 191], "task": [2, 4, 8, 10, 24, 25, 29, 30, 31, 34, 35, 38, 39, 40, 48, 52, 54, 56, 57, 59, 60, 62, 65, 67, 69, 70, 71, 72, 73, 74, 76, 83, 85, 86, 92, 94, 95, 97, 101, 103, 107, 111, 114, 117, 118, 119, 120, 121, 122, 124, 128, 130, 131, 145, 149, 151, 157, 158, 159, 160, 161, 162, 165, 166, 168, 170, 174, 176, 177, 179, 180, 184, 186, 188], "abstractli": 2, "discov": [2, 4, 19, 29, 74, 80, 92, 94, 98, 101, 103, 111, 132, 153, 162, 167, 168], "separ": [2, 4, 9, 10, 29, 37, 44, 46, 49, 62, 63, 69, 71, 76, 92, 103, 106, 110, 111, 113, 115, 117, 120, 123, 126, 128, 133, 144, 147, 149, 150, 156, 170, 176, 177, 182, 183, 186], "distinct": [2, 41, 51, 62, 66, 69, 77, 79, 80, 92, 94, 98, 101, 107, 117, 153, 156, 157, 169, 171, 175, 185, 186, 187], "cluster": [2, 41, 88, 92, 140], "peopl": [2, 5, 6, 9, 38, 62, 78, 92, 94, 122, 138, 153, 157, 167], "Not": [2, 7, 41, 94, 99, 103, 113, 151], "arrow": [2, 20, 56, 64, 109, 178, 190], "drawn": [2, 4, 6, 9, 11, 21, 22, 64, 79, 80, 83, 85, 92, 94, 95, 98, 101, 103, 105, 107, 111, 116, 144, 146, 148, 155, 189], "represent": [2, 21, 23, 24, 25, 26, 27, 28, 29, 30, 35, 42, 48, 52, 55, 56, 60, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 92, 98, 99, 114, 116, 117, 118, 120, 121, 123, 124, 128, 130, 132, 134, 135, 149, 150, 153, 156, 158, 160, 168, 170, 177, 184, 185, 186, 191], "benefit": [2, 9, 12, 19, 22, 25, 27, 29, 31, 32, 35, 37, 39, 41, 42, 44, 45, 62, 63, 66, 69, 74, 75, 92, 93, 99, 103, 107, 108, 111, 114, 118, 135, 138, 144, 145, 150, 167, 184], "act": [2, 25, 35, 63, 68, 83, 92, 94, 114, 157, 170, 172, 184, 189], "sum_i": [2, 4, 6, 7, 8, 9, 21, 27, 98, 100, 103, 108, 140, 145, 150], "u_i": [2, 80, 138, 151, 155], "v_i": [2, 9, 80, 138, 155], "symmetr": [2, 3, 4, 72, 75, 77, 78, 129, 146, 153, 178, 186], "mirror": [2, 5, 70, 75, 82, 92], "notat": [2, 4, 5, 7, 10, 23, 64, 74, 77, 78, 94, 98, 101, 103, 105, 108, 109, 114, 129, 137, 141, 145, 151, 155, 157, 169, 178, 179, 190, 191], "classic": [2, 11, 21, 24, 27, 62, 86, 92, 94, 95, 101, 102, 103, 108, 110, 112, 162, 167, 186], "exchang": [2, 7, 19, 44, 46, 61, 69, 92, 114, 153], "order": [2, 4, 5, 7, 8, 19, 21, 22, 25, 28, 35, 36, 37, 38, 39, 41, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 60, 62, 63, 65, 66, 67, 68, 72, 73, 74, 77, 78, 79, 81, 85, 86, 88, 89, 90, 91, 92, 95, 98, 99, 101, 103, 107, 109, 111, 114, 120, 125, 127, 131, 138, 141, 144, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162, 164, 166, 167, 168, 176, 178, 179, 180, 183, 186, 187, 188], "answer": [2, 4, 5, 6, 7, 9, 10, 21, 25, 27, 78, 83, 92, 98, 101, 108, 110, 114, 118, 119, 126, 149, 152, 153, 176], "admit": [2, 40, 103], "theta": [2, 4, 5, 6, 7, 9, 11, 20, 78, 140, 166, 183], "intim": 2, "ti": [2, 6, 19, 32, 41, 64, 71, 116, 189], "co": [2, 5, 7, 9, 10, 28, 41, 106, 110, 130, 131, 133, 135, 140, 141, 143, 146, 150, 184, 186], "sin": [2, 5, 10, 21, 28, 78, 80, 106, 141, 148, 150, 184], "axi": [2, 4, 5, 8, 9, 20, 21, 22, 23, 25, 26, 28, 29, 47, 48, 49, 50, 53, 55, 56, 60, 63, 65, 66, 71, 72, 82, 93, 95, 96, 99, 100, 103, 111, 120, 123, 124, 126, 128, 131, 135, 138, 144, 151, 153, 155, 157, 160, 161, 163, 165, 168, 173, 175, 181, 183], "With": [2, 4, 5, 9, 25, 29, 40, 42, 59, 64, 69, 77, 79, 82, 85, 90, 92, 95, 99, 100, 106, 107, 110, 111, 113, 114, 115, 116, 120, 121, 122, 126, 128, 144, 149, 151, 155, 159, 161, 165, 174, 176, 181, 184], "simpl": [2, 10, 11, 24, 25, 26, 27, 28, 31, 35, 40, 42, 44, 46, 52, 56, 57, 60, 62, 64, 65, 67, 68, 69, 70, 72, 74, 76, 78, 79, 81, 82, 85, 86, 88, 89, 90, 92, 93, 94, 96, 98, 101, 103, 108, 109, 110, 113, 114, 115, 116, 123, 124, 126, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 153, 156, 164, 165, 169, 170, 171, 173, 175, 176, 177, 178, 181, 183, 184, 186, 188, 189, 190], "manipul": [2, 4, 7, 26, 29, 36, 47, 77, 79, 92, 94, 98, 107, 108, 149, 150, 151, 152, 153, 185, 191], "rearrang": [2, 5, 11, 123], "arcco": 2, "short": [2, 3, 6, 11, 19, 23, 35, 38, 39, 41, 46, 73, 76, 77, 78, 80, 92, 94, 95, 98, 101, 106, 108, 109, 138, 140, 143, 144, 146, 148, 152, 157, 165, 167, 168, 171, 173, 174, 178, 182, 184, 186, 188, 190, 191], "combin": [2, 4, 5, 7, 8, 10, 19, 26, 27, 28, 35, 40, 41, 42, 46, 47, 53, 56, 64, 65, 66, 71, 72, 76, 77, 78, 79, 81, 86, 92, 98, 99, 103, 104, 105, 106, 108, 111, 118, 120, 130, 139, 145, 157, 158, 160, 163, 165, 168, 171, 173, 174, 180, 185], "million": [2, 25, 30, 50, 55, 62, 77, 78, 92, 95, 101, 111, 113, 114, 117, 121, 125, 126, 128, 163, 186], "pair": [2, 4, 5, 9, 12, 21, 22, 23, 25, 26, 27, 28, 29, 41, 42, 47, 72, 78, 79, 92, 98, 103, 105, 118, 119, 120, 121, 126, 127, 128, 130, 133, 134, 148, 155, 163, 166, 176, 180, 181, 185, 186, 189], "torchvis": [2, 8, 20, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 82, 91, 96, 149], "gluon": [2, 8, 20, 21, 22, 23, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 47, 49, 50, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 82, 83, 92, 93, 96, 99, 100, 104, 106, 107, 108, 110, 113, 115, 119, 120, 121, 123, 124, 126, 127, 128, 133, 135, 138, 139, 143, 144, 145, 149, 158, 159, 160, 161, 163, 164, 165, 166, 168, 170, 171, 172, 173, 175, 177, 182, 183, 184], "npx": [2, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 83, 93, 96, 99, 100, 104, 105, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 157, 158, 160, 161, 163, 165, 166, 168, 170, 171, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "set_np": [2, 5, 6, 7, 8, 9, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 82, 83, 93, 96, 99, 100, 104, 105, 107, 108, 110, 113, 114, 115, 116, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 157, 158, 160, 161, 163, 165, 166, 168, 170, 171, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "tensordot": [2, 7, 144, 150, 153], "ax": [2, 5, 7, 9, 10, 20, 21, 22, 27, 47, 48, 55, 56, 57, 60, 63, 68, 77, 78, 82, 83, 106, 140, 144, 146, 150, 151, 153, 155], "90": [2, 41, 92, 99, 101, 164], "circ": [2, 116], "prove": [2, 4, 21, 27, 30, 62, 63, 71, 76, 77, 92, 95, 98, 101, 102, 103, 105, 110, 113, 114, 138, 140, 145, 146, 148, 151, 153, 157, 178, 183, 184], "kind": [2, 4, 11, 21, 35, 69, 72, 83, 85, 94, 97, 114, 155, 169, 180, 184, 189, 191], "invari": [2, 9, 21, 30, 62, 63, 64, 68, 71, 73, 76, 79, 80, 96, 98, 179, 186], "duplic": [2, 36, 109, 178], "pixel": [2, 4, 8, 9, 20, 27, 47, 49, 50, 51, 53, 55, 56, 58, 59, 61, 62, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 92, 96, 98, 100, 110, 114, 115, 123, 179], "bright": [2, 51, 54, 56, 92, 111, 114, 183], "individu": [2, 4, 6, 11, 19, 25, 29, 32, 35, 37, 40, 41, 42, 46, 58, 62, 63, 70, 72, 92, 94, 103, 104, 110, 114, 123, 124, 130, 133, 138, 150, 153, 155, 157, 166, 167, 184, 185], "distanc": [2, 4, 9, 21, 22, 41, 49, 69, 72, 79, 80, 92, 95, 96, 103, 108, 111, 114, 129, 133, 138, 140, 141, 145, 148, 153, 157, 166, 173, 186], "darker": 2, "applic": [2, 3, 5, 6, 7, 10, 11, 12, 18, 22, 24, 25, 27, 29, 30, 35, 42, 50, 51, 52, 58, 59, 60, 63, 70, 72, 77, 78, 79, 80, 81, 83, 92, 93, 94, 100, 101, 103, 104, 114, 119, 120, 121, 122, 123, 124, 126, 127, 128, 130, 134, 135, 140, 149, 153, 156, 159, 162, 163, 167, 169, 171, 172, 174, 177, 178, 179, 181, 183, 185, 187, 191], "content": [2, 4, 5, 17, 20, 25, 27, 52, 62, 77, 83, 94, 98, 103, 142, 152, 154, 159, 167, 174, 180, 184, 186], "concern": [2, 5, 7, 11, 24, 35, 41, 46, 60, 77, 92, 94, 105, 114, 115, 146, 149, 150, 151, 153, 157, 159, 167, 175, 185, 189], "hard": [2, 5, 7, 8, 9, 12, 14, 18, 19, 30, 53, 70, 86, 92, 93, 95, 98, 103, 111, 114, 120, 126, 127, 146, 148, 169, 180, 183], "everywher": [2, 80], "long": [2, 4, 7, 8, 9, 11, 20, 22, 23, 24, 27, 28, 29, 37, 38, 41, 46, 47, 49, 59, 60, 62, 63, 67, 73, 77, 78, 80, 85, 86, 88, 89, 92, 94, 96, 98, 103, 106, 109, 119, 121, 126, 127, 128, 135, 140, 143, 145, 146, 147, 148, 150, 151, 157, 164, 168, 169, 170, 173, 174, 178, 179, 180, 181, 182, 184, 186, 187, 188, 190, 191], "occurr": [2, 4, 8, 130, 132, 133, 157, 180], "vocabulari": [2, 4, 20, 100, 119, 121, 122, 124, 125, 126, 127, 129, 131, 132, 133, 134, 135, 169, 176, 177, 179, 180, 181, 183, 184], "doubl": [2, 17, 41, 46, 49, 60, 69, 70, 71, 82, 98, 99, 103, 111, 170, 186], "emploi": [2, 22, 29, 62, 63, 64, 76, 92, 94, 95, 101, 103, 105, 121, 150, 153, 157, 159, 161, 162, 167, 179, 184], "practition": [2, 3, 11, 24, 41, 62, 63, 70, 73, 87, 95, 98, 103, 111, 114, 116, 149, 150, 155, 156, 169], "adopt": [2, 25, 39, 47, 60, 63, 69, 92, 104, 108, 111, 149, 160, 163, 165, 168, 179, 183], "minimum": [2, 7, 9, 10, 11, 41, 47, 66, 71, 72, 76, 88, 90, 94, 103, 138, 140, 141, 143, 145, 146, 148], "opposit": [2, 7, 63, 92, 116, 125, 170, 178], "high": [2, 4, 11, 12, 19, 24, 25, 29, 32, 41, 44, 45, 46, 47, 53, 54, 56, 58, 59, 61, 62, 63, 65, 68, 69, 74, 76, 77, 78, 79, 80, 83, 89, 92, 94, 95, 96, 98, 99, 101, 102, 103, 104, 106, 110, 111, 112, 114, 115, 120, 133, 134, 137, 139, 141, 146, 149, 152, 153, 154, 160, 161, 168, 170, 171, 173, 175, 177, 178, 180, 182, 186], "randomli": [2, 9, 10, 25, 33, 35, 37, 41, 50, 51, 53, 54, 59, 72, 85, 86, 90, 92, 95, 96, 98, 101, 103, 105, 110, 111, 126, 129, 133, 134, 155, 164, 165, 180, 183, 184, 189], "nearli": [2, 4, 10, 11, 24, 62, 63, 79, 92, 93, 95, 103, 104, 105, 111, 151], "half": [2, 5, 10, 21, 31, 41, 44, 47, 55, 60, 62, 75, 126, 137, 140, 147, 150, 170], "iff": 2, "trigonometri": 2, "project": [2, 5, 7, 25, 26, 28, 30, 63, 67, 82, 106, 119, 131, 146, 149, 153, 158, 165, 176, 180, 183, 184, 186], "onto": [2, 12, 140, 150, 155, 157, 183], "find": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 19, 35, 36, 38, 47, 48, 49, 53, 54, 59, 64, 69, 72, 75, 77, 78, 79, 80, 85, 86, 90, 91, 92, 94, 95, 96, 99, 101, 103, 105, 106, 108, 111, 113, 114, 116, 131, 135, 137, 138, 141, 143, 146, 149, 151, 152, 157, 158, 164, 166, 167, 169, 178, 180, 184, 185, 186, 187, 188, 189, 190], "inequ": [2, 4, 9, 95, 148, 153, 157], "cut": [2, 71, 111, 116, 165, 182], "halv": [2, 60, 64, 65, 69, 70, 74, 75, 82, 87, 98, 143, 144, 145, 191], "threshold": [2, 9, 11, 47, 60, 92, 94, 114, 116], "stori": [2, 4, 9, 11, 25, 41, 62, 94, 111, 179, 186, 191], "abil": [2, 5, 9, 11, 25, 32, 34, 41, 42, 44, 50, 51, 63, 69, 71, 80, 92, 98, 101, 105, 150, 152, 157, 171, 184, 186, 189], "ten": [2, 19, 30, 35, 41, 50, 55, 57, 62, 63, 75, 77, 86, 90, 92, 95, 149, 157, 167, 169, 185], "hundr": [2, 6, 35, 37, 62, 77, 78, 90, 92, 95, 101, 121, 125, 149, 155, 185], "billion": [2, 6, 7, 8, 25, 62, 64, 71, 77, 126, 133, 144, 186], "classif": [2, 3, 21, 25, 30, 48, 49, 50, 52, 54, 57, 59, 60, 61, 62, 64, 66, 72, 74, 78, 83, 86, 94, 99, 100, 101, 102, 103, 111, 114, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 149, 159, 161, 174, 181, 184, 186, 191], "method": [2, 5, 6, 7, 9, 10, 11, 12, 21, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 45, 47, 48, 50, 52, 53, 55, 58, 59, 60, 62, 63, 67, 72, 74, 77, 78, 79, 81, 83, 85, 86, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 120, 121, 123, 125, 127, 129, 133, 134, 135, 138, 140, 142, 143, 147, 149, 150, 153, 154, 155, 157, 161, 162, 166, 167, 169, 171, 172, 175, 176, 178, 179, 180, 182, 183, 184, 185, 186, 187, 189], "target": [2, 19, 20, 23, 24, 25, 29, 37, 49, 50, 51, 53, 56, 57, 60, 63, 78, 79, 92, 94, 97, 99, 103, 120, 135, 142, 143, 150, 155, 156, 157, 159, 166, 168, 172, 176, 177, 178, 179, 180, 181, 184], "class": [2, 8, 16, 22, 23, 26, 28, 29, 30, 31, 33, 35, 36, 37, 41, 43, 49, 50, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 70, 72, 74, 77, 78, 79, 80, 81, 82, 85, 86, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 120, 121, 123, 124, 126, 127, 131, 133, 135, 143, 144, 149, 151, 152, 153, 155, 157, 158, 159, 160, 161, 163, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 182, 183, 184, 185, 186, 188, 191], "decis": [2, 11, 41, 46, 64, 68, 70, 85, 88, 89, 92, 94, 101, 114, 122, 130, 144, 149, 157, 171, 177, 186, 187, 189, 190, 191], "major": [2, 9, 11, 16, 20, 22, 24, 25, 41, 42, 43, 48, 52, 58, 62, 63, 64, 68, 69, 77, 85, 92, 95, 96, 120, 134, 149, 157, 159, 162, 163, 164, 172, 176, 184], "fed": [2, 22, 24, 25, 26, 29, 30, 54, 92, 103, 106, 116, 117, 118, 121, 126, 130, 144, 160, 168, 177, 181, 183], "softmax": [2, 20, 27, 35, 49, 54, 58, 60, 64, 74, 76, 86, 94, 95, 97, 102, 114, 115, 116, 117, 120, 130, 134, 140, 177, 180, 181, 189, 191], "role": [2, 32, 40, 67, 69, 78, 86, 92, 94, 116, 117, 126, 140, 142, 149, 159, 163, 167, 185], "embed": [2, 23, 24, 25, 28, 29, 68, 120, 123, 124, 125, 126, 127, 130, 131, 158, 160, 161, 163, 165, 168, 177, 183, 186, 191], "produc": [2, 5, 11, 21, 24, 26, 53, 60, 61, 64, 65, 72, 75, 92, 103, 104, 107, 111, 114, 116, 122, 123, 132, 143, 153, 155, 157, 169, 170, 171, 172, 179, 180, 183, 184], "shirt": [2, 20, 96], "trouser": [2, 20, 96], "fashion": [2, 20, 30, 44, 50, 51, 57, 62, 63, 64, 66, 68, 69, 70, 74, 82, 86, 94, 96, 99, 100, 110, 111, 114, 115, 126, 129, 138, 143, 147, 150, 179, 184, 186], "mnist": [2, 8, 20, 30, 44, 50, 51, 57, 62, 63, 64, 66, 68, 69, 70, 74, 82, 86, 92, 96, 99, 100, 110, 115, 138, 143, 147, 179, 186], "eyebal": 2, "crude": [2, 138], "load": [2, 17, 20, 31, 32, 41, 44, 47, 48, 53, 57, 58, 59, 76, 82, 97, 104, 107, 118, 120, 122, 127, 128, 130, 153, 156, 158, 159, 160, 162, 165, 174, 175, 177, 182, 183, 185], "tran": [2, 20, 96, 186], "totensor": [2, 8, 20, 49, 50, 51, 53, 54, 56, 82, 96], "compos": [2, 5, 7, 8, 20, 29, 31, 50, 51, 53, 54, 56, 62, 64, 65, 70, 82, 83, 92, 96, 103, 105, 107, 126, 144, 149, 151, 153, 157, 184, 185], "train": [2, 3, 10, 11, 12, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 35, 36, 37, 38, 40, 41, 42, 43, 50, 52, 57, 58, 59, 67, 72, 73, 77, 78, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 102, 103, 107, 111, 112, 113, 114, 116, 117, 118, 119, 121, 122, 126, 127, 128, 129, 130, 131, 132, 138, 139, 142, 143, 144, 146, 147, 148, 149, 150, 151, 153, 156, 157, 159, 162, 164, 166, 169, 170, 171, 172, 174, 176, 178, 179, 180, 181, 185, 186, 187, 191], "fashionmnist": [2, 20, 30, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 86, 88, 89, 96, 99, 100, 110, 115], "download": [2, 8, 12, 14, 17, 20, 38, 50, 51, 52, 59, 82, 96, 106, 112, 119, 120, 121, 122, 124, 127, 131, 133, 144, 149, 159, 164, 174, 185], "test": [2, 3, 4, 7, 8, 14, 17, 20, 23, 25, 26, 35, 37, 40, 41, 44, 45, 49, 50, 51, 52, 57, 59, 60, 63, 64, 74, 78, 83, 86, 91, 92, 94, 96, 97, 100, 101, 104, 107, 110, 111, 113, 115, 117, 119, 120, 121, 122, 124, 131, 133, 140, 143, 144, 149, 154, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 177, 179, 185, 187], "fals": [2, 8, 10, 11, 20, 21, 22, 23, 26, 27, 28, 29, 30, 40, 41, 45, 48, 49, 50, 51, 53, 54, 57, 59, 61, 62, 63, 64, 68, 69, 70, 72, 82, 93, 95, 96, 99, 105, 106, 110, 113, 119, 120, 121, 122, 123, 124, 126, 127, 128, 143, 157, 158, 160, 161, 163, 164, 165, 171, 173, 175, 176, 177, 182, 183, 189], "x_train_0": 2, "stack": [2, 8, 28, 29, 30, 36, 47, 48, 54, 64, 66, 67, 69, 70, 71, 74, 77, 114, 153, 155, 171, 174, 175, 183, 184, 186], "256": [2, 19, 23, 29, 34, 35, 37, 39, 41, 42, 44, 45, 50, 51, 53, 54, 57, 59, 60, 62, 66, 68, 69, 70, 71, 82, 85, 86, 88, 89, 90, 99, 100, 103, 110, 115, 120, 121, 128, 143, 144, 158, 164, 177, 185, 186, 189], "x_train_1": 2, "x_test": 2, "y_test": 2, "ave_0": 2, "ave_1": 2, "vision": [2, 8, 20, 24, 25, 29, 35, 40, 44, 48, 49, 50, 51, 53, 54, 56, 59, 62, 64, 67, 69, 71, 72, 73, 74, 77, 82, 92, 94, 96, 111, 123, 143, 149, 156, 186, 191], "astyp": [2, 8, 20, 21, 29, 47, 49, 53, 56, 57, 59, 60, 93, 100, 110, 113, 135, 157, 176, 177], "float": [2, 6, 8, 11, 19, 20, 22, 23, 26, 28, 29, 30, 31, 41, 45, 47, 51, 54, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 83, 85, 86, 88, 89, 90, 92, 98, 99, 100, 104, 105, 108, 110, 113, 115, 128, 131, 135, 141, 143, 144, 155, 156, 157, 158, 163, 165, 170, 171, 173, 175, 177, 183], "train_imag": [2, 8], "train_label": [2, 8, 59, 163], "test_imag": [2, 8, 49], "test_label": [2, 8, 49], "kera": [2, 4, 8, 20, 22, 23, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 42, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 82, 83, 92, 93, 96, 99, 104, 106, 108, 110, 115, 137, 138, 139, 143, 144, 145, 147, 171, 172, 173, 175, 177, 182], "fashion_mnist": [2, 20, 96], "load_data": [2, 8, 20, 96], "label": [2, 4, 8, 20, 21, 25, 30, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 66, 68, 69, 78, 80, 83, 93, 95, 96, 98, 100, 101, 103, 106, 107, 108, 109, 111, 113, 114, 117, 119, 120, 121, 122, 124, 126, 127, 130, 133, 134, 135, 140, 145, 147, 148, 151, 156, 157, 159, 161, 163, 174, 176, 177, 180, 181, 184, 186], "enumer": [2, 20, 27, 29, 35, 47, 51, 53, 54, 59, 60, 64, 65, 69, 77, 92, 103, 113, 121, 127, 131, 135, 143, 159, 163, 164, 165, 168, 169, 176, 183, 185], "reduce_mean": [2, 4, 11, 20, 31, 63, 76, 93, 100, 105, 113, 144, 153], "resembl": [2, 10, 24, 62, 63, 83, 92, 111, 116, 145, 155, 160, 173, 175], "blurri": 2, "imshow": [2, 20, 21, 27, 47, 48, 49, 51, 55, 56, 60, 82], "reshap": [2, 8, 20, 21, 22, 23, 26, 27, 28, 29, 30, 44, 47, 49, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 83, 93, 99, 100, 104, 105, 107, 110, 113, 115, 120, 124, 126, 128, 131, 133, 135, 144, 153, 155, 160, 168, 177, 183, 184], "28": [2, 8, 45, 56, 62, 63, 66, 70, 74, 78, 92, 96, 100, 115, 179, 186], "cmap": [2, 20, 21, 27, 28], "grei": [2, 88], "fulli": [2, 3, 11, 23, 25, 26, 29, 30, 31, 32, 35, 36, 42, 44, 46, 50, 52, 54, 58, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 78, 82, 83, 92, 94, 98, 99, 103, 104, 105, 106, 110, 111, 112, 114, 115, 116, 117, 121, 123, 124, 126, 149, 158, 168, 173, 175, 177, 181, 182, 183, 186, 191], "solut": [2, 6, 7, 9, 19, 21, 50, 64, 65, 69, 75, 78, 79, 90, 92, 94, 95, 98, 99, 101, 104, 105, 111, 113, 126, 141, 143, 145, 146, 148, 149, 160, 163, 164, 175, 180, 183, 186, 187, 189], "accuraci": [2, 8, 9, 20, 25, 30, 43, 44, 45, 47, 49, 50, 51, 53, 58, 60, 62, 63, 64, 66, 67, 68, 69, 70, 74, 76, 83, 86, 92, 94, 95, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 120, 121, 123, 124, 138, 143, 151, 158, 165, 168, 169, 171, 180, 184], "pytorch": [2, 4, 11, 14, 18, 20, 33, 35, 38, 39, 40, 42, 51, 76, 78, 81, 83, 91, 92, 104, 106, 108, 126, 143, 149, 150, 154, 155], "2000": [2, 19, 25, 38, 58, 62, 74, 92, 104, 148, 175, 186], "flatten": [2, 10, 20, 22, 23, 26, 29, 30, 33, 35, 36, 37, 45, 60, 62, 63, 64, 65, 66, 68, 69, 70, 73, 74, 99, 100, 109, 110, 115, 120, 126, 143, 163, 177, 182, 185], "1500000": 2, "transpos": [2, 7, 21, 22, 23, 26, 29, 30, 52, 56, 57, 59, 60, 72, 82, 120, 123, 124, 136, 153, 177, 182, 183, 191], "reduce_sum": [2, 4, 5, 8, 9, 11, 20, 21, 35, 71, 72, 100, 108, 150, 153, 155, 157, 176, 177, 183], "nest": [2, 35, 36, 69, 72, 87, 151, 155], "solid": [2, 4, 40, 56, 69, 85, 129, 149, 157], "omit": [2, 4, 11, 23, 28, 42, 60, 64, 113, 129, 134, 139, 141, 148, 160, 164, 168, 181], "matric": [2, 3, 7, 17, 22, 27, 28, 33, 38, 41, 56, 61, 62, 69, 77, 98, 108, 109, 115, 116, 136, 140, 144, 145, 149, 150, 151, 152, 155, 158, 163, 178, 181, 183, 186], "intern": [2, 23, 63, 92, 93, 105, 110, 132, 141, 154, 173, 174, 186], "signific": [2, 5, 9, 19, 24, 26, 27, 30, 38, 39, 41, 42, 44, 45, 46, 47, 51, 62, 63, 67, 68, 69, 71, 72, 73, 74, 75, 77, 92, 94, 95, 101, 104, 105, 111, 114, 115, 116, 139, 141, 143, 144, 149, 153, 182], "build": [2, 4, 7, 8, 12, 19, 23, 28, 29, 31, 35, 37, 41, 42, 53, 59, 62, 63, 69, 70, 72, 73, 80, 83, 92, 94, 95, 99, 107, 111, 113, 114, 133, 143, 149, 150, 151, 153, 157, 162, 164, 167, 171, 176, 177, 180, 181, 183, 184, 185, 186, 187], "cx": [2, 48, 141], "dy": [2, 4, 5, 7, 9, 20, 82, 92, 94, 95, 101, 136, 140, 151], "odd": [2, 75, 157], "becam": [2, 24, 92, 161, 163, 175], "impenetr": 2, "moment": [2, 5, 7, 9, 22, 24, 72, 80, 92, 100, 111, 137, 139, 149, 180], "draw": [2, 9, 19, 20, 21, 23, 33, 47, 48, 59, 64, 77, 79, 80, 82, 83, 85, 92, 93, 98, 103, 105, 106, 109, 110, 116, 133, 138, 140, 148, 157, 173, 178, 180], "logic": [2, 4, 10, 32, 62, 65, 70, 92, 99, 119, 120, 126, 149, 155, 180, 181, 186], "grid": [2, 5, 7, 12, 20, 47, 58, 73, 77, 86, 92, 115, 151, 179, 189, 190], "skew": [2, 96], "structur": [2, 8, 35, 41, 46, 54, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 80, 85, 86, 87, 92, 98, 100, 105, 106, 113, 115, 125, 132, 138, 144, 153, 157, 158, 160, 163, 164, 165, 167, 168, 173, 176, 179, 180, 181, 184, 185, 186, 187], "transport": [2, 187], "along": [2, 4, 6, 7, 9, 11, 24, 25, 28, 58, 60, 63, 64, 65, 66, 72, 76, 86, 92, 95, 99, 100, 103, 109, 111, 114, 123, 140, 153, 155, 162, 174, 181, 183, 187, 188], "incap": [2, 166], "distort": [2, 138, 145], "sever": [2, 4, 6, 7, 10, 11, 14, 19, 36, 37, 38, 40, 45, 48, 52, 59, 60, 62, 69, 70, 79, 85, 86, 88, 92, 95, 99, 101, 108, 111, 115, 126, 129, 138, 149, 151, 156, 164, 168, 174, 176, 184], "later": [2, 5, 6, 10, 17, 19, 20, 21, 22, 23, 25, 27, 29, 31, 34, 35, 37, 38, 39, 42, 44, 47, 51, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 76, 78, 79, 80, 85, 90, 92, 93, 94, 98, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 114, 116, 124, 127, 131, 138, 139, 141, 144, 145, 147, 148, 149, 150, 151, 153, 164, 171, 172, 175, 176, 177, 178, 180, 182, 184, 185, 189], "bent": 2, "back": [2, 3, 7, 10, 11, 14, 20, 32, 37, 38, 39, 40, 41, 44, 46, 49, 59, 62, 63, 69, 70, 77, 88, 92, 94, 95, 96, 98, 103, 114, 140, 141, 150, 151, 157, 158, 183, 184, 185, 186], "cannot": [2, 6, 7, 9, 11, 12, 19, 25, 28, 34, 37, 38, 41, 50, 59, 62, 63, 71, 75, 76, 78, 82, 83, 86, 89, 90, 92, 94, 95, 98, 101, 103, 104, 105, 107, 110, 111, 113, 116, 132, 133, 134, 140, 141, 143, 144, 154, 155, 157, 179, 183, 184, 187], "came": [2, 6, 11, 62, 83, 92, 94, 109, 126, 128, 151, 157, 169, 175], "times2": [2, 49, 60, 71, 72, 74, 75, 98, 123, 155], "prevent": [2, 25, 28, 63, 99, 111, 143, 145, 156, 175, 178, 186], "lesson": [2, 95], "feel": [2, 7, 9, 11, 12, 42, 78, 79, 85, 88, 92, 95], "deal": [2, 8, 9, 22, 31, 41, 44, 46, 62, 64, 77, 83, 92, 93, 94, 95, 98, 103, 107, 108, 113, 115, 116, 140, 143, 144, 145, 149, 155, 156, 157, 159, 167, 178, 179, 180, 183, 184, 185], "live": [2, 38, 52, 78, 92, 94, 104, 156, 162], "question": [2, 4, 5, 6, 7, 8, 9, 10, 11, 21, 25, 30, 46, 62, 63, 67, 69, 76, 78, 83, 88, 92, 94, 95, 98, 101, 110, 111, 113, 114, 118, 119, 126, 138, 143, 149, 154, 157, 176, 180, 186], "aris": [2, 27, 42, 45, 63, 65, 71, 87, 92, 94, 100, 101, 103, 105, 139, 142, 144, 156, 169, 178, 179, 189, 190], "detect": [2, 8, 11, 24, 25, 35, 47, 49, 52, 58, 59, 62, 63, 66, 67, 71, 73, 76, 77, 92, 94, 157, 170, 186, 191], "rememb": [2, 14, 27, 63, 91, 92, 94, 147, 150, 153, 173, 190], "everyth": [2, 4, 5, 6, 7, 9, 10, 14, 27, 38, 76, 77, 81, 83, 92, 95, 100, 115, 149, 185], "a_1": [2, 47, 95, 188, 190], "a_2": [2, 47, 188], "2a_1": 2, "redund": [2, 4, 19, 98, 103, 113, 119, 139, 155], "uniqu": [2, 4, 35, 41, 47, 88, 89, 95, 103, 105, 110, 149, 156, 157, 164, 179, 180, 185], "alreadi": [2, 4, 5, 7, 8, 9, 10, 12, 14, 17, 23, 24, 27, 29, 33, 36, 38, 40, 41, 44, 49, 69, 76, 78, 79, 80, 81, 86, 89, 90, 91, 92, 94, 95, 101, 105, 107, 108, 110, 113, 114, 118, 138, 141, 142, 144, 145, 149, 150, 151, 153, 155, 157, 169, 171, 177, 178, 179, 183, 184, 185], "collaps": [2, 80, 114, 126, 157], "moreov": [2, 7, 8, 22, 24, 25, 27, 35, 38, 41, 42, 44, 45, 48, 58, 62, 64, 65, 66, 75, 76, 77, 80, 85, 88, 89, 92, 94, 95, 98, 99, 101, 103, 104, 105, 106, 108, 111, 114, 115, 116, 133, 137, 139, 140, 141, 143, 146, 148, 149, 150, 156, 157, 160, 161, 162, 168, 171, 177, 178, 179, 182], "captur": [2, 9, 20, 23, 24, 26, 28, 29, 41, 48, 62, 65, 66, 69, 74, 75, 77, 78, 83, 92, 98, 101, 103, 111, 123, 131, 149, 153, 157, 158, 160, 163, 168, 169, 173, 178, 179, 180, 181, 184, 185], "_k": [2, 7, 129], "a_k": 2, "a_i": [2, 47], "effect": [2, 3, 11, 19, 22, 25, 27, 29, 30, 39, 41, 44, 46, 50, 51, 52, 58, 60, 62, 63, 64, 68, 69, 70, 71, 72, 75, 76, 77, 78, 79, 80, 81, 85, 86, 92, 94, 98, 100, 103, 104, 108, 110, 114, 138, 139, 141, 143, 144, 146, 147, 157, 158, 159, 160, 162, 163, 164, 165, 168, 173, 178, 181, 183, 187], "render": [2, 63, 83, 94, 98, 100, 116, 149], "wit": [2, 24, 104], "lower": [2, 4, 6, 12, 19, 20, 25, 28, 41, 46, 47, 48, 57, 58, 62, 64, 69, 72, 76, 77, 78, 86, 92, 95, 98, 101, 103, 109, 110, 114, 121, 127, 141, 143, 148, 151, 153, 157, 158, 163, 176, 177, 185], "undon": 2, "map": [2, 3, 4, 8, 20, 28, 37, 49, 53, 55, 58, 59, 60, 61, 64, 65, 66, 69, 71, 73, 74, 76, 77, 82, 83, 85, 86, 92, 96, 98, 100, 114, 121, 132, 133, 134, 135, 140, 141, 144, 151, 153, 155, 157, 158, 172, 175, 176, 178, 180, 185, 186], "bear": [2, 62, 73, 94, 101, 122, 123], "amongst": [2, 164], "subset": [2, 19, 25, 41, 44, 54, 86, 90, 92, 101, 110, 117, 131, 153, 157], "four": [2, 6, 7, 9, 23, 27, 28, 41, 46, 47, 49, 50, 51, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 72, 74, 76, 77, 82, 89, 92, 95, 98, 113, 114, 144, 153, 164, 169, 180, 184, 186, 188, 190], "procedur": [2, 11, 66, 78, 79, 80, 92, 94, 103, 105, 111, 113, 128, 138, 142, 144, 145, 147, 148, 150, 151, 155, 178, 179], "ineffici": [2, 10, 40, 42, 44, 46, 83, 107, 161], "exponenti": [2, 3, 8, 10, 21, 22, 27, 62, 82, 98, 99, 100, 103, 113, 136, 139, 140, 145, 148, 153, 155, 169, 180, 181], "computation": [2, 10, 25, 38, 62, 64, 66, 70, 73, 77, 92, 99, 115, 129, 139, 144, 169, 173, 178], "effici": [2, 7, 19, 22, 23, 25, 28, 29, 30, 38, 39, 40, 41, 42, 44, 45, 46, 53, 57, 60, 61, 62, 64, 65, 66, 67, 69, 72, 73, 75, 77, 85, 86, 87, 88, 89, 90, 92, 96, 98, 100, 103, 105, 107, 112, 113, 115, 123, 129, 132, 133, 135, 139, 140, 141, 142, 143, 144, 148, 149, 150, 155, 156, 162, 169, 176, 177, 178, 180, 182, 184, 186], "invers": [2, 4, 47, 92, 110, 136, 148, 151], "recov": [2, 5, 8, 37, 63, 105, 107, 108, 132, 145, 153, 157, 169, 173], "vdot": [2, 5, 6, 7, 26, 79, 153, 183, 184], "ddot": [2, 5, 7, 79, 153], "elsewher": [2, 28, 151], "leav": [2, 7, 10, 63, 64, 70, 76, 78, 85, 101, 108, 113, 116, 121, 127, 140, 148, 149, 164, 174], "system": [2, 4, 9, 11, 14, 19, 24, 25, 35, 39, 40, 41, 44, 46, 48, 52, 62, 67, 73, 77, 78, 89, 91, 94, 96, 98, 103, 105, 107, 111, 114, 117, 134, 138, 149, 151, 155, 163, 164, 165, 180, 184, 186, 187, 188, 191], "unknown": [2, 6, 11, 20, 34, 53, 54, 92, 95, 111, 119, 131, 132, 133, 153, 157, 158, 164, 176, 185, 187, 189, 190], "hold": [2, 3, 4, 7, 9, 19, 41, 47, 49, 60, 61, 64, 72, 77, 79, 86, 92, 94, 95, 98, 101, 107, 108, 125, 129, 138, 140, 141, 145, 148, 151, 153, 156, 157, 184, 190], "quantiti": [2, 7, 9, 10, 12, 41, 78, 92, 93, 95, 110, 113, 153, 157, 178, 180, 188, 190], "bc": [2, 144], "m_inv": 2, "wish": [2, 4, 5, 6, 7, 9, 10, 11, 17, 18, 34, 36, 38, 75, 78, 80, 92, 94, 95, 98, 103, 104, 106, 111, 113, 120, 150, 151, 153, 155, 157, 170, 171, 184], "divis": [2, 49, 50, 63, 69, 75, 92, 100, 105, 115, 147, 153, 155], "instabl": [2, 100, 160, 174, 178, 183], "low": [2, 4, 9, 11, 19, 30, 32, 41, 42, 62, 63, 64, 66, 68, 92, 94, 101, 103, 107, 111, 113, 114, 133, 153, 157, 158, 160, 163, 171, 183, 186], "spars": [2, 41, 61, 62, 139, 140, 142, 159, 160, 161, 164, 167, 186], "were": [2, 4, 5, 7, 9, 11, 22, 24, 25, 30, 33, 35, 36, 39, 40, 41, 42, 44, 50, 62, 63, 64, 66, 67, 68, 69, 70, 74, 77, 78, 79, 83, 92, 93, 94, 95, 98, 101, 103, 105, 110, 111, 114, 115, 116, 123, 124, 142, 149, 150, 151, 153, 157, 166, 175, 176, 179, 180, 183, 184, 185, 187, 188, 189], "explor": [2, 4, 63, 64, 66, 67, 72, 75, 78, 86, 92, 96, 98, 101, 110, 114, 116, 118, 132, 142, 145, 150, 154, 162, 167, 174, 179, 186, 187, 188], "store": [2, 8, 10, 12, 17, 19, 23, 29, 35, 37, 38, 41, 42, 43, 54, 59, 62, 63, 86, 88, 92, 93, 96, 98, 103, 106, 107, 108, 109, 110, 119, 123, 137, 139, 141, 145, 149, 150, 152, 155, 156, 162, 163, 177, 178, 180, 181, 184, 186], "typic": [2, 6, 8, 9, 14, 19, 25, 27, 28, 35, 38, 40, 41, 46, 60, 61, 62, 63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 86, 89, 90, 92, 93, 94, 95, 96, 101, 103, 110, 111, 113, 115, 116, 133, 134, 138, 139, 140, 143, 144, 147, 148, 149, 151, 153, 157, 158, 175, 177, 180, 184, 185, 187, 188, 189], "almost": [2, 11, 38, 41, 42, 52, 62, 64, 68, 70, 76, 78, 90, 94, 101, 103, 105, 127, 134, 142, 143, 154, 155, 178, 180, 184, 186], "trillion": [2, 25, 95, 186], "dive": [2, 4, 5, 10, 16, 21, 22, 64, 68, 73, 85, 98, 106, 109, 112, 116, 119, 126, 149, 152, 163], "thorni": 2, "proce": [2, 23, 34, 36, 38, 44, 47, 64, 77, 90, 103, 109, 113, 143, 144, 145, 176, 184], "caution": [2, 9, 39, 92, 100, 144, 153], "avoid": [2, 18, 19, 26, 32, 41, 42, 46, 56, 59, 68, 69, 75, 86, 88, 89, 94, 96, 98, 99, 100, 103, 105, 109, 110, 113, 126, 141, 149, 150, 153, 155, 163, 174, 176, 178, 182, 188], "rule": [2, 3, 4, 5, 6, 8, 9, 38, 61, 62, 64, 86, 89, 92, 93, 95, 101, 109, 136, 139, 141, 150, 152, 157, 163, 178, 180, 184], "thumb": [2, 7, 38, 86, 92, 101, 136, 167], "region": [2, 5, 9, 11, 12, 47, 51, 52, 55, 59, 62, 73, 76, 77, 78, 79, 92, 141, 186, 191], "edg": [2, 5, 7, 41, 50, 62, 71, 73, 76, 77, 92, 99, 103, 104, 174, 175, 179, 186], "parallelogram": 2, "quickli": [2, 4, 7, 10, 19, 21, 41, 57, 78, 79, 80, 85, 86, 89, 92, 94, 105, 116, 138, 139, 140, 147, 148, 149, 151, 154, 157, 161, 180, 184, 185], "eagl": 2, "matter": [2, 4, 6, 17, 19, 25, 28, 40, 41, 42, 43, 46, 62, 63, 66, 72, 74, 86, 92, 101, 103, 108, 112, 114, 115, 130, 141, 143, 144, 145, 147, 153, 157, 178, 181, 186], "negat": [2, 119], "segment": [2, 10, 24, 49, 52, 61, 66, 67, 77, 92, 113, 117, 121, 126, 127, 128, 132, 140, 157, 176, 178, 186, 191], "And": [2, 4, 5, 7, 11, 20, 46, 62, 76, 77, 82, 83, 92, 94, 95, 98, 101, 111, 113, 114, 149, 153, 157, 175, 187], "comment": [2, 3, 122, 151], "imagin": [2, 4, 5, 6, 7, 8, 9, 11, 24, 28, 35, 38, 58, 77, 79, 80, 92, 94, 98, 101, 115, 116, 138, 140, 157, 185, 189, 190], "scientist": [2, 9, 10, 64, 92, 94, 101, 113, 114, 149, 154, 179, 180, 184], "decompos": [2, 3, 5, 42, 46, 65, 71, 120, 145, 153, 178, 184, 186], "essenc": [2, 7, 9, 55, 146, 191], "labori": 2, "contract": 2, "unifi": [2, 9, 25, 63, 92, 149, 186], "knew": [2, 83], "c_": [2, 7, 64, 69, 71, 80, 94, 153, 178], "b_": [2, 47, 153, 173, 175, 178], "univers": [2, 4, 70, 80, 81, 92, 94, 144, 149, 164, 186, 187], "specifi": [2, 8, 18, 20, 22, 23, 26, 29, 30, 32, 34, 35, 37, 38, 42, 47, 49, 50, 51, 53, 58, 59, 60, 61, 63, 64, 66, 70, 72, 76, 78, 79, 80, 81, 83, 88, 89, 90, 91, 92, 95, 102, 104, 105, 106, 107, 108, 110, 111, 116, 119, 120, 123, 127, 128, 131, 132, 151, 153, 154, 155, 157, 164, 169, 171, 172, 175, 176, 180, 182, 183, 189], "y_": [2, 4, 78, 160, 169, 177, 184], "il": [2, 23, 29, 172, 177], "jk": [2, 138], "x_": [2, 7, 8, 47, 56, 72, 78, 79, 103, 129, 136, 145, 151, 153, 178, 180, 181, 183, 184], "ijkl": 2, "Such": [2, 7, 9, 59, 70, 92, 103, 111, 116, 117, 118, 119, 120, 121, 144, 184, 185, 187, 189], "alon": [2, 6, 7, 25, 76, 86, 92, 101, 103, 108, 149, 186], "simplif": [2, 6], "einstein": [2, 7, 156], "summat": [2, 4, 9, 11, 103, 125, 136, 153, 160, 169, 175, 181, 189, 190], "implicitli": [2, 75, 78, 92, 106, 189], "compact": [2, 22, 23, 26, 28, 29, 30, 35, 41, 62, 63, 65, 98, 99, 103, 106, 110, 115, 137, 171, 173, 175, 182], "v_iw_i": [2, 9], "v_iv_i": 2, "sum_j": [2, 21, 27, 98], "v_j": 2, "ik": [2, 4, 7, 100, 120, 129], "tr": [2, 186], "replac": [2, 4, 5, 6, 12, 14, 20, 21, 22, 23, 25, 29, 30, 42, 45, 54, 56, 58, 60, 61, 63, 64, 68, 69, 72, 74, 76, 90, 92, 104, 105, 106, 108, 110, 113, 114, 121, 122, 123, 124, 126, 127, 129, 132, 133, 138, 139, 144, 145, 148, 151, 155, 156, 162, 165, 171, 173, 174, 175, 176, 177, 178, 183, 189], "myriad": [2, 111, 156, 174], "flexibli": [2, 178], "creat": [2, 4, 5, 9, 10, 11, 14, 16, 17, 20, 28, 29, 31, 33, 35, 38, 41, 44, 47, 49, 50, 51, 54, 56, 57, 59, 60, 61, 63, 68, 69, 70, 71, 72, 74, 75, 78, 79, 88, 91, 92, 94, 95, 96, 100, 103, 104, 106, 107, 108, 113, 118, 123, 126, 131, 133, 134, 139, 144, 149, 150, 153, 154, 155, 156, 158, 162, 163, 164, 165, 168, 177, 181, 182, 184, 188], "implement": [2, 4, 7, 8, 11, 14, 15, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 33, 35, 39, 41, 42, 43, 44, 46, 47, 49, 53, 55, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 86, 88, 89, 90, 92, 93, 94, 96, 97, 98, 102, 109, 111, 112, 113, 114, 116, 119, 120, 121, 122, 123, 126, 127, 128, 131, 133, 135, 141, 142, 143, 149, 153, 154, 157, 159, 162, 167, 172, 174, 176, 177, 179, 181, 186, 187, 191], "directli": [2, 4, 5, 6, 7, 9, 10, 14, 17, 21, 28, 31, 33, 37, 41, 42, 46, 53, 57, 58, 62, 63, 67, 69, 79, 80, 81, 86, 91, 92, 93, 94, 95, 98, 100, 102, 103, 104, 108, 111, 114, 115, 132, 134, 141, 142, 157, 173, 175, 177, 184], "pass": [2, 7, 10, 20, 24, 30, 34, 35, 39, 40, 44, 45, 60, 62, 63, 64, 69, 74, 85, 86, 88, 90, 94, 97, 99, 100, 103, 104, 105, 106, 107, 109, 110, 128, 133, 139, 144, 148, 149, 150, 153, 165, 170, 171, 175, 178, 179, 180, 183], "string": [2, 17, 22, 23, 37, 91, 127, 156, 173, 176, 182, 185], "upon": [2, 32, 35, 62, 63, 67, 68, 77, 85, 92, 98, 103, 106, 108, 114, 156, 157, 170, 177, 179, 188, 189, 190], "strip": [2, 71, 75, 119, 127], "themselv": [2, 6, 9, 27, 37, 62, 71, 72, 73, 92, 149, 150, 151, 162, 184], "reimplement": [2, 27, 35, 42, 149, 162, 168, 182], "einsum": 2, "highli": [2, 9, 39, 44, 46, 62, 72, 79, 81, 99, 105, 144, 147, 157, 162, 182, 183, 186], "tradition": [2, 7, 92, 137], "kl": [2, 136], "ijk": [2, 31, 46, 153], "via": [2, 4, 5, 7, 8, 14, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 40, 41, 42, 43, 46, 47, 49, 50, 51, 56, 57, 60, 61, 63, 64, 65, 68, 69, 70, 72, 74, 76, 82, 83, 85, 88, 92, 94, 99, 103, 104, 105, 106, 107, 108, 109, 113, 114, 115, 124, 126, 127, 133, 135, 137, 140, 141, 143, 145, 148, 149, 150, 151, 153, 155, 156, 157, 158, 169, 175, 178, 179, 180, 181, 183, 186, 187], "readabl": [2, 106], "human": [2, 8, 10, 25, 64, 69, 77, 83, 92, 96, 111, 130, 149, 186], "bulki": 2, "programmat": [2, 11], "altern": [2, 4, 9, 11, 12, 17, 19, 24, 25, 28, 41, 42, 51, 61, 63, 64, 65, 68, 69, 71, 75, 78, 80, 86, 88, 91, 92, 95, 103, 109, 125, 139, 140, 141, 143, 144, 147, 148, 156, 169, 175, 177, 178, 183, 186], "arbitrarili": [2, 10, 27, 59, 92, 101, 111, 119, 127, 157, 184, 189], "uniform": [2, 3, 4, 21, 22, 23, 31, 33, 34, 35, 36, 37, 38, 40, 45, 47, 49, 51, 61, 65, 72, 75, 82, 86, 94, 95, 100, 110, 116, 133, 154, 164, 180, 186, 189], "clean": [2, 5, 10, 25, 62, 63, 92, 96, 149, 164], "its": [2, 4, 6, 7, 8, 9, 10, 11, 14, 18, 19, 22, 23, 25, 27, 28, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 121, 122, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 153, 155, 157, 158, 160, 161, 162, 163, 165, 167, 168, 171, 172, 175, 176, 177, 179, 180, 184, 185, 186, 188, 189, 190], "action": [2, 20, 21, 22, 41, 42, 74, 92, 94, 100, 106, 157, 165, 168, 173, 175, 187, 188, 189], "care": [2, 4, 9, 11, 35, 38, 41, 45, 47, 63, 73, 74, 77, 78, 82, 92, 93, 94, 95, 98, 100, 101, 103, 104, 107, 113, 116, 138, 144, 151, 155, 157, 171, 177], "ow": [2, 63, 73, 92, 101, 105, 113, 129, 149, 175, 176, 179, 183], "expand": [2, 4, 5, 9, 30, 51, 90, 145, 147, 155, 157, 178], "nonzero": [2, 22, 31, 47, 72, 75, 94, 99, 111, 138, 141, 157, 164, 180], "impli": [2, 5, 9, 10, 44, 77, 89, 101, 114, 134, 140, 146, 168], "neat": [2, 72], "vec": [2, 131], "v_1": [2, 72], "qquad": [2, 7], "v_2": [2, 72], "pmatrix": [2, 7], "e_1": [2, 64], "e_2": 2, "condit": [2, 7, 8, 22, 25, 35, 72, 78, 79, 92, 94, 98, 103, 110, 111, 113, 114, 116, 125, 129, 130, 134, 136, 138, 139, 140, 141, 143, 150, 155, 157, 169, 170, 172, 177, 178, 180, 181, 183, 184, 186, 188, 190], "ae_1": 2, "ae_2": 2, "brent": [3, 27], "wer": [3, 27], "amazon": [3, 4, 12, 16, 19, 62, 81, 86, 87, 92, 122, 149, 162, 167, 187, 191], "rachel": [3, 27], "hu": [3, 27, 56, 64, 92, 149, 167, 186], "author": [3, 10, 14, 63, 69, 92, 94, 110, 116, 137, 139, 149, 167, 171, 183], "book": [3, 5, 7, 12, 13, 15, 16, 17, 18, 20, 23, 25, 29, 41, 42, 52, 63, 64, 83, 85, 91, 92, 93, 96, 98, 99, 101, 103, 104, 105, 106, 108, 113, 114, 118, 127, 130, 136, 142, 144, 148, 151, 152, 153, 154, 157, 167, 171, 179, 183, 184, 185, 186, 191], "wonder": [3, 4, 11, 21, 30, 35, 36, 98, 107, 108, 157, 184], "understood": [3, 5, 138, 144, 149, 161, 180], "field": [3, 4, 6, 19, 28, 30, 48, 52, 55, 57, 59, 60, 62, 67, 70, 73, 76, 86, 92, 103, 106, 114, 122, 149, 156, 157, 159, 160, 163, 167, 176, 184, 186], "matur": [3, 32, 149], "softwar": [3, 17, 32, 36, 42, 92, 149, 153], "develop": [3, 4, 5, 9, 11, 12, 14, 35, 39, 41, 42, 62, 63, 67, 70, 74, 79, 91, 92, 94, 95, 96, 101, 102, 103, 104, 110, 111, 126, 144, 149, 150, 151, 155, 156, 157, 171, 178, 179, 183, 184, 186, 187, 190], "worri": [3, 5, 8, 35, 47, 63, 91, 92, 94, 95, 102, 103, 104, 107, 109, 149, 163, 184], "neither": [3, 7, 9, 35, 62, 95, 98, 116, 119, 132, 140, 146], "theoret": [3, 4, 6, 7, 8, 10, 30, 63, 78, 92, 94, 95, 101, 111, 116, 138, 142, 148, 149, 157, 160], "foundat": [3, 24, 70, 81, 92, 95, 149, 157, 186, 190], "likelihood": [3, 4, 11, 20, 47, 77, 78, 79, 92, 94, 95, 100, 103, 108, 111, 114, 117, 134, 140, 146, 157, 159, 180, 184, 191], "quit": [3, 7, 17, 22, 23, 27, 40, 41, 42, 44, 45, 46, 47, 63, 64, 65, 67, 69, 70, 72, 77, 79, 86, 89, 93, 96, 98, 99, 106, 113, 114, 137, 138, 141, 143, 144, 145, 146, 150, 155, 157, 169, 175, 178, 180, 183, 184, 185, 188, 190], "yet": [3, 4, 19, 25, 27, 31, 34, 36, 44, 46, 62, 63, 66, 74, 77, 85, 86, 89, 90, 91, 92, 94, 95, 101, 105, 106, 110, 111, 114, 126, 131, 137, 138, 143, 147, 149, 159, 175], "architectur": [3, 7, 10, 22, 23, 24, 25, 28, 30, 31, 32, 34, 35, 36, 37, 41, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 82, 83, 85, 86, 91, 92, 95, 101, 102, 104, 110, 111, 114, 115, 116, 117, 118, 120, 121, 123, 124, 126, 130, 149, 158, 162, 165, 169, 170, 171, 173, 174, 175, 177, 178, 179, 183, 184, 186, 191], "influenc": [3, 10, 11, 23, 68, 69, 70, 92, 100, 101, 103, 112, 114, 149, 150, 157, 163, 167, 168, 171, 173, 174, 175, 177, 178, 183, 184, 186], "gradient": [3, 5, 6, 20, 21, 22, 25, 27, 35, 36, 40, 41, 44, 45, 46, 51, 54, 56, 62, 72, 74, 78, 82, 83, 86, 92, 93, 97, 98, 104, 105, 108, 109, 110, 111, 112, 114, 115, 121, 125, 129, 134, 136, 137, 138, 139, 140, 142, 143, 145, 147, 149, 152, 155, 158, 161, 163, 170, 174, 175, 179, 181, 186, 189, 191], "flow": [3, 7, 35, 38, 41, 42, 44, 62, 69, 74, 82, 92, 94, 103, 109, 114, 152, 155, 173, 175, 186], "implicit": [3, 39, 75, 92, 101, 114, 162, 164, 165, 166, 168, 186], "assumpt": [3, 6, 8, 9, 11, 63, 64, 67, 77, 78, 79, 80, 92, 94, 95, 101, 103, 111, 114, 116, 157, 187, 190], "certain": [3, 4, 8, 9, 11, 33, 38, 41, 42, 47, 51, 55, 56, 72, 77, 79, 88, 90, 92, 99, 111, 123, 141, 143, 145, 149, 153, 155, 157, 180, 183, 185, 186], "loss": [3, 4, 6, 7, 10, 11, 20, 25, 36, 38, 44, 45, 46, 49, 50, 51, 52, 53, 54, 58, 62, 63, 66, 69, 70, 72, 74, 78, 82, 83, 86, 89, 92, 93, 94, 95, 97, 99, 101, 102, 106, 108, 109, 110, 111, 113, 114, 115, 117, 120, 121, 123, 124, 125, 126, 127, 128, 129, 133, 134, 142, 143, 144, 146, 148, 150, 151, 152, 157, 158, 160, 161, 162, 163, 165, 168, 174, 178, 180, 181, 183, 184, 186], "per": [3, 4, 8, 9, 19, 21, 22, 39, 41, 44, 45, 46, 53, 62, 63, 64, 66, 68, 70, 71, 74, 75, 85, 86, 89, 92, 98, 115, 122, 123, 133, 138, 139, 140, 144, 147, 153, 155, 159, 176, 178], "charact": [3, 4, 20, 23, 83, 92, 101, 132, 134, 175, 176, 178, 179, 180, 183, 185], "aim": [3, 4, 19, 41, 63, 77, 82, 86, 94, 95, 110, 112, 119, 157, 158, 165, 166, 167, 168, 170, 173, 181], "background": [3, 21, 24, 47, 57, 58, 59, 60, 62, 92, 149, 179], "core": [3, 7, 10, 11, 18, 19, 21, 24, 33, 37, 38, 39, 40, 41, 46, 62, 72, 73, 88, 92, 111, 144, 150, 167, 179], "exhaust": [3, 86, 92, 107, 149, 174], "greater": [3, 8, 11, 19, 20, 35, 47, 50, 56, 62, 71, 72, 74, 75, 78, 79, 92, 95, 98, 101, 103, 110, 111, 114, 116, 133, 134, 148, 149, 157, 164, 169, 177, 183], "depth": [3, 6, 11, 20, 41, 62, 64, 65, 71, 78, 92, 98, 100, 111, 142, 144, 145, 149, 171, 183], "oper": [3, 4, 6, 7, 17, 19, 26, 27, 28, 29, 30, 35, 36, 38, 39, 40, 41, 42, 44, 46, 49, 51, 52, 53, 54, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 92, 93, 94, 98, 100, 101, 103, 104, 108, 109, 110, 114, 115, 116, 117, 120, 123, 125, 132, 134, 138, 144, 149, 150, 151, 152, 153, 168, 171, 173, 175, 177, 178, 181, 186, 191], "enabl": [3, 10, 12, 17, 32, 41, 42, 60, 62, 63, 74, 78, 79, 91, 92, 103, 115, 130, 142, 149, 151, 160, 186, 189, 190], "variou": [3, 7, 10, 19, 26, 30, 33, 35, 36, 37, 38, 39, 41, 48, 51, 52, 55, 56, 62, 63, 64, 65, 66, 70, 79, 85, 92, 94, 96, 101, 104, 106, 110, 113, 117, 118, 126, 130, 147, 149, 153, 154, 155, 157, 167, 175, 188], "eigen": [3, 149], "differenti": [3, 4, 5, 23, 24, 27, 35, 92, 93, 101, 103, 104, 105, 109, 111, 112, 114, 116, 134, 140, 141, 149, 152, 155, 167, 177, 178, 181, 184, 186, 191], "calculu": [3, 6, 109, 141, 149, 152, 186, 191], "steepest": [3, 7, 141, 145], "descent": [3, 6, 20, 21, 44, 62, 74, 86, 92, 93, 105, 108, 109, 111, 116, 129, 134, 138, 139, 140, 142, 145, 146, 149, 161, 163, 181, 183, 186, 189, 191], "propag": [3, 31, 32, 36, 41, 45, 49, 55, 56, 58, 60, 61, 65, 69, 71, 72, 76, 86, 110, 112, 116, 150, 158, 172, 178, 179, 186, 191], "degre": [3, 4, 6, 7, 9, 10, 11, 51, 63, 64, 68, 76, 92, 101, 106, 108, 138, 141, 146, 149, 153, 157, 160, 161, 180, 183], "languag": [3, 4, 9, 22, 24, 27, 29, 30, 35, 39, 41, 42, 69, 77, 83, 92, 98, 111, 114, 117, 123, 128, 131, 132, 134, 138, 149, 150, 152, 153, 156, 157, 163, 169, 170, 172, 173, 174, 176, 177, 179, 182, 184, 186, 191], "speak": [3, 11, 35, 39, 41, 56, 72, 98, 103, 167, 181, 183], "uncertain": [3, 92, 157], "review": [3, 9, 14, 17, 21, 22, 25, 27, 41, 42, 46, 62, 63, 64, 69, 77, 92, 99, 103, 104, 108, 115, 122, 124, 130, 135, 139, 141, 143, 145, 150, 153, 157, 179, 184, 186], "probabilist": [3, 6, 92, 95, 98, 103, 157, 184, 186], "naiv": [3, 6, 71, 78, 92, 95, 103, 138, 144, 191], "bay": [3, 6, 157, 191], "justic": [3, 111], "awar": [3, 11, 39, 40, 41, 85, 92, 159, 162, 164, 165, 167, 177, 186, 191], "evalu": [3, 7, 8, 10, 20, 21, 22, 39, 42, 44, 45, 51, 53, 62, 64, 65, 66, 78, 79, 80, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 111, 113, 118, 119, 121, 126, 128, 136, 141, 142, 144, 148, 150, 151, 153, 155, 162, 169, 174, 178, 179, 180, 183, 184, 186, 187], "estim": [3, 4, 6, 8, 21, 27, 62, 63, 64, 66, 78, 79, 83, 86, 90, 92, 93, 94, 95, 98, 101, 103, 104, 105, 107, 108, 110, 111, 113, 134, 137, 139, 148, 156, 157, 163, 165, 166, 170, 178, 180, 184, 185, 186, 189, 190], "conduct": [3, 92, 95, 157, 168, 183], "hypothesi": [3, 25, 95, 101, 111, 119, 120, 121, 186], "construct": [3, 4, 5, 7, 10, 20, 27, 29, 31, 32, 35, 36, 40, 42, 47, 49, 50, 56, 60, 61, 62, 64, 65, 70, 71, 72, 75, 76, 77, 80, 81, 83, 85, 92, 98, 99, 104, 105, 113, 114, 119, 123, 124, 125, 134, 139, 141, 145, 150, 153, 155, 157, 164, 165, 166, 168, 171, 177, 181, 184, 185, 186, 188], "confid": [3, 47, 60, 72, 78, 79, 92, 95, 98, 101, 103, 110, 157, 186], "storag": [3, 19, 24, 40, 43, 46, 62, 78, 86, 91, 92, 98, 101, 104, 109, 175, 181], "transmiss": [3, 38, 41], "quantit": [3, 9, 11, 25, 110, 113, 186], "domain": [3, 5, 35, 79, 85, 92, 94, 100, 101, 103, 111, 114, 119, 127, 146, 148, 149, 167, 179, 185], "discours": [3, 63, 149], "path": [3, 7, 12, 17, 20, 25, 28, 29, 38, 41, 46, 50, 53, 54, 57, 59, 67, 69, 70, 109, 119, 121, 122, 125, 127, 131, 133, 143, 148, 149, 150, 156, 159, 160, 161, 164, 181], "toward": [3, 7, 10, 25, 30, 64, 78, 80, 89, 95, 96, 97, 98, 103, 105, 108, 109, 111, 122, 126, 139, 143, 157, 178, 183, 184, 186], "geometri": [3, 9, 62, 70, 92, 153, 191], "hyperplan": 3, "summari": [3, 16, 24, 32, 43, 52, 67, 73, 81, 84, 87, 97, 102, 112, 118, 130, 142, 152, 162, 174, 179, 187, 191], "exercis": [3, 16, 24, 32, 43, 52, 67, 73, 81, 84, 87, 97, 102, 112, 118, 130, 142, 152, 162, 174, 179, 187, 191], "eigendecomposit": [3, 138, 191], "gershgorin": 3, "circl": [3, 78, 108, 109, 138, 140, 151, 178], "growth": [3, 26, 38, 65, 92], "iter": [3, 5, 6, 7, 10, 20, 44, 45, 50, 51, 53, 54, 57, 59, 62, 63, 66, 68, 69, 70, 71, 72, 74, 78, 83, 85, 86, 87, 88, 89, 90, 92, 94, 96, 100, 103, 104, 105, 106, 107, 109, 110, 111, 116, 118, 119, 121, 123, 128, 129, 132, 133, 134, 135, 138, 141, 143, 144, 146, 148, 150, 176, 180, 183, 184, 186, 187, 189, 191], "multivari": [3, 5, 9, 78, 79, 80, 108, 142, 151, 191], "optim": [3, 4, 12, 20, 21, 22, 24, 25, 35, 40, 41, 42, 44, 45, 46, 49, 50, 51, 53, 54, 56, 60, 62, 63, 64, 67, 68, 69, 71, 72, 76, 77, 78, 82, 83, 93, 94, 98, 102, 103, 106, 108, 109, 111, 113, 114, 115, 116, 120, 121, 123, 124, 128, 135, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 153, 155, 157, 158, 160, 162, 163, 165, 166, 168, 169, 177, 178, 182, 183, 184, 186, 187, 191], "chain": [3, 5, 8, 10, 25, 35, 44, 61, 65, 74, 92, 108, 109, 150, 152, 157, 170, 173, 178, 183, 184, 186], "backpropag": [3, 10, 35, 36, 41, 44, 56, 61, 62, 71, 74, 83, 92, 99, 105, 110, 112, 116, 141, 150, 151, 175, 179, 181, 183, 186, 191], "hessian": [3, 138, 140, 141, 146], "bernoulli": [3, 4, 11, 92, 95, 110], "discret": [3, 4, 5, 6, 72, 77, 81, 92, 98, 113, 117, 122, 148, 157, 180, 184], "binomi": [3, 8], "poisson": [3, 103], "optic": [3, 62, 92, 101, 186], "recognit": [3, 23, 24, 35, 48, 51, 52, 62, 69, 76, 92, 94, 96, 101, 111, 126, 149, 174, 179, 180, 184, 186], "mutual": [3, 39, 92, 125, 157, 174], "kullback": 3, "leibler": 3, "diverg": [3, 63, 114, 116, 136, 139, 141, 143, 145, 178, 183, 184], "cross": [3, 6, 20, 21, 24, 25, 41, 44, 60, 65, 71, 73, 74, 75, 76, 77, 83, 90, 92, 95, 97, 99, 112, 123, 126, 129, 132, 160, 161, 177, 180, 181, 188], "overflow": [4, 41, 98, 99], "across": [4, 8, 22, 25, 27, 29, 36, 38, 41, 44, 45, 46, 47, 57, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 76, 80, 82, 85, 86, 88, 89, 92, 94, 101, 103, 104, 108, 110, 111, 114, 116, 117, 123, 126, 149, 156, 174, 175, 178, 179, 180], "disciplinari": 4, "rift": 4, "shakespear": 4, "sonnet": 4, "research": [4, 7, 10, 11, 24, 25, 27, 30, 31, 32, 38, 41, 50, 62, 63, 67, 68, 70, 74, 77, 78, 80, 92, 94, 95, 98, 103, 104, 110, 111, 113, 114, 116, 122, 126, 127, 130, 141, 149, 163, 164, 173, 176, 179, 186], "paper": [4, 24, 29, 41, 49, 56, 60, 62, 63, 65, 69, 70, 78, 83, 92, 95, 98, 109, 110, 116, 129, 130, 132, 133, 134, 150, 174, 177, 186], "cornel": 4, "arxiv": [4, 186], "gogh": 4, "starri": 4, "night": [4, 95], "beethoven": 4, "music": [4, 92, 162, 179, 186], "symphoni": 4, "program": [4, 11, 12, 31, 35, 38, 39, 40, 41, 43, 53, 62, 92, 103, 104, 106, 114, 149, 150, 153, 157, 184, 186, 187], "plankalk\u00fcl": 4, "art": [4, 11, 24, 25, 30, 64, 78, 80, 81, 83, 86, 87, 92, 96, 100, 115, 117, 126, 176, 180], "signal": [4, 35, 63, 75, 76, 83, 92, 98, 114, 133, 159, 167, 184], "outlin": [4, 11, 27, 48, 63, 64, 92, 141, 183, 186], "extract": [4, 11, 20, 30, 36, 49, 50, 52, 54, 58, 59, 60, 62, 63, 66, 68, 82, 107, 113, 119, 122, 123, 130, 132, 156, 164, 176, 184], "interest": [4, 11, 19, 30, 35, 42, 47, 48, 51, 56, 58, 60, 62, 63, 64, 70, 75, 80, 83, 85, 86, 88, 92, 95, 98, 100, 101, 103, 109, 111, 114, 116, 138, 145, 148, 149, 150, 153, 157, 159, 163, 166, 167, 168, 170, 176, 179, 183, 184, 186, 190], "critic": [4, 7, 62, 63, 65, 94, 103, 149, 159, 160, 163, 164, 186, 189], "decod": [4, 20, 24, 28, 41, 74, 98, 122, 123, 124, 126, 158, 169, 174, 176, 179, 186, 191], "transmit": [4, 46, 92, 98, 108], "consider": [4, 19, 44, 45, 63, 69, 70, 75, 92, 94, 95, 98, 101, 103, 104, 107, 108, 111, 113, 115, 138, 141, 144, 153, 157, 159, 168, 171, 179, 180], "soul": 4, "anyth": [4, 5, 7, 9, 14, 22, 36, 39, 63, 64, 66, 83, 92, 94, 101, 103, 138, 149, 155, 157, 184], "ourselv": [4, 22, 35, 63, 71, 83, 92, 95, 99, 100, 103, 105, 107, 115, 148, 153, 157, 184], "friend": [4, 92], "deck": 4, "card": [4, 19, 38, 40, 46, 92], "shuffl": [4, 20, 41, 50, 51, 53, 54, 57, 59, 64, 82, 96, 107, 119, 121, 127, 133, 158, 160, 161, 164, 165], "statement": [4, 5, 9, 11, 22, 39, 40, 42, 60, 92, 95, 101, 106, 140, 149, 150, 151, 155, 157, 178, 180], "assess": [4, 64, 77, 92, 93, 95, 98, 101, 103, 114, 157, 165, 170, 179], "heart": [4, 69, 83, 92, 95, 103, 144, 153, 157], "realiti": [4, 71, 76, 77, 92, 94, 98, 113], "suit": [4, 62, 97, 98, 149, 156, 166, 180, 187], "spade": 4, "52": [4, 47, 79, 146, 186], "told": [4, 9, 101, 144], "medium": [4, 19, 150], "extrem": [4, 10, 11, 41, 78, 92, 94, 98, 99, 101, 103, 111, 131, 144, 157, 159, 161, 164, 173, 175, 184], "read": [4, 7, 11, 19, 20, 32, 37, 38, 41, 42, 46, 51, 52, 55, 62, 71, 76, 86, 88, 92, 94, 97, 98, 102, 112, 116, 117, 118, 121, 130, 142, 152, 155, 157, 162, 164, 167, 168, 174, 179, 180, 184, 186], "conform": [4, 186], "225": [4, 50, 54, 56, 59], "knowledg": [4, 5, 7, 9, 25, 26, 35, 41, 50, 53, 60, 62, 73, 77, 86, 92, 94, 95, 111, 113, 114, 134, 142, 149, 152, 157, 175, 187], "unusu": [4, 35, 44, 178, 180], "1948": [4, 98, 186], "claud": [4, 92, 98], "shannon": [4, 92, 98, 186], "publish": [4, 74, 80, 95, 149, 175], "establish": [4, 11, 62, 63, 77, 111, 163], "hi": [4, 74, 77, 92, 134, 149, 168, 175, 176], "articl": [4, 21, 25, 63, 92, 98, 117, 130, 133, 136, 144, 145, 185], "journei": [4, 74, 153, 167], "embodi": [4, 189], "terminologi": [4, 6, 11, 72, 103, 126, 169], "john": [4, 11, 117, 149, 186], "tukei": 4, "histor": [4, 10, 42, 78, 92, 95, 103, 116, 164, 168, 180, 181, 184], "antiqu": 4, "transmitt": 4, "receiv": [4, 13, 24, 27, 38, 39, 46, 77, 92, 94, 95, 103, 107, 112, 117, 138, 151, 157, 159, 184, 189, 190], "binari": [4, 8, 21, 28, 42, 58, 83, 92, 94, 95, 96, 98, 110, 114, 123, 125, 126, 127, 141, 155, 157, 159, 161], "digit": [4, 6, 8, 9, 10, 41, 74, 91, 92, 96, 101, 159, 186], "At": [4, 5, 7, 8, 9, 10, 14, 19, 21, 23, 24, 28, 29, 34, 41, 42, 46, 47, 52, 55, 60, 62, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 79, 82, 83, 87, 88, 89, 90, 91, 92, 94, 96, 100, 101, 103, 104, 105, 106, 110, 111, 112, 120, 122, 144, 148, 149, 150, 151, 153, 163, 168, 169, 171, 177, 180, 181, 183, 184, 188, 190], "mention": [4, 8, 9, 10, 34, 35, 39, 41, 42, 47, 51, 54, 56, 60, 63, 64, 65, 92, 129, 163, 169, 178, 181, 183, 184], "transfer": [4, 25, 38, 41, 44, 46, 50, 52, 64, 80, 86, 186, 191], "gave": [4, 10, 11, 92, 94], "log_2": [4, 6, 70, 136], "logarithm": [4, 6, 8, 9, 10, 86, 98, 100, 103, 104, 113, 114, 125, 129, 136, 157, 169], "sake": [4, 17, 46, 63, 72, 94, 109, 164], "rest": [4, 9, 29, 47, 50, 58, 59, 72, 90, 92, 95, 106, 110, 113, 126, 132, 144, 155, 163, 164, 175, 180], "subscript": [4, 9, 77, 98, 103, 153], "0010": 4, "necessari": [4, 24, 35, 39, 66, 69, 70, 72, 73, 77, 78, 92, 104, 109, 140, 146, 149, 184, 185, 186], "packag": [4, 14, 15, 48, 78, 113, 124, 149, 150, 151, 155, 164, 185, 187], "nn": [4, 20, 21, 22, 23, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 82, 83, 86, 99, 100, 104, 105, 106, 108, 110, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 128, 131, 135, 143, 144, 149, 158, 160, 161, 163, 165, 168, 170, 171, 172, 173, 175, 177, 182, 183, 184], "nllloss": 4, "nansum": 4, "offer": [4, 12, 18, 19, 25, 27, 32, 38, 39, 41, 46, 62, 63, 64, 67, 68, 69, 70, 71, 75, 92, 104, 108, 110, 113, 116, 130, 139, 144, 149, 150, 153, 154, 157, 162, 167, 170, 173], "inbuilt": 4, "isnan": 4, "self_inform": 4, "log2": 4, "64": [4, 12, 19, 29, 31, 35, 41, 44, 45, 49, 53, 59, 60, 62, 65, 66, 69, 70, 79, 82, 92, 96, 113, 122, 123, 124, 127, 128, 144, 171, 184, 186], "metric": [4, 11, 20, 45, 51, 53, 54, 60, 78, 82, 83, 86, 88, 89, 90, 111, 128, 135, 143, 157, 159, 163, 165, 186], "negativeloglikelihood": 4, "ndarrai": [4, 7, 38, 42, 93, 155], "is_nan": 4, "zeros_lik": [4, 21, 110, 115, 155], "axiom": [4, 157], "forc": [4, 9, 19, 20, 39, 41, 64, 66, 67, 92, 94, 139, 140, 144, 145, 173, 174, 183], "csisz": [4, 186], "\u00e1": [4, 149, 186], "2008": [4, 7, 62, 63, 153, 167, 174, 179, 186], "gain": [4, 36, 42, 44, 62, 66, 80, 89, 106, 111, 113, 114, 157, 165, 166, 173, 182, 183, 184], "observ": [4, 5, 6, 8, 9, 10, 11, 20, 21, 22, 25, 27, 30, 36, 39, 42, 44, 45, 51, 62, 63, 64, 69, 70, 72, 78, 79, 85, 86, 88, 89, 90, 92, 94, 95, 98, 101, 103, 108, 111, 114, 129, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 153, 157, 158, 161, 163, 166, 167, 170, 175, 177, 178, 180, 181, 184, 185, 189, 190], "presenc": 4, "ambigu": [4, 101, 151, 179, 180], "fair": [4, 6, 9, 41, 92, 97, 145, 157], "e_": [4, 83, 94, 95, 101, 120, 140, 148, 157, 190], "otherwis": [4, 7, 9, 11, 12, 18, 21, 38, 39, 41, 45, 51, 56, 60, 72, 74, 79, 82, 85, 92, 101, 104, 105, 110, 125, 129, 133, 136, 140, 148, 155, 157, 165, 176, 189], "int_x": [4, 5], "dx": [4, 5, 7, 9, 10, 20, 114, 136, 150, 151, 157], "nan": [4, 99, 113, 156], "as_nd_ndarrai": 4, "curiou": [4, 41], "f_1": [4, 65, 95, 116], "f_2": [4, 65, 95], "f_n": 4, "f_i": [4, 148, 151], "luckili": 4, "ordinari": [4, 92, 98, 153, 157, 175], "monoton": [4, 28, 98, 111, 114, 140], "ideal": [4, 11, 21, 56, 64, 73, 77, 85, 92, 98, 101, 120, 127, 147, 149, 165, 169, 180, 189], "forget": [4, 18, 94, 104, 139, 151, 152], "add": [4, 5, 7, 8, 9, 12, 14, 17, 19, 20, 25, 29, 30, 31, 33, 34, 35, 36, 38, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 78, 82, 83, 85, 90, 92, 98, 99, 103, 105, 106, 107, 108, 109, 110, 114, 115, 120, 123, 125, 126, 128, 129, 131, 132, 135, 140, 143, 144, 145, 148, 157, 158, 160, 163, 165, 167, 168, 171, 172, 180, 181], "front": [4, 7, 10, 41, 42, 59, 111], "similarli": [4, 5, 6, 7, 9, 10, 11, 28, 30, 38, 42, 51, 54, 63, 70, 74, 77, 80, 83, 92, 95, 98, 99, 108, 111, 116, 123, 128, 136, 137, 149, 151, 155, 183, 189], "slot": [4, 19, 41, 89, 121], "emit": [4, 64, 69, 74, 92, 183], "symbol": [4, 5, 23, 25, 43, 92, 103, 132, 136, 151, 153, 157, 173], "s_1": [4, 47, 168, 188, 190], "s_k": 4, "p_1": [4, 129, 177], "s_i": [4, 117, 157], "geq": [4, 11, 27, 47, 64, 95, 98, 140, 148, 157, 178], "q": [4, 20, 21, 22, 26, 27, 58, 60, 63, 76, 92, 93, 94, 98, 99, 101, 109, 114, 129, 132, 136, 138, 144, 145, 163, 165, 168, 170, 171, 177, 178, 181, 183, 186, 187, 190, 191], "leq": [4, 21, 22, 28, 60, 64, 94, 99, 103, 113, 117, 125, 134, 138, 140, 141, 146, 148, 153, 157, 168, 178, 183], "bound": [4, 22, 52, 55, 57, 58, 59, 63, 69, 74, 78, 80, 86, 95, 98, 101, 111, 116, 140, 141, 143, 147, 148, 157, 180, 183, 191], "spread": [4, 41, 46, 55, 80, 103, 156], "evenli": [4, 41, 44, 60, 108, 155], "among": [4, 24, 31, 41, 44, 46, 47, 54, 56, 58, 60, 66, 70, 71, 74, 77, 92, 93, 94, 95, 98, 101, 103, 105, 106, 108, 111, 113, 114, 115, 116, 117, 123, 126, 129, 130, 131, 132, 133, 134, 144, 149, 150, 155, 157, 162, 167, 169, 174, 176, 178, 180, 185], "foral": [4, 11], "complic": [4, 47, 50, 57, 66, 71, 75, 83, 92, 98, 101, 102, 103, 109, 111, 113, 140, 141, 146, 153, 157, 165, 178], "impos": [4, 37, 70, 77, 92, 103, 110, 140], "highest": [4, 6, 20, 47, 77, 90, 93, 95, 98, 117, 123, 169, 177], "previous": [4, 6, 12, 33, 35, 36, 39, 42, 62, 69, 71, 76, 77, 86, 92, 94, 95, 98, 101, 103, 110, 114, 115, 138, 143, 147, 150, 151, 155, 171, 175, 180, 181, 183, 184, 185], "p_": [4, 8, 9, 11, 28, 64, 71, 75, 76, 94, 129, 146], "p_y": [4, 8], "similar": [4, 5, 7, 8, 9, 11, 18, 22, 24, 25, 29, 30, 35, 41, 42, 44, 45, 46, 47, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 64, 65, 66, 69, 70, 72, 73, 74, 75, 76, 77, 82, 85, 88, 92, 93, 94, 95, 96, 98, 104, 105, 106, 108, 110, 114, 116, 117, 120, 122, 124, 125, 126, 130, 132, 133, 134, 135, 144, 145, 147, 148, 160, 161, 164, 166, 167, 171, 173, 175, 176, 177, 178, 180, 181, 183, 185, 186, 189, 190, 191], "precis": [4, 5, 6, 7, 9, 10, 11, 19, 24, 41, 62, 63, 68, 70, 72, 73, 75, 77, 78, 79, 80, 92, 95, 97, 98, 99, 101, 103, 105, 108, 111, 114, 149, 153, 157, 165, 171, 177, 178, 179, 184, 185, 186], "int_": [4, 5, 9, 80], "scratch": [4, 25, 32, 35, 44, 45, 50, 64, 67, 81, 88, 89, 92, 93, 94, 96, 97, 98, 102, 104, 112, 114, 116, 117, 121, 126, 139, 142, 149, 151, 157, 174, 179, 182, 184, 186, 191], "joint_entropi": 4, "p_xy": [4, 8], "joint_ent": 4, "oftentim": [4, 9, 10, 153, 156], "substanti": [4, 25, 88, 89, 94, 101, 108], "unless": [4, 10, 35, 38, 39, 41, 44, 51, 75, 77, 94, 95, 101, 115, 116, 140, 150, 155, 180], "illeg": [4, 57, 60], "extend": [4, 9, 10, 11, 25, 30, 53, 54, 64, 65, 69, 75, 86, 92, 93, 95, 98, 99, 102, 106, 115, 127, 132, 149, 158, 164, 165, 167, 184], "int_i": 4, "minu": [4, 72], "conditional_entropi": 4, "p_y_given_x": 4, "cond_ent": 4, "straight": [4, 10, 80, 88, 161, 185], "summar": [4, 5, 9, 10, 11, 23, 25, 35, 39, 41, 62, 74, 92, 110, 120, 177, 180, 186], "excel": [4, 7, 17, 41, 44, 62, 92, 101, 141, 148, 149, 153], "18": [4, 5, 8, 45, 46, 49, 50, 51, 53, 65, 69, 78, 79, 80, 186], "extens": [4, 14, 21, 25, 42, 53, 65, 69, 75, 80, 85, 108, 130, 141, 153, 155, 161, 177, 180], "correl": [4, 56, 59, 71, 73, 75, 76, 77, 79, 92, 123, 136, 157, 180], "mutual_inform": 4, "75": [4, 9, 10, 41, 47, 78, 129, 133, 169, 176], "25": [4, 9, 10, 20, 41, 47, 56, 70, 72, 78, 79, 80, 92, 95, 114, 145, 146, 158, 186], "memor": [4, 7, 8, 63, 92, 95, 101, 111, 160], "mind": [4, 10, 24, 28, 32, 41, 92, 95, 101, 107, 123, 144, 155, 186, 188], "notabl": [4, 25, 29, 30, 41, 64, 101, 111, 128, 185, 189], "vice": [4, 9, 48, 56, 120, 129, 131, 155, 157], "versa": [4, 9, 48, 56, 120, 129, 131, 155, 157], "chapter": [4, 14, 20, 22, 23, 24, 25, 32, 35, 38, 42, 43, 44, 45, 49, 50, 51, 52, 58, 64, 67, 70, 73, 74, 77, 78, 81, 85, 86, 87, 91, 92, 95, 96, 100, 101, 102, 103, 105, 106, 109, 111, 112, 114, 117, 118, 121, 122, 126, 130, 138, 142, 143, 144, 146, 148, 149, 151, 152, 162, 167, 174, 176, 178, 179, 180, 183, 184, 187, 189], "pmi": 4, "chanc": [4, 51, 78, 113, 116, 157], "denomin": [4, 7, 8, 10, 25, 99, 100, 169], "pure": [4, 42, 92, 100], "resolut": [4, 30, 34, 62, 64, 66, 68, 69, 70, 71, 75, 76, 77, 92, 96, 101, 114, 116, 126, 179], "issu": [4, 5, 8, 9, 10, 28, 37, 39, 41, 42, 44, 49, 59, 63, 69, 75, 77, 78, 86, 92, 94, 99, 108, 112, 116, 132, 134, 138, 139, 145, 147, 150, 155, 159, 167], "unclear": [4, 11, 14, 44, 77, 138], "recent": [4, 22, 25, 29, 30, 41, 52, 62, 64, 67, 70, 72, 73, 78, 83, 86, 87, 92, 94, 95, 109, 111, 130, 134, 149, 153, 164, 167, 168, 179, 184, 186, 189], "headlin": [4, 149], "report": [4, 6, 25, 38, 45, 62, 77, 85, 88, 89, 92, 93, 95, 100, 101, 106, 113, 117, 157, 163, 184], "fire": [4, 92, 114, 116], "whether": [4, 8, 11, 19, 21, 22, 25, 36, 41, 42, 44, 47, 52, 58, 62, 63, 64, 70, 71, 72, 73, 76, 77, 78, 79, 80, 83, 88, 91, 92, 94, 95, 100, 103, 105, 107, 108, 113, 114, 117, 119, 126, 140, 141, 148, 153, 155, 157, 159, 165, 175, 177, 183, 184, 185, 187], "compani": [4, 19, 92, 94, 101, 149, 157, 162, 163], "rain": [4, 180, 186], "forest": [4, 94], "resolv": [4, 44, 111, 114, 143, 148, 180, 189], "group": [4, 6, 11, 12, 35, 37, 41, 46, 54, 62, 63, 64, 66, 69, 70, 73, 92, 149, 157], "rel": [4, 6, 8, 9, 11, 19, 21, 24, 41, 47, 49, 54, 55, 60, 62, 64, 65, 66, 74, 76, 78, 79, 80, 92, 94, 95, 98, 100, 101, 109, 113, 114, 133, 136, 138, 143, 144, 145, 148, 149, 153, 155, 157, 166, 167, 177, 178, 179, 180, 184, 186], "commerc": [4, 92, 156], "technologi": [4, 24, 74, 92, 94, 149, 159], "onlin": [4, 33, 50, 51, 91, 92, 96, 122, 149, 153, 161, 162, 167, 186, 187], "tropic": 4, "disambigu": 4, "nicest": 4, "d_": [4, 64, 136, 151], "under": [4, 5, 9, 10, 11, 19, 22, 34, 38, 53, 63, 65, 80, 92, 94, 95, 101, 103, 105, 106, 109, 111, 113, 126, 143, 145, 149, 151, 152, 155, 157, 165, 169, 176, 187, 189, 190], "kl_diverg": 4, "asscalar": 4, "besid": [4, 28, 39, 41, 42, 44, 46, 48, 50, 58, 59, 60, 79, 82, 94, 108, 109, 116, 117, 123, 129, 131, 132, 143, 146, 167, 172, 178], "e_i": [4, 64, 117], "e_x": [4, 140], "reduct": [4, 20, 31, 44, 46, 49, 50, 51, 53, 54, 56, 60, 66, 68, 69, 70, 71, 74, 75, 77, 82, 83, 99, 120, 121, 123, 124, 126, 135, 144, 145, 152, 157], "uncertainti": [4, 11, 78, 79, 92, 110, 148, 152, 157, 186], "symmetri": [4, 63, 98, 114, 157], "000": [4, 8, 11, 41, 62, 78, 92, 95, 96, 103, 104, 113, 114, 116, 117, 157, 164, 180, 185, 186], "candid": [4, 9, 10, 62, 71, 85, 92, 133, 165, 168, 169, 170, 174, 175, 184], "q_1": 4, "q_2": 4, "tensor_len": 4, "10000": [4, 11, 28, 39, 53, 86, 103, 105, 119, 126, 133, 157, 169, 180], "q1": 4, "q2": 4, "nd_len": 4, "loc": [4, 11, 113], "asnumpi": [4, 5, 7, 8, 9, 20, 21, 27, 39, 42, 47, 48, 49, 51, 53, 54, 55, 56, 60, 82, 83, 103, 106, 113, 135, 141, 145, 146, 147, 155, 158, 159, 163, 165, 168, 184], "kl_pq1": 4, "kl_pq2": 4, "similar_percentag": 4, "contrast": [4, 11, 25, 29, 30, 50, 51, 54, 58, 61, 62, 63, 65, 74, 79, 92, 95, 101, 104, 108, 120, 126, 133, 149, 153, 157, 173, 174, 177, 178], "around": [4, 9, 10, 14, 29, 41, 46, 60, 62, 69, 72, 75, 77, 86, 92, 94, 143, 150, 155, 184], "40": [4, 21, 25, 41, 46, 53, 58, 62, 78, 82, 132, 145, 147, 157, 169], "kl_q2p": 4, "differ_percentag": 4, "quick": [4, 7, 9, 27, 45, 93, 106, 141, 145, 148, 154, 175], "y_i": [4, 21, 94, 100, 113, 148, 150, 153], "parametr": [4, 26, 60, 65, 69, 70, 77, 92, 94, 97, 98, 102, 103, 104, 108, 111, 114, 116, 141, 157, 181], "best": [4, 5, 6, 7, 9, 10, 14, 37, 44, 46, 62, 63, 64, 66, 69, 71, 74, 77, 85, 86, 89, 90, 92, 95, 101, 103, 105, 113, 115, 120, 130, 138, 140, 143, 144, 146, 149, 157, 163, 173, 180, 186, 188, 190], "hat": [4, 6, 8, 11, 21, 63, 64, 78, 94, 95, 98, 99, 100, 101, 103, 104, 113, 120, 139, 160, 161, 163, 165, 166, 168, 180, 184, 186, 189], "pi_i": 4, "prod_": [4, 8, 98, 103, 125, 134, 166, 169, 177, 178, 180, 184], "maxim": [4, 6, 7, 9, 78, 83, 88, 98, 103, 111, 117, 125, 134, 140, 146, 153, 157, 166, 169, 187, 189, 190], "minim": [4, 6, 7, 9, 10, 11, 21, 25, 36, 38, 56, 69, 74, 78, 83, 86, 87, 88, 92, 93, 94, 95, 98, 103, 108, 111, 114, 117, 118, 126, 129, 134, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 153, 155, 158, 163, 178, 186, 189], "ce": [4, 169], "cross_entropi": [4, 49, 99, 100], "y_hat": [4, 20, 21, 44, 53, 56, 63, 72, 86, 93, 99, 100, 104, 105, 106, 108, 110, 120, 143, 177], "len": [4, 8, 11, 20, 22, 23, 27, 29, 34, 36, 38, 44, 47, 51, 53, 54, 56, 57, 59, 60, 63, 65, 80, 82, 90, 93, 96, 100, 106, 107, 113, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 132, 133, 135, 143, 144, 150, 151, 153, 159, 160, 163, 164, 165, 168, 171, 173, 175, 176, 177, 180, 182, 183, 185], "gather_nd": 4, "zip": [4, 20, 21, 23, 27, 29, 44, 45, 50, 51, 53, 54, 56, 57, 60, 71, 82, 83, 85, 91, 100, 105, 113, 119, 120, 121, 122, 123, 127, 128, 131, 133, 137, 138, 139, 140, 141, 144, 145, 147, 151, 159, 163, 164, 165, 168, 170, 176, 177, 185, 186], "pred": [4, 8, 20, 23, 29, 49, 51, 53, 54, 60, 80, 93, 100, 113, 135, 158, 163, 177, 184], "indirectli": [4, 58, 167], "i1": 4, "hot": [4, 19, 21, 52, 98, 100, 113, 116, 130, 150, 159], "th": [4, 7, 9, 10, 11, 28, 29, 38, 47, 86, 94, 103, 113, 125, 133, 135, 136, 141, 151, 153, 155, 158, 160, 161, 163, 165, 168, 171, 176, 177, 183, 184, 185, 190], "multinoulli": 4, "z": [4, 5, 7, 25, 29, 38, 39, 61, 64, 72, 76, 77, 80, 82, 83, 94, 109, 132, 136, 138, 140, 145, 146, 150, 151, 153, 155, 157, 160, 165, 168, 173, 184, 185, 186], "z_": 4, "z_1": 4, "z_k": 4, "pi_": [4, 190], "therefor": [4, 10, 19, 28, 29, 35, 42, 43, 50, 54, 55, 58, 60, 61, 62, 69, 78, 80, 82, 101, 106, 109, 129, 140, 141, 148, 167, 169, 178, 180, 181, 188, 189], "proof": [4, 141, 142, 148, 151, 186], "earlier": [4, 22, 25, 29, 40, 42, 48, 49, 50, 57, 60, 62, 63, 65, 68, 72, 74, 76, 92, 95, 103, 104, 113, 118, 121, 148, 149, 174, 181, 184], "logsoftmax": 4, "nll_loss": 4, "updat": [4, 7, 12, 14, 16, 20, 23, 25, 28, 35, 41, 44, 45, 46, 50, 56, 62, 63, 72, 83, 85, 90, 91, 92, 93, 94, 97, 103, 104, 105, 106, 107, 108, 109, 111, 114, 116, 121, 124, 129, 134, 135, 137, 138, 139, 141, 142, 143, 144, 145, 149, 151, 155, 157, 158, 163, 170, 174, 175, 178, 183, 184, 189, 190], "convert": [4, 7, 8, 9, 20, 25, 38, 42, 48, 51, 60, 64, 78, 93, 96, 99, 127, 153, 155, 156, 159, 164, 172, 176, 179, 184, 191], "util": [4, 11, 16, 31, 39, 44, 45, 50, 51, 53, 54, 57, 59, 63, 75, 82, 95, 96, 102, 107, 113, 119, 120, 121, 127, 128, 133, 152, 157, 158, 159, 162, 163, 165, 167, 168, 175, 187, 191], "to_categor": 4, "num_class": [4, 30, 45, 47, 49, 53, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 88, 89], "argument": [4, 20, 21, 22, 26, 31, 33, 34, 35, 38, 40, 42, 46, 47, 48, 51, 53, 58, 60, 62, 63, 66, 69, 70, 72, 77, 85, 88, 98, 99, 100, 105, 106, 107, 108, 109, 110, 114, 119, 120, 121, 127, 132, 133, 136, 141, 143, 150, 151, 153, 157, 170, 172, 176, 180, 183, 184, 185], "nll": 4, "categoricalcrossentropi": [4, 20], "from_logit": [4, 20, 82, 83, 99, 143], "verifi": [4, 20, 31, 37, 40, 41, 45, 48, 64, 82, 113, 125, 131, 140, 150, 164], "claim": [4, 5, 9, 11, 24, 41, 63, 110], "nonneg": [4, 22, 27, 98, 100, 103, 108, 139, 140, 153, 157], "hint": [4, 7, 9, 10, 21, 28, 29, 34, 38, 39, 41, 46, 56, 57, 77, 85, 86, 88, 93, 94, 98, 100, 101, 103, 104, 105, 107, 113, 114, 129, 132, 134, 141, 150, 151, 156, 157, 178, 184], "jensen": [4, 148], "convex": [4, 27, 62, 63, 78, 98, 138, 139, 141, 142, 143, 146, 147, 173, 186, 191], "sourc": [4, 6, 11, 12, 14, 15, 16, 17, 18, 20, 23, 25, 29, 32, 34, 46, 50, 63, 71, 78, 83, 85, 88, 92, 94, 103, 104, 106, 107, 111, 114, 120, 149, 152, 154, 162, 167, 171, 176, 185], "watch": [4, 19, 72, 98, 101, 157, 162, 165, 167, 172, 186, 187], "monkei": [4, 180, 186], "typewrit": [4, 180], "press": [4, 12, 25, 92, 94, 149, 169], "Being": 4, "unhappi": 4, "drunk": 4, "typesett": 4, "albeit": [4, 9, 12, 44, 68, 69, 70, 75, 92, 99, 116, 138, 141, 144, 145, 148, 185], "coher": [4, 94, 111, 180], "letter": [4, 20, 96, 127, 136, 153, 176], "english": [4, 20, 23, 25, 29, 92, 119, 124, 126, 127, 131, 132, 134, 149, 172, 176, 177, 180], "qualiti": [4, 11, 58, 64, 69, 92, 94, 103, 105, 108, 113, 132, 143, 145, 148, 149, 154, 156, 157, 163, 177, 179, 180, 184, 186], "current": [4, 12, 14, 19, 21, 23, 29, 38, 40, 41, 44, 50, 52, 55, 60, 63, 67, 77, 85, 89, 90, 91, 92, 96, 101, 103, 104, 105, 107, 108, 109, 111, 115, 135, 143, 144, 148, 149, 153, 170, 171, 172, 173, 175, 177, 178, 180, 181, 183, 187, 188, 189, 190], "perplex": [4, 143, 171, 173, 175, 179, 182, 183], "15": [4, 9, 20, 41, 46, 47, 49, 55, 91, 95, 117, 118, 121, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 141, 143, 149, 178, 186], "ppl": [4, 183, 186], "prod_i": [4, 8], "explain": [4, 8, 11, 25, 27, 28, 29, 41, 49, 51, 52, 56, 60, 61, 72, 78, 92, 93, 94, 95, 98, 101, 106, 111, 117, 118, 121, 126, 129, 140, 141, 143, 148, 149, 157, 163, 167, 168, 169, 172, 174, 176, 177, 178, 181], "mu_1": 4, "sigma_1": [4, 114], "mu_2": 4, "sigma_2": [4, 114], "tradit": [5, 7, 24, 27, 41, 62, 63, 80, 92, 103, 111, 146, 158, 174], "educ": [5, 92], "disjoint": [5, 86, 140, 144, 157], "underneath": 5, "curv": [5, 9, 10, 25, 79, 88, 89, 90, 99, 105, 143, 151, 157, 165], "seemingli": [5, 7, 64, 77, 107, 111, 184], "unrel": [5, 9, 94, 129, 157], "tightli": [5, 44, 101], "intertwin": [5, 157], "brief": [5, 11, 92, 143, 144, 174], "introduct": [5, 11, 30, 31, 48, 51, 62, 78, 81, 95, 101, 106, 146, 149, 152, 153, 163, 186, 191], "lai": [5, 41, 149], "groundwork": [5, 149], "mpl_toolkit": [5, 7, 140, 146], "mplot3d": [5, 7, 140, 146], "color": [5, 7, 9, 11, 20, 47, 48, 49, 50, 53, 54, 56, 57, 59, 62, 71, 73, 78, 80, 88, 89, 92, 96, 106, 141, 153, 157, 190], "black": [5, 8, 9, 59, 72, 74, 76, 78, 80, 92, 94, 96, 103, 105, 140, 142, 157, 164, 186], "fill_between": [5, 9, 78, 80], "undefin": [5, 9, 78], "talk": [5, 16, 41, 75, 83, 92, 98, 101, 103, 117, 148, 183], "50": [5, 40, 44, 51, 53, 56, 63, 78, 80, 85, 92, 104, 114, 119, 120, 122, 128, 131, 143, 148, 157, 165, 173, 175], "250": [5, 25, 47, 92, 189], "int_a": [5, 136], "inner": [5, 7, 41, 80, 136, 153, 155], "dummi": [5, 7, 22, 34, 38], "index": [5, 7, 20, 28, 36, 46, 47, 53, 57, 59, 60, 64, 74, 77, 78, 79, 90, 92, 93, 100, 103, 113, 119, 120, 126, 128, 129, 131, 133, 134, 135, 141, 148, 152, 153, 156, 157, 159, 164, 165, 177, 183, 184, 185], "dz": [5, 7], "chop": 5, "vertic": [5, 9, 25, 72, 75, 76, 79, 140, 151, 153, 168], "slice": [5, 9, 75, 101, 107, 108, 113, 140, 152, 153, 176, 180, 184], "rectangl": [5, 25, 48, 95], "exampl": [5, 7, 8, 9, 10, 12, 14, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 140, 141, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 159, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 190, 191], "epsilon": [5, 6, 7, 9, 10, 11, 21, 47, 63, 72, 78, 79, 86, 95, 98, 103, 107, 108, 110, 111, 137, 138, 139, 140, 141, 147, 184, 189], "05": [5, 9, 11, 47, 60, 64, 68, 83, 108, 114, 141, 144, 146, 158, 168, 186], "bar": [5, 9, 11, 12, 17, 20, 78, 79, 94, 99, 134, 138, 148, 184], "width": [5, 8, 21, 30, 41, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 80, 82, 86, 96, 111, 115, 123, 153, 171], "ylim": [5, 10, 20, 51, 56, 106, 144, 151, 163, 165], "truth": [5, 49, 55, 57, 58, 60, 62, 69, 78, 79, 92, 93, 94, 105, 107, 117, 119, 126, 153, 163, 165, 177], "analyt": [5, 10, 62, 95, 111, 116, 146, 183, 186], "main": [5, 11, 14, 19, 38, 41, 45, 48, 50, 56, 58, 62, 63, 65, 68, 69, 83, 86, 88, 89, 92, 103, 105, 125, 134, 137, 138, 140, 144, 155, 168, 184, 190], "tool": [5, 7, 10, 11, 14, 17, 22, 32, 39, 42, 45, 46, 62, 63, 64, 66, 72, 74, 75, 77, 92, 94, 95, 102, 103, 104, 105, 108, 110, 111, 113, 134, 140, 142, 143, 146, 149, 150, 153, 156, 157, 167, 179, 180, 184, 185, 191], "int_0": [5, 9], "sliver": 5, "rectangular": [5, 47, 48, 49, 59, 76], "height": [5, 8, 9, 30, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 80, 82, 95, 96, 123, 141, 151, 153, 157], "better": [5, 6, 7, 8, 11, 14, 19, 21, 24, 25, 30, 38, 39, 41, 42, 46, 50, 54, 62, 64, 69, 70, 74, 76, 78, 82, 85, 86, 89, 90, 92, 94, 95, 98, 99, 100, 101, 103, 111, 113, 114, 116, 120, 132, 134, 138, 139, 141, 143, 144, 145, 148, 149, 154, 157, 158, 160, 167, 173, 178, 180, 183, 184, 185, 186], "df": [5, 7, 10, 53, 78, 88, 89, 150, 151, 158, 165, 168], "priori": [5, 28, 63, 77, 80, 95, 107, 113, 150], "complet": [5, 11, 12, 20, 23, 38, 39, 40, 44, 49, 53, 63, 64, 66, 78, 90, 92, 94, 100, 109, 126, 131, 133, 154, 158, 163, 168, 169, 176, 177, 178, 180, 182, 184, 189, 190], "life": [5, 77, 81, 96, 99, 101, 137, 147, 167], "thankfulli": [5, 9, 10], "drop": [5, 6, 22, 45, 47, 62, 72, 105, 108, 110, 113, 114, 133, 148, 155, 157, 184, 185], "irrelev": [5, 17, 20, 121, 141, 175, 177], "appreci": [5, 80], "whole": [5, 7, 32, 41, 62, 63, 67, 70, 76, 77, 80, 92, 93, 103, 155, 158, 180], "perspect": [5, 81, 96, 111, 129, 179, 184, 186], "goal": [5, 6, 11, 36, 40, 41, 60, 64, 76, 77, 83, 85, 86, 88, 92, 95, 98, 101, 103, 105, 111, 117, 141, 142, 148, 149, 151, 159, 162, 168, 169, 179, 180, 184, 188, 189, 190], "incred": [5, 74], "revers": [5, 26, 61, 92, 109, 157, 165, 170, 184, 185, 186], "tabl": [5, 9, 10, 11, 41, 65, 69, 70, 92, 107, 129, 153, 156, 157, 179], "nx": [5, 10], "ny": [5, 107, 180], "leverag": [5, 25, 32, 35, 42, 50, 52, 54, 55, 56, 58, 73, 82, 83, 92, 94, 100, 103, 114, 117, 126, 129, 130, 149, 150, 155, 165, 182, 183, 186], "tractabl": [5, 77], "arguabl": [5, 23, 24, 66, 70, 78, 92, 100, 101, 104, 139], "du": [5, 9, 137, 149, 151, 186], "rewritten": [5, 7, 41, 42, 129, 134], "agre": [5, 11, 77, 95, 103, 110], "thin": [5, 19], "properli": [5, 33, 35, 44, 62, 72, 77, 104, 129, 140, 141, 149, 164, 180], "incredibli": [5, 72, 180], "chose": [5, 7, 64, 79, 188], "2xe": 5, "dig": [5, 9, 10, 32], "manifest": [5, 70, 94, 178], "progress": [5, 10, 20, 32, 41, 62, 64, 66, 67, 69, 70, 74, 77, 82, 83, 92, 94, 101, 104, 106, 138, 141, 143, 144, 145, 146, 147, 148, 149, 183, 186], "wrong": [5, 8, 9, 11, 89, 92, 94, 100, 103, 115, 141, 171, 178, 183, 184], "cancel": [5, 9, 10, 103, 108, 110, 145], "sound": [5, 41, 92, 94, 140, 180], "meshgrid": [5, 7, 47, 141, 146], "linspac": [5, 7, 78, 80, 146], "101": [5, 7, 146], "add_subplot": [5, 7, 146], "111": [5, 7, 146, 186], "3d": [5, 7, 22, 146], "plot_wirefram": [5, 7, 146], "xtick": [5, 90, 146], "ytick": [5, 146], "set_xlim": [5, 7, 20, 151], "set_ylim": [5, 7, 20, 78, 151], "set_zlim": [5, 7], "dist": [5, 7, 21, 80, 91], "my": [5, 9, 12, 24, 157, 185], "int_c": 5, "g": [5, 7, 8, 10, 12, 14, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 83, 86, 89, 90, 91, 92, 94, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 113, 114, 115, 116, 117, 120, 122, 123, 126, 129, 132, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 162, 163, 165, 168, 169, 172, 173, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190], "_a": [5, 120, 126], "put": [5, 8, 9, 24, 38, 63, 64, 74, 77, 78, 92, 95, 96, 98, 106, 107, 113, 114, 118, 123, 127, 129, 130, 140, 151, 157, 163, 164, 169, 174, 177, 179, 187], "did": [5, 7, 8, 9, 25, 34, 35, 38, 44, 54, 62, 63, 68, 70, 76, 77, 79, 85, 89, 92, 93, 94, 104, 105, 113, 131, 138, 148, 149, 157, 184, 185], "fubini": 5, "fail": [5, 11, 23, 38, 46, 63, 92, 94, 99, 101, 111, 114, 138, 139, 145, 148, 157, 183, 184], "xy": [5, 7, 8, 9, 37, 47, 48, 146], "condens": 5, "reparametr": [5, 146], "inject": [5, 28, 63, 92, 110, 144, 148], "fold": [5, 44, 70, 71, 90, 101, 111, 112, 167], "jacobian": [5, 150], "partial": [5, 6, 7, 25, 63, 92, 93, 94, 99, 100, 109, 110, 134, 136, 140, 141, 149, 150, 152, 157, 158, 177, 178, 186], "phi_1": [5, 165], "phi_n": 5, "except": [5, 6, 11, 20, 22, 25, 29, 38, 41, 45, 49, 50, 60, 61, 63, 78, 82, 85, 99, 103, 106, 107, 110, 117, 146, 171, 173, 183, 185], "hyper": [5, 78, 186, 189], "cube": 5, "fill": [5, 14, 29, 44, 48, 75, 79, 90, 92, 94, 149, 158, 184], "plai": [5, 10, 25, 32, 40, 63, 67, 69, 78, 83, 86, 92, 94, 116, 140, 143, 148, 149, 159, 162, 163, 167, 175, 186, 187, 189], "dr": 5, "re": [5, 6, 7, 42, 44, 46, 77, 78, 80, 83, 85, 86, 92, 98, 100, 107, 119, 132, 139, 149, 168, 185, 186], "meet": [5, 50, 53, 114, 186], "int_1": [5, 9], "1xy": 5, "2f": [5, 7, 10, 11, 44, 45, 60, 96, 140, 141, 143, 145, 147], "bayesian": [6, 8, 63, 78, 79, 80, 81, 85, 88, 90, 98, 103, 108, 157, 162, 186], "mathop": [6, 21, 27, 69, 94, 139, 140, 143], "mathrm": [6, 8, 21, 22, 69, 86, 89, 90, 94, 98, 100, 114, 140, 143, 158, 163, 181, 189, 190], "argmax": [6, 8, 20, 47, 49, 53, 60, 93, 98, 100, 120, 124, 169, 177, 183, 189, 190], "agnost": [6, 130], "prior": [6, 25, 30, 39, 40, 56, 63, 66, 69, 70, 73, 78, 79, 81, 86, 88, 92, 108, 143, 146, 155, 157, 166, 170, 191], "declar": [6, 11, 36, 72, 106], "belief": [6, 78, 157], "uninform": 6, "tail": [6, 9, 11, 157, 185], "n_h": [6, 61, 82], "n_t": 6, "hhhthtthhhhht": 6, "verbal": [6, 9], "guess": [6, 7, 63, 78, 92, 95, 101, 113, 138, 140, 154, 157, 167, 184], "everyon": [6, 113, 149], "correctli": [6, 10, 92, 100], "situat": [6, 19, 36, 40, 41, 44, 62, 69, 92, 94, 101, 104, 108, 111, 113, 116, 138, 139, 141, 146, 157, 180, 188, 189], "001": [6, 8, 10, 29, 49, 50, 51, 120, 123], "autograd": [6, 7, 20, 21, 26, 28, 29, 38, 39, 44, 45, 51, 54, 56, 60, 63, 72, 74, 83, 93, 100, 104, 105, 108, 110, 113, 114, 115, 116, 128, 135, 143, 144, 149, 150, 158, 163, 165, 177, 183, 184], "somewher": [6, 77], "flat": [6, 25, 74, 115, 145], "minima": [6, 7, 103, 148], "maxima": 6, "assign": [6, 8, 9, 21, 23, 24, 28, 33, 35, 38, 41, 44, 49, 60, 61, 63, 66, 72, 76, 77, 82, 83, 86, 90, 92, 95, 98, 100, 101, 103, 108, 111, 113, 117, 126, 129, 136, 137, 138, 139, 144, 145, 147, 150, 153, 155, 157, 177, 180, 184, 185], "1000000000": 6, "301029995": 6, "perfectli": [6, 78, 79, 80, 83, 92, 94, 95, 98, 99, 101, 105, 111, 138, 141, 157, 170, 180], "32": [6, 7, 8, 19, 28, 35, 41, 46, 49, 51, 53, 54, 57, 60, 62, 64, 65, 66, 69, 70, 74, 82, 85, 86, 88, 89, 90, 92, 96, 98, 103, 107, 144, 153, 171, 173, 175, 182, 183, 186], "mapsto": 6, "pretend": [6, 148], "256245": 6, "paramter": 6, "requires_grad": [6, 7, 20, 50, 54, 100, 105, 114, 116, 123, 124, 144, 150, 183], "lr": [6, 20, 23, 29, 30, 44, 45, 49, 50, 51, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 78, 82, 83, 85, 86, 88, 89, 93, 99, 100, 104, 105, 108, 110, 113, 115, 120, 121, 123, 124, 128, 135, 137, 138, 139, 143, 144, 145, 147, 148, 158, 160, 161, 163, 165, 168, 171, 173, 175, 177, 182, 183, 184], "1e": [6, 47, 49, 54, 63, 71, 85, 86, 88, 89, 90, 121, 128, 131, 133, 135, 137, 138, 139, 143, 144, 147, 158, 163, 165, 168], "backward": [6, 7, 20, 35, 41, 44, 45, 51, 54, 56, 60, 71, 72, 78, 83, 105, 112, 114, 116, 128, 135, 143, 144, 151, 152, 155, 157, 163, 165, 170, 178, 183, 191], "no_grad": [6, 20, 44, 78, 86, 105, 137, 138, 139, 143, 145, 147], "grad": [6, 7, 20, 36, 44, 72, 93, 105, 106, 114, 116, 137, 138, 139, 144, 145, 147, 149, 150, 183], "zero_": [6, 20, 105, 114, 137, 138, 139, 144, 145, 147, 150], "attach_grad": [6, 7, 38, 44, 100, 105, 114, 115, 116, 144, 150, 183], "record": [6, 7, 11, 20, 27, 29, 38, 41, 44, 45, 51, 54, 56, 60, 72, 79, 83, 85, 92, 103, 105, 111, 113, 114, 116, 128, 135, 143, 144, 150, 153, 156, 157, 159, 163, 164, 165, 176, 179, 189, 190], "gradienttap": [6, 7, 20, 72, 83, 105, 114, 116, 144, 150], "assign_sub": [6, 20, 105, 144], "conveni": [6, 7, 8, 10, 12, 21, 24, 27, 34, 35, 36, 37, 38, 40, 42, 44, 45, 59, 61, 63, 78, 92, 93, 96, 98, 99, 103, 104, 106, 107, 108, 113, 139, 140, 143, 144, 145, 151, 153, 159, 164, 171, 178, 180, 183, 185], "prefer": [6, 9, 12, 17, 19, 38, 41, 46, 62, 63, 64, 70, 71, 76, 92, 98, 103, 111, 148, 149, 158, 159, 165, 166, 167, 168, 170, 176, 180, 181, 184], "quad": [6, 7, 41, 98, 120, 153], "proport": [6, 9, 19, 69, 72, 94, 98, 109, 188], "quadrat": [6, 7, 10, 28, 30, 62, 69, 98, 103, 108, 120, 138, 141, 147, 153, 157], "clever": [6, 62, 73, 83, 110, 114, 116, 151], "compel": [6, 25, 80, 92], "motiv": [6, 7, 8, 46, 51, 63, 69, 72, 73, 75, 77, 95, 103, 108, 111, 126, 140, 149, 157, 167, 179, 185, 191], "ok": [6, 14, 92], "trace": [6, 11, 23, 94, 141, 145, 150, 151, 186], "demand": [6, 12, 18, 19, 35, 38, 70, 86, 95, 103, 106, 149, 179], "easili": [6, 11, 18, 22, 28, 38, 41, 42, 47, 58, 62, 69, 78, 79, 88, 92, 95, 100, 109, 114, 116, 132, 143, 144, 161, 171, 178, 179, 180, 185, 189], "varieti": [6, 11, 27, 31, 33, 40, 41, 62, 66, 78, 80, 81, 92, 93, 94, 106, 113, 114, 116, 130, 143, 148, 149, 152, 155, 161, 187], "convers": [6, 24, 25, 39, 42, 48, 70, 71, 92, 94, 113, 138, 140, 141, 143, 144, 145, 148, 151, 152, 157, 159, 184, 186], "datapoint": [6, 11, 78, 79], "alpha": [6, 9, 11, 21, 22, 23, 27, 60, 63, 78, 80, 82, 95, 98, 114, 120, 129, 140, 141, 143, 147, 148, 153, 157, 160, 165, 169, 183, 185, 189], "strong": [7, 9, 79, 80, 92, 96, 101, 114, 157, 186], "w_1": [7, 10, 58, 80, 103, 148], "epsilon_1": [7, 180, 184], "w_2": [7, 58, 148], "w_n": [7, 10], "dw_1": 7, "epsilon_2": [7, 180, 184], "epsilon_n": 7, "discard": [7, 9, 14, 18, 41, 47, 53, 54, 59, 90, 92, 93, 101, 114, 133, 156, 169, 176, 180], "manner": [7, 21, 27, 41, 42, 44, 77, 87, 92, 94, 106, 110, 118, 139, 142, 143, 144, 145, 148, 150, 165, 173, 185], "epsilon_i": [7, 98], "w_i": [7, 9, 26, 64, 80, 101, 103, 108, 129, 133, 153], "mess": 7, "nabla_": [7, 27, 61, 136, 151, 189], "ponder": [7, 92], "perturb": [7, 10, 63, 92, 94, 105, 110, 138, 145, 151, 175, 184], "nabla": [7, 140, 141, 148, 151], "grad_f": 7, "03": [7, 104, 105, 144, 157], "grad_approx": 7, "true_valu": 7, "rapidli": [7, 10, 25, 32, 70, 79, 101, 108, 111, 114, 141, 143, 145, 148, 151, 157, 173, 184], "rewrit": [7, 8, 42, 61, 77, 125, 138, 139, 145], "cosin": [7, 9, 28, 131, 134, 135, 140, 141, 153], "radian": 7, "180": 7, "achiev": [7, 8, 23, 25, 32, 35, 41, 42, 44, 49, 53, 54, 58, 61, 62, 64, 65, 66, 69, 70, 73, 74, 76, 77, 80, 92, 94, 95, 96, 98, 101, 111, 120, 138, 143, 144, 149, 157, 158, 160, 173, 175, 178, 182, 188, 190], "bring": [7, 10, 77, 94, 141, 149, 168, 178], "decent": [7, 25, 158], "leftarrow": [7, 103, 105, 108, 113, 139, 140, 141, 143, 144, 145, 147, 148, 183, 189, 190], "adapt": [7, 20, 24, 25, 30, 46, 63, 73, 74, 77, 78, 83, 86, 89, 90, 92, 94, 95, 97, 98, 106, 110, 116, 129, 130, 137, 140, 142, 147, 149, 179, 186], "focu": [7, 8, 11, 24, 27, 29, 30, 31, 35, 41, 43, 44, 48, 52, 58, 60, 69, 77, 79, 81, 86, 92, 95, 96, 98, 102, 103, 104, 108, 109, 115, 118, 130, 146, 148, 149, 150, 151, 153, 176, 179, 180, 184], "_0": [7, 138, 139, 145, 161], "someon": [7, 92, 95, 98, 157, 184], "truli": [7, 27, 34, 66, 70, 74, 77, 98, 101, 103, 111, 112, 114, 169], "3x": [7, 151], "12x": 7, "24x": 7, "confirm": [7, 14, 34, 38, 62, 63, 107, 148, 154, 158], "global": [7, 19, 21, 25, 30, 38, 41, 49, 50, 56, 60, 64, 65, 66, 68, 69, 76, 86, 100, 103, 123, 130, 141, 146, 148, 161, 186, 191], "node": [7, 46, 62, 76, 86, 110, 111, 114, 125, 174, 179, 183], "ourself": 7, "swamp": 7, "massiv": [7, 24, 41, 58, 92, 101, 111, 113, 130, 150, 178, 183, 184, 186], "wast": [7, 22, 70, 94, 148, 176, 182], "revolut": [7, 41, 92, 179], "stall": [7, 38, 143, 144, 145, 146, 148], "began": [7, 24, 94, 103, 173], "break": [7, 20, 23, 29, 46, 47, 59, 62, 69, 82, 94, 103, 105, 110, 119, 122, 127, 128, 132, 133, 137, 144, 168, 176, 177, 178, 180, 190], "notation": [7, 103], "burdensom": 7, "abbrevi": [7, 9, 48, 64, 114], "pathwai": [7, 25, 165, 186], "pai": [7, 24, 27, 41, 46, 69, 92, 106, 109, 146, 156, 157, 159, 175], "great": [7, 21, 32, 38, 39, 41, 46, 62, 80, 81, 92, 98, 107, 113, 116, 122, 123, 124, 126, 127, 140, 145, 146, 149, 150, 175, 179, 180, 184], "dividend": [7, 106], "lstm": [7, 23, 24, 124, 126, 171, 173, 174, 177, 182, 186, 191], "residu": [7, 24, 30, 45, 53, 63, 64, 65, 66, 67, 96, 175, 186, 191], "control": [7, 11, 14, 22, 24, 27, 35, 39, 41, 42, 44, 46, 58, 60, 63, 65, 69, 75, 78, 79, 80, 81, 87, 92, 95, 101, 103, 108, 110, 113, 114, 116, 139, 145, 147, 148, 152, 165, 173, 175, 179, 183, 186, 187], "multi": [7, 12, 19, 24, 25, 28, 29, 30, 38, 39, 43, 44, 64, 67, 69, 71, 76, 86, 87, 92, 98, 120, 123, 139, 180, 186, 191], "variat": [7, 9, 11, 21, 63, 78, 79, 80, 89, 92, 104, 114, 140, 146, 186], "manag": [7, 32, 39, 92, 101, 111, 122, 143, 149, 157, 162, 167, 191], "df_du": 7, "df_dv": 7, "du_da": 7, "du_db": 7, "dv_da": 7, "dv_db": 7, "da_dw": 7, "db_dw": 7, "du_dw": 7, "dv_dw": 7, "df_dw": 7, "dw": [7, 144], "kept": [7, 22, 47, 92, 133, 148, 156], "explicit": [7, 8, 9, 10, 11, 27, 40, 42, 92, 139, 155, 158, 162, 163, 164, 165, 166, 173, 175], "da_dx": 7, "db_dx": 7, "da_di": 7, "db_dy": 7, "da_dz": 7, "db_dz": 7, "df_da": 7, "df_db": 7, "df_dx": 7, "df_dy": 7, "df_dz": 7, "forward": [7, 10, 12, 17, 20, 22, 23, 24, 26, 28, 30, 31, 32, 34, 36, 37, 41, 42, 44, 45, 49, 55, 56, 58, 60, 61, 62, 63, 65, 66, 69, 71, 72, 76, 78, 82, 85, 86, 88, 99, 100, 104, 105, 106, 110, 112, 115, 116, 120, 121, 123, 124, 126, 128, 143, 150, 151, 158, 160, 161, 163, 165, 166, 168, 170, 171, 172, 173, 175, 177, 178, 182, 183, 184, 186, 188, 191], "snippet": [7, 28, 29, 35, 39, 61, 74, 92, 107, 126, 133, 149, 150, 153, 155, 176, 181], "astonish": [7, 46, 64], "encapsul": [7, 91, 173, 175], "attach": [7, 41, 44, 150], "execut": [7, 12, 14, 17, 27, 32, 36, 39, 40, 41, 42, 44, 62, 85, 86, 88, 91, 92, 98, 101, 104, 105, 144, 149, 150, 153, 185], "persist": [7, 41, 66, 95, 150, 155, 156, 157], "w_grad": 7, "x_grad": [7, 150], "y_grad": 7, "z_grad": 7, "automat": [7, 8, 13, 17, 34, 35, 36, 38, 41, 42, 43, 44, 45, 50, 56, 62, 63, 64, 65, 66, 67, 72, 78, 79, 86, 91, 92, 94, 98, 99, 103, 104, 105, 106, 109, 112, 113, 115, 138, 141, 143, 149, 151, 152, 155, 160, 161, 176, 181, 186, 190, 191], "immedi": [7, 9, 25, 29, 34, 62, 77, 78, 88, 89, 92, 95, 150, 157, 184, 188], "dx_idx_j": 7, "dx_i": 7, "dx_j": 7, "assembl": [7, 29, 35, 46, 66, 70, 74, 92, 149], "_f": [7, 69, 94, 158, 160], "dx_1dx_1": 7, "dx_1dx_n": 7, "dx_ndx_1": 7, "dx_ndx_n": 7, "mix": [7, 35, 41, 71, 94, 95, 113, 145, 149, 186], "dx_jdx_i": 7, "x_j": [7, 31, 78, 79, 80, 103, 116, 161, 179], "b_1x_1": 7, "b_2x_2": 7, "x_1x_2": 7, "26": [7, 186], "b_1": [7, 47, 98], "b_2": [7, 47, 98], "2c_": 7, "expans": [7, 22, 41, 65, 103, 141, 147], "xe": [7, 9], "2xy": 7, "6x": [7, 151], "2y": 7, "4xy": [7, 9], "rstride": [7, 146], "cstride": [7, 146], "purpl": [7, 11], "newton": [7, 188], "involv": [7, 9, 25, 41, 42, 43, 77, 78, 79, 80, 85, 92, 94, 109, 110, 114, 125, 134, 146, 148, 150, 153, 157, 167, 178, 180, 185], "heavi": [7, 9, 36, 43, 60, 65, 98, 145, 156], "skip": [7, 11, 14, 17, 21, 32, 42, 53, 63, 64, 69, 75, 78, 91, 92, 96, 98, 113, 125, 130, 131, 132, 133, 140, 153, 173, 175, 176], "cleaner": [7, 62, 79], "anticip": [7, 77, 92, 184], "beta": [7, 8, 11, 63, 82, 114, 120, 139, 140, 145, 148], "layout": [7, 92], "dx_1": 7, "dx_n": 7, "beta_ix_i": 7, "beta_1x_1": 7, "beta_nx_n": 7, "beta_1": [7, 82, 139], "beta_i": [7, 94], "reassembl": 7, "beta_n": 7, "counter": [7, 9, 53, 133, 138, 139, 185], "intermedi": [7, 23, 25, 28, 29, 35, 37, 39, 41, 42, 49, 55, 56, 61, 63, 64, 66, 69, 75, 76, 92, 103, 109, 110, 111, 126, 150, 175, 177, 178, 190], "bx": [7, 10], "appear": [7, 8, 19, 24, 51, 55, 63, 76, 77, 79, 82, 92, 94, 95, 111, 122, 126, 127, 129, 133, 164, 175, 176, 177, 178, 184, 185], "nowher": 7, "drive": [7, 40, 48, 52, 83, 86, 92, 101, 141, 144, 145, 149, 162], "easier": [7, 10, 14, 19, 28, 42, 47, 51, 53, 54, 55, 56, 62, 69, 75, 78, 82, 92, 96, 99, 104, 108, 138, 140, 153, 157, 175, 184], "x_ia_": 7, "dx_k": 7, "vanish": [7, 22, 27, 63, 72, 86, 98, 110, 112, 114, 141, 148, 153, 174, 175, 178, 183], "kj": [7, 120], "immateri": 7, "ki": [7, 90], "desir": [7, 9, 10, 11, 25, 27, 33, 34, 38, 39, 44, 63, 64, 69, 74, 76, 82, 92, 95, 108, 120, 141, 143, 144, 145, 147, 149, 150, 153, 166, 169, 178, 180, 183, 184], "39": [7, 9, 186], "xax": 7, "xa": 7, "2ax": [7, 10], "toss": [7, 108, 152], "suspici": [7, 10], "times1": [7, 71, 72, 75, 123, 155], "dv": 7, "uv": 7, "somehow": [7, 9, 44, 92, 108, 111], "perhap": [7, 9, 11, 35, 36, 37, 62, 67, 78, 80, 92, 95, 98, 101, 108, 111, 116], "49": 7, "remiss": 7, "free": [7, 19, 40, 57, 64, 78, 79, 85, 88, 89, 90, 92, 95, 104, 111, 137, 138, 145, 147, 157, 164, 186], "past": [7, 12, 23, 25, 27, 38, 41, 63, 70, 82, 85, 92, 95, 101, 103, 104, 114, 131, 138, 139, 144, 145, 147, 149, 150, 153, 167, 168, 174, 178, 181, 183, 184, 187, 188], "dv_": 7, "sum_k": [7, 77, 99, 100], "u_": [7, 151], "v_": [7, 78, 145, 190], "push": [7, 9, 10, 46, 62, 69, 90, 92, 103, 140, 166, 183], "ib": 7, "kb": [7, 41, 92], "ia": 7, "subtleti": 7, "ai": [7, 9, 14, 18, 23, 24, 25, 29, 91, 92, 149, 177, 186, 189, 190], "petersen": [7, 153, 186], "pedersen": [7, 153, 186], "plethora": [7, 67, 122], "appropri": [7, 28, 38, 41, 45, 46, 66, 74, 77, 91, 92, 94, 95, 101, 103, 104, 109, 114, 137, 138, 143, 144, 147, 153, 157, 170, 177, 178, 185, 187], "serv": [7, 23, 41, 45, 64, 67, 69, 76, 85, 92, 94, 96, 108, 113, 137, 143, 148, 185], "organ": [7, 52, 92, 157, 168, 186], "popular": [8, 11, 22, 35, 41, 52, 62, 63, 64, 67, 71, 73, 75, 76, 78, 80, 81, 85, 92, 94, 95, 101, 103, 108, 111, 113, 114, 116, 117, 118, 119, 126, 127, 132, 139, 143, 147, 148, 149, 161, 164, 166, 167, 173, 174, 176, 177, 179, 183, 184, 185, 187], "remark": [8, 24, 27, 35, 69, 72, 74, 92, 95, 105, 111, 153], "use_svg_displai": [8, 20, 21, 27, 96, 140, 151], "lecun": [8, 44, 62, 71, 73, 74, 92, 96, 114, 186], "1998": [8, 44, 74, 92, 96, 101, 114, 186], "60": [8, 28, 46, 48, 62, 88, 89, 92, 96, 122, 185, 186], "handwritten": [8, 23, 74, 92, 96, 186], "modul": [8, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41, 42, 45, 51, 56, 60, 63, 65, 66, 68, 69, 72, 74, 82, 90, 93, 104, 105, 106, 110, 115, 116, 120, 121, 123, 124, 126, 135, 144, 149, 152, 155, 166, 170, 171, 172, 173, 175, 177, 182, 183, 191], "retriev": [8, 27, 28, 41, 46, 89, 92, 119, 179, 186], "internet": [8, 24, 50, 57, 92, 101, 113, 149, 157, 159, 167], "local": [8, 12, 14, 16, 18, 19, 20, 21, 28, 30, 31, 40, 41, 44, 46, 48, 56, 64, 68, 69, 71, 72, 78, 86, 88, 91, 113, 123, 143, 144, 148, 159], "copi": [8, 12, 14, 26, 39, 40, 44, 45, 49, 50, 53, 63, 103, 113, 127, 144, 149, 153, 155, 158, 173], "request": [8, 12, 13, 20, 36, 38, 41, 92, 149], "grayscal": [8, 96, 98, 115], "custom": [8, 32, 53, 54, 57, 63, 92, 94, 98, 105, 119, 121, 126, 127, 141, 143, 156, 157, 159, 162, 168, 177, 184, 191], "remov": [8, 21, 22, 25, 36, 40, 41, 42, 45, 47, 53, 58, 60, 61, 62, 63, 79, 92, 106, 108, 110, 113, 119, 121, 123, 131, 133, 135, 141, 144, 168, 178, 186], "channel": [8, 28, 30, 41, 44, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 82, 96, 123, 143, 153, 186, 191], "unsign": 8, "quantiz": [8, 31], "data_transform": 8, "255": [8, 20, 49, 56, 57, 59, 82, 96, 99, 186], "128": [8, 19, 23, 29, 30, 31, 41, 42, 44, 45, 50, 53, 54, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 85, 88, 89, 90, 119, 121, 128, 144, 176, 177, 186], "mnist_train": [8, 20], "temp": [8, 165, 168], "mnist_test": [8, 20], "uint8": [8, 49], "access": [8, 12, 17, 18, 19, 31, 32, 33, 34, 35, 39, 41, 42, 44, 45, 47, 59, 60, 74, 88, 90, 91, 92, 94, 95, 99, 101, 103, 104, 106, 107, 112, 119, 127, 138, 144, 149, 150, 153, 155, 157, 177, 186, 189], "scalar": [8, 11, 20, 21, 26, 27, 35, 39, 60, 63, 72, 83, 98, 100, 104, 105, 107, 109, 117, 123, 129, 136, 141, 144, 146, 151, 152, 155, 157, 178, 183], "Its": [8, 25, 44, 50, 55, 58, 69, 85, 124, 127, 133, 146, 173, 175], "38": [8, 99, 186], "show_imag": [8, 20, 49, 50, 51, 57, 59, 82, 96], "categori": [8, 48, 50, 51, 53, 54, 62, 77, 82, 92, 94, 96, 98, 103, 114, 119, 122, 123, 124, 126, 146, 156, 181], "explan": [8, 14, 15, 28, 63, 78, 98, 106, 149, 174, 186], "784": [8, 74, 99, 100, 115], "unfortun": [8, 19, 39, 41, 42, 44, 65, 69, 78, 86, 92, 94, 95, 96, 103, 108, 116, 125, 138, 143, 144, 147, 148, 157, 169, 178, 180, 184], "x_d": [8, 103, 141, 179, 180], "signifi": [8, 109, 153, 185], "appl": [8, 62, 92, 98, 103, 186], "prepar": [8, 38, 92, 95, 101, 106, 149, 152, 177], "realli": [8, 28, 64, 65, 69, 71, 79, 80, 83, 92, 94, 95, 101, 105, 108, 119, 137, 141, 143, 146, 148, 157, 180, 184, 186, 189], "fortun": [8, 17, 35, 40, 41, 62, 78, 79, 80, 92, 94, 95, 98, 99, 103, 105, 115, 125, 141, 146, 150, 151, 153, 155, 156, 170, 171, 174], "induct": [8, 64, 69, 77, 86, 101, 111], "bia": [8, 22, 26, 29, 31, 33, 36, 44, 49, 50, 61, 63, 64, 69, 71, 72, 77, 80, 82, 86, 92, 94, 95, 98, 101, 103, 104, 105, 108, 109, 111, 114, 115, 129, 139, 160, 161, 163, 165, 168, 170, 171, 173, 175, 178, 181, 183], "capabl": [8, 25, 41, 46, 62, 66, 68, 80, 92, 101, 107, 111, 114, 117, 144, 158, 159, 160, 165, 167, 169, 184, 186, 188], "modest": [8, 41, 89, 149], "_y": 8, "intract": [8, 11, 92], "awai": [8, 9, 14, 34, 36, 69, 77, 78, 79, 80, 92, 101, 114, 134, 145, 148, 149, 157, 166, 184], "ignor": [8, 9, 10, 13, 20, 23, 36, 41, 50, 61, 63, 72, 73, 77, 82, 93, 95, 103, 105, 106, 141, 154, 166, 173, 177, 178, 180, 185], "roughli": [8, 19, 25, 44, 75, 80, 85, 86, 92, 95, 109, 149, 169, 184, 185, 189], "condition": [8, 136, 157, 184, 186], "suddenli": [8, 92, 94, 95, 175], "predictor": [8, 62, 78, 79, 94, 111, 114, 159], "save": [8, 12, 20, 22, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 38, 42, 44, 45, 47, 48, 50, 51, 53, 54, 57, 59, 63, 69, 72, 74, 80, 82, 83, 85, 86, 90, 93, 96, 99, 104, 105, 106, 107, 110, 111, 113, 119, 120, 122, 124, 126, 127, 128, 131, 133, 141, 144, 146, 149, 151, 152, 159, 163, 164, 165, 166, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 185], "t_i": [8, 148, 184], "t_d": 8, "x_t": [8, 145, 177, 178, 180, 181, 183, 184], "o": [8, 20, 21, 28, 32, 39, 46, 50, 53, 54, 57, 59, 69, 71, 78, 83, 88, 89, 91, 95, 96, 98, 99, 109, 114, 116, 119, 121, 122, 125, 127, 131, 132, 133, 134, 138, 141, 143, 145, 147, 148, 149, 156, 158, 159, 160, 161, 164, 168, 169, 170, 171, 175, 176, 178, 181, 183, 186, 191], "dn": 8, "n_y": 8, "n_8": 8, "800": [8, 9, 11, 41, 44, 126], "0967": 8, "slightli": [8, 22, 25, 30, 39, 40, 42, 44, 45, 53, 62, 63, 66, 72, 75, 76, 85, 95, 96, 98, 107, 135, 138, 139, 141, 143, 144, 145, 157, 169, 180], "white": [8, 59, 72, 74, 76, 94, 96, 171], "switch": [8, 12, 25, 41, 46, 77, 92, 110, 116, 129, 134, 139, 149, 173, 186], "n_": [8, 72, 75, 116, 157], "troubl": [8, 63, 92, 94, 99, 101, 103, 107, 114, 148, 157, 186], "crop": [8, 49, 50, 53, 54, 57, 59, 92, 107, 116], "corner": [8, 14, 47, 48, 49, 53, 57, 58, 72, 75, 92, 99, 109], "statistician": [8, 72, 94, 95, 98, 103, 157, 184], "pseudo": 8, "laplac": [8, 9], "smooth": [8, 21, 60, 66, 80, 82, 83, 106, 110, 114, 143, 145, 146, 148, 183, 186], "hoc": [8, 46, 95], "n_x": 8, "bayes_pr": 8, "unsqueez": [8, 20, 22, 23, 28, 47, 49, 56, 57, 60, 128, 177], "prod": [8, 109, 136, 178], "expand_dim": [8, 20, 22, 23, 28, 47, 49, 56, 57, 60, 80, 96, 128, 168, 177], "reduce_prod": 8, "went": [8, 32, 66, 126, 131, 141, 157, 170], "horribli": 8, "expon": [8, 116, 143, 185], "underflow": [8, 41, 98, 99, 116], "round": [8, 41, 58, 64, 69, 89, 90, 95, 99, 101, 127], "phenomena": [8, 11, 63, 184], "big": [8, 25, 38, 83, 92, 95, 99, 101, 111, 121, 124, 130, 131, 149, 153, 161, 189, 190], "log_p_xi": 8, "log_p_xy_neg": 8, "log_p_i": 8, "bayes_pred_st": 8, "py": [8, 17, 105, 186], "correct": [8, 11, 14, 19, 20, 40, 45, 48, 49, 92, 93, 97, 98, 100, 103, 104, 107, 139, 145, 153, 170, 178, 183, 187, 190], "comparison": [8, 19, 44, 50, 62, 85, 92, 101, 113, 120, 126, 186], "output_typ": 8, "str": [8, 20, 21, 29, 35, 44, 45, 47, 51, 53, 54, 57, 59, 60, 82, 119, 121, 128, 135, 163, 165], "overal": [8, 29, 39, 87, 88, 90, 111, 116, 139, 145, 157, 161, 165, 167, 171], "error": [8, 10, 19, 30, 34, 42, 45, 56, 60, 64, 66, 67, 69, 72, 74, 78, 79, 85, 86, 87, 88, 90, 92, 95, 96, 98, 102, 103, 104, 105, 108, 109, 111, 112, 114, 121, 126, 128, 129, 141, 143, 144, 146, 149, 150, 156, 157, 158, 163, 181, 184, 186], "poor": [8, 39, 41, 78, 86, 92, 101, 116, 139, 141, 189], "incorrect": 8, "led": [8, 25, 41, 42, 63, 67, 68, 69, 92, 138], "downfal": 8, "overli": [8, 77, 78, 95, 110, 141, 147], "gold": [8, 70, 95], "decad": [8, 10, 23, 27, 38, 41, 62, 64, 70, 74, 78, 92, 96, 101, 104, 114, 149, 150, 167, 176], "spam": [8, 92, 93, 94, 98], "xor": 8, "successfulli": [8, 52, 73, 74, 112, 149, 174], "violat": [8, 9, 64, 95, 114, 116, 140], "graph": [8, 10, 19, 24, 34, 39, 40, 41, 42, 44, 46, 65, 69, 73, 86, 92, 112, 144, 146, 150, 151, 155, 157, 178, 186, 191], "koller": [8, 186], "friedman": [8, 63, 186], "2009": [8, 62, 73, 92, 96, 101, 157, 163, 166, 167, 184, 186], "creation": 8, "analogi": [9, 11, 62, 110, 124, 130, 134, 191], "technic": [9, 25, 56, 60, 63, 92, 94, 133, 137, 145, 149, 152, 161, 163, 170, 181, 186], "jump": [9, 90], "throw": [9, 34, 56, 92, 184], "dart": [9, 186], "board": [9, 38, 85, 92, 106, 108, 111, 113, 149], "hit": [9, 20, 41, 76, 86, 165], "cm": 9, "bin": [9, 12, 91, 122, 164], "fall": [9, 11, 94, 95, 119, 146, 157], "fell": 9, "undet": 9, "bucket": [9, 176], "00000": 9, "conceiv": [9, 32, 92, 101], "physic": [9, 19, 38, 41, 46, 92, 94, 98, 100, 140, 149, 156], "meaning": [9, 44, 45, 62, 74, 113, 115, 125, 134, 138, 145, 148, 180, 188], "micromet": 9, "Or": [9, 42, 157, 185], "00": [9, 41], "cdot10": 9, "99995": 9, "00005": 9, "thrower": 9, "unlik": [9, 11, 28, 29, 36, 39, 49, 54, 62, 76, 77, 78, 92, 94, 95, 103, 111, 129, 134, 139, 165, 169, 176, 180, 181], "ge": [9, 11, 149], "blue": [9, 28, 47, 48, 50, 71, 77, 78, 79, 92, 96, 149, 153, 186], "300": [9, 11, 25, 30, 41, 46, 56, 59, 62, 124, 131], "pitfal": [9, 85, 149], "fourth": [9, 46, 56, 60, 64, 66, 77, 99], "bullet": 9, "framework": [9, 11, 12, 14, 19, 22, 27, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 51, 53, 54, 62, 63, 65, 66, 70, 74, 76, 81, 85, 92, 93, 96, 98, 99, 100, 104, 105, 106, 107, 108, 109, 114, 115, 116, 143, 144, 149, 150, 155, 161, 165, 171, 182, 183, 186], "mixtur": [9, 78, 166, 186], "roll": [9, 32, 140, 145, 157, 164], "die": [9, 92, 157], "behavior": [9, 10, 22, 25, 26, 32, 63, 69, 92, 94, 95, 98, 103, 105, 107, 108, 111, 137, 138, 143, 144, 145, 147, 150, 157, 167, 168, 175], "tend": [9, 11, 50, 62, 63, 73, 75, 78, 94, 95, 98, 101, 104, 106, 108, 111, 113, 137, 157, 163, 169, 173, 177, 184, 185], "minimalist": [9, 171], "2p": 9, "mu_i": [9, 47, 78, 80, 157], "profit": [9, 94], "pm": [9, 79, 95, 101], "sale": [9, 92, 103], "despit": [9, 21, 24, 29, 63, 77, 78, 79, 92, 94, 95, 103, 111, 114, 123, 149, 157, 171, 174], "fluctuat": [9, 11, 103], "risk": [9, 11, 92, 95, 101, 112, 114, 116, 144, 146, 148, 150, 153, 186], "magnitud": [9, 11, 19, 22, 25, 39, 41, 46, 62, 63, 68, 77, 86, 92, 101, 103, 116, 138, 139, 141, 143, 153, 163, 186], "var": [9, 11, 12, 63, 116, 136, 157], "middl": [9, 47, 51, 66, 72, 92], "readili": [9, 27, 41, 92, 167, 171], "8p": 9, "spectrum": [9, 95, 169, 186], "hiccup": 9, "star": [9, 14, 86, 92, 164, 167], "web": [9, 25, 53, 54, 91, 92, 94, 104, 149, 164, 180, 186], "page": [9, 12, 14, 91, 92, 94, 109, 113, 138, 149], "deduc": [9, 11], "restat": [9, 35], "regard": [9, 28, 44, 63, 72, 77, 94, 100, 140, 141, 148, 149, 164, 172, 177, 178], "resound": 9, "chebyshev": [9, 157], "outsid": [9, 11, 77, 83, 94, 99, 108, 140, 148, 150, 180], "possibli": [9, 29, 34, 44, 46, 62, 63, 92, 94, 95, 103, 104, 107, 111, 114, 116, 121, 133, 141, 143, 154, 155, 157, 184], "horizont": [9, 25, 53, 71, 72, 75, 79, 145, 153, 168], "safe": [9, 10, 11, 12, 41, 113, 138], "helper": [9, 48, 75, 128, 130, 141], "plot_chebyshev": 9, "hline": 9, "lw": [9, 47], "vline": 9, "53": [9, 71, 186], "47": [9, 186], "3f": [9, 10, 20, 23, 29, 51, 53, 54, 72, 78, 82, 83, 128, 131, 135, 143, 144, 163, 165, 177], "touch": [9, 70, 101, 106, 108, 114, 140], "sharp": [9, 76, 99, 126], "125": [9, 113, 186], "invalid": 9, "xp_x": 9, "2_x": [9, 136], "2p_x": 9, "xp": 9, "warn": [9, 13, 82], "cauchi": 9, "innoc": 9, "consult": [9, 63, 70, 95, 145, 149], "goe": [9, 10, 18, 92, 95, 143, 157, 184], "astrai": 9, "integrand": 9, "dip": 9, "disturb": [9, 180], "vast": [9, 60, 95, 111, 130, 133, 159], "circumst": [9, 92, 94, 101], "r_": [9, 89, 90, 95, 101], "red": [9, 12, 14, 21, 25, 27, 48, 50, 71, 77, 92, 96, 140, 153, 188], "p_t": [9, 94], "stock": [9, 92, 94, 101, 103, 113, 157, 184], "price": [9, 18, 19, 41, 62, 63, 65, 71, 77, 92, 94, 98, 99, 101, 103, 112, 156, 183, 184, 186, 191], "nearbi": [9, 12, 73], "unneed": 9, "y_j": [9, 94, 98, 99], "cov": [9, 27, 78, 79, 80, 136, 157], "simultan": [9, 41, 44, 45, 46, 51, 59, 63, 66, 94, 95, 98, 103, 108, 111, 116, 140, 149, 157, 170, 179], "4p": 9, "miss": [9, 14, 41, 57, 79, 113, 153, 156, 158, 166, 170, 180], "determinist": [9, 22, 28, 29, 30, 62, 63, 68, 70, 76, 92, 94, 103, 110, 171, 189, 190], "transit": [9, 20, 67, 92, 188, 189, 190], "analogu": 9, "tunabl": [9, 35, 54, 103, 183], "adjust": [9, 21, 22, 31, 44, 47, 49, 50, 51, 56, 63, 65, 66, 69, 71, 74, 76, 86, 92, 94, 100, 105, 108, 113, 115, 137, 138, 139, 140, 141, 143, 147, 148, 152, 160, 167, 173, 175, 177, 180, 183], "500": [9, 41, 51, 56, 78, 122, 144, 158], "scatter": [9, 11, 44, 78, 83, 90, 111, 149, 186], "inch": [9, 41], "dollar": [9, 50, 92, 98, 103, 111, 157], "related": 9, "cent": 9, "rho": [9, 136, 137, 147], "sigma_i": [9, 47, 136], "45": [9, 47, 48, 79, 138, 141, 183, 186], "direction": 9, "cor": 9, "x_iy_ip_": 9, "difficulti": [9, 174, 184, 186], "viewpoint": [9, 63, 151], "unwant": 9, "2e": [9, 11, 53, 60], "street": [9, 113, 133, 153], "me": [9, 14, 41, 186], "concaten": [10, 20, 22, 23, 26, 29, 30, 35, 47, 56, 57, 58, 61, 65, 66, 71, 76, 82, 113, 115, 120, 123, 124, 126, 127, 133, 135, 136, 151, 155, 160, 165, 168, 170, 177, 178, 181, 183], "extraordinarili": 10, "imposs": [10, 44, 68, 70, 72, 92, 94, 108, 116, 150, 157], "surfac": [10, 63, 78, 80, 92, 98, 103, 116, 151, 157, 184], "0000001": 10, "x_big": 10, "simpler": [10, 22, 36, 46, 62, 63, 69, 83, 94, 101, 111, 114, 120, 140, 143, 157, 175, 178], "x_med": 10, "zoom": [10, 41, 95], "x_small": 10, "0001": [10, 95], "1701": [10, 186], "00001": 10, "5f": [10, 103, 151], "seek": [10, 41, 77, 92, 95, 96, 103, 149], "digress": 10, "tri": [10, 23, 41, 63, 66, 83, 92, 94, 132, 149], "paltri": 10, "thousand": [10, 11, 24, 41, 50, 58, 62, 63, 77, 78, 92, 95, 101, 111, 125, 178, 183, 184, 185], "1986": [10, 21, 186], "rumelhart": [10, 186], "1988": [10, 41, 74, 77, 104, 176, 186], "nabla_xf": 10, "d_xf": 10, "f_x": 10, "stick": [10, 72, 92, 94, 103, 108, 183], "unravel": 10, "treatment": [10, 11, 94, 138, 152], "indulg": 10, "temptat": 10, "eas": [10, 53, 62, 74, 99, 120, 128], "gift": 10, "codifi": 10, "importantli": [10, 21, 64, 72, 94, 157], "composit": [10, 50, 103, 111, 151, 175], "dg": 10, "dh": 10, "jointli": [10, 26, 58, 62, 71, 92, 98, 110, 114, 115, 120, 157, 186], "sit": [10, 89, 95, 126, 130, 170], "0000000000001": 10, "tediou": [10, 35, 36, 37, 80, 109, 150], "prone": [10, 150], "perfect": [10, 64, 83, 94, 95, 103, 149], "revisit": [10, 24, 35, 63, 66, 67, 70, 95, 97, 101, 112, 121, 129, 145, 181, 186], "slope": [10, 64, 80, 151], "x0": [10, 78, 119], "fist": 10, "upward": [10, 109], "downward": [10, 143], "2g": [10, 80], "2a": 10, "x_0": [10, 145], "furthermor": [10, 19, 24, 41, 62, 64, 65, 72, 86, 92, 113, 116, 139, 140, 141, 143, 145, 146, 149, 153, 157, 176, 177, 180, 185], "p_n": [10, 177], "am": [10, 113, 120, 170, 186], "own": [10, 12, 14, 28, 31, 35, 39, 44, 63, 67, 69, 87, 92, 93, 95, 98, 99, 104, 105, 106, 107, 110, 116, 140, 143, 144, 149, 153, 157, 171, 179, 180, 184, 189], "reconstruct": [10, 25, 94, 158], "p1": [10, 20, 190], "p2": [10, 12, 20, 41, 44, 45, 190], "p5": 10, "24": [10, 29, 30, 46, 66, 78, 92, 98, 128, 153, 184, 186], "120": [10, 54, 63, 74, 143, 186], "legend": [10, 20, 21, 28, 51, 53, 54, 56, 60, 78, 82, 83, 103, 106, 116, 128, 143, 144, 145, 151, 157, 163, 165, 176, 184, 185], "primari": [10, 21, 24, 74, 92, 93, 95, 100, 103, 149, 152], "open": [10, 12, 13, 14, 16, 17, 18, 20, 25, 32, 46, 49, 51, 53, 54, 56, 59, 62, 63, 72, 83, 85, 90, 91, 92, 94, 104, 106, 111, 114, 119, 121, 122, 127, 131, 133, 149, 156, 159, 174, 176, 185, 186, 189, 190], "fine": [10, 20, 22, 24, 39, 46, 51, 52, 59, 79, 92, 94, 108, 118, 126, 128, 149, 151, 157, 170, 186, 191], "grain": [10, 22, 39, 46, 59, 79, 108], "ge0": 10, "undoubtedli": 11, "crucial": [11, 22, 27, 38, 78, 85, 92, 94, 95, 101, 105, 111, 116, 150, 151, 157, 179], "improv": [11, 14, 19, 25, 29, 30, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 54, 58, 60, 62, 63, 64, 66, 67, 68, 69, 73, 74, 76, 78, 83, 85, 87, 92, 94, 95, 96, 98, 101, 103, 104, 111, 113, 117, 121, 123, 124, 126, 132, 135, 139, 141, 142, 143, 145, 148, 149, 157, 158, 159, 163, 165, 169, 177, 183, 184, 186], "earliest": [11, 21, 24, 51, 77, 92, 114, 150], "arab": [11, 184], "scholar": [11, 92, 157], "kindi": 11, "centuri": [11, 21, 41, 92, 103, 114, 150], "who": [11, 23, 41, 46, 92, 94, 98, 99, 101, 103, 104, 113, 117, 149, 157, 188], "descript": [11, 14, 19, 23, 25, 42, 44, 46, 59, 64, 72, 92, 127, 135, 149, 150, 154, 160, 164, 167, 185], "frequenc": [11, 19, 28, 41, 56, 62, 95, 132, 133, 157, 184, 185, 186], "deciph": 11, "encrypt": 11, "messag": [11, 13, 41, 46, 72, 94, 167, 186], "year": [11, 14, 19, 22, 24, 25, 52, 62, 63, 81, 83, 92, 94, 95, 101, 103, 113, 134, 149, 157, 175, 184], "aros": 11, "germani": 11, "1700": 11, "focus": [11, 24, 25, 35, 36, 40, 42, 59, 92, 95, 113, 114, 118, 130, 143, 149, 153, 158, 171, 178, 179, 184, 186], "demograph": [11, 92, 164], "econom": [11, 19, 92], "todai": [11, 39, 62, 77, 92, 96, 103, 149, 176, 182, 184, 187], "scienc": [11, 92, 101, 103, 111, 149, 156, 186], "academia": [11, 50, 52], "industri": [11, 52, 62, 92, 117, 149, 159, 162, 167], "govern": [11, 31, 63, 64, 78, 92, 103, 145, 157, 175], "infer": [11, 12, 20, 25, 34, 41, 62, 63, 64, 66, 79, 80, 81, 86, 92, 101, 103, 104, 117, 118, 126, 144, 146, 149, 153, 155, 157, 168, 175, 186, 191], "former": [11, 17, 19, 25, 29, 41, 42, 44, 47, 50, 58, 63, 65, 74, 104, 107, 126, 128, 139, 146, 151, 159, 166, 168], "popul": [11, 85, 92, 94, 95, 101, 111, 133, 146, 157], "contrari": [11, 42, 63, 116, 119], "characterist": [11, 41, 46, 63, 77, 83, 92, 94, 138, 151, 157, 163], "replic": [11, 144, 155], "causal": [11, 25, 92, 94, 184, 186], "emphas": [11, 25, 78, 99, 129, 148, 154], "breviti": [11, 17, 134, 155, 158, 160, 164], "straightforward": [11, 30, 42, 44, 46, 72, 75, 89, 95, 100, 109, 111, 117, 126, 131, 137, 139, 141, 143, 145, 147, 150, 153, 169, 177, 178, 179, 184], "_n": [11, 22, 28, 64, 83, 94, 120], "visibl": [11, 96, 139], "clearer": [11, 150], "xd": 11, "max": [11, 21, 45, 47, 53, 56, 60, 62, 65, 66, 68, 69, 70, 74, 76, 83, 89, 90, 98, 114, 115, 118, 126, 127, 132, 133, 140, 141, 143, 165, 166, 186, 189, 190], "yd": 11, "axvlin": 11, "linestyl": [11, 20, 157], "reduce_min": 11, "reduce_max": [11, 76], "mse": [11, 113, 143, 161], "l_2": 11, "quantifi": [11, 47, 85, 92, 95, 98, 103, 111, 157, 169, 186], "regress": [11, 20, 24, 25, 27, 35, 56, 58, 60, 74, 79, 81, 83, 86, 93, 94, 95, 97, 101, 106, 111, 113, 114, 115, 116, 118, 144, 149, 161, 179, 180, 181, 184, 186, 191], "systemat": [11, 25, 64, 77, 87], "unbias": [11, 93, 95, 110, 148, 186], "bias": [11, 36, 64, 69, 77, 98, 100, 101, 103, 108, 111, 114, 126, 158, 163, 170, 173, 175, 178], "flaw": [11, 92, 141], "asymptot": [11, 95, 140], "avail": [11, 18, 19, 21, 24, 25, 27, 31, 38, 39, 40, 41, 44, 51, 62, 64, 66, 74, 85, 88, 89, 90, 92, 94, 95, 96, 101, 104, 108, 111, 131, 145, 147, 148, 149, 157, 162, 164, 166, 167, 171, 179, 180, 182, 184, 186, 187], "infin": [11, 80, 94, 95, 98, 125, 180], "shock": 11, "actual": [11, 22, 27, 35, 36, 39, 41, 44, 47, 62, 63, 64, 65, 66, 70, 71, 72, 77, 78, 79, 80, 88, 92, 94, 95, 98, 100, 104, 111, 113, 114, 138, 141, 143, 144, 145, 149, 155, 157, 163, 170, 175, 178, 180, 184, 185, 189], "plu": [11, 23, 62, 64, 70, 71, 78, 79, 92, 94, 96, 100], "That": [11, 19, 21, 22, 36, 41, 42, 44, 46, 47, 62, 63, 64, 65, 69, 72, 76, 77, 92, 93, 94, 98, 100, 103, 104, 108, 111, 114, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 151, 155, 157, 178, 184], "irreduc": [11, 78], "suffer": [11, 44, 92, 140, 147, 157, 164, 183, 184], "underfit": [11, 95, 102], "lack": [11, 19, 30, 62, 77, 79, 90, 92, 99, 147, 149, 151, 159, 184], "overfit": [11, 21, 50, 51, 53, 62, 63, 70, 80, 86, 92, 95, 102, 108, 110, 112, 113, 123, 124, 143, 146, 149, 182, 186], "sensit": [11, 25, 51, 63, 76, 78, 92, 93, 94, 103, 110, 128, 130, 143, 147, 153], "nois": [11, 20, 25, 54, 56, 63, 74, 76, 78, 79, 82, 83, 86, 92, 98, 100, 103, 107, 108, 110, 111, 125, 126, 133, 135, 138, 144, 145, 146, 148, 184, 186], "std": [11, 33, 45, 56, 59, 103, 113, 144], "stat_bia": 11, "true_theta": 11, "est_theta": 11, "simul": [11, 39, 40, 42, 92, 148, 157, 186, 190], "theta_tru": 11, "sample_len": 11, "theta_est": 11, "reduce_std": 11, "earli": [11, 21, 44, 62, 74, 89, 90, 92, 94, 112, 116, 143, 175], "arbuthnot": 11, "80": [11, 41, 46, 62, 64, 92, 113, 126, 127, 157, 176, 186], "birth": 11, "london": 11, "men": [11, 92, 94], "born": 11, "women": [11, 119], "intellig": [11, 38, 92, 149, 157, 186], "heritag": 11, "karl": [11, 101], "pearson": [11, 136, 186], "invent": [11, 31, 32, 63, 68, 72, 77, 92, 98, 99, 103, 104, 110, 111, 116], "chi": [11, 161, 186], "william": [11, 77, 78, 186], "gosset": 11, "father": [11, 98], "student": [11, 62, 92, 94, 101, 149, 157], "ronald": [11, 92], "fisher": [11, 92, 114, 186], "null": [11, 50, 123, 124], "evid": [11, 70, 72, 103, 157], "h_0": 11, "reject": [11, 14, 80, 180], "h_a": [11, 47], "h_1": [11, 26, 58, 110], "reflect": [11, 89, 92, 94, 95, 111, 117, 134, 167, 180], "testabl": 11, "chemist": 11, "spend": [11, 18, 41, 68, 90, 92, 98, 180], "hour": [11, 14, 62, 86, 88, 92, 142, 184], "lab": [11, 19, 20, 41, 74, 92, 164, 179], "medicin": [11, 92, 98, 127, 149, 184], "dramat": [11, 32, 62, 68, 77, 103, 108, 138, 157, 170, 184], "magic": [11, 35, 42, 63, 105, 106], "volunt": 11, "user": [11, 12, 14, 17, 19, 32, 34, 36, 38, 39, 40, 41, 42, 50, 85, 86, 90, 91, 92, 94, 98, 99, 103, 104, 113, 149, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 183, 188, 189], "asid": [11, 63, 74, 78, 95, 98, 108, 141, 149, 169], "benchmark": [11, 25, 39, 40, 42, 52, 62, 85, 88, 92, 93, 94, 95, 96, 101, 103, 117, 119, 144, 186], "environ": [11, 12, 20, 38, 42, 48, 88, 91, 97, 149, 155, 157, 187, 189, 190, 191], "setup": [11, 22, 23, 26, 28, 29, 30, 31, 35, 37, 41, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 88, 92, 94, 99, 100, 103, 104, 105, 106, 110, 115, 170, 171, 172, 173, 175, 177, 182, 183, 189, 190], "impact": [11, 39, 89, 92, 94, 101, 149, 158, 160, 161, 165, 168, 175, 185, 186], "period": [11, 37, 79, 80, 101, 113, 127, 143, 183, 184, 189], "suitabl": [11, 12, 19, 21, 22, 30, 31, 41, 50, 58, 60, 63, 69, 72, 77, 92, 98, 108, 114, 116, 127, 141, 143, 146, 148, 158, 166, 172], "decid": [11, 14, 38, 46, 77, 85, 89, 92, 94, 111, 114, 119, 138, 141, 149, 157, 180, 184], "score": [11, 23, 24, 28, 29, 47, 60, 77, 89, 92, 93, 94, 95, 98, 113, 117, 157, 158, 161, 163, 164, 165, 166, 169, 177, 186, 191], "experiment": [11, 20, 38, 41, 62, 64, 66, 67, 73, 74, 75, 82, 92, 139, 144, 145, 147, 186], "design": [11, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 39, 40, 41, 42, 44, 46, 47, 49, 50, 55, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 77, 86, 88, 92, 94, 96, 98, 99, 102, 103, 104, 105, 107, 110, 113, 115, 116, 117, 118, 119, 120, 121, 123, 126, 129, 132, 134, 139, 140, 141, 142, 143, 150, 153, 155, 156, 157, 161, 170, 171, 172, 174, 175, 177, 180, 182, 183, 184, 185, 186, 188, 191], "certainti": [11, 98, 157], "erron": 11, "willing": [11, 90, 92, 98, 115], "caus": [11, 42, 78, 89, 92, 94, 95, 98, 100, 114, 116, 141, 146, 155, 157, 180, 183], "discrep": [11, 41, 113, 178], "accept": [11, 14, 63, 72, 92, 105, 106, 117, 186], "80000": 11, "water": [11, 19, 101, 129], "filter": [11, 47, 52, 56, 59, 60, 62, 63, 65, 66, 72, 74, 77, 86, 88, 89, 92, 94, 107, 122, 127, 138, 143, 158, 162, 163, 168, 177, 185, 186, 191], "filtrat": 11, "harm": [11, 68, 92], "substanc": 11, "escap": [11, 99, 114], "gap": [11, 24, 64, 69, 95, 101, 110, 111, 143, 186], "catch": [11, 94], "distinguish": [11, 38, 55, 59, 62, 63, 77, 83, 88, 90, 92, 94, 96, 111, 121, 126, 132, 133, 146, 153, 166, 173, 178, 189], "drastic": [11, 71, 75, 77, 143, 183], "predefin": [11, 35, 47, 86, 104, 119, 120, 121, 125, 126, 132, 133, 147, 178, 180], "hypothes": [11, 119, 120, 157], "favor": [11, 28, 42, 64, 98, 144], "scenario": [11, 40, 41, 89, 95, 148, 166, 170, 180], "clinic": 11, "trail": [11, 92], "ago": [11, 94, 98, 149], "excit": [11, 25, 27, 64, 67, 70, 82, 92, 98, 103, 140, 185, 186], "jerzi": 11, "neyman": [11, 186], "1937": [11, 186], "c_n": 11, "ni": [11, 90, 92, 186], "coverag": [11, 24, 154], "tempt": [11, 111, 183], "li": [11, 27, 44, 46, 58, 60, 63, 76, 85, 89, 92, 99, 103, 111, 117, 123, 137, 148, 149, 186], "sadli": [11, 146], "pedant": 11, "implic": [11, 157], "satisfi": [11, 21, 35, 46, 47, 64, 77, 94, 95, 98, 100, 116, 138, 140, 141, 146, 153, 157, 178, 180, 184, 187], "morei": [11, 186], "2016": [11, 27, 28, 29, 30, 35, 40, 41, 45, 56, 58, 60, 61, 62, 63, 64, 66, 67, 69, 70, 73, 90, 92, 101, 103, 104, 114, 117, 120, 126, 127, 143, 149, 150, 157, 179, 186, 187], "fallaci": [11, 186], "suffic": [11, 12, 19, 41, 66, 72, 138, 144, 181], "mu_n": 11, "2_n": 11, "sigma_n": 11, "freedom": [11, 63, 150], "96": [11, 30, 62, 64, 65, 66, 68, 69, 129], "precomput": [11, 56, 129], "regim": [11, 62, 63, 92, 111], "t_star": 11, "bessel": 11, "ddof": 11, "imit": [11, 77, 92, 186, 187], "lookup": 11, "mu_hat": 11, "sigma_hat": 11, "overset": 11, "iid": [11, 78, 79, 101], "unif": [11, 25], "tild": [11, 80, 138, 173, 175], "contradict": [11, 19, 77, 119, 120, 121, 140], "raw": [12, 35, 41, 53, 54, 62, 64, 92, 100, 127, 157, 176, 179, 191], "linux": [12, 14, 17, 91, 92], "23": [12, 13, 14, 17, 18, 19, 47, 65, 98, 106, 149, 186], "sagemak": [12, 16, 88, 191], "yourself": [12, 32, 69, 86, 92, 100, 111], "cost": [12, 19, 22, 26, 41, 44, 50, 54, 60, 62, 64, 66, 69, 70, 71, 76, 90, 92, 94, 98, 109, 118, 125, 129, 138, 141, 144, 145, 148, 161, 169, 175, 181], "walkthrough": 12, "gpu": [12, 13, 16, 18, 20, 22, 24, 32, 39, 42, 43, 46, 54, 62, 65, 69, 70, 73, 74, 77, 82, 85, 88, 89, 91, 92, 96, 98, 105, 106, 109, 111, 115, 139, 144, 155, 186, 191], "preinstal": 12, "cloud": [12, 18, 19, 38, 86, 88, 92, 156], "minor": [12, 16, 20, 21, 22, 93, 155], "account": [12, 13, 14, 18, 41, 53, 54, 92, 95, 97, 103, 111, 113, 114, 149, 168, 170, 175, 180], "click": [12, 13, 14, 17, 18, 53, 54, 91, 92, 94, 113, 159, 160, 161, 162, 165, 167, 186], "panel": [12, 14, 18, 64], "consol": [12, 18], "latenc": [12, 43, 62, 144], "oregon": 12, "mark": [12, 14, 20, 25, 58, 66, 72, 113, 117, 126, 149, 151, 154, 176, 177], "box": [12, 14, 52, 57, 58, 59, 69, 113, 140, 142, 171, 178, 186, 187, 191], "china": [12, 131], "asia": 12, "pacif": 12, "seoul": 12, "tokyo": [12, 131], "pleas": [12, 14, 51, 91, 92, 149], "choos": [12, 18, 19, 25, 26, 40, 41, 42, 47, 54, 56, 58, 64, 68, 71, 75, 80, 85, 87, 92, 93, 95, 98, 100, 101, 103, 104, 108, 111, 115, 116, 118, 126, 134, 137, 138, 141, 143, 144, 145, 148, 149, 157, 169, 171, 186, 189, 190], "xlarg": [12, 86], "accord": [12, 17, 21, 27, 28, 33, 34, 35, 38, 47, 49, 53, 54, 55, 58, 64, 66, 76, 77, 88, 91, 92, 94, 95, 98, 101, 103, 108, 109, 110, 111, 113, 116, 117, 121, 127, 133, 134, 135, 140, 153, 155, 178, 184], "link": [12, 14, 18, 41, 46, 50, 110, 113, 149, 179], "quota": 12, "dai": [12, 14, 25, 37, 44, 62, 74, 77, 86, 88, 92, 93, 94, 95, 98, 103, 104, 111, 142, 153, 179, 182, 184, 186], "button": [12, 13, 14, 25, 53, 54, 92, 113, 167], "ami": 12, "ubuntu": [12, 14], "configur": [12, 17, 19, 41, 64, 66, 69, 70, 85, 88, 89, 90, 105, 108, 128, 139, 173, 175, 186], "overwhelm": [12, 42, 44, 98], "g2": [12, 138, 141, 147, 148], "k520": 12, "ancient": [12, 151], "kepler": 12, "k80": 12, "old": [12, 21, 71, 76, 92, 94, 95, 114, 173, 175], "cheap": [12, 19, 24, 41, 87, 90, 92, 101, 103, 105, 138, 143, 144, 169], "spot": [12, 14, 41, 92, 94, 96, 186], "g3": 12, "maxwel": 12, "m60": 12, "trade": [12, 39, 62, 64, 66, 69, 70, 71, 94, 95, 98, 103, 108, 139, 144, 169, 184], "p3": [12, 18, 19, 44, 46], "volta": [12, 41], "v100": [12, 18, 19, 41, 46], "fp16": [12, 19, 41, 99], "p4": 12, "amper": [12, 62, 64], "a100": [12, 62], "g4": [12, 19], "ture": [12, 19, 25, 41, 92, 186], "t4": [12, 41], "int8": [12, 19, 41, 99], "server": [12, 16, 37, 38, 39, 41, 42, 43, 44, 62, 91, 95, 144, 156, 159, 186, 191], "flavor": [12, 171, 176], "16xlarg": [12, 44, 45, 46], "memori": [12, 19, 20, 22, 29, 37, 38, 39, 42, 43, 44, 46, 54, 59, 62, 63, 65, 66, 68, 69, 70, 71, 72, 75, 86, 92, 94, 96, 99, 101, 103, 107, 109, 115, 121, 133, 138, 144, 150, 152, 153, 156, 167, 173, 174, 178, 181, 182, 185, 186, 191], "driver": [12, 24, 38, 103, 126, 128], "ssh": [12, 17], "edit": [12, 13, 16, 18, 149], "subnet": 12, "secur": [12, 18, 48, 184], "disk": [12, 19, 32, 36, 37, 42, 107, 111], "gb": [12, 19, 25, 41, 44, 46, 59, 92, 144], "id": [12, 53, 54, 92, 94, 113, 121, 126, 149, 155, 159, 163, 164, 186], "statu": [12, 14, 24, 144, 157, 184], "green": [12, 14, 50, 71, 77, 92, 96, 153, 188], "publicli": [12, 179], "viewabl": 12, "folder": [12, 17, 20, 50, 53, 54, 98, 113, 159, 164], "d2l_kei": 12, "pem": 12, "command": [12, 14, 17, 18, 19, 38, 39, 44, 91, 92, 114, 144, 149, 188], "chmod": 12, "400": [12, 48, 51, 120], "startup": [12, 94, 139, 149], "xx": [12, 17, 80], "xxx": 12, "amazonaw": [12, 127], "com": [12, 14, 18, 20, 53, 54, 91, 94, 105, 113, 127, 162], "prompt": [12, 14, 25, 38, 91, 116, 176, 186], "readi": [12, 14, 18, 38, 39, 60, 72, 94, 96, 97, 100, 105, 112, 113, 127, 139, 156, 173, 183, 189], "latest": [12, 18, 19, 62, 116, 149, 165, 168], "sudo": [12, 91], "apt": [12, 14, 91], "git": [12, 17, 18], "libgfortran3": 12, "visit": [12, 46, 91, 92, 113, 184, 189], "nvidia": [12, 19, 22, 38, 40, 44, 46, 62, 64, 91, 92, 99], "offici": [12, 14, 113, 152, 154, 177], "repositori": [12, 15, 18, 149, 156], "address": [12, 14, 17, 22, 27, 30, 35, 37, 41, 42, 49, 50, 53, 54, 63, 76, 77, 92, 94, 95, 98, 100, 101, 108, 113, 114, 115, 116, 118, 120, 132, 134, 138, 139, 140, 143, 145, 149, 151, 155, 156, 157, 158, 159, 165, 175, 178, 183, 184], "instruct": [12, 14, 25, 39, 41, 42, 62, 67, 91, 104, 142, 154, 180, 183, 186], "termin": [12, 18, 103, 111, 178, 189], "file": [12, 14, 20, 32, 41, 42, 50, 53, 54, 57, 59, 70, 91, 92, 107, 113, 121, 122, 131, 133, 156, 159, 164, 191], "wget": 12, "http": [12, 14, 17, 18, 20, 53, 54, 91, 105, 113, 119, 127, 131, 164, 186], "repo": 12, "ubuntu2204": 12, "x86_64": [12, 91], "pin": [12, 62, 92, 143], "mv": [12, 131, 135, 144, 153], "etc": [12, 63, 64, 66, 78, 79, 80, 94, 101, 103, 106, 113, 143, 149, 153, 184, 185, 187, 188], "600": [12, 20, 92, 184], "local_instal": 12, "local_12": 12, "530": [12, 25, 186], "02": [12, 53, 82, 83, 145, 157, 161, 186], "1_amd64": 12, "deb": 12, "dpkg": 12, "cp": [12, 30], "keyr": 12, "gpg": 12, "usr": [12, 91], "smi": [12, 38, 44], "bashrc": 12, "export": [12, 42], "ld_library_path": 12, "lib64": 12, "tip": 12, "bash": [12, 91], "script": [12, 42, 78, 88, 91], "miniconda": 12, "miniconda3": [12, 91], "conda": [12, 91], "init": [12, 20, 23, 28, 29, 31, 33, 34, 35, 36, 38, 45, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 82, 83, 91, 99, 104, 105, 106, 108, 110, 113, 120, 123, 124, 128, 135, 143, 144, 149, 158, 160, 161, 163, 165, 168, 177, 184], "reopen": [12, 91], "shell": [12, 17, 91], "port": [12, 17, 42], "monitor": [12, 52, 59, 92, 94, 105, 111, 113], "keyboard": [12, 17], "desktop": [12, 14, 38, 41, 44], "laptop": [12, 39, 62, 91, 156], "8889": 12, "localhost": [12, 17, 91], "8888": [12, 17, 91], "activ": [12, 22, 24, 25, 29, 30, 31, 33, 34, 35, 36, 37, 41, 42, 44, 45, 53, 54, 60, 63, 64, 65, 66, 68, 69, 70, 74, 77, 80, 81, 82, 83, 86, 91, 92, 94, 96, 98, 103, 105, 109, 110, 112, 115, 116, 120, 123, 125, 126, 135, 140, 143, 146, 158, 160, 165, 168, 170, 171, 173, 175, 178, 179, 181, 183, 186], "url": [12, 18, 20, 113, 186], "browser": [12, 14, 17, 91, 92, 154], "servic": [12, 18, 24, 98, 149, 159, 162, 167, 180], "bill": [12, 18, 92, 179], "akin": [12, 25, 27, 76, 139], "regular": [12, 14, 22, 23, 29, 30, 39, 46, 61, 62, 63, 66, 67, 69, 79, 86, 94, 101, 105, 109, 110, 112, 113, 116, 144, 145, 149, 158, 160, 163, 173, 175, 178, 186], "retain": [12, 24, 32, 35, 56, 59, 68, 74, 105, 109, 110, 114, 127, 155, 171, 173, 175, 181], "delet": [12, 25, 105, 156], "futur": [12, 25, 36, 39, 52, 63, 70, 78, 92, 93, 94, 106, 137, 149, 157, 166, 174, 184, 187, 188, 189], "templat": [12, 64, 70, 92], "option": [12, 13, 16, 21, 27, 33, 34, 41, 63, 69, 77, 91, 92, 96, 98, 103, 106, 113, 144, 145, 148, 150, 186], "reinstal": 12, "runtim": [12, 34, 38, 78, 85, 91, 144, 149, 173], "bui": [12, 19, 98, 162, 165, 167, 168, 184], "fast": [12, 19, 32, 38, 39, 41, 42, 52, 60, 62, 70, 71, 72, 94, 96, 103, 111, 132, 144, 148, 155, 161, 186], "aw": [13, 16, 17, 18, 38, 42, 44, 45, 46, 92, 149, 191], "cell": [13, 17, 20, 41, 94, 171, 173, 174, 186, 189, 190], "anywai": [13, 108], "typo": 14, "outdat": [14, 154], "citat": [14, 63, 149], "eleg": [14, 62, 69, 86, 92, 99, 149], "delai": [14, 41, 46, 77, 186, 187], "incorpor": [14, 31, 35, 37, 77, 79, 92, 94, 101, 103, 113, 157, 167, 168, 173, 177, 181, 184, 186], "ci": 14, "merg": [14, 47, 132], "contributor": [14, 92, 149], "sentenc": [14, 22, 23, 24, 25, 29, 92, 117, 119, 120, 121, 123, 124, 128, 133, 170, 176, 177, 180, 184, 185, 186], "recommend": [14, 19, 39, 41, 44, 50, 63, 64, 73, 94, 106, 111, 143, 149, 153, 158, 161, 163, 164, 165, 184, 186, 187, 191], "search": [14, 18, 27, 41, 58, 62, 64, 67, 85, 87, 89, 90, 91, 94, 103, 117, 131, 159, 162, 174, 177, 183, 184, 186, 191], "markdown": 14, "upper": [14, 25, 47, 48, 49, 53, 57, 58, 69, 72, 75, 76, 78, 86, 88, 89, 95, 109, 148, 157, 180, 183], "bottom": [14, 20, 46, 72, 75, 76, 92, 113, 149, 178], "redirect": [14, 106], "plan": [14, 48, 62, 92, 94, 106, 149, 157], "editor": [14, 92, 149], "jupyt": [14, 16, 18, 91, 106, 149, 151, 154, 191], "notebook": [14, 16, 20, 78, 79, 80, 81, 88, 91, 92, 106, 154, 191], "block": [14, 20, 22, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 41, 42, 53, 56, 63, 64, 67, 71, 72, 74, 78, 82, 91, 95, 106, 120, 121, 123, 124, 126, 128, 144, 149, 151, 158, 160, 161, 163, 165, 168, 172, 186, 191], "tab": [14, 53, 54, 91, 113, 176], "d2lbook": [14, 88], "suggest": [14, 19, 25, 38, 39, 41, 70, 71, 85, 86, 90, 95, 103, 104, 107, 110, 113, 114, 116, 129, 133, 138, 144, 145, 176, 180], "nutshel": [14, 38, 41, 44, 47, 55, 60, 77, 78, 80, 92, 98, 137, 180], "astonzhang": 14, "xcode": 14, "maco": [14, 17, 91], "client": [14, 184], "fork": 14, "usernam": 14, "en": [14, 17, 18, 23, 29, 91, 124, 131, 177], "date": [14, 35, 69, 92, 98, 103, 149, 150, 184], "your_github_usernam": 14, "chapter_appendix": 14, "md": [14, 17], "mylaptop": 14, "branch": [14, 41, 62, 64, 67, 69, 108, 191], "master": [14, 63, 92, 95, 105, 114, 150, 175, 186], "stage": [14, 39, 41, 64, 68, 92, 138, 147, 165, 187, 190], "commit": [14, 18, 64], "checkout": 14, "directori": [14, 17, 18, 53, 113], "person": [14, 59, 92, 95, 138, 149, 153, 157, 159, 162, 164, 167, 186, 188, 191], "screen": [14, 92, 99], "feedback": [14, 25, 92, 94, 149, 158, 162, 164, 165, 166, 168, 186], "bundl": 14, "huge": [14, 39, 62, 64, 92, 95, 107, 117, 118, 125, 126, 127, 134, 135], "alphabet": 15, "github": [15, 17, 18, 41, 105], "interact": [16, 22, 39, 41, 71, 74, 77, 88, 96, 106, 113, 114, 130, 145, 149, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 178, 184, 186], "ec2": [16, 38, 86, 191], "instal": [16, 17, 19, 38, 41, 94, 124, 127, 149, 191], "cuda": [16, 19, 38, 39, 40, 41, 44, 62, 63, 91], "remot": [16, 18, 41, 183, 186], "unus": [16, 105, 155], "googl": [16, 20, 41, 62, 92, 162, 186, 191], "colab": [16, 191], "submit": [16, 52, 112], "propos": [16, 21, 23, 24, 25, 27, 29, 30, 58, 63, 68, 69, 70, 74, 92, 95, 114, 116, 117, 120, 126, 132, 134, 137, 139, 143, 145, 147, 157, 161, 163, 167, 175, 177, 178, 180, 181, 186], "api": [16, 23, 28, 29, 32, 42, 44, 45, 53, 54, 59, 61, 63, 87, 88, 92, 96, 98, 99, 104, 105, 106, 107, 110, 114, 115, 137, 149, 154, 170, 171, 173, 175, 182, 191], "tutori": [17, 88, 149, 154, 156, 186], "yy": 17, "cd": [17, 18, 91], "interfac": [17, 23, 41, 44, 62, 85, 88, 92, 96, 106, 144, 155, 172], "webpag": [17, 53, 54, 92, 149], "suffix": [17, 132], "ipynb": [17, 18], "temporari": [17, 175], "mode": [17, 20, 25, 29, 41, 42, 59, 63, 76, 78, 88, 89, 92, 98, 107, 110, 143, 164, 165, 168, 186], "hello": [17, 22], "demonstr": [17, 21, 25, 28, 30, 36, 42, 50, 52, 53, 55, 58, 70, 72, 76, 77, 78, 82, 83, 92, 111, 113, 116, 118, 120, 121, 123, 126, 127, 128, 131, 149, 150, 155, 156, 157, 159, 168, 169, 170, 177, 181, 185], "menu": 17, "shortcut": [17, 69], "ctrl": 17, "kernel": [17, 22, 24, 27, 28, 30, 33, 40, 41, 44, 45, 49, 61, 62, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 81, 82, 92, 101, 104, 108, 111, 114, 123, 161, 186], "restart": [17, 46, 186], "latter": [17, 25, 39, 41, 42, 47, 50, 63, 65, 66, 69, 70, 71, 74, 83, 89, 94, 104, 107, 126, 128, 140, 144, 146, 148, 156, 175], "faster": [17, 19, 22, 39, 41, 42, 52, 62, 63, 69, 71, 88, 89, 103, 104, 108, 131, 141, 144, 150, 160, 173, 175, 182, 186], "nativ": [17, 66, 149], "auxiliari": [17, 19, 44, 51, 70, 93, 99, 100, 110, 138, 145, 150], "mostli": [17, 19, 62, 63, 70, 77, 79, 85, 92, 110, 148, 170], "confus": [17, 78, 92, 94, 103, 150, 153], "notedown": 17, "plugin": 17, "pip": [17, 38, 91, 124, 127], "uninstal": [17, 38], "notebookapp": 17, "contents_manager_class": 17, "notedowncontentsmanag": 17, "config": [17, 38, 85, 86, 90], "jupyter_notebook_config": 17, "parti": [17, 25], "putti": 17, "myserv": 17, "executetim": 17, "jupyter_contrib_nbextens": 17, "contrib": 17, "nbextens": 17, "execute_tim": 17, "1024": [17, 66, 77, 85, 86, 115, 126, 128, 158, 165, 171, 173, 175, 182, 183], "resourc": [18, 24, 40, 41, 68, 85, 86, 88, 90, 92, 108, 117, 121, 149, 153, 159], "intens": [18, 38, 42, 44, 77, 86, 92, 95, 114, 153, 166], "authent": 18, "encourag": [18, 41, 92, 103, 126, 148, 149, 154, 188], "alert": [18, 92], "vari": [18, 27, 34, 47, 49, 50, 54, 55, 57, 60, 63, 67, 78, 79, 80, 92, 95, 101, 104, 108, 122, 124, 133, 140, 150, 157, 158, 160, 161, 163, 165, 168, 172, 177, 178, 179, 184, 185], "2xlarg": 18, "tesla": [18, 19, 92], "cpu": [18, 19, 23, 29, 38, 39, 40, 42, 43, 44, 45, 46, 49, 53, 54, 60, 62, 82, 85, 88, 89, 91, 103, 106, 115, 135, 144, 155, 186], "clone": [18, 37, 74, 153], "finish": [18, 39, 88, 89, 90], "charg": [18, 92], "regularli": [18, 178], "pull": [18, 46, 94], "reset": [18, 20, 90, 150, 174, 175, 189], "host": [18, 41, 46, 92, 98, 113, 155, 164], "hardwar": [19, 30, 32, 38, 43, 46, 64, 72, 92, 106, 115, 149, 191], "acceler": [19, 30, 40, 43, 62, 63, 66, 69, 76, 82, 89, 98, 103, 107, 116, 121, 122, 139, 145, 155, 167, 186, 188], "cheaper": [19, 66, 86, 138, 186], "engin": [19, 27, 38, 46, 62, 64, 70, 72, 74, 75, 83, 92, 94, 98, 99, 114, 117, 144, 149, 154, 159, 160, 161, 162, 164, 183], "workstat": 19, "heat": [19, 28, 94], "cool": [19, 143], "escal": 19, "offic": [19, 57, 94], "deploy": [19, 37, 42, 94, 157], "purchas": [19, 50, 92, 156, 167, 187], "thread": [19, 39, 40, 41, 42], "lock": [19, 38, 41], "gil": 19, "clock": [19, 41, 62, 85, 88, 89, 90, 138, 144], "ghz": [19, 41], "aggreg": [19, 22, 23, 25, 27, 40, 41, 44, 45, 46, 63, 64, 68, 69, 73, 76, 77, 92, 103, 104, 138, 139, 145, 147, 157, 186], "speed": [19, 26, 29, 38, 40, 41, 42, 46, 62, 66, 68, 70, 74, 86, 88, 90, 94, 100, 102, 104, 105, 115, 133, 144, 145, 148, 149, 153, 169, 171, 173, 183, 186], "dissip": 19, "chassi": 19, "guidelin": [19, 64], "suppli": [19, 35, 37, 41, 144, 155, 182, 183], "budget": [19, 25, 41, 62, 86, 90, 92], "350w": 19, "devic": [19, 20, 22, 28, 29, 32, 37, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 56, 60, 62, 63, 68, 74, 82, 83, 94, 101, 107, 120, 121, 123, 124, 128, 135, 142, 143, 144, 158, 159, 160, 161, 163, 165, 168, 173, 175, 177, 183, 186], "peak": [19, 40, 41, 62, 77, 92, 103], "graphic": [19, 38, 41, 62, 92, 151, 175], "energi": [19, 62, 98, 105, 186], "unstabl": [19, 99, 116, 143, 178, 183], "connector": 19, "extra": [19, 31, 39, 41, 75, 89, 117, 121, 145, 172], "invest": [19, 72, 94, 157], "fewer": [19, 25, 55, 57, 60, 64, 68, 73, 74, 77, 78, 79, 90, 93, 95, 98, 99, 101, 104, 111, 120, 126, 176, 180, 189], "fan": [19, 33, 92, 186], "air": [19, 117, 187], "intak": 19, "thick": [19, 79], "thermal": 19, "throttl": 19, "pcie": [19, 41, 46], "move": [19, 23, 31, 32, 36, 38, 40, 41, 46, 47, 54, 55, 60, 63, 69, 70, 74, 75, 76, 77, 78, 79, 80, 82, 92, 103, 114, 116, 138, 139, 141, 143, 144, 147, 150, 151, 165, 179, 180, 183, 187, 188, 189, 190], "bandwidth": [19, 22, 40, 41, 44, 46, 62, 66, 144], "lane": [19, 41, 46, 149], "mount": [19, 56], "motherboard": 19, "oppos": [19, 94, 98], "downgrad": 19, "partli": [19, 67, 71, 92, 105], "consumpt": [19, 39, 62, 65, 94], "game": [19, 30, 62, 77, 83, 92, 94, 111, 149, 186, 188, 189], "150": [19, 51, 186], "200w": 19, "lucki": [19, 62, 69, 94, 101, 141], "dram": [19, 41], "ssd": [19, 41, 60, 186], "600w": 19, "1000w": 19, "mainboard": 19, "x16": [19, 41], "60mm": 19, "amd": [19, 41, 62], "threadripp": [19, 41], "expens": [19, 22, 41, 62, 68, 74, 78, 86, 88, 90, 92, 94, 101, 129, 130, 138, 141, 144, 148, 149, 150, 166, 181], "plx": 19, "multiplex": [19, 46], "1600": 19, "2000w": 19, "outlet": 19, "loud": 19, "desk": 19, "tb": [19, 41], "nvme": [19, 41], "bunch": [19, 20, 67], "raid": 19, "dedic": [19, 41, 62, 153, 175], "1600w": 19, "dual": [19, 62, 76], "socket": [19, 39, 41, 62, 144], "ecc": 19, "gbe": [19, 46], "airflow": 19, "wire": [19, 41, 67, 98, 103], "placement": [19, 186], "consum": [19, 38, 41, 46, 62, 68, 86, 88, 92, 108, 111, 144, 150], "rtx": [19, 41], "2080": [19, 41], "insuffici": [19, 41, 92, 101, 107, 111, 119, 141, 160], "clearanc": 19, "cabl": 19, "har": [19, 38], "coauthor": 19, "painfulli": 19, "manufactur": [19, 41, 157], "buyer": 19, "gtx": [19, 62], "enterpris": [19, 41], "passiv": [19, 94], "preconfigur": 19, "supermicro": 19, "asu": 19, "vendor": [19, 39, 41, 62], "releas": [19, 25, 32, 42, 62, 91, 92, 96], "pascal": [19, 49, 52], "2019": [19, 22, 24, 25, 30, 58, 64, 67, 85, 86, 92, 104, 117, 132, 139, 167, 186], "mainstream": 19, "widespread": [19, 69, 104, 159, 176], "batch": [19, 20, 24, 28, 29, 30, 38, 44, 45, 46, 47, 51, 53, 54, 57, 59, 60, 62, 64, 65, 66, 67, 69, 72, 74, 75, 76, 78, 82, 85, 86, 88, 89, 92, 93, 96, 99, 100, 103, 105, 106, 107, 109, 110, 114, 119, 120, 122, 123, 124, 126, 127, 128, 133, 135, 139, 144, 145, 150, 175, 177, 181, 182, 183, 186, 189, 191], "dure": [19, 25, 29, 35, 36, 41, 42, 46, 47, 50, 51, 53, 54, 56, 59, 60, 68, 69, 72, 86, 88, 89, 92, 93, 94, 100, 103, 109, 110, 116, 117, 121, 123, 124, 126, 127, 128, 133, 138, 140, 141, 143, 144, 149, 158, 165, 167, 173, 175, 177, 178, 181, 183, 189], "bigger": [19, 60, 62, 103, 111, 114, 121, 186], "hbm2": [19, 41], "gddr6": [19, 41], "ddr": 19, "tensorcor": 19, "gui": 19, "ram": [19, 41, 68, 96, 114, 186], "safeti": [19, 166], "900": 19, "wikipedia": [19, 21, 25, 126, 127, 131, 144, 180], "titan": [19, 41], "premium": 19, "newer": 19, "980": 19, "1080": 19, "superior": [19, 25, 30, 42, 64, 92, 158], "int4": [19, 41], "gflop": 19, "affin": [19, 63, 98, 103, 114], "disproportion": [19, 178], "compat": [19, 20, 27, 28, 63, 101, 111, 137, 155], "pytorchmxnetjaxtensorflow": [20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 91, 93, 96, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 149, 150, 151, 153, 154, 155, 156, 157, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "inspect": [20, 21, 24, 36, 74, 96, 107, 149, 155, 156, 164, 185], "jax": [20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 91, 92, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 149, 150, 151, 153, 154, 155, 156, 157, 170, 171, 172, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "hyperparamet": [20, 21, 23, 29, 30, 36, 49, 50, 53, 54, 56, 60, 61, 63, 64, 66, 67, 69, 79, 80, 81, 82, 83, 88, 89, 94, 95, 100, 101, 103, 104, 105, 106, 107, 108, 109, 113, 115, 119, 120, 121, 122, 123, 124, 125, 126, 133, 135, 142, 144, 145, 160, 168, 169, 171, 173, 175, 177, 180, 183, 186, 191], "add_to_class": [20, 26, 34, 38, 63, 64, 65, 66, 69, 74, 85, 90, 93, 96, 99, 100, 104, 105, 106, 107, 110, 113, 115, 170, 171, 173, 175, 176, 177, 180, 183, 184, 185], "save_hyperparamet": [20, 30, 38, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 90, 96, 99, 100, 104, 105, 106, 107, 108, 110, 113, 115, 170, 171, 173, 175, 176, 177, 180, 182, 183, 184], "self": [20, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 37, 38, 42, 48, 52, 53, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 78, 82, 85, 86, 90, 93, 96, 99, 100, 104, 105, 106, 107, 108, 110, 113, 115, 119, 120, 121, 123, 124, 126, 127, 128, 130, 131, 133, 135, 143, 144, 149, 158, 159, 160, 161, 163, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 182, 183, 184, 185, 186, 187, 191], "attribut": [20, 24, 34, 35, 36, 51, 63, 74, 88, 92, 106, 110, 113, 115, 150, 153, 154, 155, 157, 179], "frame": [20, 58, 86, 92, 95, 158, 159], "currentfram": 20, "f_back": 20, "local_var": 20, "getargvalu": 20, "hparam": [20, 110], "startswith": 20, "setattr": [20, 38, 50, 60, 106, 108, 123, 124], "progressboard": [20, 85, 106], "every_n": [20, 85, 106], "namedtupl": 20, "hasattr": [20, 106, 151, 185], "raw_point": 20, "ordereddict": [20, 35], "plt_line": 20, "gca": [20, 144, 146, 151, 157], "set_xlabel": [20, 21, 27, 151, 157], "set_ylabel": [20, 27, 151, 157], "set_xscal": [20, 144, 151], "xscale": [20, 106, 151, 185], "set_yscal": [20, 151], "yscale": [20, 106, 108, 113, 151, 185], "clear_output": 20, "wait": [20, 34, 38, 39, 40, 41, 88, 89, 155], "frozenlak": [20, 189, 190], "enviro": [20, 190], "frozen_lak": 20, "www": [20, 53, 54, 113, 186], "gymlibrari": 20, "dev": 20, "toy_text": 20, "env": [20, 189], "adpat": 20, "site": [20, 92, 94, 159, 162, 164], "rl": [20, 78, 113, 148, 187], "bootcamp": 20, "gym": [20, 189, 190], "v1": [20, 117, 127, 145, 189, 190], "is_slipperi": 20, "action_spac": [20, 189], "np_random": 20, "env_info": [20, 189, 190], "desc": [20, 189, 190], "2d": [20, 22, 28, 72, 82, 141, 145, 185, 189, 190], "num_stat": [20, 189, 190], "ob": [20, 94], "num_act": [20, 189, 190], "na": [20, 64, 86, 113, 156], "nextstat": [20, 190], "reward": [20, 92, 94, 104, 157, 188, 189, 190], "tupl": [20, 27, 30, 34, 47, 64, 65, 66, 69, 70, 92, 93, 105, 107, 132, 153, 166, 185, 188, 189], "trans_prob_idx": [20, 190], "nextstate_idx": [20, 190], "reward_idx": [20, 190], "done_idx": 20, "mdp": [20, 187, 189, 190, 191], "a0": 20, "a1": 20, "pxrd": [20, 190], "next1": [20, 190], "r1": [20, 190], "d1": [20, 190], "next2": [20, 190], "r2": [20, 190], "d2": [20, 190], "make_env": [20, 189, 190], "valueerror": 20, "show_value_function_progress": [20, 190], "env_desc": [20, 189, 190], "polici": [20, 92, 108, 122, 142, 149, 187, 189], "num_it": [20, 189, 190], "bone": [20, 99, 157], "set_xtick": 20, "set_ytick": 20, "linewidth": [20, 48, 78, 80], "tick_param": 20, "action2dxdi": 20, "va": [20, 23, 29, 47, 177], "fontweight": 20, "bold": [20, 125, 149, 153], "elif": [20, 47, 60, 76, 151], "head_width": 20, "head_length": 20, "set_titl": [20, 27], "fontsiz": [20, 47, 78, 80], "tight_layout": 20, "show_q_function_progress": [20, 189], "v_all": 20, "pi_al": 20, "num_iters_al": 20, "vis_indx": 20, "trainer": [20, 23, 29, 30, 38, 45, 49, 50, 51, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 82, 83, 85, 86, 88, 89, 93, 99, 100, 104, 105, 106, 108, 110, 113, 115, 120, 121, 123, 124, 128, 135, 137, 138, 139, 141, 143, 144, 145, 147, 158, 160, 161, 163, 165, 168, 171, 173, 175, 177, 182, 183, 184], "deprec": 20, "load_arrai": [20, 83, 122, 144], "data_arrai": 20, "batch_siz": [20, 22, 23, 26, 28, 29, 30, 44, 45, 47, 49, 50, 51, 53, 54, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 82, 83, 85, 86, 88, 89, 90, 96, 99, 100, 105, 107, 108, 110, 113, 115, 119, 120, 121, 122, 123, 124, 126, 127, 128, 133, 135, 137, 138, 139, 143, 144, 145, 147, 158, 160, 161, 163, 164, 165, 168, 171, 173, 175, 176, 177, 180, 182, 183, 184], "is_train": [20, 29, 51, 57, 59, 63, 110, 119, 122, 144, 158], "tensordataset": [20, 107], "dataload": [20, 50, 51, 53, 54, 57, 59, 82, 96, 105, 107, 119, 121, 127, 133, 158, 159, 160, 161, 164, 165, 168], "synthetic_data": 20, "num_exampl": [20, 82, 83, 107, 143], "xw": [20, 105], "sgd": [20, 44, 45, 49, 50, 53, 54, 60, 86, 93, 103, 104, 105, 108, 138, 142, 143, 144, 145, 148], "param": [20, 22, 23, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 44, 45, 50, 54, 56, 63, 72, 74, 93, 99, 100, 103, 104, 105, 106, 108, 110, 113, 115, 121, 124, 126, 137, 138, 139, 144, 145, 147, 171, 173, 175, 177, 183, 184], "minibatch": [20, 22, 23, 25, 29, 38, 39, 40, 44, 45, 51, 57, 59, 60, 63, 74, 92, 93, 94, 97, 98, 100, 104, 105, 107, 108, 109, 114, 116, 119, 120, 121, 122, 127, 128, 129, 130, 135, 138, 139, 142, 143, 145, 146, 170, 171, 173, 176, 177, 180, 181, 182, 183, 186, 191], "stochast": [20, 21, 44, 62, 64, 74, 76, 78, 86, 92, 93, 105, 108, 109, 110, 111, 116, 129, 134, 138, 139, 140, 141, 142, 143, 145, 146, 149, 161, 163, 181, 183, 186, 187, 191], "get_dataloader_work": [20, 51, 59, 82, 119, 121, 127, 133, 158, 160, 161, 165, 168], "load_data_fashion_mnist": [20, 44, 45, 143], "resiz": [20, 30, 50, 53, 54, 56, 58, 60, 62, 64, 65, 66, 68, 69, 70, 82, 96], "insert": [20, 29, 39, 63, 90, 115, 126, 127, 128, 132, 144, 176], "num_work": [20, 51, 59, 82, 96, 106, 119, 121, 127, 133, 158, 160, 161, 165, 168], "evaluate_accuracy_gpu": [20, 44, 45, 51, 53, 143], "net": [20, 31, 33, 34, 35, 36, 37, 38, 42, 45, 49, 50, 51, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 83, 99, 104, 106, 108, 110, 115, 120, 121, 123, 124, 128, 135, 143, 144, 158, 160, 161, 163, 165, 168, 178, 186], "data_it": [20, 45, 54, 82, 83, 105, 133, 135, 137, 138, 139, 144, 145, 147], "isinst": [20, 30, 38, 47, 51, 93, 151, 163, 183, 185], "eval": [20, 22, 29, 30, 37, 60, 78, 86, 105, 120], "accumul": [20, 41, 44, 45, 46, 51, 53, 54, 60, 82, 83, 92, 128, 135, 138, 143, 144, 145, 147, 163, 165, 184], "bert": [20, 24, 51, 118, 130, 186, 191], "tune": [20, 21, 24, 27, 41, 49, 51, 52, 53, 56, 62, 66, 69, 80, 81, 85, 86, 88, 89, 92, 94, 95, 103, 111, 113, 118, 123, 124, 126, 128, 135, 142, 170, 171, 186, 191], "numel": [20, 47, 51, 54, 56, 60, 135, 153, 155], "train_ch6": [20, 143], "train_it": [20, 44, 45, 49, 50, 51, 53, 54, 57, 59, 60, 119, 120, 121, 122, 123, 124, 127, 128, 143, 158, 160, 161, 163, 164, 165, 168], "test_it": [20, 44, 45, 49, 50, 51, 53, 54, 59, 119, 120, 121, 122, 123, 124, 143, 158, 160, 161, 163, 164, 165, 168], "num_epoch": [20, 44, 45, 49, 50, 51, 53, 54, 56, 60, 82, 83, 120, 121, 123, 124, 135, 143, 144, 145, 158, 160, 161, 163, 165, 168], "init_weight": [20, 45, 123, 124, 135, 144, 173, 175], "conv2d": [20, 44, 45, 49, 53, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 82, 143, 168], "xavier_uniform_": [20, 33, 50, 74, 123, 124, 135, 177], "crossentropyloss": [20, 44, 45, 50, 51, 53, 54, 60, 120, 121, 123, 124, 126, 128, 143], "anim": [20, 44, 45, 51, 53, 54, 56, 60, 62, 72, 82, 83, 92, 94, 106, 128, 135, 143, 144, 145, 163, 165], "epoch": [20, 44, 45, 50, 51, 53, 54, 56, 60, 62, 72, 74, 82, 83, 86, 88, 89, 90, 95, 99, 100, 104, 105, 106, 110, 111, 115, 121, 124, 128, 135, 141, 143, 144, 163, 164, 165, 180, 183, 184], "acc": [20, 44, 45, 51, 53, 93, 143], "timer": [20, 42, 44, 45, 51, 53, 54, 60, 82, 83, 128, 135, 144, 163, 165], "num_batch": [20, 51, 53, 54, 135], "zero_grad": [20, 45, 51, 54, 56, 60, 72, 78, 83, 105, 128, 135, 143, 144], "train_l": [20, 163], "train_acc": [20, 143], "test_acc": [20, 51, 143], "1f": [20, 44, 45, 51, 53, 54, 60, 82, 83, 128, 135, 163, 165], "sec": [20, 42, 44, 45, 51, 53, 54, 60, 82, 83, 96, 103, 128, 135, 144, 163, 165], "img": [20, 47, 48, 49, 51, 55, 56, 57, 59, 60, 82, 96], "num_row": [20, 27, 51, 82, 96], "num_col": [20, 27, 51, 82, 96], "detach": [20, 21, 27, 47, 49, 54, 56, 82, 83, 85, 86, 88, 89, 106, 113, 114, 116, 145, 147, 152, 178, 184], "get_xaxi": 20, "set_vis": 20, "get_yaxi": 20, "linreg": [20, 144], "squared_loss": [20, 144], "get_fashion_mnist_label": 20, "text_label": [20, 96, 100], "pullov": [20, 96], "dress": [20, 96], "coat": [20, 74, 96], "sandal": [20, 96], "sneaker": [20, 94, 96], "bag": [20, 62, 96, 111, 125, 130, 132, 185], "ankl": [20, 96], "boot": [20, 96], "__init__": [20, 22, 23, 26, 28, 29, 30, 31, 35, 37, 38, 42, 53, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 78, 82, 85, 90, 96, 99, 100, 104, 105, 106, 107, 108, 110, 113, 115, 119, 120, 121, 123, 124, 126, 127, 131, 133, 135, 143, 144, 158, 159, 160, 161, 163, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 182, 183, 184, 185], "fmt": [20, 141, 151], "nrow": [20, 82, 83, 96], "ncol": [20, 56, 96], "increment": [20, 39, 47, 103, 162, 186], "config_ax": 20, "set_ax": [20, 151], "__len__": [20, 57, 59, 107, 119, 121, 127, 131, 133, 151, 159, 165, 168, 185], "cla": [20, 82, 83, 151], "arg": [20, 23, 35, 42, 106, 172, 177], "__getitem__": [20, 57, 59, 119, 121, 127, 131, 133, 159, 165, 168, 185], "idx": [20, 35, 57, 59, 60, 113, 119, 121, 127, 131, 133, 159, 163, 165, 168, 176, 180, 185], "cmp": 20, "hashlib": [20, 149], "tarfil": [20, 149], "zipfil": [20, 149], "sha1_hash": [20, 113], "filepath": [20, 113], "data_hub": [20, 50, 53, 54, 57, 59, 82, 119, 121, 122, 127, 131, 133, 144, 159, 164], "makedir": [20, 53, 156], "exist_ok": [20, 53, 156], "fname": [20, 53, 59, 185], "join": [20, 23, 29, 50, 53, 54, 57, 59, 119, 121, 122, 127, 131, 132, 133, 156, 159, 160, 161, 164, 176, 177, 183, 185], "cach": [20, 40, 62, 66, 82, 103, 113, 133, 142, 178], "sha1": 20, "rb": [20, 122], "1048576": 20, "hexdigest": 20, "stream": [20, 40, 41, 62, 98, 101, 107, 163, 184], "wb": 20, "filenam": [20, 53, 113], "tar": [20, 59, 113, 122], "base_dir": 20, "dirnam": 20, "ext": 20, "splitext": 20, "assert": [20, 44, 63, 71, 106, 110, 133, 136, 183], "gz": [20, 122], "fp": 20, "extractal": 20, "download_extract": [20, 49, 50, 53, 54, 57, 59, 82, 119, 121, 122, 127, 131, 133, 159, 160, 161, 164], "data_dir": [20, 50, 53, 54, 57, 82, 119, 121, 122, 127, 131, 133, 159, 160, 161, 164], "token": [20, 22, 23, 24, 25, 27, 28, 29, 30, 41, 53, 98, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133, 135, 169, 170, 171, 172, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 191], "char": [20, 176], "evaluate_loss": [20, 54, 144], "grad_clip": 20, "clip": [20, 25, 47, 56, 62, 140, 171, 174, 175, 178, 179, 186], "arraydataset": [20, 107, 133, 164, 165], "sy": [20, 149], "platform": [20, 92, 106, 113, 122, 149, 167, 186], "win": [20, 83, 92, 94, 98, 113, 157, 163, 187], "transform_first": [20, 50, 51, 53, 54, 82, 96], "queri": [20, 21, 22, 23, 24, 26, 28, 29, 38, 45, 76, 78, 80, 90, 92, 107, 117, 154, 191], "collect_param": [20, 34, 36, 38, 45, 49, 50, 51, 53, 54, 56, 60, 82, 83, 93, 100, 104, 108, 120, 121, 123, 124, 128, 135, 143, 144, 158, 160, 161, 163, 165, 168], "list_ctx": [20, 45], "as_in_ctx": [20, 28, 38, 49, 53, 54, 56, 60, 82, 135, 143], "force_reinit": [20, 33, 45, 56, 82, 83, 135, 143, 158, 163, 165, 168], "ctx": [20, 28, 29, 31, 38, 40, 44, 45, 47, 49, 51, 53, 54, 56, 60, 63, 82, 83, 120, 121, 123, 124, 126, 128, 135, 143, 158, 160, 161, 163, 165, 168, 173, 175, 182, 183], "xavier": [20, 23, 33, 49, 50, 51, 53, 54, 60, 62, 64, 65, 66, 68, 69, 70, 74, 120, 123, 124, 128, 143, 160, 161, 177], "softmaxcrossentropyloss": [20, 44, 45, 49, 50, 51, 53, 54, 60, 99, 120, 121, 123, 124, 126, 143], "learning_r": [20, 45, 49, 50, 51, 53, 54, 56, 60, 82, 83, 85, 86, 88, 89, 90, 93, 104, 108, 120, 121, 123, 124, 128, 135, 137, 138, 139, 143, 144, 145, 147, 158, 160, 161, 163, 165, 168, 177], "train_epoch_ch3": 20, "evaluate_accuraci": 20, "asarrai": [20, 29, 110, 113, 184], "from_tensor_slic": [20, 96, 107], "buffer_s": [20, 82, 107], "stddev": [20, 31, 33, 82, 83, 104, 105, 144], "resize_fn": [20, 96], "resize_with_pad": [20, 96], "traincallback": [20, 143], "callback": [20, 88, 89, 143], "visiual": 20, "device_nam": [20, 143], "on_epoch_begin": 20, "on_epoch_end": 20, "verbos": [20, 143], "return_dict": 20, "cardin": [20, 136, 144], "avg": [20, 44, 45, 68, 76, 144], "net_fn": [20, 143], "_device_nam": [20, 82, 143], "strategi": [20, 21, 23, 27, 30, 38, 41, 42, 44, 46, 63, 64, 66, 68, 69, 71, 92, 94, 103, 111, 115, 138, 140, 141, 143, 144, 148, 165, 169, 177, 180, 183, 184], "onedevicestrategi": [20, 143], "sparsecategoricalcrossentropi": [20, 99, 143], "compil": [20, 41, 43, 63, 94, 143, 150, 155, 173, 175, 186, 191], "new_grad": [20, 183], "indexedslic": [20, 183], "convert_to_tensor": [20, 29, 36, 183], "fra": [20, 23, 29, 176, 177], "eng": [20, 23, 29, 176, 177], "data_url": [20, 50, 53, 54, 57, 59, 82, 113, 121, 122, 131, 133, 144, 159, 176, 185], "94646ad1522d915e7b0f9296181140edcf86a4f5": [20, 176], "read_data_nmt": 20, "french": [20, 23, 24, 25, 29, 92, 132, 172, 176, 177], "txt": [20, 59, 91, 119, 131, 133, 176, 185], "utf": [20, 122, 176], "preprocess_nmt": 20, "preprocess": [20, 52, 54, 63, 82, 92, 96, 101, 106, 112, 114, 118, 144, 152, 164, 174, 185, 191], "no_spac": [20, 176], "prev_char": [20, 176], "uppercas": [20, 127, 176], "lowercas": [20, 127, 132, 136, 153, 176], "u202f": [20, 176], "xa0": [20, 176], "punctuat": [20, 127, 176, 185], "tokenize_nmt": 20, "truncate_pad": [20, 119, 122], "num_step": [20, 23, 28, 29, 30, 119, 120, 122, 128, 171, 173, 175, 176, 177, 180, 182, 183], "padding_token": 20, "truncat": [20, 33, 58, 60, 121, 122, 176, 180, 186], "pad": [20, 22, 23, 28, 29, 30, 45, 49, 52, 53, 57, 58, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 82, 99, 119, 121, 122, 127, 133, 135, 143, 172, 176, 177, 184, 186, 191], "build_array_nmt": 20, "vocab": [20, 119, 120, 121, 122, 123, 124, 127, 128, 133, 135, 171, 173, 175, 176, 180, 182, 183, 185], "translat": [20, 21, 22, 23, 24, 25, 27, 29, 30, 63, 64, 68, 71, 76, 79, 80, 92, 94, 98, 103, 111, 113, 117, 118, 119, 120, 122, 130, 169, 172, 174, 179, 180, 184, 186, 191], "eo": [20, 23, 25, 29, 169, 176, 177], "valid_len": [20, 22, 26, 28, 29, 30, 121, 126, 127, 128, 176], "load_data_nmt": 20, "src_vocab": [20, 23, 29, 176, 177], "min_freq": [20, 119, 122, 127, 133, 176, 185], "reserved_token": [20, 119, 122, 127, 185], "bo": [20, 25, 176, 177], "tgt_vocab": [20, 23, 29, 176, 177], "src_arrai": [20, 176], "src_valid_len": [20, 176, 177], "tgt_arrai": [20, 176], "tgt_valid_len": 20, "sequence_mask": [20, 22], "mask": [20, 25, 29, 34, 47, 52, 60, 92, 110, 117, 121, 128, 133, 135, 158, 164, 170, 174, 186], "maxlen": [20, 22], "maskedsoftmaxceloss": 20, "vocab_s": [20, 23, 29, 123, 124, 126, 128, 171, 173, 175, 177, 182, 183], "ones_lik": [20, 114, 116], "unweighted_loss": 20, "super": [20, 22, 23, 26, 28, 29, 30, 31, 35, 37, 42, 53, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 78, 82, 96, 99, 100, 104, 105, 106, 107, 108, 110, 113, 115, 116, 120, 121, 123, 124, 126, 135, 158, 160, 161, 163, 165, 166, 168, 170, 171, 172, 173, 175, 176, 177, 180, 182, 183], "permut": [20, 23, 25, 26, 29, 49, 56, 57, 59, 60, 73, 82, 98, 107, 116, 120, 123, 135, 144, 186], "weighted_loss": 20, "train_seq2seq": 20, "xavier_init_weight": 20, "gru": [20, 23, 170, 171, 174, 175, 177, 182, 191], "_flat_weights_nam": [20, 124, 177], "_paramet": [20, 124, 177], "adam": [20, 51, 56, 63, 78, 82, 83, 120, 121, 123, 124, 128, 135, 142, 149, 158, 160, 161, 163, 165, 168, 177, 186, 191], "x_valid_len": 20, "y_valid_len": 20, "dec_input": 20, "teacher": [20, 174], "num_token": [20, 133], "predict_seq2seq": 20, "src_sentenc": [20, 176], "save_attention_weight": [20, 177], "src_token": 20, "enc_valid_len": [20, 23, 29], "enc_x": [20, 172], "enc_output": [20, 23, 29, 177], "dec_stat": [20, 172, 177], "init_st": [20, 23, 29, 172, 177], "dec_x": [20, 172], "output_seq": 20, "attention_weight_seq": 20, "attention_weight": [20, 22, 23, 26, 27, 29, 177], "to_token": [20, 23, 29, 133, 135, 176, 177, 185], "softmaxceloss": [20, 128], "label_one_hot": 20, "one_hot": [20, 100, 182, 183], "concat": [20, 23, 29, 76, 82, 113, 155, 170, 177, 181], "tape": [20, 83, 105, 150], "trainable_vari": [20, 82, 83, 105, 144], "apply_gradi": [20, 83, 105, 144], "1964": [21, 27, 95, 145, 150, 186], "detour": [21, 65], "reli": [21, 22, 24, 27, 29, 32, 35, 36, 51, 62, 63, 64, 69, 83, 92, 94, 95, 96, 98, 101, 103, 104, 105, 108, 109, 110, 111, 115, 118, 134, 143, 149, 177, 182, 183], "boxcar": 21, "epanechikov": 21, "parzen": [21, 186], "1957": [21, 186, 188, 190], "heurist": [21, 27, 62, 70, 72, 92, 101, 108, 110, 111, 113, 116, 143, 156, 174, 183, 186], "regardless": [21, 22, 27, 39, 46, 71, 73, 76, 77, 80, 93, 95, 126], "alik": [21, 77], "_j": [21, 22, 27, 56, 98, 99, 120, 129, 134, 153, 157, 161], "multiclass": [21, 64, 92, 93, 95, 113], "consist": [21, 24, 25, 27, 30, 35, 39, 41, 47, 50, 53, 54, 56, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 82, 86, 89, 92, 93, 94, 96, 98, 99, 100, 101, 103, 106, 107, 110, 111, 112, 113, 115, 117, 120, 121, 122, 124, 126, 133, 134, 141, 148, 153, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 168, 171, 172, 175, 176, 177, 178, 179, 183, 184, 185, 186], "mack": [21, 186], "silverman": [21, 186], "1982": [21, 77, 186], "flax": [21, 22, 23, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 91, 99, 100, 104, 105, 106, 107, 110, 115, 149, 170, 171, 172, 173, 175, 177, 182, 183], "linen": [21, 22, 23, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 99, 100, 104, 105, 106, 110, 115, 149, 171, 172, 173, 175, 177, 182, 183], "jnp": [21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 76, 93, 96, 99, 100, 103, 104, 105, 106, 107, 108, 110, 113, 114, 115, 116, 149, 150, 153, 155, 156, 157, 170, 171, 173, 175, 176, 177, 180, 181, 182, 183, 184, 185], "sharei": [21, 27], "attend": [21, 23, 24, 25, 26, 28, 29, 30, 186], "indiscrimin": 21, "x_train": 21, "y_train": 21, "x_val": 21, "y_val": 21, "get_kei": [21, 22, 23, 26, 28, 29, 30, 31, 33, 34, 35, 36, 65, 69, 74, 106, 110, 116, 177, 181, 183, 184], "diagnost": [21, 36, 59, 92], "covari": [21, 63, 78, 79, 80, 81, 83, 92, 103, 136, 157, 166, 186], "attention_w": [21, 23, 29], "nadaraya_watson": 21, "pcm": [21, 27], "colorbar": [21, 27], "nontrivi": [21, 44, 46, 62, 92, 94, 98, 104, 143, 149, 157, 171, 175, 180], "workabl": 21, "trivial": [21, 27, 71, 75, 78, 88, 89, 94, 104, 117, 126], "unrealist": [21, 141], "affect": [21, 29, 30, 34, 42, 43, 46, 47, 55, 56, 62, 64, 66, 72, 79, 80, 92, 94, 96, 115, 116, 119, 133, 142, 143, 157, 169, 174, 176, 178, 187, 190], "gaussian_with_width": 21, "trick": [21, 34, 35, 62, 66, 69, 92, 98, 99, 108, 111, 116, 120, 140, 157], "norelli": [21, 186], "2022": [21, 25, 56, 62, 63, 64, 67, 70, 85, 86, 88, 92, 186], "nearest": [21, 111, 131, 167], "neighbor": [21, 46, 56, 106, 111, 131, 167], "interpol": [21, 49, 58, 111, 184, 186], "modal": [21, 25, 92, 179], "astut": [21, 108, 157, 184], "precursor": [21, 62, 64], "craft": [21, 47, 62, 94, 117, 118, 126, 160], "embark": 21, "lie": [21, 68, 85, 92, 95, 114, 157, 173], "sphere": 21, "gone": [22, 83], "pool": [22, 23, 24, 26, 27, 28, 29, 44, 45, 49, 50, 51, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 73, 74, 88, 117, 118, 121, 168, 186, 191], "disappear": [22, 78, 79, 94, 157], "vaswani": [22, 23, 24, 26, 28, 29, 69, 92, 186], "remaind": [22, 40, 47, 70, 77, 92, 94, 110, 176, 189, 190], "deploi": [22, 37, 38, 42, 63, 67, 73, 92, 94], "necessit": [22, 41, 63], "carri": [22, 27, 29, 31, 41, 46, 63, 64, 66, 69, 77, 92, 109, 113, 129, 138, 141, 173, 175, 185], "blank": [22, 92, 170], "cheat": [22, 53, 126, 189], "ever": [22, 64, 66, 69, 70, 76, 80, 92, 94, 95, 99, 101, 114, 143, 146, 149, 188], "heavili": [22, 32, 35, 39, 42, 64, 92, 94, 101, 104, 144, 184, 188], "masked_softmax": 22, "1d": 22, "_sequence_mask": 22, "repeat_interleav": [22, 26, 47, 126], "1e6": 22, "ndim": [22, 151], "handi": [22, 27, 41, 42, 69, 99, 105, 150, 151, 153, 157, 180], "bmm": [22, 120, 135], "elementwis": [22, 47, 63, 72, 93, 103, 109, 114, 123, 136, 144, 153, 155, 157, 165, 173, 175], "check_shap": [22, 23, 26, 28, 29, 30, 177, 183], "batch_dot": [22, 120, 135], "lax": [22, 150, 173, 175], "batch_matmul": 22, "dropout": [22, 23, 24, 26, 28, 29, 30, 34, 62, 63, 68, 70, 85, 86, 92, 105, 106, 111, 112, 113, 116, 120, 121, 123, 126, 128, 158, 160, 168, 171, 177, 186, 191], "dotproductattent": [22, 26], "swap": [22, 41, 109], "transpose_b": [22, 120], "__call__": [22, 23, 26, 28, 29, 30, 31, 33, 35, 37, 63, 65, 66, 69, 99, 104, 105, 106, 110, 115, 143, 171, 172, 173, 175, 177, 182, 183], "swapax": [22, 23, 135, 177, 182], "dropout_lay": [22, 110], "kwarg": [22, 23, 26, 28, 29, 31, 35, 37, 42, 53, 56, 60, 63, 65, 66, 69, 72, 82, 106, 120, 123, 124, 126, 163, 165, 166, 168], "lastli": [22, 41, 46, 63, 64, 69, 72, 76, 93, 95, 96, 98, 143, 157], "init_with_output": [22, 23, 26, 28, 29, 30, 31, 37, 65, 69, 75, 177, 183], "sixth": 22, "show_heatmap": [22, 23, 27, 28, 29], "mismatch": [22, 34, 126, 141], "bahdanau": [22, 24, 27, 29, 92, 186, 191], "2014": [22, 23, 24, 27, 44, 46, 58, 62, 63, 66, 67, 70, 73, 76, 83, 92, 98, 103, 104, 110, 111, 114, 123, 129, 139, 173, 177, 179, 186], "w_v": [22, 26], "tanh": [22, 82, 83, 86, 126, 146, 173, 175, 183, 186], "w_q": [22, 26], "w_k": [22, 26, 125, 129], "learnabl": [22, 26, 28, 29, 30, 62, 77, 92, 106, 126, 170, 171, 183], "mlp": [22, 29, 30, 32, 34, 35, 36, 37, 40, 42, 63, 64, 65, 71, 73, 74, 83, 85, 109, 110, 111, 114, 115, 116, 117, 118, 120, 121, 126, 146, 160, 165, 171, 173, 178, 181, 186], "hidden": [22, 23, 28, 29, 35, 36, 37, 41, 42, 62, 63, 71, 72, 76, 77, 80, 81, 83, 85, 92, 109, 110, 112, 115, 116, 121, 124, 126, 128, 130, 146, 149, 158, 161, 165, 170, 171, 174, 177, 178, 179, 182, 183], "disabl": [22, 108, 110], "additiveattent": [22, 23], "num_hidden": [22, 23, 26, 28, 29, 30, 115, 120, 121, 124, 126, 128, 158, 165, 170, 171, 173, 175, 177, 182, 183], "lazylinear": [22, 23, 26, 29, 30, 31, 33, 34, 35, 36, 37, 38, 62, 63, 64, 65, 66, 69, 70, 74, 99, 104, 110, 115, 121, 126, 177, 182], "broadcast": [22, 44, 46, 61, 63, 100, 103, 105, 152, 153, 175, 177, 181], "dens": [22, 23, 26, 29, 30, 31, 33, 34, 35, 36, 37, 38, 42, 45, 53, 54, 62, 63, 64, 66, 67, 69, 70, 74, 83, 99, 104, 108, 110, 115, 117, 120, 121, 123, 124, 126, 143, 144, 158, 160, 161, 165, 168, 177, 182, 186, 191], "use_bia": [22, 26, 29, 30, 72, 82, 158, 160, 161, 165], "key_siz": [22, 26, 29], "query_s": [22, 26, 29], "likewis": [22, 35, 41, 44, 61, 64, 69, 92, 94, 98, 99, 103, 107, 114, 116, 120, 138, 141, 144, 150, 153, 155, 157, 173, 175, 180], "qualit": [22, 24, 80, 92, 96, 110, 185], "mainstai": [22, 62, 92, 111, 174], "megatron": [22, 25, 186], "shoeybi": [22, 186], "variant": [22, 25, 45, 46, 62, 63, 64, 66, 69, 70, 89, 92, 94, 114, 132, 137, 138, 140, 143, 144, 145, 158, 166, 175, 180, 182], "rnn": [23, 24, 27, 29, 117, 118, 123, 149, 170, 171, 172, 173, 174, 175, 176, 177, 179, 182, 184, 185, 186], "sutskev": [23, 24, 27, 62, 145, 177, 179, 186], "convention": [23, 42, 73], "relev": [23, 27, 39, 40, 41, 42, 45, 47, 64, 77, 81, 86, 91, 92, 93, 96, 101, 105, 113, 114, 117, 159, 162, 166, 185], "exclus": [23, 41, 46, 92, 153, 157, 174], "piec": [23, 42, 66, 83, 98, 104, 105, 139, 183, 185], "infeas": [23, 58, 59, 60, 63, 64, 77, 86, 92, 117, 138, 178], "grave": [23, 174, 179, 186], "2013": [23, 58, 62, 66, 67, 68, 71, 76, 77, 86, 90, 133, 134, 145, 149, 157, 159, 186, 187, 189], "pen": [23, 150], "speech": [23, 24, 29, 35, 63, 69, 76, 83, 92, 117, 149, 170, 179, 180, 184, 186], "markov": [23, 92, 157, 181, 187, 189, 190, 191], "rabin": [23, 186], "juang": [23, 186], "1993": [23, 114, 153, 186], "inspir": [23, 25, 29, 42, 69, 73, 77, 92, 101, 103, 106, 112, 116, 139, 183], "unidirect": [23, 170, 177], "deem": 23, "innocu": [23, 107], "influenti": [23, 52, 101], "rise": [23, 73, 92, 94, 175, 184], "dynam": [23, 24, 31, 41, 42, 56, 92, 99, 138, 142, 143, 149, 150, 168, 179, 184, 186, 187], "depict": [23, 25, 30, 40, 41, 44, 46, 66, 69, 70, 75, 77, 90, 92, 98, 103, 114, 117, 118, 120, 121, 126, 177, 179], "chan": [23, 186], "2015": [23, 35, 49, 58, 62, 63, 66, 67, 69, 77, 82, 86, 92, 95, 98, 104, 114, 119, 126, 132, 145, 148, 158, 163, 168, 179, 186], "redefin": [23, 46, 93, 110], "unsurprisingli": [23, 41, 45, 141], "attentiondecod": [23, 29], "notimplementederror": [23, 85, 96, 106, 172, 182], "seq2seqattentiondecod": 23, "iii": [23, 25, 35, 56, 60, 62, 64, 70, 92, 100, 105, 106, 126, 127, 149, 150, 151, 152, 169, 175, 184, 185], "exclud": [23, 25, 69, 103, 113, 127, 131, 133, 166, 172, 176, 177], "embed_s": [23, 120, 123, 124, 135, 177], "num_lay": [23, 124, 171, 177], "init_seq2seq": [23, 177], "hidden_st": [23, 177], "_attention_weight": [23, 29], "emb": [23, 29, 120, 123, 124, 131, 135, 177, 182, 183], "sow": [23, 28, 29], "dec_attention_weight": [23, 29, 177], "stackedrnncel": 23, "grucel": [23, 171, 173], "return_sequ": [23, 171, 173, 175, 182], "return_st": [23, 171, 173, 175, 182], "perm": [23, 26, 29], "seven": 23, "seq2seqencod": [23, 177], "instanti": [23, 24, 29, 31, 34, 35, 37, 74, 103, 104, 108, 121, 126, 147, 173, 175, 177, 181], "mtfraeng": [23, 29, 176, 177], "seq2seq": [23, 29, 176, 177], "tgt_pad": [23, 29, 177], "005": [23, 82, 83, 144, 145, 177], "max_epoch": [23, 29, 30, 38, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 86, 88, 89, 90, 99, 100, 104, 105, 106, 108, 110, 113, 115, 171, 173, 175, 177, 182, 183, 184], "gradient_clip_v": [23, 29, 38, 105, 106, 171, 173, 175, 177, 182, 183], "num_gpu": [23, 29, 30, 38, 44, 45, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 88, 89, 90, 106, 171, 173, 175, 177, 182, 183], "try_gpu": [23, 29, 38, 39, 44, 45, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 82, 120, 124, 135, 143, 171, 173, 175, 177, 182, 183], "bleu": [23, 29, 177, 186], "he": [23, 25, 29, 35, 45, 58, 67, 69, 92, 98, 110, 114, 120, 128, 149, 160, 163, 165, 168, 177, 186], "calm": [23, 29, 177], "home": [23, 29, 92, 94, 103, 156, 157, 177], "perdu": [23, 29, 177], "est": [23, 29, 177], "je": [23, 29, 177], "sui": [23, 29, 177], "chez": [23, 29, 177, 186], "moi": [23, 29, 177], "predict_step": [23, 29, 177], "fr": [23, 29, 177], "boom": [24, 62], "driven": [24, 149, 179, 184], "multilay": [24, 30, 62, 92, 111, 124, 149, 171, 177, 179, 191], "perceptron": [24, 63, 86, 92, 111, 149, 179, 186, 191], "convolut": [24, 27, 28, 29, 30, 34, 35, 41, 44, 45, 51, 52, 53, 55, 56, 58, 60, 65, 66, 68, 69, 70, 75, 76, 84, 87, 92, 99, 100, 104, 118, 120, 143, 149, 168, 174, 178, 179, 186, 191], "recurr": [24, 28, 29, 69, 73, 83, 114, 118, 120, 123, 149, 175, 177, 178, 186, 191], "underpin": [24, 92, 101], "breakthrough": [24, 62, 83, 92, 176, 179], "2010": [24, 41, 46, 53, 62, 67, 92, 98, 103, 104, 113, 114, 116, 161, 173, 179, 186], "anteced": 24, "laps": 24, "plenti": [24, 46, 92, 149, 154], "methodolog": 24, "innov": [24, 92, 103, 111, 114, 141, 174, 175], "toolkit": [24, 106, 114], "relu": [24, 29, 30, 31, 33, 34, 35, 36, 37, 42, 44, 45, 53, 54, 60, 62, 64, 65, 66, 68, 69, 70, 74, 76, 82, 86, 110, 115, 116, 120, 123, 126, 143, 146, 160, 165, 168, 183], "schedul": [24, 39, 40, 53, 54, 56, 87, 90, 142, 144, 147, 148, 186, 191], "recogniz": [24, 63], "sepp": 24, "hochreit": [24, 28, 92, 174, 175, 186], "domin": [24, 28, 30, 62, 64, 67, 74, 86, 92, 98, 149, 175], "rapid": [24, 32, 38, 42, 69, 82, 92, 141, 149, 152], "emerg": [24, 25, 30, 70, 73, 94, 95, 111, 116, 149, 180, 186], "thank": [24, 67, 92, 132, 149], "sea": [24, 78], "landscap": [24, 30, 56, 63, 92, 145], "grab": [24, 92, 105, 107], "pretrain": [24, 49, 50, 52, 56, 58, 64, 70, 92, 117, 118, 120, 132, 149, 170, 186, 191], "devlin": [24, 25, 30, 92, 126, 128, 186], "2018": [24, 25, 27, 28, 30, 46, 63, 64, 67, 69, 72, 80, 81, 85, 86, 89, 92, 103, 104, 111, 116, 126, 128, 139, 140, 143, 145, 167, 168, 186], "electra": [24, 25, 186], "clark": [24, 25, 186], "2020": [24, 25, 29, 30, 62, 63, 64, 67, 69, 75, 80, 92, 94, 186], "roberta": [24, 25, 132], "liu": [24, 25, 30, 60, 64, 67, 70, 92, 103, 132, 186], "longform": [24, 186], "beltagi": [24, 186], "downstream": [24, 25, 92, 117, 118, 120, 121, 123, 124, 126, 128, 130, 131], "breathless": 24, "openai": [24, 92, 186], "gpt": [24, 126, 132, 186], "brown": [24, 25, 30, 92, 109, 176, 186], "radford": [24, 25, 30, 80, 82, 126, 132, 186], "meanwhil": [24, 167], "divers": [24, 25, 38, 69, 71, 92, 94, 111, 122, 126, 149, 167, 179, 180, 189], "semant": [24, 46, 49, 52, 58, 61, 76, 117, 119, 120, 126, 129, 131, 134, 135, 159, 180, 186, 191], "superresolut": 24, "dosovitskii": [24, 25, 30, 64, 67, 92, 186], "2021": [24, 25, 30, 64, 67, 70, 80, 92, 98, 111, 149, 186], "competit": [24, 25, 35, 53, 54, 62, 67, 70, 83, 86, 92, 113, 175, 186], "gulati": [24, 92, 186], "reinforc": [24, 25, 27, 29, 64, 69, 149, 157, 186, 188, 189, 190, 191], "chen": [24, 92, 104, 149, 186], "dwivedi": [24, 92, 186], "bresson": [24, 92, 186], "envis": 24, "enhanc": [24, 41, 92, 116, 165], "extent": [24, 41, 64, 65, 66, 92, 94, 163, 164, 173, 184], "insight": [24, 32, 39, 62, 64, 67, 68, 80, 109, 138, 148, 149, 157, 179, 182, 186, 187, 189], "lingual": 24, "synonym": [24, 153], "feet": [24, 92, 98, 103], "hurt": [24, 86, 89, 101, 111, 186], "mal": 24, "au": 24, "spur": 24, "confer": [24, 63, 76, 92], "hazi": 24, "soon": [24, 30, 34, 78, 88, 89, 94, 95, 103, 175], "salient": [24, 175], "dispens": 24, "altogeth": [24, 68, 94, 95, 99, 103, 113, 157], "cleverli": [24, 92], "arrang": [24, 35, 66, 74, 92, 153, 179], "enorm": [24, 63, 64, 77, 92, 157, 169], "corpora": [24, 25, 92, 121, 124, 126, 127, 130, 131, 133, 134, 185, 186], "supervis": [24, 25, 67, 74, 83, 98, 101, 117, 126, 130, 156, 157, 161, 177, 186, 189], "grew": [24, 92], "especi": [24, 36, 59, 61, 62, 80, 82, 86, 92, 101, 104, 108, 116, 126, 129, 145, 149, 157, 159, 161, 175, 178, 184], "paradigm": [24, 25, 41, 42, 62, 92, 160], "ascend": 24, "bommasani": [24, 70, 186], "nadaraya": [24, 27, 186], "watson": [24, 27, 186], "cnn": [24, 27, 29, 30, 49, 52, 55, 56, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 117, 118, 123, 149, 171, 179, 186, 191], "positionwis": [24, 30, 126], "patch": [24, 25, 67, 77, 92, 176], "scalabl": [24, 30, 45, 64, 78, 81, 85, 92, 112, 145, 149, 167, 186], "expert": [25, 46, 86, 117, 149, 161, 187], "slight": [25, 44, 64, 85, 90, 127, 138, 139, 145, 157, 178], "compet": [25, 66, 81, 95, 101, 113, 149], "generalist": [25, 186], "increasingli": [25, 32, 44, 65, 73, 79, 81], "kaplan": [25, 92, 186], "evidenc": 25, "boost": [25, 74, 186], "gato": 25, "atari": [25, 92, 188], "caption": [25, 72, 92, 179, 184], "chat": [25, 92, 130, 186], "robot": [25, 48, 92, 179, 188, 189, 190], "reed": [25, 92, 186], "joint": [25, 78, 79, 80, 92, 125, 157, 180, 184], "torqu": [25, 92], "multimod": [25, 186], "serial": [25, 31, 37], "wealth": [25, 167], "cl": [25, 30, 60, 117, 121, 126, 127, 128], "bidirect": [25, 123, 124, 130, 174, 177, 186, 191], "love": [25, 134, 149], "car": [25, 53, 59, 74, 92, 117, 149], "prepend": 25, "constraint": [25, 30, 64, 117, 138, 142, 144, 186, 189, 190], "manual": [25, 34, 40, 53, 62, 64, 66, 69, 72, 76, 86, 92, 126, 156, 164, 170], "sentiment": [25, 117, 118, 119, 126, 184, 186, 191], "350": [25, 92], "tag": [25, 98, 118, 126, 184, 186], "albert": [25, 156, 186], "enforc": [25, 140], "lan": [25, 186], "spanbert": 25, "span": [25, 27, 81, 92, 111, 117, 176, 179, 186], "joshi": [25, 186], "distilbert": 25, "lightweight": [25, 106, 141, 149], "distil": [25, 145, 149, 186], "sanh": [25, 186], "swin": [25, 30, 67, 186], "mae": [25, 60], "autoencod": [25, 92, 162, 186, 191], "outfit": [25, 77], "autoregress": [25, 29, 81, 126, 175, 179, 182, 186], "literatur": [25, 63, 72, 92, 95, 103, 140, 163, 168], "mislead": [25, 95], "bart": [25, 186], "lewi": [25, 186], "raffel": [25, 30, 186], "concurr": [25, 88, 89], "attempt": [25, 34, 63, 83, 92, 94, 95, 101, 104, 143, 146, 149, 157, 180], "multitask": [25, 186], "comprehens": [25, 83, 111, 117, 118, 148, 149, 168, 179, 186], "ablat": [25, 168], "triangl": [25, 151, 153], "corrupt": [25, 92, 98, 107, 108, 184], "c4": [25, 66, 186], "coloss": 25, "crawl": 25, "corpu": [25, 83, 117, 119, 126, 127, 130, 133, 135, 180, 183, 185, 186], "11b": 25, "fedu": [25, 186], "imagen": [25, 92], "frozen": [25, 126, 189, 190], "xxl": 25, "saharia": [25, 92, 186], "photorealist": [25, 82, 83, 92, 186], "sublay": [25, 29], "nowadai": [25, 46, 62, 74, 92, 167], "de": [25, 64, 92, 113, 186], "facto": [25, 107], "abund": [25, 62, 92, 101, 126, 162], "unlabel": [25, 47, 92, 94, 95, 101, 186], "pre": [25, 30, 38, 54, 95, 107, 114, 116, 126, 173, 186], "backbon": [25, 30, 73, 92, 149, 157], "promis": [25, 41, 53, 85, 90, 111], "shot": [25, 52, 58, 186, 191], "prefix": [25, 54, 132, 169, 173, 182, 183, 184], "categor": [25, 92, 93, 98, 113, 122, 156, 159, 160, 167, 183, 190], "predecessor": [25, 66, 149], "sparser": [25, 67], "disclos": 25, "2023": [25, 53, 92, 186], "empir": [25, 29, 30, 63, 64, 65, 70, 78, 92, 93, 95, 101, 103, 118, 126, 143, 146, 157, 180, 186], "smoothli": 25, "tandem": 25, "bottleneck": [25, 41, 42, 46, 58, 62, 64, 69, 78, 96, 156], "petaflop": 25, "debat": [25, 63, 103, 110], "hoffmann": [25, 92, 186], "enjoi": [25, 28, 29, 74, 92, 119, 122, 145, 157], "trend": [25, 41, 63, 83, 92, 95, 186], "nlg": [25, 186], "smith": [25, 117, 186], "270": 25, "280": 25, "gopher": [25, 186], "rae": [25, 92, 186], "inherit": [25, 31, 35, 42, 59, 106, 115, 119, 172, 182], "chinchilla": 25, "70": [25, 186], "outperform": [25, 30, 62, 70, 85, 86, 95, 101, 110, 144, 160, 186], "emphasi": [25, 92], "palm": 25, "chowdheri": [25, 92, 186], "540": 25, "780": 25, "bench": 25, "srivastava": [25, 62, 69, 92, 110, 111, 186], "anil": [25, 63, 92, 186], "multilingu": [25, 186], "minerva": 25, "lewkowycz": [25, 186], "galactica": [25, 186], "taylor": [25, 65, 141, 186], "scientif": [25, 36, 63, 64, 70, 95, 101, 111, 155], "opt": [25, 166, 186], "zhang": [25, 27, 67, 77, 80, 98, 111, 149, 150, 162, 167, 186], "bloom": [25, 186], "scao": [25, 186], "falcon": 25, "penedo": [25, 186], "democrat": [25, 74], "llama": 25, "touvron": [25, 30, 64, 92, 186], "2023a": [25, 92, 186], "2023b": [25, 92, 186], "wei": [25, 186], "inher": [25, 46, 62, 63, 64, 92, 116, 138, 139, 143, 160, 167], "held": [25, 67, 79, 92, 107, 111, 163, 164], "ouyang": [25, 92, 186], "instructgpt": 25, "intent": [25, 92, 99, 157, 168], "chatgpt": [25, 92], "respons": [25, 39, 62, 72, 92, 94, 98, 143, 157, 175, 186, 189], "debug": [25, 36, 41, 42, 92, 107, 149], "creativ": [25, 31, 35, 64, 77, 92, 149, 151], "qin": [25, 186], "bai": [25, 62, 186], "autom": [25, 69, 86, 92, 94, 96, 104, 105, 149, 186], "prospect": [25, 162], "formul": [25, 42, 77, 80, 92, 93, 94, 103, 149, 157, 165, 166, 176, 188, 190], "induc": [25, 80], "elicit": [25, 150, 186], "commonsens": 25, "wang": [25, 30, 41, 46, 63, 149, 168, 186], "diversifi": 25, "sub": [25, 35, 36, 58, 86, 88, 119, 157, 185], "zhou": [25, 186], "kojima": [25, 186], "lean": 25, "nonetheless": [25, 27, 41, 42, 44, 62, 63, 64, 71, 77, 92, 96, 98, 99, 101, 103, 107, 114, 115, 142, 143, 145, 146, 167, 180], "flamingo": [25, 186], "alayrac": [25, 186], "dall": [25, 92], "ramesh": [25, 92, 186], "yu": [25, 186], "fidel": [25, 64, 87, 139, 186, 191], "rich": [25, 73, 77, 92, 103, 114, 129, 130, 140, 150, 162, 186, 191], "350m": 25, "750m": 25, "3b": 25, "20b": 25, "subspac": [26, 29, 92, 140], "d_q": 26, "d_k": 26, "d_v": 26, "p_v": 26, "p_q": 26, "w_o": [26, 125, 134], "p_o": 26, "h_h": 26, "sophist": [26, 39, 40, 41, 44, 46, 62, 85, 86, 88, 92, 114, 153, 160, 177, 178], "multiheadattent": [26, 28, 29, 30], "num_head": [26, 28, 29, 30, 121, 126, 128], "transpose_qkv": 26, "output_concat": 26, "transpose_output": 26, "bool": [26, 29, 30, 62, 63, 64, 65, 68, 69, 70, 110, 172, 177, 182], "value_s": [26, 29], "transposit": [26, 52, 109, 153], "num_queri": [26, 28], "num_kvpair": 26, "prune": [26, 155], "imagenet": [27, 30, 35, 49, 50, 52, 56, 62, 64, 66, 67, 69, 70, 92, 96, 101, 143, 186, 191], "224": [27, 50, 54, 56, 59, 62, 64, 65, 66, 68, 70], "sequenti": [27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 41, 43, 44, 45, 49, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 82, 83, 85, 86, 88, 99, 109, 110, 115, 120, 123, 126, 135, 143, 144, 149, 160, 162, 165, 171, 179, 184, 186, 187], "kalchbrenn": [27, 73, 186], "yang": [27, 98, 149, 150, 186], "databas": [27, 92, 149, 156, 186], "aston": [27, 92, 98, 162], "lipton": [27, 63, 179, 186], "zachari": 27, "smola": [27, 46, 62, 101, 114, 186], "alex": [27, 62, 92], "teach": [27, 92, 105, 149], "wasn": 27, "stackrel": [27, 63, 64, 69, 94, 98, 99, 116, 129, 136, 138, 140, 141, 144, 145, 148, 157, 166, 189], "_m": [27, 94, 120, 153], "cone": [27, 63], "resort": [27, 64, 92], "multinomi": [27, 154, 157], "mnih": [27, 92, 186, 187, 189], "bulk": [27, 41, 64], "exposit": [27, 109, 149, 179], "heatmap": 27, "sharex": 27, "row_ax": 27, "row_matric": 27, "saniti": [27, 31, 96, 113], "ey": [27, 59, 62, 78], "mysteri": [27, 111, 151], "lin": [28, 29, 60, 66, 67, 68, 71, 77, 92, 149, 186], "intra": 28, "cheng": [28, 29, 186], "parikh": [28, 120, 186], "paulu": [28, 29, 186], "2001": [28, 92, 114, 167, 175, 186], "gram": [28, 56, 119, 123, 125, 130, 132, 133, 177, 181, 185], "knd": 28, "hierarch": [28, 46, 55, 56, 62, 76, 92, 130, 179, 186], "_5": 28, "recept": [28, 55, 60, 73, 76, 186], "nd": [28, 153], "shortest": [28, 29, 41, 92], "prohibit": [28, 78, 98, 141, 150, 169], "slow": [28, 38, 41, 58, 66, 78, 96, 103, 133, 139, 141, 143, 144, 145, 157, 178, 183], "ditch": 28, "preserv": [28, 29, 56, 58, 65, 73, 75, 95, 98, 114, 120, 150, 186], "scheme": [28, 30, 47, 94, 95, 116], "sine": 28, "2j": 28, "glanc": [28, 76, 184], "trigonometr": [28, 184], "weird": [28, 94, 111], "positionalencod": [28, 29], "max_len": [28, 121, 126, 127, 128, 133, 135, 168], "pow": [28, 143, 177], "offset": [28, 55, 58, 60, 63, 77, 103, 105, 140, 159], "encoding_dim": 28, "pos_encod": [28, 29], "col": 28, "inter_var": 28, "mutabl": [28, 63, 74, 99, 105, 110, 155, 177], "lowest": [28, 41, 62, 86, 89, 98, 140], "03b": 28, "delta": [28, 63, 71, 77, 80, 95, 113, 137, 138], "omega_j": 28, "huang": [28, 65, 67, 98, 149, 186], "shaw": [28, 186], "appeal": [29, 95, 98, 116, 140, 178], "sole": [29, 92, 101], "pervas": [29, 69, 92, 165], "panda": [29, 53, 57, 113, 149, 156, 164], "pd": [29, 53, 57, 113, 149, 156, 164], "overview": [29, 41, 60, 75, 92, 98, 111, 143, 149, 162, 186, 191], "resnet": [29, 30, 35, 45, 49, 50, 51, 53, 54, 60, 64, 67, 74, 86, 92, 149, 191], "feasibl": [29, 62, 69, 86, 118, 141, 145], "ba": [29, 62, 63, 139, 186], "ffn_num_output": 29, "positionwiseffn": 29, "ffn_num_hidden": [29, 121, 126, 128], "dense1": [29, 30], "dense2": [29, 30], "innermost": [29, 47, 48, 60], "ffn": [29, 30], "ln": [29, 63, 151, 166], "layernorm": [29, 30, 126], "bn": [29, 63, 65], "lazybatchnorm1d": [29, 63], "nbatch": 29, "batchnorm": [29, 45, 53, 60, 63, 64, 65, 69, 82, 93], "use_running_averag": 29, "addnorm": 29, "norm_shap": [29, 30], "add_norm": 29, "normalized_shap": 29, "transformerencoderblock": [29, 126], "addnorm1": 29, "addnorm2": 29, "encoder_blk": [29, 30], "48": [29, 30, 41, 66], "num_blk": [29, 30, 121, 126, 128], "transformerencod": [29, 126], "blk": [29, 30, 45, 53, 60, 64, 65, 68, 69, 70, 126], "add_modul": [29, 30, 35, 45, 49, 64, 65, 69, 126], "enc_attention_weight": [29, 177], "200": [29, 41, 51, 59, 75, 92, 108, 120, 144, 153], "transformerdecoderblock": 29, "dec_valid_len": 29, "attention1": 29, "attention2": 29, "addnorm3": 29, "key_valu": 29, "x2": [29, 37, 48, 80, 138, 141, 145, 147, 148], "y2": [29, 37, 48, 60, 71], "tile": [29, 30, 47, 177], "attention_w1": 29, "attention_w2": 29, "facilit": [29, 35, 50, 51, 53, 95, 106, 113, 121, 127, 144, 149, 167], "decoder_blk": 29, "transformerdecod": 29, "dec_attention_weights_2d": 29, "attn": 29, "dec_attention_weights_fil": 29, "datafram": [29, 53, 113, 164], "fillna": [29, 113, 156], "dec_self_attention_weight": 29, "dec_inter_attention_weight": 29, "survei": [29, 56, 114, 148, 149, 186], "tai": [29, 162, 186], "spark": 30, "immens": 30, "ramachandran": [30, 114, 186], "cordonni": [30, 186], "vit": 30, "margin": [30, 62, 63, 78, 79, 94, 157, 166, 186], "changer": [30, 62], "pytorchjax": [30, 34], "patchifi": 30, "bodi": [30, 42, 59, 64, 66, 68, 92, 105, 111, 114, 140], "nine": [30, 72, 126, 168, 184, 185], "hw": [30, 55, 56], "stride": [30, 41, 44, 45, 49, 52, 53, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 82, 143, 191], "patchembed": 30, "img_siz": 30, "patch_siz": 30, "512": [30, 41, 42, 45, 49, 53, 66, 69, 70, 121, 127, 128, 133, 135, 144, 163, 176], "_make_tupl": 30, "num_patch": 30, "conv": [30, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 123, 168, 186], "lazyconv2d": [30, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75], "kernel_s": [30, 44, 45, 49, 53, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 82, 123, 143], "patch_emb": 30, "gelu": [30, 114, 126, 186], "smoother": [30, 60, 63, 138], "hendryck": [30, 114, 126, 186], "gimpel": [30, 114, 126, 186], "vitmlp": 30, "mlp_num_hidden": 30, "mlp_num_output": 30, "dropout1": 30, "dropout2": 30, "post": [30, 41, 47, 68, 92, 95, 107, 145, 149, 150, 163, 167, 180], "baevski": [30, 186], "auli": [30, 186], "xiong": [30, 92, 186], "vitblock": 30, "ln1": 30, "ln2": 30, "emb_dropout": 30, "blk_dropout": 30, "patch_embed": 30, "cls_token": 30, "pos_embed": [30, 126], "pos_emb": 30, "2048": [30, 160, 161], "intrins": [30, 85, 107, 111, 157], "deit": 30, "reinstat": [30, 37], "loop": [31, 35, 36, 39, 45, 56, 62, 70, 72, 86, 88, 92, 94, 96, 100, 103, 104, 105, 108, 110, 115, 128, 150, 173, 175, 178, 183], "sooner": 31, "centeredlay": 31, "intend": [31, 78, 99, 118, 157], "housekeep": [31, 35], "bake": [31, 107], "in_unit": [31, 160, 168], "mylinear": 31, "mydens": 31, "x_shape": [31, 74], "add_weight": [31, 63, 72], "random_normal_initi": [31, 33, 72, 144], "zeros_initi": [31, 33], "get_weight": [31, 34, 36, 72, 104], "invok": [31, 35, 36, 37, 42, 45, 47, 53, 56, 60, 66, 77, 85, 94, 96, 99, 103, 104, 106, 109, 115, 119, 127, 128, 138, 143, 150, 151, 153, 154, 155, 157, 182, 183], "y_k": 31, "w_": [31, 64, 98, 103, 116, 134, 178], "fourier": [31, 80, 81, 98], "alongsid": [32, 79, 104], "giant": [32, 68, 92, 183], "indispens": [32, 41, 51, 63, 162], "pathbreak": 32, "theano": [32, 42, 62, 92, 104, 186], "2007": [32, 46, 64, 98, 186], "prototyp": [32, 92, 94, 141, 175], "repetit": [32, 85, 88, 104, 115, 149, 157], "recycl": [32, 101], "maintain": [32, 35, 41, 44, 63, 70, 90, 92, 95, 101, 116, 137, 138, 145, 149, 184, 190], "evolv": [32, 69, 88, 95, 110, 111, 143, 157, 167, 184, 188, 189], "coars": 32, "semiconductor": 32, "transistor": [32, 70], "circuit": [32, 41, 92], "artifici": [32, 57, 62, 92, 103, 107, 114, 116, 126, 133, 186], "neuron": [32, 35, 70, 82, 92, 103, 110, 112, 114, 115, 116, 160, 165, 175, 186], "coarser": [32, 76, 157], "ramp": [32, 148, 153], "effortlessli": [32, 92], "peel": 32, "curtain": 32, "speedup": [32, 41, 44, 103, 133], "reap": [32, 183], "lazi": [32, 65, 104, 191], "protocol": [33, 41, 46, 94, 165], "uniformli": [33, 47, 55, 64, 85, 133, 144, 148, 180, 189], "preset": 33, "07": 33, "lecun_norm": 33, "fan_in": 33, "init_norm": 33, "normal_": [33, 45, 82, 83, 104, 144], "zeros_": 33, "freshli": 33, "weight_init": 33, "bias_init": 33, "kernel_init": [33, 74, 104], "prngkei": [33, 35, 36, 37, 38, 71, 72, 75, 100, 107, 108, 110, 116, 150, 155, 171, 173, 175], "get_se": [33, 36, 37, 71, 72, 75, 100, 116], "layer_0": 33, "layers_0": 33, "kernel_initi": [33, 104, 108, 144], "bias_initi": 33, "init_const": 33, "constant_": 33, "init_xavi": 33, "init_42": 33, "xavier_uniform": [33, 74], "layers_2": [33, 36], "glorotuniform": 33, "my_init": 33, "named_paramet": [33, 36, 50], "uniform_": 33, "subclass": [33, 35, 42, 85, 90, 93, 105, 106, 107, 108], "_init_weight": 33, "myinit": 33, "float_": 33, "minval": [33, 110], "maxval": [33, 110], "dictionari": [33, 34, 35, 36, 37, 53, 63, 88, 93, 99, 100, 104, 110, 125, 132, 133, 134, 135, 139, 144, 164, 169, 185], "frozen_dict": 33, "frozendict": 33, "advis": [33, 41, 64, 139, 144], "ecosystem": [33, 42], "alter": [33, 60, 77, 115, 155], "datatyp": 33, "immut": [33, 103, 155], "unfreez": 33, "got": [34, 82, 83, 92, 141, 146, 176], "sloppi": 34, "unintuit": 34, "defer": [34, 63, 106], "fly": [34, 77, 94, 107, 126, 128], "greatli": [34, 64, 74, 78, 92, 106, 161], "trigger": [34, 38, 80, 92, 175], "regist": [34, 41, 53, 105, 106, 107, 113, 115, 144, 149], "decoupl": [34, 36, 39, 46, 139, 147, 157], "stateless": 34, "empti": [34, 90, 92, 93, 99, 100, 110, 121, 156, 168, 176, 177], "tree_util": [34, 36, 38, 105, 183], "tree_map": [34, 36, 38, 72, 105, 183], "tree_flatten_with_kei": 34, "plug": [34, 94, 95, 98, 116, 141, 148, 151, 184], "dry": 34, "apply_init": [34, 63, 66, 68, 69, 70, 74, 85, 88, 89, 106], "rng": [34, 63, 99, 110, 177], "ultim": [34, 62, 76, 80, 94, 99, 100, 101, 103, 151, 160, 175, 184, 185], "hood": [34, 105, 106, 109], "dummy_input": [34, 106], "elimin": [34, 92, 119, 138], "ty": [34, 36, 64, 178], "arithmet": [35, 62, 152, 155, 186], "character": [35, 63, 65, 77, 92, 95, 103, 108, 110, 149, 157, 169, 184, 185, 186], "interestingli": [35, 62, 94, 150, 157], "constitu": [35, 59], "possess": [35, 77, 94, 95, 109, 111, 117, 157, 163], "ingest": [35, 66, 69, 92, 152, 179, 183], "152": [35, 69], "wildli": [35, 67, 101], "hypothet": 35, "won": [35, 62, 66, 69, 92, 163], "coco": 35, "ubiquit": [35, 72, 73, 92, 108, 156, 162, 183], "artifact": [35, 75, 157], "recurs": [35, 36, 145, 178], "surprisingli": [35, 64, 69, 77, 95, 98, 103, 109, 113], "standpoint": [35, 178], "scene": [35, 77, 92, 186], "auto": [35, 81, 92, 184, 186], "shorthand": [35, 157], "slick": 35, "random_se": 35, "easiest": [35, 42, 114], "briefli": [35, 59, 67, 77, 92, 110, 114, 117, 151], "parent": [35, 149], "constructor": [35, 62, 66, 72, 106, 110, 119], "logit": [35, 68, 98, 99], "net1": 35, "net2": 35, "spare": [35, 83], "pain": [35, 40], "boilerpl": [35, 63, 105], "virtu": [35, 140], "versatil": [35, 78], "exploit": [35, 68, 77, 85, 87, 88, 90, 92, 94, 96, 100, 144, 146, 148, 149, 150, 186], "daisi": 35, "mysequenti": 35, "deliv": [35, 92, 187], "children": [35, 49, 77], "member": [35, 50, 85, 101, 106, 182], "_children": 35, "travers": [35, 41, 47, 75, 76, 109, 125, 144, 148, 151, 178], "chief": 35, "advantag": [35, 40, 42, 44, 45, 62, 63, 64, 65, 72, 75, 76, 78, 80, 92, 94, 96, 104, 105, 109, 114, 149, 160, 173, 183], "wrote": [35, 74], "nor": [35, 62, 78, 95, 98, 103, 116, 119, 132, 140, 146], "fixedhiddenmlp": 35, "rand_weight": 35, "reus": [35, 36, 37, 44, 54, 60, 65, 83, 90, 97, 100, 106, 109, 115, 155, 178], "get_const": 35, "thereaft": [35, 68, 74, 94, 190], "ran": [35, 89], "ell_1": [35, 60, 108, 111, 140, 153], "nestmlp": [35, 36], "chimera": 35, "compris": [35, 65, 66, 71, 73, 77, 78, 92, 95, 102, 164, 185], "nitti": [36, 73], "gritti": [36, 73], "lift": [36, 98, 155, 156], "weed": 36, "state_dict": [36, 37], "unwieldi": [36, 75, 77, 78, 180], "tree": [36, 46, 56, 92, 94, 101, 114, 125, 133, 180, 186], "elegantli": 36, "alloc": [36, 38, 40, 42, 44, 63, 66, 75, 85, 90, 94, 104, 109, 115, 150, 153, 155], "happi": [37, 157, 170, 179, 184], "checkpoint": [37, 41, 89], "lose": [37, 38, 71, 75, 92, 157, 166], "trip": [37, 41], "cord": [37, 186], "npy": 37, "allow_pickl": 37, "mydict": 37, "mydict2": 37, "sprinkl": 37, "save_paramet": 37, "save_checkpoint": 37, "ckpt_dir": 37, "overwrit": [37, 155], "save_weight": 37, "load_state_dict": [37, 121], "load_paramet": [37, 121], "cloned_param": 37, "freez": [37, 54, 56, 101, 126], "restore_checkpoint": 37, "load_weight": 37, "y_clone": 37, "tab_intro_decad": 38, "opportun": [38, 94, 105, 186], "pytorchmxnet": [38, 39, 40, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 82, 83, 119, 120, 121, 122, 123, 124, 126, 127, 128, 131, 132, 133, 135], "hairier": 38, "job": [38, 77, 78, 83, 85, 88, 89, 90, 92, 94, 113], "spent": [38, 41, 46, 50, 86, 90, 92, 104], "cu100": 38, "extravag": 38, "parenthes": 38, "device_count": 38, "backend": [38, 40, 42, 43, 88, 89], "list_physical_devic": 38, "try_all_gpu": [38, 40, 45, 49, 50, 51, 53, 54, 120, 121, 123, 124, 128, 158, 160, 161, 163, 165, 168], "tpu": [38, 41], "usag": [38, 68, 94, 100, 154, 155], "exce": [38, 39, 47, 62, 92, 95, 98, 99, 113, 114, 133, 144, 183], "device_put": [38, 106, 155], "copyto": [38, 40, 44, 56, 63], "op": [38, 58], "z2": 38, "slower": [38, 41, 46, 62, 70, 138, 145], "crash": [38, 149, 153, 156], "realiz": [38, 41, 55, 62, 81, 111, 114, 116, 145, 149, 150, 153, 157], "wors": [38, 41, 46, 64, 69, 86, 89, 103, 110, 111, 144, 145, 148, 160, 180, 184], "coffe": [38, 92, 94], "queue": [38, 39, 41, 90], "phone": [38, 62, 68, 92], "overhead": [38, 39, 41, 42, 44, 45, 88, 108, 109, 138, 144, 155], "dread": [38, 99], "key1": [38, 107], "key2": [38, 107], "mirroredstrategi": 38, "pytorchmxnetjax": [38, 68, 76, 170], "prepare_batch": [38, 86, 105], "prepare_model": [38, 106], "set_scratch_params_devic": 38, "attr": [38, 93], "dir": [38, 93, 154], "getattr": [38, 60, 93], "elem": [38, 128, 131], "as_in_context": [38, 177], "reset_ctx": [38, 49, 50, 54, 56], "mistak": [38, 92, 96], "frobeniu": [38, 108, 109, 153], "enqueu": 39, "necessarili": [39, 65, 92, 94, 98, 101, 167, 184, 185, 187, 189], "proactiv": [39, 162, 167], "processor": [39, 40, 41, 62, 92, 103, 144], "subprocess": 39, "warmup": [39, 186], "mm": [39, 40, 44, 144, 153], "frontend": 39, "synchron": [39, 40, 41, 43, 45, 88, 89, 179], "queu": 39, "waital": [39, 40, 42, 44, 45, 128], "scala": [39, 42], "obvious": [39, 41, 44, 56, 59, 71, 143, 167], "bad": [39, 41, 62, 92, 94, 101, 111, 115, 120, 123, 124, 130, 131, 169, 183, 189], "wait_to_read": [39, 144], "afterward": [39, 85, 89, 90, 161, 164, 165, 168], "obviou": [39, 50, 94, 98, 99, 114, 126, 138, 161, 163, 180], "destroi": [39, 63, 68, 92, 116], "multithread": 39, "durat": 39, "t_3": 39, "9999t_1": 39, "overfil": 39, "excess": [39, 56, 62, 65, 96, 103, 116, 141, 155, 176, 183], "chip": [39, 41, 62, 66, 70, 72, 131, 133, 135], "Be": 39, "careless": [39, 78], "ruin": 39, "9999": 39, "interdepend": [40, 109], "hadji": [40, 186], "accomplish": [40, 41, 62, 64, 69, 74, 75, 76, 92, 98, 107, 109, 120, 141, 143, 145, 146, 149, 180], "workload": [40, 44, 103, 144], "x_gpu1": 40, "x_gpu2": 40, "4000": 40, "warm": [40, 45, 143, 183, 186], "current_devic": 40, "gpu1": 40, "gpu2": 40, "behalf": [40, 144], "copy_to_cpu": 40, "non_block": 40, "y_cpu": 40, "backprop": [40, 78, 186], "pci": [40, 41], "copy_": [40, 49, 56, 120, 123, 124], "caller": 40, "bypass": [40, 69], "unnecessari": [40, 103, 149], "asynchron": [40, 43, 46, 87, 191], "eight": [40, 62, 70, 111, 168], "debugg": 40, "nsight": 40, "aspect": [41, 46, 47, 50, 51, 55, 56, 58, 60, 62, 63, 64, 77, 92, 94, 98, 99, 100, 103, 105, 126, 143, 145, 157, 190], "modicum": 41, "substitut": [41, 96, 101, 119, 156, 178], "cours": [41, 57, 63, 64, 67, 76, 77, 92, 95, 125, 144, 149, 153, 156, 157, 183, 184], "throughput": [41, 62], "week": [41, 86, 92, 142], "month": [41, 62, 74, 92, 104], "deadlin": 41, "programm": [41, 92, 186], "impati": [41, 94], "colin": 41, "scott": 41, "jeff": 41, "dean": [41, 62, 104, 186], "stanford": [41, 117, 118, 122, 131, 186], "rational": [41, 111], "guid": [41, 63, 64, 70, 77, 86, 98, 113, 184, 186, 191], "cursori": 41, "meant": [41, 63], "hennessi": [41, 186], "patterson": [41, 186], "2011": [41, 63, 86, 113, 123, 124, 138, 143, 167, 175, 180, 186], "arst": 41, "asanov": 41, "thereof": [41, 146, 175], "ethernet": [41, 46], "interconnect": [41, 46, 62], "topologi": 41, "durabl": 41, "magnet": 41, "gbit": [41, 46], "seamlessli": 41, "starv": 41, "interleav": [41, 77, 149], "ddr4": 41, "0gb": 41, "bank": [41, 92, 126, 130, 133, 157, 170], "zen": 41, "impress": [41, 92, 116, 159], "burst": [41, 46, 77, 144], "boundari": [41, 47, 72, 75, 77, 92, 96, 101, 114, 132, 140, 176], "flag": [41, 42, 51, 121], "lectur": [41, 92, 148, 186], "zeshan": 41, "chishti": 41, "wider": [41, 54, 55, 62, 101, 103, 114, 144, 149, 186], "352": 41, "grade": [41, 46, 92, 105], "hbm": 41, "silicon": 41, "wafer": 41, "hdd": 41, "spin": 41, "platter": 41, "inexpens": [41, 64, 92], "downsid": [41, 71, 111, 183], "catastroph": [41, 94], "rpm": 41, "shatter": 41, "centrifug": 41, "exert": [41, 140, 149, 183], "sector": 41, "iop": 41, "mb": [41, 46, 62, 92], "releg": [41, 44], "archiv": [41, 92], "flash": 41, "reach": [41, 57, 62, 69, 70, 88, 89, 90, 92, 96, 98, 100, 103, 111, 114, 115, 133, 141, 143, 144, 149, 169, 171, 176, 184, 188, 189, 190], "3gb": [41, 62], "wise": [41, 63, 67, 71, 94, 103, 138, 144, 145, 147, 175], "eras": 41, "firmwar": 41, "mitig": [41, 51, 76, 86, 92, 94, 108, 111, 114, 116, 138, 174, 176, 183, 189], "qlc": 41, "wear": [41, 94], "protect": [41, 99, 100], "degrad": [41, 94, 184], "volatil": 41, "8gb": [41, 68], "virtual": [41, 46, 62, 63, 78, 88], "provis": 41, "centerpiec": 41, "aid": [41, 68, 149], "media": [41, 122, 130, 163], "intel": [41, 46, 91, 92, 133], "skylak": 41, "ringbu": 41, "peripher": 41, "wifi": 41, "bluetooth": 41, "usb": 41, "chipset": 41, "assembli": [41, 74], "microinstruct": 41, "arm": [41, 62, 92, 94, 139, 181, 186], "cortex": [41, 72, 186], "a77": 41, "cycl": [41, 62, 92, 94, 179, 186], "pursu": [41, 80], "hungri": [41, 170], "neon": 41, "x86": 41, "avx2": 41, "simd": 41, "fuse": [41, 144, 165], "openvino": 41, "dwarf": 41, "ipc": 41, "byte": [41, 127, 130, 144, 186], "strictli": [41, 69, 72, 78, 98, 103], "penalti": [41, 46, 63, 69, 92, 93, 103, 111, 177], "keyword": 41, "l1": [41, 144], "defens": 41, "hierarchi": [41, 92, 144, 186], "l2": [41, 108, 144], "l3": [41, 62, 144], "epyc": 41, "whop": [41, 62, 96], "chiplet": [41, 144], "ahead": [41, 92, 153, 162, 184], "sword": [41, 103], "worst": [41, 90, 95, 101, 131, 141, 180, 183], "slowli": [41, 78, 79, 94, 100, 103, 138, 139, 141, 143, 147, 148, 175], "courtesi": [41, 46, 62, 64, 77], "exagger": 41, "argu": [41, 70, 110, 114, 148], "evolut": [41, 92], "jouppi": [41, 186], "Of": [41, 57, 64, 67, 76, 93, 95, 125, 144, 157, 190], "fp32": [41, 62, 68, 99], "shortli": [41, 68, 175], "multiprocessor": 41, "tu102": 41, "ampl": [41, 70], "complement": [41, 149, 157], "faulti": [41, 156], "casual": [41, 159], "beneath": 41, "systol": 41, "kung": [41, 186], "compromis": [41, 149, 169, 184], "interrupt": 41, "gunrock": [41, 186], "dgl": 41, "mediocr": 41, "microsecond": 41, "\u03bc": 41, "preciou": 41, "xeon": 41, "ryzen": 41, "i9": 41, "packet": 41, "resili": [41, 110, 113, 139], "c5": 41, "udp": 41, "tcp": 41, "ip": [41, 186], "nvlink": [41, 46], "six": [41, 47, 64, 72, 92, 117, 126, 128, 169], "nccl": 41, "eliot": 41, "eshelman": 41, "gist": 41, "mult": 41, "fma": 41, "mispredict": 41, "unshar": 41, "65": 41, "mutex": 41, "unlock": [41, 92], "116": [41, 186], "qpi": 41, "hop": [41, 92], "64mb": [41, 96], "ref": 41, "tinymembench": 41, "broadwel": 41, "e5": 41, "2690v4": 41, "256mb": 41, "optan": 41, "ucsd": 41, "4kb": 41, "gbp": 41, "hpc": 41, "fabric": [41, 46, 92], "mvapich2": 41, "omni": 41, "1kb": 41, "snappi": 41, "dc": [41, 80], "p3608": 41, "qo": 41, "500\u03bc": 41, "1mb": 41, "33gb": 41, "40gb": 41, "12gb": 41, "sata": 41, "s3510": 41, "ping": 41, "250\u03bc": 41, "550mb": 41, "200mb": 41, "ca": 41, "netherland": 41, "conflict": [41, 148, 149], "launch": [41, 92, 94, 114, 149], "shine": [41, 62, 70], "lesser": [41, 64], "alias": 41, "footprint": [41, 44, 62, 71, 109, 153, 156, 186], "sketch": [41, 86, 92], "novel": [41, 62, 83, 92, 175, 180, 186], "profil": [41, 96, 159], "sweet": [41, 92], "misalign": [41, 115], "extern": 41, "instantan": [41, 94, 145, 148, 151, 190], "commerci": [41, 92, 149, 164], "tbit": 41, "ring": [41, 43], "outer": [41, 157], "san": [41, 92, 180], "francisco": [41, 92, 180], "amsterdam": 41, "km": [41, 153], "imper": [42, 43, 69, 92, 186], "fancy_func": 42, "therebi": [42, 47, 51, 61, 75, 92, 95, 189], "acquir": [42, 79, 92, 155], "add_": 42, "fancy_func_": 42, "evoke_": 42, "prog": 42, "exec": 42, "cntk": [42, 92], "chainer": [42, 92], "revis": [42, 105, 159], "effort": [42, 44, 45, 86, 92, 111, 126, 130, 140, 160, 161, 162, 167], "portabl": [42, 103, 104], "torchscript": 42, "hybridblock": [42, 53], "hybridsequenti": [42, 49, 53, 54, 143], "sacrific": 42, "welcom": 42, "decor": [42, 106, 155], "brought": [42, 73], "wrap": [42, 92, 122, 153, 155, 164], "team": [42, 62, 74, 98, 163], "autograph": 42, "p3dn": 42, "24xlarg": 42, "struggl": [42, 77, 92, 103], "get_net": [42, 53, 54], "jit": [42, 63, 93, 99, 100, 110, 149, 173, 175, 177], "input_shap": [42, 63, 83, 126], "formerli": 42, "eagertensor": 42, "behavor": 42, "cen": 42, "direcli": 42, "mlir": 42, "jit_compil": 42, "xla": [42, 150], "vein": [42, 65, 151], "__enter__": 42, "__exit__": 42, "4f": [42, 135], "eagerli": 42, "eager": [42, 153], "my_mlp": 42, "lh": 42, "json": [42, 121], "perl": 42, "hybrid_forward": [42, 53], "hybridnet": 42, "invoc": [42, 107, 137], "spuriou": 42, "streamlin": [42, 62, 106, 173], "percentag": [42, 159], "saved_model": 42, "hybrid": [43, 50, 53, 54, 143, 167], "asynchroni": 43, "barrier": [43, 44, 46, 92], "blocker": 43, "archaic": 44, "lenet": [44, 45, 62, 64, 66, 67, 68, 70, 71, 73, 85, 88, 89, 96, 114, 143, 149, 191], "alexnet": [44, 51, 64, 66, 67, 68, 69, 70, 149, 191], "krizhevski": [44, 62, 67, 69, 73, 186], "2012": [44, 46, 59, 62, 67, 69, 73, 85, 104, 137, 147, 186], "g4dn": [44, 86], "12xlarg": 44, "partit": [44, 66, 70, 92, 98, 100, 109, 113, 151, 156, 178, 179], "reproduc": [44, 78, 79, 80, 108, 114, 186, 190], "fraction": [44, 61, 76, 82, 90, 92, 93, 94, 95, 110, 156, 157, 186], "tight": 44, "tricki": [44, 46, 63, 75, 94, 105, 141, 146, 178, 180], "exacerb": 44, "mirhoseini": [44, 186], "layerwis": [44, 52, 55, 56, 60, 116], "accordingli": [44, 45, 64, 73, 77, 94, 138, 140, 153, 158], "w1": [44, 115], "b1": [44, 65, 66, 69, 115], "w2": [44, 115], "b2": [44, 66, 115], "w3": 44, "b3": [44, 66], "w4": 44, "b4": [44, 66], "h1_conv": 44, "h1_activ": 44, "h1": [44, 110], "avg_pool2d": 44, "h2_conv": 44, "h2_activ": 44, "h2": [44, 110], "h3_linear": 44, "h3": 44, "num_filt": [44, 60], "pool_typ": 44, "get_param": [44, 59], "allreduc": 44, "new_param": 44, "requires_grad_": [44, 150], "split_and_load": [44, 45, 120, 128, 158, 163, 165], "split_batch": [44, 45, 51, 53, 54, 120], "train_batch": 44, "device_param": 44, "x_shard": [44, 45, 51, 54], "y_shard": [44, 45, 51, 54], "device_w": 44, "idl": [44, 88, 89, 90], "unsophist": 44, "choreograph": 44, "fun": [45, 180], "resnet18": [45, 49, 50, 51, 53, 69], "in_channel": [45, 49, 60, 82, 168], "resnet_block": [45, 53], "out_channel": [45, 49, 60, 68, 70, 82], "num_residu": [45, 53, 69], "first_block": [45, 53, 69], "use_1x1conv": [45, 53, 64, 69], "batchnorm2d": [45, 60, 82], "resnet_block1": 45, "resnet_block2": 45, "resnet_block3": 45, "resnet_block4": 45, "global_avg_pool": 45, "adaptiveavgpool2d": [45, 64, 65, 66, 68, 69], "fc": [45, 50, 160, 161, 168], "num_channel": [45, 53, 56, 60, 64, 65, 68, 69, 70, 123], "globalavgpool2d": [45, 53, 64, 65, 66, 68, 69], "refresh": [45, 100, 143, 149], "runtimeerror": 45, "split_f": [45, 51], "pred_shard": [45, 51], "dataparallel": [45, 51, 53, 54, 128], "device_id": [45, 51, 53, 54, 128], "meaningfulli": [45, 111], "primit": [45, 85, 150, 173, 175, 180, 186], "overlap": [45, 47, 55, 58, 77, 101, 117, 157], "rack": [46, 186], "100gbe": 46, "unreason": [46, 64, 94, 113, 141], "narayanamurthi": [46, 186], "latent": [46, 78, 79, 82, 83, 160, 161, 163, 165, 167, 173, 175, 181, 184, 186], "ahm": [46, 186], "rebroadcast": 46, "retrospect": 46, "_4": 46, "frivol": [46, 92], "16x": 46, "gen3": 46, "160": [46, 66, 186], "incur": [46, 78, 92, 94, 95, 98, 103, 144], "anywher": [46, 77], "dispos": [46, 108], "sergeev": [46, 186], "del": [46, 105, 186], "balso": [46, 186], "horovod": [46, 186], "bespok": 46, "dgx": [46, 92], "bidirection": [46, 126], "broke": 46, "chunk": [46, 153, 155], "misconcept": 46, "elabor": [46, 155, 175], "subtli": [46, 69, 98], "worker": [46, 88, 89, 90, 121], "commut": [46, 153], "dynamo": [46, 186], "decandia": [46, 186], "hide": [46, 99, 109, 138, 157], "infrastructur": 46, "ongo": 46, "fault": 46, "toler": 46, "set_printopt": 47, "s_n": 47, "r_m": 47, "whnm": 47, "s_2": [47, 188], "s_3": 47, "wh": [47, 132], "multibox_prior": [47, 55, 60], "in_height": 47, "in_width": 47, "num_siz": 47, "num_ratio": 47, "boxes_per_pixel": 47, "size_tensor": 47, "ratio_tensor": 47, "offset_h": 47, "offset_w": 47, "steps_h": 47, "steps_w": 47, "center_h": 47, "center_w": 47, "shift_i": 47, "shift_x": 47, "xmin": 47, "xmax": 47, "ymin": 47, "ymax": 47, "anchor_manipul": 47, "out_grid": 47, "imread": [47, 48, 49, 51, 55, 56, 57, 59, 60], "catdog": [47, 48, 49, 55], "jpg": [47, 48, 49, 51, 55, 56, 59, 60], "show_bbox": [47, 55, 57, 60], "bbox": [47, 48, 60], "make_list": 47, "obj": [47, 106], "default_valu": 47, "rect": [47, 59], "bbox_to_rect": [47, 48], "add_patch": [47, 48], "text_color": 47, "dict": [47, 53, 85, 90, 132, 146], "facecolor": 47, "restor": [47, 56], "bbox_scal": [47, 55], "surround": [47, 92, 114, 130, 134], "jaccard": 47, "cap": [47, 92, 136, 140, 157], "cup": [47, 136, 140, 157], "box_iou": 47, "pairwis": [47, 161, 165, 166, 186], "boxes1": 47, "boxes2": 47, "box_area": 47, "areas1": 47, "areas2": 47, "inter_upperleft": 47, "inter_lowerright": 47, "inter": [47, 164], "clamp": [47, 56], "inter_area": 47, "union_area": 47, "criteria": [47, 94], "closest": [47, 49, 56, 109, 140, 187], "n_a": 47, "n_b": 47, "b_j": 47, "i_1": 47, "j_1": 47, "i_2": 47, "j_2": 47, "b_3": [47, 98], "71": [47, 60, 186], "shade": [47, 61, 71, 72, 75, 76, 79, 123, 178], "a_7": 47, "54": [47, 60, 186], "b_4": 47, "a_5": 47, "92": 47, "a_9": 47, "a_3": 47, "a_4": 47, "a_6": 47, "a_8": 47, "assign_anchor_to_bbox": 47, "ground_truth": 47, "iou_threshold": 47, "num_anchor": [47, 60], "num_gt_box": 47, "x_ij": 47, "anchors_bbox_map": 47, "max_iou": 47, "anc_i": 47, "box_j": 47, "col_discard": 47, "row_discard": 47, "max_idx": 47, "box_idx": 47, "anc_idx": 47, "x_a": 47, "y_a": 47, "x_b": 47, "y_b": 47, "w_a": 47, "w_b": 47, "h_b": 47, "mu_w": 47, "sigma_w": 47, "mu_h": 47, "sigma_h": 47, "offset_box": 47, "assigned_bb": 47, "ep": [47, 63, 137, 138, 139, 147], "c_anc": 47, "box_corner_to_cent": [47, 48], "c_assigned_bb": 47, "offset_xi": 47, "offset_wh": 47, "multibox_target": [47, 60], "batch_offset": 47, "batch_mask": 47, "batch_class_label": 47, "bbox_mask": [47, 60], "class_label": 47, "indices_tru": 47, "bb_idx": 47, "bbox_offset": 47, "a_0": [47, 188, 190], "55": [47, 60, 141], "88": [47, 60, 186], "63": [47, 148], "98": [47, 114, 157, 186], "66": [47, 186], "57": [47, 186], "analyz": [47, 62, 63, 92, 116, 118, 130, 138, 139, 140, 141, 143, 145, 150, 153, 157, 173, 175, 178, 189, 190], "offset_invers": 47, "offset_pr": 47, "anc": 47, "pred_bbox_xi": 47, "pred_bbox_wh": 47, "pred_bbox": 47, "predicted_bbox": 47, "box_center_to_corn": [47, 48], "nm": [47, 186], "descend": 47, "argsort": 47, "ind": 47, "multibox_detect": [47, 60], "cls_prob": [47, 60], "nms_threshold": 47, "pos_threshold": 47, "009999999": 47, "conf": 47, "class_id": 47, "predicted_bb": 47, "all_idx": 47, "return_count": 47, "non_keep": 47, "all_id_sort": 47, "below_min_idx": 47, "pred_info": 47, "56": [47, 70, 71], "62": 47, "91": [47, 186], "greedi": [47, 132, 174, 189], "softli": [47, 120], "soft": [47, 94, 98, 120, 186], "bodla": [47, 186], "travel": [48, 153, 188, 190], "rout": [48, 77, 92], "vehicl": [48, 52, 59, 92], "pedestrian": 48, "road": [48, 99, 191], "obstacl": [48, 62, 101], "video": [48, 92, 96, 111, 113, 163, 179, 184, 186, 189], "navig": [48, 91, 92, 94, 149, 188, 190], "abnorm": 48, "intrud": 48, "bomb": 48, "spatial": [48, 49, 55, 58, 60, 61, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 100, 115, 149, 153, 186], "x1": [48, 80, 119, 138, 141, 145, 147, 148], "y1": [48, 60, 71], "cy": 48, "dog_bbox": 48, "cat_bbox": 48, "378": 48, "516": 48, "112": [48, 66, 186], "655": 48, "493": 48, "edgecolor": 48, "fcn": 49, "pretrained_net": [49, 50, 56], "model_zoo": [49, 50, 54, 56], "resnet18_v2": [49, 50], "320": [49, 59, 66], "480": [49, 59, 62, 66], "voc2012": [49, 52], "final_conv": 49, "transpose_conv": 49, "convtranspose2d": [49, 61, 82], "conv2dtranspos": [49, 61, 82], "upsampl": [49, 61, 62, 70], "bilinear": [49, 58, 160], "bilinear_kernel": 49, "og": 49, "filt": 49, "conv_tran": 49, "out_img": 49, "crop_siz": [49, 59], "load_data_voc": [49, 59], "wd": [49, 50, 53, 54, 60, 108, 158, 163, 165, 168], "weight_decai": [49, 50, 53, 54, 60, 108], "train_ch13": [49, 50, 51, 120, 121, 123, 124, 128, 160, 161], "normalize_imag": [49, 59], "_dataset": [49, 60], "label2imag": 49, "colormap": [49, 59], "voc_colormap": [49, 59], "indivis": [49, 185], "union": [49, 52, 132, 136, 140, 168], "times480": 49, "ground": [49, 55, 57, 58, 60, 78, 79, 92, 93, 94, 105, 107, 117, 119, 126, 153, 163, 165, 177, 187], "voc_dir": [49, 59], "vocdevkit": [49, 59], "read_voc_imag": [49, 59], "crop_rect": 49, "fixed_crop": [49, 59], "60000": [50, 86], "chair": [50, 59], "tenth": [50, 144], "monei": [50, 94, 130, 157], "fund": 50, "textur": [50, 56, 62, 77, 94], "1400": 50, "food": 50, "unzip": [50, 53, 54, 91], "hotdog": 50, "subfold": [50, 54], "fba480ffa8aa7e0febbb511d181409f899b9baa5": 50, "train_img": 50, "imagefold": [50, 53, 54, 82], "test_img": 50, "imagefolderdataset": [50, 53, 54, 82], "not_hotdog": 50, "rgb": [50, 53, 54, 56, 59, 64, 71, 82], "485": [50, 54, 56, 59], "456": [50, 54, 56, 59], "406": [50, 54, 56, 59], "229": [50, 54, 56, 59], "train_aug": [50, 51], "randomresizedcrop": [50, 51, 53, 54], "randomhorizontalflip": [50, 51, 53, 54], "test_aug": [50, 51], "centercrop": [50, 54], "randomflipleftright": [50, 51, 53, 54], "finetune_net": [50, 54], "in_featur": 50, "lr_mult": 50, "train_fine_tun": 50, "param_group": [50, 143], "params_1x": 50, "5e": [50, 53, 54, 60, 151], "scratch_net": 50, "grad_req": [50, 123, 124], "hotdog_w": 50, "934": 50, "713": 50, "prerequisit": [51, 94, 149, 151], "tweak": [51, 53, 92, 108, 149], "cat1": 51, "aug": 51, "hinder": 51, "randomverticalflip": 51, "randomfliptopbottom": 51, "shape_aug": 51, "satur": [51, 54], "hue": 51, "colorjitt": [51, 54], "randombright": 51, "randomhu": 51, "randomcolorjitt": [51, 54], "color_aug": 51, "cifar": [51, 52, 54, 62, 86, 191], "all_imag": 51, "cifar10": 51, "load_cifar10": 51, "train_batch_ch13": [51, 53, 121], "train_loss_sum": 51, "train_acc_sum": 51, "stale": [51, 121, 155], "ignore_stale_grad": [51, 121], "train_with_data_aug": 51, "init_cnn": [51, 62, 63, 64, 65, 66, 68, 69, 70, 74, 85, 88, 89], "medic": [52, 59, 92, 100, 101, 179], "diagnosi": [52, 100, 157], "camera": [52, 76, 94], "smart": [52, 62, 92, 94, 99], "insepar": 52, "augment": [52, 57, 59, 62, 67, 126, 186, 191], "style": [52, 67, 74, 94, 106, 149, 175, 186, 191], "materi": [52, 63, 94, 139, 149, 179], "anchor": [52, 58, 60, 191], "intersect": [52, 136, 140, 157], "iou": 52, "suppress": [52, 58, 60], "multiscal": [52, 60, 191], "multibox": [52, 58, 186, 191], "postprocess": [52, 103, 107, 114], "synthes": [52, 83, 105], "kaggl": [52, 112, 191], "breed": [52, 191], "identif": [52, 186, 191], "shutil": [53, 149], "50000": 53, "300000": 53, "290000": 53, "png": [53, 59], "airplan": [53, 59, 62, 103], "bird": [53, 59, 103], "deer": 53, "frog": 53, "hors": [53, 59], "boat": [53, 59], "truck": [53, 187], "7z": 53, "trainlabel": 53, "csv": [53, 54, 57, 113, 156, 159, 160, 161, 164], "samplesubmiss": 53, "sample_submiss": [53, 54], "submiss": [53, 54, 113], "demo": [53, 54], "cifar10_tini": 53, "kaggle_cifar10_tini": 53, "2068874e4b9a9f0fb07ebe0ad2b29754449ccacd": 53, "read_csv_label": [53, 54], "header": [53, 131], "readlin": [53, 119, 127], "rstrip": [53, 131, 159], "reorg_train_valid": [53, 54], "valid_ratio": [53, 54], "lfloor": [53, 75, 82, 180], "nr": 53, "rfloor": [53, 75, 82, 180], "45000": 53, "train_valid_test": [53, 54], "5000": [53, 180], "copyfil": 53, "target_dir": 53, "fewest": 53, "most_common": 53, "n_valid_per_label": 53, "label_count": 53, "train_fil": 53, "listdir": [53, 54, 122], "train_valid": [53, 54], "reorg_test": [53, 54], "test_fil": 53, "reorg_cifar10_data": 53, "transform_train": [53, 54], "4914": 53, "4822": 53, "4465": 53, "1994": [53, 62, 80, 101, 175, 186], "transform_test": [53, 54], "train_d": [53, 54], "train_valid_d": [53, 54], "valid_d": [53, 54], "test_d": [53, 54], "train_valid_it": [53, 54], "drop_last": [53, 54, 59], "valid_it": [53, 54], "last_batch": [53, 54, 59, 158, 160, 161, 164, 165, 168], "conv1": [53, 69], "conv2": [53, 69], "conv3": [53, 69], "bn1": [53, 69], "bn2": [53, 69], "lr_period": [53, 54], "lr_decai": [53, 54], "momentum": [53, 54, 63, 82, 86, 137, 138, 139, 141, 142, 147, 186, 191], "lr_schedul": [53, 54, 56, 143], "steplr": [53, 54, 56], "valid_acc": 53, "set_learning_r": [53, 54, 56, 143, 144], "retrain": [53, 54], "sorted_id": 53, "to_csv": [53, 113], "synset": [53, 54], "websit": [54, 91, 113, 131, 159, 164, 185], "10222": 54, "10357": [54, 186], "jpeg": 54, "labrador": 54, "poodl": [54, 92], "dachshund": 54, "samoi": 54, "huski": 54, "chihuahua": 54, "yorkshir": 54, "terrier": 54, "train_valid_test_tini": 54, "dog_tini": 54, "kaggle_dog_tini": 54, "0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d": 54, "reorg_dog_data": 54, "randomlight": 54, "34": [54, 98, 159, 186], "resnet34": 54, "output_new": 54, "resnet34_v2": 54, "l_sum": 54, "output_featur": 54, "valid_loss": 54, "num": 54, "561": [55, 186], "728": 55, "display_anchor": 55, "fmap": 55, "fmap_w": 55, "fmap_h": 55, "photographi": 56, "enthusiast": [56, 149], "photo": [56, 57, 83, 92, 94, 153], "sharper": 56, "portrait": 56, "whiten": [56, 144], "skin": [56, 92], "gati": [56, 67, 186], "rainier": 56, "nation": [56, 92, 103], "park": [56, 92, 186], "suburb": 56, "seattl": 56, "oil": [56, 103, 117], "paint": 56, "theme": [56, 63, 111], "autumn": 56, "oak": 56, "brush": 56, "stroke": [56, 92], "vivid": 56, "dash": [56, 85, 113, 157], "content_img": 56, "style_img": 56, "rgb_mean": [56, 59], "rgb_std": [56, 59], "image_shap": 56, "topilimag": 56, "imres": [56, 60], "vgg": [56, 60, 64, 66, 67, 68, 69, 191], "19": [56, 68, 70, 72, 85, 86, 88, 89, 90, 145, 157, 186], "vgg19": 56, "style_lay": 56, "content_lay": 56, "extract_featur": 56, "get_cont": 56, "get_styl": 56, "content_x": 56, "contents_i": 56, "style_x": 56, "styles_i": 56, "content_loss": 56, "_c": [56, 125, 134], "chw": 56, "gram_i": 56, "style_loss": 56, "dark": [56, 190], "denois": [56, 92, 186], "tv_loss": 56, "balanc": [56, 60, 119, 140, 146], "retent": 56, "content_weight": 56, "style_weight": 56, "tv_weight": 56, "1e4": 56, "compute_loss": 56, "contents_y_hat": 56, "styles_y_hat": 56, "styles_y_gram": 56, "contents_l": 56, "styles_l": 56, "tv_l": 56, "synthesizedimag": 56, "img_shap": 56, "get_init": 56, "gen_img": 56, "lr_decay_epoch": 56, "tv": [56, 59], "450": 56, "pil": [56, 149], "sceneri": 56, "banana": [57, 60, 180], "5de26c8fce5ccdea9f91267273464dc968d20d72": 57, "read_data_banana": 57, "csv_fname": 57, "bananas_train": 57, "bananas_v": 57, "csv_data": 57, "read_csv": [57, 113, 156, 164], "set_index": 57, "img_nam": 57, "iterrow": 57, "io": [57, 59, 60, 91, 127, 162], "read_imag": [57, 59, 60], "bananasdataset": 57, "load_data_banana": [57, 60], "val_it": 57, "edge_s": 57, "pioneer": [58, 92, 114], "girshick": [58, 186], "ren": [58, 69, 186], "uijl": [58, 186], "trainabl": [58, 63, 105, 114, 123, 144, 186], "h_2": [58, 110], "roi": 58, "subwindow": 58, "shall": [58, 74, 120, 167], "spatial_scal": 58, "roi_pool": 58, "output_s": 58, "pooled_s": 58, "yolo": 58, "redmon": [58, 67, 69, 186], "zhao": [58, 149, 186], "border": [59, 75], "mouth": 59, "mainli": [59, 60, 68, 92, 94, 167], "yellow": [59, 140], "voctrainval_11": 59, "4e443f8a2eca6b1dac8a6c57641b67dd40621a49": 59, "imageset": 59, "jpegimag": 59, "segmentationclass": 59, "voc": 59, "txt_fname": 59, "val": [59, 86, 96, 113, 165, 186], "imagereadmod": 59, "train_featur": [59, 122], "192": [59, 66], "voc_class": 59, "aeroplan": 59, "bicycl": 59, "bottl": [59, 92], "cow": 59, "diningt": 59, "motorbik": 59, "pot": 59, "plant": [59, 153, 157], "sheep": 59, "sofa": 59, "voc_colormap2label": 59, "voc_label_indic": 59, "colormap2label": 59, "105": [59, 186], "115": [59, 186], "130": 59, "140": 59, "inaccur": [59, 78], "voc_rand_crop": 59, "randomcrop": 59, "random_crop": 59, "vocsegdataset": 59, "vocsegdatas": 59, "voc_train": 59, "voc_test": 59, "autonom": [59, 94], "hwa": 60, "times3": [60, 62, 70, 71, 72, 75, 92, 123], "cls_predictor": 60, "num_input": [60, 100, 105, 108, 115, 120, 160, 161, 170, 171, 173, 175, 182, 183], "bbox_predictor": 60, "flatten_pr": 60, "start_dim": [60, 120, 126], "concat_pr": 60, "batch_flatten": 60, "down_sample_blk": 60, "times6": 60, "enlarg": [60, 82], "maxpool2d": [60, 62, 65, 66, 68, 69, 70, 76, 143], "times256": 60, "base_net": 60, "fifth": [60, 62, 66, 95, 186], "get_blk": 60, "adaptivemaxpool2d": 60, "globalmaxpool2d": 60, "blk_forward": 60, "cls_pred": 60, "bbox_pr": 60, "37": [60, 72, 114, 148, 186], "272": [60, 186], "447": 60, "619": 60, "79": [60, 113, 157, 186], "961": 60, "tinyssd": 60, "idx_to_in_channel": 60, "blk_i": 60, "blk_": 60, "cls_": 60, "bbox_": 60, "5444": 60, "cls_loss": 60, "bbox_loss": 60, "l1loss": 60, "calc_loss": 60, "cls_label": 60, "bbox_label": 60, "cls_eval": 60, "bbox_ev": 60, "cls_err": 60, "bbox_ma": 60, "err": [60, 92, 113, 149, 186], "smooth_l1": 60, "p_j": 60, "focal": [60, 63, 186], "gamma": [60, 63, 116, 143, 147, 186, 188, 189, 190], "misclassifi": [60, 92, 94], "focal_loss": 60, "downsampl": [61, 64, 70, 71, 74, 75, 76], "dumoulin": [61, 186], "visin": [61, 186], "n_w": [61, 82], "k_h": [61, 82], "k_w": [61, 82], "slide": [61, 72, 75, 76, 123], "trans_conv": 61, "tconv": 61, "c_i": [61, 64, 71, 80, 129, 140, 155], "mathsf": [61, 77, 109, 136, 153], "corr2d": [61, 71, 72, 76], "kernel2matrix": 61, "1995": [62, 63, 71, 73, 92, 96, 110, 111, 186], "realist": [62, 85, 96, 103, 159], "interven": 62, "1990": [62, 74, 76, 92, 96, 114, 149, 175, 176, 178, 186], "watersh": 62, "surpass": [62, 64, 104, 186], "sch": [62, 96, 101, 114, 186], "\u00f6": [62, 96, 101, 114, 163, 186], "lkopf": [62, 96, 101, 114, 186], "2002": [62, 92, 101, 114, 167, 177, 178, 186], "ensembl": [62, 98, 100, 163, 186], "freund": [62, 186], "schapir": [62, 186], "taskar": [62, 186], "2004": [62, 92, 141, 186], "lightli": 62, "pipelin": [62, 86, 92, 94, 107, 115, 156, 185], "sift": [62, 92], "surf": [62, 186], "2006": [62, 78, 113, 149, 163, 186], "sivic": [62, 186], "zisserman": [62, 66, 67, 70, 114, 186], "2003": [62, 78, 98, 181, 186], "hartlei": [62, 186], "afterthought": 62, "multichannel": 62, "geforc": 62, "1999": [62, 76, 98, 107, 149, 164, 186], "mflop": [62, 96], "tflop": 62, "ocr": [62, 74], "glorot": [62, 116, 186], "bengio": [62, 116, 175, 181, 186], "kingma": [62, 63, 92, 139, 186], "squash": [62, 114], "nair": [62, 114, 186], "hinton": [62, 114, 147, 186], "sensor": [62, 63, 72, 92, 96, 103, 156, 184], "quicktak": 62, "sport": [62, 68, 98], "megapixel": [62, 77, 101], "vga": 62, "occasion": [62, 126, 178], "serendipit": [62, 63], "discoveri": [62, 95, 186], "graduat": [62, 149], "extractor": [62, 92], "robust": [62, 63, 78, 79, 88, 94, 100, 104, 108, 139, 140, 146, 178, 183, 186], "opencv": 62, "dump": [62, 92], "favorit": 62, "spoke": [62, 157], "repli": [62, 92, 176], "beauti": [62, 64, 92, 131, 145], "boucheron": [62, 95, 101, 186], "2005": [62, 92, 95, 101, 174, 186], "boyd": [62, 141, 186], "vandenbergh": [62, 141, 186], "thrive": 62, "emin": 62, "hear": [62, 92], "dirti": [62, 93, 153, 155], "kahl": [62, 186], "drove": [62, 94], "justifi": [62, 68, 92, 101, 102, 148], "affair": 62, "promin": [62, 92, 175, 179], "hog": 62, "histogram": [62, 122, 133, 176, 186], "dalal": [62, 186], "trigg": [62, 186], "roost": 62, "yann": [62, 74], "geoff": 62, "yoshua": 62, "andrew": [62, 81, 149], "ng": [62, 92, 186], "shun": 62, "ichi": 62, "amari": 62, "juergen": 62, "schmidhub": [62, 92, 174, 175, 186], "ought": [62, 100, 105, 109], "olshausen": [62, 186], "advent": [62, 92, 167], "traction": 62, "inventor": [62, 63, 114], "evolutionari": 62, "reproduct": [62, 74, 110], "descriptor": [62, 186], "nose": 62, "blade": 62, "grass": 62, "frisbe": 62, "beg": [62, 88], "tighter": 62, "uci": [62, 156], "deng": [62, 73, 96, 101, 186], "noun": [62, 92, 117, 132], "wordnet": 62, "miller": [62, 186], "prefilt": 62, "turk": 62, "crowdsourc": 62, "unpreced": [62, 167], "exceed": [62, 92], "tinyimag": 62, "torralba": [62, 186], "thumbnail": 62, "dub": 62, "russakovski": [62, 186], "academ": [62, 92, 109, 149], "laion": [62, 64, 186], "5b": [62, 64], "schuhmann": [62, 64, 186], "metadata": 62, "voraci": 62, "strikingli": [62, 171], "ati": [62, 149], "begun": [62, 67, 95], "fernando": [62, 186], "market": [62, 92, 94, 122, 159, 179], "gpgpu": 62, "microprocessor": 62, "megabyt": [62, 74, 155], "specul": [62, 63], "bell": [62, 74, 96, 105, 186], "whistl": [62, 105], "appar": [62, 114, 167], "strength": [62, 64, 66, 111, 161], "achil": 62, "heel": 62, "alu": 62, "aforement": [62, 69, 109, 116, 125, 126, 127, 128, 132, 146, 150, 165, 177], "nivida": 62, "6912": 62, "warp": 62, "weak": [62, 186], "1ghz": 62, "bfloat16": [62, 99], "graviton": 62, "m1": [62, 153], "flop": [62, 64, 186], "ilya": [62, 186], "580": [62, 186], "convnet": [62, 73, 98, 186], "coupl": [62, 94, 157, 186], "transcend": 62, "quirk": 62, "sigmoid": [62, 63, 74, 83, 116, 125, 135, 143, 158, 160, 161, 165, 166, 173, 175, 186], "delv": [62, 94, 116, 145, 149, 186], "times11": 62, "taller": [62, 132], "occupi": [62, 68, 89], "times5": 62, "4096": [62, 70, 168], "1gb": 62, "buslaev": [62, 186], "384": [62, 66, 68, 85, 144], "pool_siz": [62, 63, 65, 66, 68, 69, 70, 74, 76, 143], "max_pool": [62, 65, 66, 68, 69, 70, 76, 168], "window_shap": [62, 63, 64, 65, 66, 69, 70, 74, 76], "layer_summari": [62, 64, 66, 68, 69, 70, 74], "faith": 62, "costli": [62, 66, 69, 103, 108, 141, 170, 175], "strike": [62, 72, 92, 149, 169], "dozen": [62, 78, 116], "6400": 62, "164": 62, "81": [62, 78, 157, 186], "outlai": 62, "mobil": [62, 68, 92, 159, 162], "shallow": [62, 70, 92, 102, 109], "hardli": [62, 75, 76, 98, 116, 179], "embrac": [62, 77, 149], "conceptu": [62, 64, 92, 115, 126], "distbelief": [62, 104], "caff": [62, 92, 104, 186], "jia": [62, 92, 104, 186], "bergstra": [62, 86, 104, 186], "abadi": [62, 104, 186], "ioff": [63, 66, 114, 144, 186], "szegedi": [63, 66, 67, 71, 114, 186], "secondari": [63, 86, 114], "functool": [63, 93, 99, 100, 110, 149, 177], "optax": [63, 93, 99, 104, 105, 106, 108, 110, 149, 177], "hous": [63, 65, 91, 92, 98, 103, 112, 157, 186, 187, 188, 191], "1987": [63, 72, 92, 186], "uniti": 63, "guyon": [63, 186], "constrain": [63, 64, 73, 79, 86, 96, 108, 111, 114, 140, 157], "celebr": [63, 92, 103], "vapnik": [63, 95, 101, 105, 186], "novikoff": [63, 186], "1962": [63, 72, 92, 186], "cousin": 63, "postul": 63, "drift": [63, 168], "hamper": 63, "conjectur": 63, "compensatori": 63, "solver": [63, 145, 148, 157, 186], "adagrad": [63, 137, 141, 142, 147, 191], "duchi": [63, 138, 186], "yogi": [63, 142], "zaheer": [63, 139, 186], "shampoo": 63, "liabl": 63, "bishop": [63, 78, 92, 110, 149, 186], "devot": [63, 92, 108, 157], "takeawai": [63, 110], "calibr": [63, 137], "odot": [63, 109, 136, 137, 139, 147, 153, 165, 173, 175], "aggress": [63, 77, 95, 138, 148], "counteract": [63, 178], "noisi": [63, 78, 86, 90, 103, 111, 145, 148, 159, 167], "recur": [63, 184], "tey": [63, 186], "luo": [63, 186], "shed": [63, 92, 117, 148], "light": [63, 92, 95, 105, 117, 148, 157, 190], "puzzl": 63, "moder": [63, 64, 79, 90, 116, 145], "resid": 63, "nonlinear": [63, 64, 65, 68, 69, 70, 71, 77, 82, 92, 103, 108, 116, 148, 158, 160, 165, 186], "luxuri": 63, "exhibit": [63, 66, 77, 88, 92, 113, 114, 116, 140, 178, 184], "batch_norm": [63, 65, 82], "moving_mean": 63, "moving_var": 63, "is_grad_en": 63, "x_hat": 63, "keepdim": [63, 100, 153, 157, 160, 161, 166], "reciproc": [63, 180], "inv": [63, 78], "rsqrt": 63, "bookkeep": [63, 87, 88, 90], "num_featur": 63, "num_dim": 63, "batch_stat": [63, 74, 93, 105, 106], "weight_shap": 63, "moving_vari": 63, "assign_moving_averag": 63, "batch_mean": 63, "batch_vari": 63, "squared_differ": 63, "stop_gradi": [63, 150], "mean_upd": 63, "variance_upd": 63, "add_upd": 63, "misnom": [63, 72, 103], "whatsoev": 63, "bnlenetscratch": 63, "avgpool2d": [63, 65, 74, 143], "84": [63, 70, 74, 143], "avg_pool": [63, 64, 65, 66, 68, 69, 74], "trainstat": [63, 106, 110], "mutat": 63, "static_argnum": [63, 93, 99, 100, 110, 177], "apply_fn": [63, 93, 99, 100, 104, 105, 106, 110, 177], "dropout_rng": [63, 105, 106, 110, 177], "fn": [63, 99, 104, 110, 177], "softmax_cross_entropy_with_integer_label": [63, 99, 110, 177], "get_dataload": [63, 66, 68, 69, 70, 74, 85, 88, 89, 96, 106, 107, 108, 113, 176, 180, 184], "layers_1": 63, "bnlenet": 63, "lazybatchnorm2d": [63, 64, 65, 69], "unseen": [63, 77, 92, 95, 101, 103, 110, 111, 149, 151], "refin": [63, 76, 139, 143], "presum": 63, "delin": [63, 76], "hunch": 63, "broader": [63, 72, 97, 149, 157], "award": 63, "neurip": [63, 80], "ali": [63, 149, 186], "rahimi": [63, 149], "liken": [63, 92], "alchemi": 63, "steinhardt": [63, 186], "santurkar": [63, 186], "worthi": [63, 92, 94], "vagu": [63, 92], "reson": 63, "broad": [63, 92, 101, 111, 126, 167], "audienc": [63, 99], "proven": [63, 72, 82, 140, 142, 150, 158, 174, 181], "earn": [63, 92, 157, 186, 188], "lite": [63, 186], "displac": [63, 67, 149], "monarch": 63, "sparsif": 63, "tour": [64, 67], "tremend": [64, 68, 74, 92, 113, 174], "beat": [64, 67, 92, 101, 149, 180], "nin": [64, 66, 67, 191], "googlenet": [64, 67, 69, 191], "incept": [64, 67, 69, 186], "testament": 64, "resnext": [64, 67, 71, 191], "senet": 64, "zoph": [64, 186], "brute": [64, 66, 67], "genet": [64, 66, 92], "efficientnet": 64, "tan": [64, 186], "quest": [64, 68, 70, 111], "radosavov": [64, 67, 69, 186], "regnetx": [64, 67, 69], "regneti": 64, "regressor": [64, 83, 92, 166], "quarter": [64, 76], "d_i": [64, 151], "g_i": [64, 151], "k_i": 64, "c_0": [64, 80], "c_4": 64, "rightmost": 64, "afford": [64, 72, 101, 104, 139], "d_1": [64, 157], "d_4": 64, "k_1": [64, 71, 80], "k_4": 64, "g_1": 64, "g_4": 64, "warrant": [64, 93], "arch": [64, 65, 69, 70], "stem_channel": 64, "create_net": [64, 65, 69], "bot_mul": [64, 69], "resnextblock": [64, 69], "131072": 64, "exorbit": 64, "sensibl": [64, 85, 86, 180], "needl": 64, "haystack": 64, "reliabl": [64, 78, 92, 104, 111, 144, 189, 190], "guidanc": [64, 95, 111, 149, 154, 157], "proxi": [64, 87, 90, 138, 143], "forrest": [64, 186], "cheapli": 64, "cdf": 64, "disribut": 64, "e_n": 64, "indiffer": [64, 76], "rid": [64, 89, 141], "unconstrain": [64, 186], "corresond": 64, "iv": [64, 105, 126, 149, 150, 151, 152, 169, 186], "multitud": [64, 92], "anynetx": 64, "_d": [64, 138], "_e": 64, "c_j": [64, 80, 129], "c_a": 64, "piecewis": [64, 114, 143, 148, 150], "perus": [64, 149], "c_1": [64, 80, 140], "c_2": [64, 140], "d_2": [64, 157], "se": 64, "regnetx32": 64, "backport": 64, "hopper": 64, "widen": [64, 68], "prevail": 64, "400m": 64, "tolstikhin": [64, 186], "trump": 64, "invit": [64, 88], "ifi": 64, "vionet": 64, "b_i": [64, 129, 163, 175], "extrapol": [64, 184, 186], "preced": [65, 90, 127, 174, 177], "f_3": 65, "conv_block": 65, "convblock": 65, "listlay": 65, "denseblock": 65, "num_conv": [65, 70], "transition_block": 65, "transitionblock": 65, "growth_rat": 65, "dense_blk": 65, "tran_blk": 65, "pleiss": [65, 186], "simonyan": [66, 67, 70, 114, 186], "cocktail": 66, "ingeni": [66, 138], "meme": 66, "movi": [66, 92, 98, 122, 123, 124, 126, 149, 159, 162, 163, 164, 167, 168, 184, 186, 187], "capac": [66, 69, 86, 92, 108, 112, 184], "c1": [66, 106], "c2": [66, 106], "c3": [66, 106], "b1_1": 66, "b2_1": 66, "b2_2": 66, "b3_1": 66, "b3_2": 66, "b4_1": 66, "b4_2": 66, "b5": 66, "tripl": [66, 173, 175, 178, 185], "208": 66, "288": 66, "528": [66, 186], "832": 66, "144": 66, "grant": [66, 92, 94, 105, 116, 144, 151], "flux": 66, "deliber": [66, 92], "proud": 66, "necess": 67, "incomplet": [67, 186], "Their": [67, 106, 110, 139, 149], "farhadi": [67, 69, 186], "winner": 67, "runner": 67, "baromet": 67, "trial": [67, 85, 86, 87, 88, 89, 90, 149, 157, 189, 190], "chronolog": [67, 168], "histori": [67, 85, 92, 139, 147, 150, 167, 179, 183, 184], "convolv": 67, "shelf": [67, 92, 94, 127], "xie": [67, 69, 71, 149, 186], "densenet": [67, 186, 191], "shiftnet": [67, 69], "wu": [67, 69, 127, 149, 186], "culmin": [67, 74, 174], "mobilenet": 67, "v3": [67, 186], "howard": [67, 186], "semi": [67, 186], "insofar": [67, 74, 92, 101, 111, 147], "marri": [67, 149], "ingenu": [67, 69, 92], "pivot": [67, 97, 102, 167], "anynet": 67, "regnet": 67, "deepen": 68, "pose": [68, 92, 96, 114, 115, 116, 157, 178], "monstrou": 68, "400mb": 68, "impedi": 68, "iphon": [68, 92], "512mb": 68, "nin_block": 68, "obviat": [68, 184], "cater": 68, "bet": 69, "argmin": [69, 86, 103, 140, 158, 163], "morozov": [69, 186], "1984": [69, 114, 186], "tikhonov": [69, 110, 186], "arsenin": [69, 186], "1977": [69, 186], "subseteq": [69, 157], "_3": [69, 178, 181], "_6": 69, "newli": [69, 103, 150, 155], "profound": [69, 92, 95, 157], "kim": [69, 123, 149, 186], "prakash": [69, 149, 186], "kipf": [69, 73, 186], "predat": [69, 103], "highwai": [69, 186], "globalavg2d": 69, "smorgasbord": 69, "fittingli": 69, "proportion": 69, "amend": [69, 139], "sandwich": 69, "duti": 69, "ill": [69, 94], "bot_channel": 69, "bn3": 69, "conv4": 69, "bn4": 69, "feature_group_count": 69, "resnetblock": 69, "gate": [69, 149, 171, 174, 186, 191], "frugal": 69, "mimick": 69, "vlsi": [70, 186], "mead": [70, 186], "1980": [70, 74, 92, 115, 150, 186], "grown": 70, "repurpos": 70, "oxford": [70, 94], "eponym": 70, "subroutin": 70, "counterpart": [70, 92, 104, 109, 153], "stapl": [70, 179], "lavin": [70, 186], "grai": [70, 78, 186], "vgg_block": 70, "dimenson": 70, "undergon": 70, "conv_blk": 70, "xml": 70, "parnet": 70, "goyal": [70, 186], "k_": [71, 72, 75, 78, 79, 80], "times4": [71, 123], "times0": [71, 72, 75, 169], "corr2d_multi_in": 71, "0th": [71, 123], "respond": [71, 72, 77, 92, 94], "detector": [71, 72, 77, 92, 94, 186], "corr2d_multi_in_out": 71, "adjac": [71, 72, 73, 76, 123, 179, 180, 181, 184], "constitut": [71, 92, 100, 101, 108, 153, 157, 171, 185, 186], "corr2d_multi_in_out_1x1": 71, "c_o": 71, "k_2": [71, 80], "s_": [71, 75, 76, 78, 168, 188, 189, 190], "scan": [71, 74, 92, 171, 173, 175], "broken": [71, 116, 144, 157, 189], "subtensor": [72, 76, 123], "43": [72, 115, 186], "wholli": 72, "pars": [72, 92], "partial_i": [72, 138, 151], "3e": 72, "value_and_grad": [72, 93, 106, 183], "watch_accessed_vari": 72, "set_weight": 72, "strict": 72, "noteworthi": [72, 119, 126, 181], "unaffect": 72, "neurophysiologi": 72, "stimuli": 72, "hubel": [72, 186], "wiesel": [72, 186], "1959": [72, 186], "1968": [72, 95, 186], "reprint": 72, "diagram": [72, 98, 103, 145, 157, 175], "kuzovkin": [72, 186], "biologi": [72, 73, 92], "hindsight": [72, 89], "herald": 72, "door": 72, "blur": [72, 98], "sharpen": [72, 157], "delightfulli": 72, "brain": [72, 92, 114, 179], "strongli": [72, 78, 79, 86, 92, 99, 106, 157], "monochromat": 73, "irrespect": [73, 189, 190], "unsatisfi": [73, 95], "imagnet": 73, "colloqui": [73, 98], "healthi": [73, 94, 157], "dose": 73, "tinker": 73, "chetlur": [73, 186], "credibl": [73, 78, 79], "competitor": [73, 162], "audio": [73, 75, 77, 83, 92, 113, 156], "abdel": [73, 186], "hamid": [73, 186], "ingredi": [74, 86, 92, 114], "cloth": [74, 92, 96, 114, 187], "amen": [74, 92, 114], "times28": 74, "parsimoni": 74, "AT": [74, 96], "1989": [74, 77, 103, 114, 150, 186], "outstand": 74, "deposit": [74, 92, 126, 130, 170], "atm": 74, "colleagu": [74, 149], "leon": [74, 186], "bottou": [74, 103, 104, 186], "functiontyp": [74, 149], "remind": [74, 92], "liberti": [74, 186], "tabul": 74, "nifti": 74, "summaris": 74, "bind": 74, "__class__": 74, "__name__": [74, 106, 143, 149], "bound_model": 74, "compens": [74, 94, 138], "trim": [74, 92, 119], "forgo": [74, 95, 104], "fare": [74, 95], "particip": [74, 113, 181], "sn": [74, 186], "lisp": [74, 104, 114], "cun": [74, 104, 186], "rabbit": 74, "hole": [74, 189, 190], "sweater": 74, "wind": [75, 92, 101], "240": 75, "obliter": 75, "perimet": 75, "filler": 75, "lceil": 75, "rceil": 75, "cleric": 75, "elev": 75, "comp_conv2d": 75, "undesir": [75, 92, 145, 155, 178], "shrinkag": 75, "whitespac": [75, 119], "alsallakh": [75, 186], "gradual": [76, 92, 94, 134, 141], "tripod": 76, "stationari": [76, 80, 94, 103, 143, 184, 186], "vibrat": 76, "movement": [76, 167], "shutter": 76, "slid": 76, "riesenhub": [76, 186], "poggio": [76, 186], "cognit": [76, 92, 151, 179, 186], "neurosci": [76, 92, 103], "yamaguchi": [76, 186], "pool2d": 76, "p_h": [76, 82], "p_w": [76, 82], "needless": 76, "overrid": [76, 166], "x_pad": 76, "syntax": [76, 92, 103, 106, 131], "exceedingli": [76, 141], "zeiler": [76, 137, 186], "fergu": [76, 186], "graham": [76, 186], "fancier": [77, 102, 113], "perceptu": [77, 92], "structureless": 77, "thorough": [77, 138, 149], "annot": [77, 92, 94, 106, 146, 186], "photograph": [77, 83, 92, 94, 101, 157], "talent": [77, 92], "extraordinari": [77, 81, 101], "patienc": [77, 111], "grossli": [77, 95], "underestim": [77, 95], "pig": [77, 170], "swim": 77, "waldo": 77, "chaotic": 77, "lurk": 77, "him": [77, 101], "distract": [77, 102], "sweep": 77, "murphi": 77, "infomatiqu": 77, "desiderata": 77, "equivari": 77, "distant": [77, 92, 186], "sink": 77, "sum_l": 77, "sum_a": [77, 153, 157, 190], "sum_b": 77, "cosmet": [77, 139], "vicin": [77, 146], "tdnn": 77, "waibel": [77, 186], "glean": 77, "paid": 77, "desideratum": 77, "rudin": [77, 186], "1973": [77, 103, 186], "summabl": 77, "weigh": [77, 94], "wherev": [77, 129], "blissfulli": 77, "multidimension": [77, 140, 155], "sum_c": 77, "neighborhood": [77, 94], "neocognitron": [77, 186], "fukushima": [77, 186], "satellit": [77, 92], "agricultur": 77, "meteorologi": 77, "hyperspectr": [77, 96], "wavelength": [77, 105], "spectrogram": 77, "ll": [78, 163, 186], "land": [78, 187], "temperatur": [78, 94, 98, 105, 114, 153, 183, 189], "co_2": 78, "concentr": [78, 79, 108], "textbf": [78, 165], "rbf": [78, 79, 81, 114], "ell": [78, 79, 80, 165, 186, 189], "aka": 78, "2i": [78, 153], "m_": [78, 146], "amplitud": [78, 79, 80, 92], "lengthscal": [78, 79, 80], "compartment": 78, "occam": 78, "razor": 78, "mackai": [78, 98, 186], "ch": 78, "rasmussen": [78, 186], "pyplot": [78, 89, 149, 151], "scipi": [78, 80, 85, 86, 90, 149], "distance_matrix": [78, 80, 149], "choleski": 78, "reput": 78, "jitter": 78, "data_maker1": 78, "sig": 78, "train_x": 78, "test_x": 78, "train_i": [78, 164], "test_i": [78, 164], "rbfkernel": [78, 80], "prior_sampl": [78, 80], "multivariate_norm": [78, 80], "diag": [78, 138, 141], "f_": [78, 94, 95, 151], "ell_est": 78, "post_sig_est": 78, "neg_mll": 78, "par": 78, "kernel_term": 78, "logdet": 78, "const": 78, "learned_hyp": 78, "299": 78, "immun": 78, "k_x_xstar": 78, "k_x_x": 78, "k_xstar_xstar": 78, "post_mean": 78, "post_cov": 78, "lw_bd": [78, 80], "up_bd": [78, 80], "func": [78, 86, 140], "orang": [78, 79, 98], "lw_bd_observ": 78, "up_bd_observ": 78, "epistem": [78, 79, 157, 186], "aleator": [78, 157], "meaningless": [78, 125, 143], "spirit": [78, 92, 160], "posteriori": 78, "post_sampl": 78, "mont": [78, 92], "carlo": [78, 92], "acquisit": [78, 157], "cumbersom": [78, 141, 190], "ski": [78, 149], "kiss": 78, "exactgpmodel": 78, "exactgp": 78, "mean_modul": 78, "zeromean": 78, "covar_modul": 78, "scalekernel": 78, "mean_x": 78, "covar_x": 78, "multivariatenorm": 78, "matern_kernel": 78, "gpyotrch": 78, "spectral_mixture_kernel": 78, "gaussianlikelihood": 78, "training_it": 78, "mll": 78, "exactmarginalloglikelihood": 78, "mini": [78, 85, 86, 186, 189], "bfg": [78, 186], "inclin": [78, 94, 153], "calc": 78, "base_kernel": 78, "observed_pr": 78, "codeblock": 78, "confidence_region": 78, "283": [78, 186], "autocorrel": 78, "covariogram": 78, "biggest": [78, 131, 156, 183], "lkelihood": 78, "optima": [78, 86, 146, 186], "plausibli": [78, 83], "room": [78, 92, 156], "matern": 78, "spectral": [78, 105, 153], "valuabl": [78, 149], "versu": [78, 79, 89, 95, 156, 157], "uninterpret": [79, 80, 163], "carbon": 79, "dioxid": 79, "forecast": [79, 94, 103, 184], "posterior": [79, 80, 81, 108, 157, 166], "radial": [79, 81, 114], "wiggli": 79, "pronounc": [79, 108, 153], "gp": [79, 80, 81], "uncorrel": 79, "contour": [79, 141], "ellips": 79, "stronger": [79, 92, 94, 184], "83": [79, 186], "righli": 79, "introductori": [79, 81, 149], "delta_": [79, 148], "wiggili": 79, "Will": 79, "inaccess": 80, "langl": [80, 136, 148, 153, 161], "rangl": [80, 136, 148, 153, 161], "acquaint": 80, "w_0": [80, 101], "intercept": [80, 103], "lin_func": 80, "n_sampl": 80, "x_point": 80, "w_1x": 80, "w_0w_1x": 80, "w_1w_0x": 80, "2xx": 80, "phi_i": 80, "centr": 80, "w_j": [80, 129, 134], "riemann": 80, "phi_c": 80, "apart": [80, 83, 85, 86, 95, 153, 164, 168], "propto": [80, 98, 108, 157, 166, 183, 185], "absorb": 80, "fuss": 80, "overparametr": 80, "misplac": 80, "wilson": [80, 81, 186], "izmailov": [80, 103, 140, 143, 186], "meanvec": 80, "covmat": 80, "neal": [80, 186], "infam": 80, "tangent": [80, 96, 111, 114, 151, 186], "matthew": [80, 149, 186], "novak": [80, 186], "sigma_b": 80, "sigma_v": 80, "h_i": 80, "u_0": 80, "u_j": 80, "dt": 80, "tau": [80, 145, 178, 184, 188, 190], "stationar": [80, 184], "ornstein": 80, "uhlenbeck": 80, "ou": 80, "m_1": 80, "m_2": 80, "gordon": [81, 186], "york": [81, 92, 124, 134, 186], "ubitiqu": 81, "joke": 81, "spatiotempor": 81, "harmon": 81, "gpytorch": [81, 186], "gardner": [81, 149, 186], "complementari": 81, "tradiat": 81, "upcom": [81, 92], "gan": [82, 83, 186], "dcgan": 82, "borrow": [82, 169], "sprite": 82, "pokemondb": 82, "c065c0e2593b8b161a2d7873e42418bf6a21106c": 82, "image_dataset_from_directori": 82, "image_s": 82, "transform_func": 82, "num_parallel_cal": 82, "autotun": 82, "prefetch": 82, "filterwarn": 82, "g_block": 82, "conv2d_tran": 82, "s_h": 82, "s_w": [82, 137, 138, 139, 147], "2p_h": 82, "2p_w": 82, "g_blk": 82, "n_g": 82, "net_g": [82, 83], "leaki": [82, 137, 139, 147], "leakyrelu": 82, "d_block": 82, "inplac": 82, "d_blk": 82, "n_d": 82, "net_d": [82, 83], "outupt": 82, "fight": 82, "latent_dim": [82, 83], "bcewithlogitsloss": [82, 83], "trainer_hp": 82, "999": [82, 139], "trainer_d": [82, 83], "trainer_g": [82, 83], "subplots_adjust": [82, 83], "hspace": [82, 83], "loss_d": [82, 83], "loss_g": [82, 83], "update_d": [82, 83], "update_g": [82, 83], "synthet": [82, 83, 92, 94, 102, 105, 108, 156, 157, 184, 191], "fake_x": [82, 83], "sigmoidbceloss": [82, 83, 135], "beta1": [82, 139], "binarycrossentropi": [82, 83], "optimizer_hp": 82, "beta_2": [82, 139], "optimizer_d": [82, 83], "optimizer_g": [82, 83], "0005": 82, "upend": 83, "useless": [83, 95, 184], "spiel": 83, "astoundingli": 83, "overcom": [83, 86, 114, 174, 184], "goodfellow": [83, 92, 149, 186], "fake": [83, 92], "hei": [83, 92], "fool": [83, 92], "min_d": 83, "max_g": 83, "min_g": 83, "minimax": 83, "lamest": 83, "ta": [83, 132], "transpose_a": 83, "liter": [83, 92, 110, 155], "real_i": 83, "fake_i": 83, "grads_d": 83, "recomput": 83, "bcewithlogit": 83, "grads_g": 83, "logist": [83, 86, 92, 94, 98, 114, 171, 179], "lr_d": 83, "lr_g": 83, "equilibrium": 83, "unabl": [83, 101], "discrimin": [84, 92, 94, 186], "pokemon": 84, "methodologi": 85, "hposearch": [85, 90], "hposchedul": [85, 90], "hpotun": [85, 90], "syne": [85, 88, 89, 186], "salina": [85, 88, 186], "rai": 85, "liaw": [85, 186], "optuna": [85, 186], "akiba": [85, 186], "stat": [85, 86, 90, 186], "sample_configur": [85, 90], "additional_info": [85, 90], "prescrib": 85, "initial_config": [85, 88, 89, 90], "randomsearch": [85, 88, 90], "config_spac": [85, 86, 88, 89, 90], "rv": [85, 86], "deleg": 85, "info": [85, 88, 89, 90], "basicschedul": [85, 88], "callabl": 85, "bookeep": 85, "incumb": [85, 88], "incumbent_error": 85, "incumbent_trajectori": 85, "cumulative_runtim": 85, "current_runtim": 85, "number_of_tri": [85, 90], "start_tim": 85, "wall": [85, 88, 89, 90, 133, 140], "sequel": 85, "trajectori": [85, 88, 92, 138, 141, 145, 147, 148, 184, 188, 189, 190], "hpo_objective_lenet": [85, 90], "hpotrain": [85, 86, 88, 89], "validation_error": [85, 86, 88, 89], "loguniform": [85, 86, 88, 89, 90], "time_stamp": 85, "median": [85, 113], "snoek": [85, 186], "laid": [85, 92, 149, 155], "dropoutmlp": [85, 88, 110], "num_hiddens_1": [85, 110], "num_hiddens_2": [85, 110], "dropout_1": [85, 110], "dropout_2": [85, 110], "probab_loc": 85, "num_init_random": 85, "attain": [85, 95, 140], "localsearch": [85, 88], "optimum": [86, 146], "workflow": [86, 149], "elast": 86, "bardenet": [86, 186], "feurer": [86, 186], "wistuba": [86, 186], "hpo": [86, 87, 88, 89, 90], "tackl": [86, 92, 95, 103, 111, 184], "hutter": [86, 143, 186], "elsken": [86, 186], "automl": 86, "softmaxregress": [86, 99], "criterion": [86, 88, 101, 103, 111, 162, 166], "franceschi": [86, 186], "maclaurin": [86, 186], "hypergradi": 86, "burden": 86, "val_batch_idx": [86, 105, 106], "val_dataload": [86, 96, 100, 105, 106], "hpo_objective_softmax_classif": 86, "num_output": [86, 99, 100, 110, 115, 120], "lear": [86, 189], "ning": 86, "loat": 86, "atch": 86, "eger": 86, "mome": 86, "ntum": 86, "ac": 86, "tiva": 86, "tion": 86, "egor": 86, "ical": 86, "ath": [86, 186], "nu": 86, "mber": 86, "nit": 86, "la": [86, 186], "yer": 86, "baptista": [86, 186], "poloczek": [86, 186], "jenatton": [86, 186], "num_iter": 86, "best_idx": 86, "shortcom": 86, "poorli": [86, 90, 108, 140, 180], "phrase": [86, 124, 132, 134, 180, 184, 186], "curs": [86, 99], "bellman": [86, 186, 188, 190], "1966": [86, 186], "loader": [86, 96, 102, 105, 106, 115, 180], "problemat": [86, 94, 101], "rough": 86, "sheer": [86, 104], "unpract": 86, "baselin": [86, 88, 89, 98, 102, 113, 157, 163, 180], "equi": 86, "combinatori": [86, 186], "cartesian": 86, "sizabl": 86, "aaron": 87, "klein": [87, 186], "matthia": [87, 149], "seeger": [87, 186], "cedric": 87, "archambeau": [87, 186], "suboptim": [87, 89, 90, 92, 143], "searcher": [87, 88, 90], "tuner": [87, 88, 89, 90], "synchronis": [88, 89], "straggler": [88, 89], "basicconfig": [88, 89], "syne_tun": [88, 89], "stoppingcriterion": [88, 89], "python_backend": [88, 89], "pythonbackend": [88, 89], "load_experi": [88, 89], "hpo_objective_lenet_synetun": [88, 89], "fit_epoch": [88, 89, 104, 105, 106, 110, 183], "n_worker": [88, 89], "max_wallclock_tim": [88, 89], "trial_backend": [88, 89], "tune_funct": [88, 89], "behaviour": [88, 186], "points_to_evalu": [88, 89], "mediat": [88, 94], "stop_criterion": [88, 89], "print_update_interv": [88, 89], "tuning_experi": 88, "trial_id": [88, 89], "st_tuner_tim": [88, 89], "marker": [88, 89], "hpo_objective_dropoutmlp_synetun": 88, "facil": 88, "bayesianoptim": 88, "sh": [89, 91], "rung": [89, 90], "promot": [89, 90, 92], "idel": 89, "implementaiton": 89, "asha": 89, "favour": 89, "pend": [89, 168, 171], "min_number_of_epoch": [89, 90], "max_number_of_epoch": [89, 90], "resource_attr": 89, "max_resource_attr": 89, "grace_period": 89, "reduction_factor": 89, "underperform": 89, "paus": [89, 94, 185], "resum": [89, 92], "sped": 90, "defaultdict": [90, 132, 149, 159, 177], "jamieson": [90, 186], "talwalkar": [90, 186], "karnin": [90, 186], "surviv": [90, 92, 98, 152], "successivehalvingschedul": 90, "r_min": 90, "r_max": 90, "prefact": 90, "rung_level": 90, "observed_error_at_rung": 90, "all_observed_error_at_rung": 90, "n0": 90, "pop": [90, 92, 103, 121, 149, 179], "ri": 90, "kiplus1": 90, "niplus1": 90, "best_performing_configur": 90, "get_top_n_configur": 90, "riplus1": 90, "sorted_rung": 90, "vanilla": [90, 171, 173, 175, 182, 186], "rung_index": 90, "xi": [90, 140, 141, 148, 175], "macosx": 91, "mac": 91, "py39_4": 91, "cmd": 91, "horsepow": 91, "nvcc": 91, "cu112": 91, "cu101": 91, "cu90": 91, "cuda11_pip": 91, "googleapi": 91, "jax_cuda_releas": 91, "html": 91, "fetch": [91, 177], "mkdir": 91, "curl": 91, "rm": [91, 113, 137], "exit": [91, 92], "deactiv": 91, "rigid": [92, 95], "huddl": 92, "whiteboard": 92, "settl": [92, 98, 149], "transact": [92, 157], "spell": [92, 94, 153, 175, 180, 186], "shop": [92, 162], "cart": 92, "kink": 92, "feat": [92, 149, 158, 159], "devis": 92, "bend": 92, "smartest": 92, "tomorrow": [92, 94, 101], "weather": [92, 149, 184], "geograph": [92, 94, 186], "factoid": 92, "brows": [92, 167], "elit": 92, "gracefulli": 92, "consciou": 92, "subconsci": 92, "accru": [92, 175], "healthcar": [92, 157], "genom": 92, "caffein": 92, "siri": 92, "awaken": 92, "voic": 92, "transcript": 92, "app": [92, 130, 162], "fulfil": 92, "pedagog": [92, 149], "everydai": [92, 130, 153, 162], "engag": [92, 149, 179, 184], "wake": [92, 95, 157], "alexa": 92, "microphon": 92, "wave": 92, "stuck": [92, 140, 141, 145, 146, 152], "knob": 92, "meta": 92, "apricot": 92, "chines": [92, 149, 176], "coerc": [92, 114], "awesom": 92, "bare": [92, 99, 116, 145, 184], "wavi": 92, "badli": [92, 95, 101, 108, 140], "usefulli": 92, "times200": 92, "120000": 92, "electron": [92, 98, 111], "health": [92, 111, 114], "patient": [92, 94, 98, 101, 103, 111, 153, 157, 184], "ag": [92, 94, 103, 157, 164], "vital": [92, 130, 140, 150, 153, 178], "comorbid": 92, "microscop": 92, "equip": [92, 96, 175], "mine": 92, "resist": [92, 105], "stubbornli": 92, "imdb": [92, 122, 124, 167], "tripadvisor": 92, "stink": 92, "rambl": 92, "grace": 92, "preconceiv": 92, "clich\u00e9": [92, 157], "garbag": 92, "polic": [92, 94], "lend": 92, "unrepres": 92, "cancer": [92, 94, 103, 157], "societ": [92, 94], "prejudic": 92, "hire": 92, "inadvert": [92, 155], "injustic": 92, "conspir": 92, "smilei": 92, "ness": 92, "anomal": [92, 103, 157], "spit": 92, "disagre": [92, 95], "mere": [92, 94, 95, 103, 104, 111, 114, 178], "surrog": [92, 151, 186], "exam": [92, 101], "falter": 92, "supervisor": 92, "crispli": 92, "tomographi": 92, "financi": [92, 157, 184], "ton": 92, "harvest": 92, "footag": 92, "bedroom": [92, 98], "bathroom": 92, "town": 92, "ceo": 92, "microsoft": 92, "facebook": [92, 94], "sq": [92, 186], "pittsburgh": 92, "3000": [92, 159], "netflix": [92, 162, 163, 167, 187], "prize": [92, 113, 157, 163, 186], "hospit": [92, 98, 103, 157, 184], "surgeri": 92, "rainfal": 92, "drain": 92, "repair": 92, "contractor": 92, "gunk": 92, "sewag": 92, "pipe": 92, "invoic": 92, "snap": 92, "sought": 92, "firm": [92, 112], "attack": [92, 111, 153, 157], "demystifi": [92, 98], "mushroom": 92, "backyard": 92, "death": [92, 184], "eat": [92, 117, 157, 170, 180], "poison": 92, "delici": 92, "dinner": 92, "outweigh": [92, 148], "detriment": [92, 144], "mycologist": 92, "linnaeu": 92, "fauna": 92, "schnauzer": 92, "dinosaur": 92, "rattlesnak": 92, "garter": 92, "snake": 92, "phylogenet": 92, "rattler": 92, "fatal": [92, 141], "neatli": [92, 120], "musician": [92, 119], "bremen": 92, "german": [92, 175], "fairi": 92, "tale": 92, "donkei": [92, 98], "rooster": [92, 98], "blog": [92, 104, 122, 149, 163], "gadget": 92, "profession": [92, 105, 149], "pubm": 92, "mesh": 92, "ontologi": 92, "lag": 92, "provision": 92, "bioasq": 92, "pagerank": 92, "secret": 92, "sauc": 92, "weirdli": 92, "priorit": [92, 149], "authorit": 92, "fiction": 92, "connoisseur": 92, "peter": [92, 126, 149, 184, 186], "seller": 92, "comedi": 92, "retail": [92, 103, 162, 187], "goodread": 92, "playlist": 92, "dissatisfact": 92, "mayb": 92, "song": [92, 186], "inappropri": 92, "seriou": [92, 100, 101, 116, 149], "censor": 92, "preferenti": 92, "conspicu": 92, "habit": 92, "incent": 92, "downtown": [92, 153], "forgotten": [92, 149], "po": [92, 117, 122], "contigu": 92, "entiti": [92, 126, 188], "cartoonishli": 92, "ent": 92, "tom": 92, "washington": 92, "salli": 92, "speaker": [92, 186], "8khz": 92, "16khz": 92, "spoken": 92, "formid": [92, 95, 96, 103, 149], "ea": 92, "unalign": [92, 172, 176, 177, 184], "peculiar": [92, 139], "tendenc": 92, "verb": [92, 117, 132], "haben": 92, "sie": 92, "sich": 92, "schon": 92, "dies": 92, "grossartig": 92, "lehrwerk": 92, "angeschaut": 92, "textbook": [92, 108, 149], "dialogu": [92, 149, 179, 180], "tempor": [92, 94, 124, 149, 168, 184], "learner": [92, 111, 186], "dictatori": 92, "boss": [92, 109], "shoulder": 92, "lame": 92, "frustrat": [92, 95], "whet": [92, 98], "appetit": [92, 98], "babi": [92, 98, 131, 185], "mountain": 92, "ball": [92, 140, 145, 146, 183], "veloc": [92, 145, 188], "diamet": 92, "tailor": [92, 167], "euclidean": [92, 108, 153], "rome": 92, "itali": 92, "franc": [92, 186], "pari": [92, 186], "pollut": 92, "crime": [92, 94], "salari": 92, "rezend": [92, 186], "adversari": [92, 94, 186, 191], "dinh": [92, 186], "diffus": [92, 186], "ho": [92, 149, 175, 186], "sohl": [92, 186], "dickstein": [92, 186], "ermon": [92, 186], "doersch": [92, 186], "occlud": 92, "pile": 92, "upfront": 92, "motion": [92, 188], "disconnect": 92, "offlin": 92, "charm": 92, "upsid": 92, "isol": [92, 186], "asimov": 92, "agent": [92, 149, 157, 167, 186], "spammer": [92, 94], "email": [92, 93, 98, 130, 159, 167, 183, 184], "evad": 92, "met": [92, 103, 111, 121], "homework": 92, "assist": [92, 104, 130, 183], "surg": 92, "alphago": 92, "dethron": 92, "champion": 92, "silver": [92, 186, 187], "actuat": [92, 103], "overst": 92, "recast": 92, "chess": [92, 94, 186], "credit": [92, 94], "blame": 92, "employe": 92, "octob": 92, "trap": [92, 188], "closet": [92, 140], "rescu": [92, 157], "constantli": 92, "contextu": [92, 167, 186], "bandit": [92, 186], "jacob": [92, 149], "1655": 92, "1705": [92, 186], "carl": 92, "friedrich": 92, "gauss": [92, 103, 186], "1777": 92, "1855": 92, "insur": 92, "ohm": [92, 105], "voltag": [92, 105], "resistor": 92, "k\u00f6bel": 92, "1460": [92, 113], "1533": [92, 186], "adult": [92, 98], "foot": 92, "church": 92, "misshapen": 92, "longest": [92, 132, 177], "1890": [92, 186], "iri": 92, "1936": 92, "propon": 92, "eugen": 92, "moral": 92, "dubiou": 92, "endur": [92, 110], "1916": 92, "alan": [92, 94], "1912": 92, "1954": 92, "famou": [92, 111, 113, 119, 157, 163], "1950": [92, 114, 186, 190], "textual": [92, 117, 119, 186], "psychologi": [92, 103, 164], "biolog": [92, 103, 114, 116], "donald": 92, "hebb": [92, 186], "1904": [92, 186], "1985": 92, "groundbreak": 92, "1949": [92, 186], "hebbian": 92, "rosenblatt": 92, "diminish": [92, 110, 138, 184], "alexand": 92, "bain": 92, "1873": 92, "jame": [92, 109, 186], "sherrington": 92, "languish": 92, "scarc": [92, 101], "efficaci": [92, 111, 117, 145, 149, 157, 174], "scarciti": 92, "dissemin": [92, 94], "kryder": 92, "moor": 92, "revolution": [92, 126, 149], "1970": [92, 100, 114, 186], "kf": 92, "8080": 92, "boston": [92, 113], "mf": [92, 163], "80186": 92, "80486": 92, "gf": 92, "advertis": [92, 94, 138, 160, 162], "c2050": 92, "social": [92, 93, 122, 130, 164], "pf": 92, "pace": [92, 111], "outpac": 92, "mcculloch": [92, 103, 114, 186], "pitt": [92, 103, 114, 186], "1943": [92, 114, 186], "1997": [92, 164, 170, 174, 175, 186], "watkin": [92, 186, 189], "dayan": [92, 186, 189], "1992": [92, 105, 114, 167, 186, 189], "rediscov": 92, "ly": [92, 140, 157, 169, 184], "dormant": [92, 148], "cambrian": [92, 104], "explos": [92, 104, 178], "speci": 92, "plagu": [92, 95, 114, 116, 156], "pointer": [92, 186], "commenc": 92, "sukhbaatar": [92, 186], "freita": [92, 186], "permit": [92, 94, 101, 108], "sampler": 92, "gallop": 92, "zebra": 92, "zhu": [92, 126, 149, 186], "karra": [92, 186], "testimoni": 92, "amateur": 92, "doodler": 92, "workhors": 92, "024": 92, "superhuman": [92, 186], "starcraft": [92, 94], "mujoco": 92, "avenu": [92, 111, 153], "semin": [92, 95, 104], "supersed": 92, "apach": [92, 149], "ignit": 92, "labor": 92, "ph": [92, 186], "carnegi": 92, "mellon": 92, "firmli": 92, "mail": 92, "creditworthi": 92, "fraud": 92, "payment": 92, "paypal": 92, "stripe": 92, "alipai": 92, "wechat": 92, "visa": 92, "mastercard": 92, "sight": [92, 130, 157], "limelight": 92, "menial": [92, 150], "barber": 92, "appoint": 92, "dialog": [92, 176, 180], "pariti": [92, 149], "nec": 92, "illinoi": [92, 186], "urbana": [92, 186], "champaign": [92, 186], "stun": 92, "birdsong": 92, "diagnos": [92, 94, 101, 149, 157, 179, 186], "prowess": 92, "td": 92, "gammon": 92, "backgammon": [92, 94], "deepblu": 92, "garri": 92, "kasparov": 92, "campbel": [92, 186], "poker": [92, 186], "oppon": [92, 187], "libratu": [92, 186], "sandholm": [92, 186], "autonomi": [92, 149], "waymo": 92, "ship": [92, 94], "perceiv": [92, 94], "particl": 92, "astronomi": 92, "apocalyps": 92, "fear": 92, "sentient": 92, "livelihood": 92, "autopilot": 92, "bail": 92, "creator": [92, 116], "illus": 92, "daili": [92, 149, 162, 167, 187], "farm": 92, "farmer": 92, "phase": [92, 103, 111, 143], "swath": 92, "societi": [92, 149], "employ": [92, 111, 153], "countri": [92, 131], "racial": [92, 94], "gender": [92, 164], "consequenti": 92, "malevol": 92, "superintellig": 92, "dizzi": 92, "foreign": 92, "canni": [92, 186], "reign": 92, "suprem": 92, "bygon": 92, "informat": [92, 149], "experienc": [92, 98], "nonparametr": [92, 112, 114, 186], "nonconvex": [92, 138, 140, 141, 142, 147, 148, 186], "empiric": 92, "influx": 92, "pride": 92, "corpor": [92, 186], "anyon": [92, 114, 125, 142], "prime": [92, 95, 177], "validation_step": [93, 105, 106, 177, 183], "num_val_batch": [93, 106], "training_step": [93, 105, 106, 183], "placehold": [93, 99, 100, 110, 136], "has_aux": [93, 183], "configure_optim": [93, 104, 105, 106, 108, 177], "gmail": 93, "forum": [93, 113, 122], "get_scratch_param": [93, 115, 183], "parameterdict": 93, "l_": 93, "probabilti": 93, "contempl": 94, "rush": 94, "marvel": [94, 149], "insidi": [94, 146], "catalyst": 94, "repai": [94, 114], "footwear": 94, "repay": [94, 114], "deni": 94, "leap": [94, 101], "disastr": 94, "starter": 94, "digest": 94, "abound": 94, "expos": 94, "stimul": 94, "damag": [94, 183], "responsibli": 94, "realm": 94, "grappl": 94, "philosoph": [94, 101, 157, 186], "ethic": 94, "salvag": 94, "confront": [94, 111, 156], "sober": 94, "absent": [94, 95, 101, 110, 111, 184], "patholog": 94, "god": 94, "lafeez": 94, "hossain": 94, "500px": 94, "getti": 94, "ilkermetinkursova": 94, "istock": 94, "globalp": 94, "musthafa": 94, "aboobakuru": 94, "sibas_minich": 94, "ghrzuzudu": 94, "digitalvis": 94, "yime": [94, 149], "cartoon": 94, "symptom": [94, 157], "preval": [94, 98, 157], "diseas": [94, 101, 149, 157], "degener": 94, "mental": 94, "geographi": 94, "drink": [94, 111, 126], "cc": [94, 131], "BY": 94, "mcconchi": 94, "popvssoda": 94, "sick": 94, "career": [94, 113, 116, 149, 156, 157], "wild": [94, 111, 156], "blood": 94, "predominantli": [94, 179], "older": [94, 184], "solicit": 94, "donat": 94, "campu": 94, "cohort": 94, "hormon": 94, "diet": 94, "alcohol": 94, "roadsid": 94, "ala": [94, 114, 138, 141, 144], "disast": 94, "simplist": 94, "armi": 94, "tank": 94, "aerial": 94, "shadow": 94, "morn": 94, "noon": 94, "adequ": [94, 138], "obscur": 94, "ipad": 94, "winter": [94, 180], "santa": 94, "christma": 94, "offend": 94, "uk": 94, "decidedli": 94, "cope": [94, 178], "y_1": [94, 148, 169, 177, 178, 184], "y_n": [94, 148], "reweigh": 94, "fanci": 94, "recalibr": 94, "overweight": [94, 178], "underweight": 94, "ambient": 94, "mild": [94, 111], "strongest": 94, "traffic": 94, "lens": 94, "environment": [94, 103], "catdoor": 94, "f_t": 94, "longrightarrow": 94, "_t": [94, 103, 137, 138, 139, 144, 145, 147, 148, 170, 171, 173, 175, 177, 178, 181, 184, 188], "ervat": 94, "y_t": [94, 138, 178, 184], "confusingli": 94, "boiler": 94, "pid": 94, "disentangl": 94, "shao": [94, 186], "cooper": 94, "accid": 94, "arbitrag": 94, "trader": [94, 184], "infrequ": [94, 95, 127, 138, 176, 180, 185], "aspir": [94, 104], "slew": [94, 178], "forese": [94, 169], "welfar": 94, "subpopul": 94, "administ": [94, 101, 157], "inferior": 94, "reconsid": 94, "seldom": [94, 95, 101, 103, 111, 157, 170, 179, 184], "er": [94, 132], "sleight": 94, "misclassif": 94, "harmless": [94, 110, 186], "patrol": 94, "unaccount": [94, 157], "runawai": 94, "outsiz": [94, 108], "dilemma": [94, 116, 143], "unavail": 94, "entangl": 94, "unanticip": 94, "corrector": 94, "burn": 95, "intellectu": 95, "absurd": [95, 101, 114], "certifi": [95, 101, 149], "sprung": 95, "fresh": [95, 101], "epsilon_": 95, "a_n": 95, "reveal": [95, 111, 153, 179], "2500": 95, "peski": 95, "hoeffd": 95, "1963": 95, "2n": [95, 153], "ballpark": 95, "court": 95, "succe": 95, "sanctiti": 95, "preliminari": [95, 149, 191], "3am": 95, "brilliant": [95, 111], "thrill": 95, "fade": 95, "f_k": 95, "distrust": 95, "contact": 95, "leak": [95, 155], "strictest": 95, "theorist": [95, 111], "dwork": [95, 186], "holdout": [95, 101, 111], "bleak": 95, "analys": [95, 180], "dial": 95, "vigil": 95, "stake": 95, "demot": 95, "ostens": 95, "dib": 95, "gnaw": 95, "trust": [95, 149], "misgiv": 95, "subfield": [95, 98, 153], "elucid": 95, "hairi": [95, 156], "ambiti": 95, "misestim": 95, "chervonenki": [95, 186], "1971": [95, 114, 186], "1981": [95, 186], "1991": [95, 175, 186], "1974": [95, 186], "vc": [95, 101, 111, 186], "emp": [95, 101], "pessimist": 95, "bedrock": 95, "nevertheless": [95, 101, 107, 161, 179], "curat": [95, 186], "vladimir": 95, "alexei": 95, "chernovenki": 95, "revolutionari": 95, "powerless": [95, 111], "straightforwardli": 95, "somebodi": 95, "sun": [96, 149, 186], "sparcstat": 96, "blister": [96, 111], "laboratori": 96, "usp": 96, "simard": [96, 186], "unsuit": [96, 166, 180, 185], "weaker": [96, 114], "xiao": [96, 116, 186], "tensorflow_dataset": [96, 107, 149], "tfd": [96, 107, 149, 157], "datamodul": [96, 106, 107, 108, 113, 176, 184, 185], "6000": 96, "upscal": 96, "hymap": 96, "126": [96, 186], "shuffle_buf": 96, "as_numpi": [96, 107], "train_dataload": [96, 105, 106, 107, 176, 180], "blazingli": 96, "tic": 96, "odditi": 96, "safeguard": 96, "apparel": 96, "palett": 96, "decompress": 96, "transcod": 96, "skill": [97, 101, 149, 152, 156, 157], "plumb": 97, "taxonomi": 97, "transpar": 97, "hammer": 98, "sold": [98, 103], "basebal": 98, "discharg": 98, "dealt": [98, 174], "inbox": 98, "overload": [98, 103, 153, 167], "entertain": 98, "flight": 98, "tsoumaka": [98, 186], "kataki": [98, 186], "wet": 98, "x_3": [98, 108, 180], "x_4": [98, 180], "chicken": 98, "impuls": 98, "toddler": 98, "adolesc": 98, "young": [98, 186], "geriatr": 98, "ordin": [98, 117], "moon": [98, 186], "beutel": [98, 186], "o_1": [98, 103, 134], "o_2": 98, "o_3": 98, "31": [98, 186], "gather": [98, 107, 164, 167], "unsatisfactori": 98, "o_i": [98, 116, 134], "brittl": 98, "outlier": [98, 103, 153, 156], "mansion": 98, "probit": 98, "fechner": [98, 186], "1860": [98, 186], "o_j": [98, 99], "operatornam": [98, 103, 114, 169], "gibb": [98, 186], "1902": [98, 186], "boltzmann": [98, 105], "ga": [98, 129], "molecul": 98, "thermodynam": [98, 100, 186], "kt": 98, "ranzato": [98, 186], "rowwis": [98, 114], "justif": [98, 110, 144], "awkward": 98, "o_k": [98, 99], "partial_": [98, 103, 105, 116, 138, 144, 145, 148, 150, 151], "thoma": [98, 186], "nat": 98, "bore": 98, "dq": 98, "fri": [98, 186], "sindhwani": [98, 186], "quaternion": [98, 186], "strive": 98, "pam": 98, "ternari": 98, "bradlei": [98, 186], "terri": [98, 186], "o_": [98, 116, 134, 178], "1952": [98, 186, 190], "realsoftmax": 98, "softmin": 98, "dector": 99, "dataclass": [99, 106, 149], "riski": [99, 157], "max_k": 99, "logsumexp": 99, "danger": 99, "bless": 99, "disincent": 99, "muscl": [99, 103], "urg": 99, "fp64": 99, "tf32": 99, "x_exp": 100, "verbatim": 100, "x_prob": 100, "softmaxregressionscratch": 100, "outnumb": 100, "impur": 100, "boolean_mask": 100, "vi": [100, 152, 169], "\u00e0": [100, 186], "incorrectli": [100, 111], "1960": 100, "colleg": [101, 149], "dilig": 101, "elli": 101, "endow": 101, "she": 101, "iren": 101, "knack": 101, "handili": 101, "her": [101, 132], "yesterdai": 101, "undiagnos": 101, "ailment": 101, "grander": 101, "engulf": 101, "public": [101, 116, 122, 137, 145, 149, 164, 185, 186], "flickr": 101, "yfc100m": 101, "thome": [101, 186], "infinitesim": [101, 151], "generaliz": 101, "phenomenon": [101, 111, 141, 143, 157, 184, 185], "combat": 101, "dead": 101, "nobodi": [101, 144], "withheld": 101, "popper": 101, "falsifi": 101, "stress": 101, "economi": 101, "aptli": 101, "honest": 101, "ong": [101, 186], "muddier": 101, "murki": 101, "worryingli": 101, "rightli": 101, "counterintuit": [101, 111, 157, 179], "predic": 101, "relax": 101, "milder": 101, "inadvis": 101, "subsum": [102, 103], "narrowli": 102, "repertoir": 102, "membership": [103, 114, 136, 153], "dawn": 103, "19th": [103, 186], "1809": [103, 186], "legendr": [103, 186], "1805": [103, 186], "superscript": 103, "disciplin": [103, 111, 149, 179], "w_d": 103, "compactli": [103, 114], "instrument": [103, 108], "unfit": 103, "noced": [103, 186], "drawback": [103, 120, 144], "predetermin": [103, 184], "partial_b": 103, "frazier": [103, 186], "noiseless": 103, "saddl": [103, 140, 145], "frankl": [103, 186], "carbin": [103, 186], "conclus": [103, 157], "reload": 103, "parentag": 103, "anachronist": 103, "cyberneticist": 103, "neurophysiologist": 103, "warren": 103, "walter": 103, "cartoonish": 103, "dendrit": 103, "nucleu": 103, "axon": 103, "synaps": 103, "anatomi": 103, "physiologi": 103, "institut": [103, 157], "surveil": 103, "epidemiologi": 103, "seer": 103, "synapt": 103, "inhibit": 103, "destin": 103, "certainli": [103, 110, 169], "russel": [103, 186], "norvig": [103, 186], "ornithologi": 103, "aeronaut": 103, "linguist": [103, 117, 132], "maximimum": 103, "solvabl": 103, "pennystock": 103, "schole": [103, 186], "groceri": 103, "sell": 103, "fortuit": 104, "sn2": 104, "simulateur": 104, "neuristiqu": 104, "modular": [104, 106, 115], "glad": 104, "lousi": 104, "reinvent": 104, "wheel": [104, 188], "inconveni": [104, 155], "linearregress": [104, 108, 113, 184], "fill_": 104, "randomnorm": [104, 108], "mseloss": [104, 144], "l2loss": [104, 144, 158, 163], "l2_loss": 104, "meansquarederror": [104, 144], "syntheticregressiondata": [104, 105, 107], "get_w_b": [104, 108], "tap": 104, "frostig": [104, 186], "paszk": [104, 186], "knock": [104, 146], "huber": 104, "stitch": [105, 153], "linearregressionscratch": [105, 108], "gradienttransform": 105, "deepmind": 105, "blob": 105, "_src": 105, "emptyst": 105, "train_stat": [105, 106, 149], "apply_upd": 105, "grads_and_var": 105, "clip_gradi": [105, 183], "train_batch_idx": [105, 106], "mutated_var": 105, "reserv": [105, 121, 153], "elid": 105, "georg": [105, 149], "simon": [105, 149, 163, 186], "planck": 105, "radiat": 105, "eman": 105, "hc": [105, 175], "y_5": 105, "reshuffl": [105, 107], "malici": 105, "lightn": 106, "fragment": [106, 180], "incompat": [106, 170], "wrapper": [106, 150, 161, 162], "signatur": [106, 144, 155], "notimpl": 106, "tensorboard": 106, "c0": 106, "reusabl": 106, "plot_train_per_epoch": 106, "plot_valid_per_epoch": 106, "num_train_batch": 106, "train_": 106, "val_": 106, "__repr__": 106, "save_hyperparam": 106, "default_factori": 106, "numref": 106, "sec_lazy_init": 106, "prepare_data": 106, "prngkeyarrai": 106, "root_kei": 106, "params_kei": 106, "dropout_kei": 106, "tx": 106, "enrich": [106, 158, 165, 167, 186], "didact": 107, "succinct": [107, 149], "num_train": [107, 108, 176, 180, 184], "num_val": [107, 108, 176, 180], "nlabel": 107, "batch_indic": 107, "ex": 107, "get_tensorload": [107, 108, 113, 176, 180, 184], "doesn": 107, "shuffle_buff": 107, "underdetermin": 107, "pseudorandom": [107, 186], "naor": [107, 186], "reingold": [107, 186], "blunt": [108, 174], "monomi": [108, 110], "x_5": 108, "blow": [108, 116, 139, 178], "banach": 108, "ell_p": [108, 136, 153], "reviv": 108, "penal": [108, 111, 113, 163, 169, 177], "ridg": [108, 111], "popularli": 108, "lasso": [108, 111], "l2_penalti": 108, "weightdecayscratch": 108, "lambd": 108, "train_scratch": 108, "weightdecai": 108, "wd_mult": 108, "additive_weight_decai": 108, "kernel_regular": 108, "hilbert": [108, 114], "rkh": 108, "wherebi": 108, "profoundli": [109, 167], "recalcul": 109, "ell_2": [109, 110, 111, 136, 140, 148, 153, 163], "etern": 109, "funk": [109, 163], "virtuoso": 109, "rightward": [109, 170], "plain": [109, 114, 157], "disadvantag": 109, "peform": 110, "drew": [110, 157], "narr": 110, "sexual": 110, "gene": 110, "debias": 110, "h_5": 110, "survivor": 110, "dropout_p": 110, "dropoutmlpscratch": 110, "lin1": 110, "lin2": 110, "lin3": 110, "protein": [111, 157], "pour": 111, "west": 111, "arsen": 111, "folk": 111, "pithi": 111, "lunch": [111, 186], "wolpert": [111, 186], "macreadi": [111, 186], "stranger": 111, "nakkiran": [111, 186], "rademach": 111, "riddl": 111, "isomorph": 111, "fruit": 111, "jacot": [111, 186], "underscor": 111, "rolnick": [111, 186], "mislabel": 111, "garg": [111, 149, 186], "mortal": 111, "radic": 111, "paradox": 111, "intervent": 111, "concert": 111, "punt": 112, "exot": 113, "cock": [113, 186], "iowa": 113, "harrison": 113, "rubinfeld": 113, "1978": 113, "boast": [113, 116], "sponsor": 113, "stakehold": 113, "foster": 113, "collabor": [113, 138, 158, 162, 163, 186, 191], "leaderboard": 113, "chase": [113, 149], "spiral": 113, "myopic": 113, "roof": [113, 156], "basement": 113, "upload": 113, "sha": 113, "clog": 113, "kagglehous": 113, "raw_train": 113, "kaggle_house_pred_train": 113, "585e9cc93e70b39160e7921475f9bcd7d31219c": 113, "raw_val": 113, "kaggle_house_pred_test": 113, "fa19780a7b011d9b009e8bff8e99922a8ee2eb90": 113, "1459": 113, "salepric": 113, "iloc": [113, 156], "mszone": 113, "mszoning_rl": 113, "mszoning_rm": 113, "numeric_featur": 113, "get_dummi": [113, 156], "dummy_na": [113, 156], "331": 113, "bug": [113, 156], "rural": 113, "ohio": 113, "horribl": 113, "lo": [113, 186], "alto": [113, 153], "hill": [113, 186], "california": 113, "stunningli": 113, "get_tensor": 113, "smarter": 113, "obfusc": 113, "unnecessarili": [113, 155], "k_fold_data": 113, "ret": 113, "fold_siz": 113, "k_fold": 113, "val_loss": 113, "data_fold": 113, "untun": 113, "ensemble_pr": 113, "late": [113, 115, 150], "wrangl": 114, "vmap": [114, 116, 149], "incom": [114, 153, 159], "relianc": 114, "doom": 114, "1925": [114, 186], "quinlan": [114, 186], "aronszajn": [114, 186], "spline": [114, 186], "wahba": [114, 186], "\u00f3": [114, 186], "ajal": [114, 186], "azoulai": [114, 186], "1894": [114, 186], "rectifi": [114, 186], "abus": [114, 157], "atop": 114, "cybenko": [114, 186], "micchelli": [114, 186], "absurdli": 114, "kimeldorf": [114, 186], "nondifferenti": 114, "adag": 114, "wisdom": 114, "mangasarian": [114, 186], "rockafellar": [114, 186], "retain_graph": [114, 165], "grad_relu": 114, "prelu": 114, "inf": 114, "plateau": [114, 143], "grad_sigmoid": [114, 116], "hyperbol": [114, 141], "nears": 114, "kalman": [114, 186], "kwasni": [114, 186], "grad_tanh": 114, "circa": 114, "fortran": 114, "resurg": [114, 189], "swish": 114, "disregard": 115, "mlpscratch": 115, "messi": [115, 156], "42b": [115, 131], "renam": 115, "1025": [115, 186], "1026": [115, 186], "1028": 115, "1032": 115, "gloss": 116, "gotten": [116, 150, 153, 157], "f_l": 116, "underbrac": [116, 189], "suscept": 116, "pressur": 116, "mantissa": 116, "unpredict": 116, "threaten": 116, "culprit": 116, "goldilock": 116, "zone": 116, "vex": [116, 146], "prng": 116, "nuisanc": 116, "2_": 116, "2_j": 116, "nonexist": 116, "stumbl": [116, 157], "110": [117, 128, 186], "340": [117, 128], "cola": 117, "judg": 117, "grammat": [117, 176, 180], "warstadt": [117, 186], "unambigu": [117, 126, 157, 179], "sep": [117, 121, 126, 127, 128, 164], "cer": [117, 186], "woman": [117, 131], "meat": 117, "danc": 117, "man": [117, 119, 131, 132, 134, 180, 186], "adject": [117, 131], "penn": [117, 133, 186], "treebank": 117, "nnp": 117, "vb": 117, "jj": [117, 138], "squad": 117, "passag": [117, 179], "rajpurkar": [117, 186], "inconclus": 117, "maker": 117, "insist": 117, "n95": 117, "respir": 117, "guard": 117, "viru": 117, "pack": [117, 121, 187], "e_j": 117, "coronaviru": 117, "outbreak": 117, "novella": [118, 180], "textcnn": 118, "snli": [118, 120, 121], "polar": [119, 122], "premis": [119, 120, 121], "entail": [119, 120, 121], "neutral": [119, 120, 121], "hug": 119, "sleep": [119, 120, 157], "500000": 119, "bowman": [119, 186], "snli_1": 119, "nlp": [119, 131], "edu": [119, 131, 186], "9fcde07509c7e87ec61c640c1b2753d9041758e4": 119, "richer": 119, "read_snli": [119, 121], "extract_text": 119, "label_set": 119, "file_nam": [119, 127], "0_train": 119, "0_test": 119, "train_data": [119, 122, 158, 159, 160, 161, 164, 165, 168], "550000": 119, "test_data": [119, 122, 158, 160, 161, 164, 165, 168], "snlidataset": 119, "all_premise_token": 119, "all_hypothesis_token": 119, "_pad": 119, "load_data_snli": [119, 120], "train_set": [119, 121, 127, 164], "test_set": [119, 121, 164], "superfici": 119, "glove": [120, 123, 124, 126, 130, 131, 132, 191], "tire": 120, "mn": [120, 153], "f_a": 120, "f_b": 120, "atch_siz": 120, "v_a": 120, "v_b": [120, 139, 145], "_b": [120, 126, 140], "decomposableattent": 120, "num_inputs_attend": 120, "num_inputs_compar": 120, "num_inputs_agg": 120, "glove_embed": [120, 123, 124], "tokenembed": [120, 123, 124, 131], "6b": [120, 123, 124, 131], "100d": [120, 123, 124, 131], "idx_to_token": [120, 121, 123, 124, 127, 131, 183, 185], "set_data": [120, 123, 124], "split_batch_multi_input": [120, 121], "even_split": [120, 128, 158, 163, 165], "predict_snli": 120, "multiprocess": 121, "wikitext": [121, 127, 128], "225d66f04cae318b841a13d32af3acc165f253ac": 121, "c72329e68a732bef0452e4b96a1c341c8910f81f": 121, "7b3820b35da691042e5d34c0971ac3edbd80d3f4": 121, "a4e718a47137ccd1809c9107ab4f5edd317bae2c": 121, "load_pretrained_model": 121, "pretrained_model": 121, "token_to_idx": [121, 131, 185], "bertmodel": [121, 126, 128], "snlibertdataset": 121, "all_premise_hypothesis_token": 121, "p_token": 121, "h_token": 121, "all_token_id": [121, 127], "all_seg": [121, 127], "_preprocess": [121, 176, 185], "_mp_worker": 121, "token_id": [121, 127, 128], "premise_hypothesis_token": 121, "_truncate_pair_of_token": 121, "get_tokens_and_seg": [121, 126, 127, 128], "bertclassifi": 121, "tokens_x": [121, 127, 128], "segments_x": [121, 127, 128], "valid_lens_x": [121, 127, 128], "encoded_x": [121, 126, 128], "masklm": [121, 126], "nextsentencepr": [121, 126], "768": [121, 126, 128], "3072": 121, "86": [121, 186], "pro": 121, "con": 121, "prolifer": 122, "opinion": [122, 167], "polit": 122, "financ": 122, "brand": 122, "25000": 122, "aclimdb": 122, "aclimdb_v1": 122, "01ada507287d82875905620988597833ad4e0903": 122, "read_imdb": 122, "folder_nam": 122, "train_token": 122, "hist": [122, 164, 176], "load_data_imdb": [122, 123, 124], "test_token": 122, "test_featur": 122, "corr1d": 123, "corr1d_multi_in": 123, "collobert": [123, 186], "constant_embed": 123, "adaptiveavgpool1d": 123, "modulelist": 123, "conv1d": 123, "globalmaxpool1d": 123, "nums_channel": 123, "predict_senti": [123, 124], "maa": [124, 186], "birnn": 124, "flatten_paramet": 124, "input_s": 124, "spaci": [124, 127], "spacy_en": 124, "tok": 124, "w_c": [125, 134], "_o": [125, 134], "n_k": 125, "n_1": 125, "i_t": 125, "h_k": 125, "i_": 125, "leaf": 125, "w_3": 125, "leftchild": 125, "child": [125, 186], "word2vec": [126, 127, 129, 130, 131, 132, 133, 191], "polysemi": [126, 128, 170], "crane": [126, 128], "taglm": 126, "tagger": 126, "cove": 126, "mccann": [126, 186], "elmo": 126, "corefer": 126, "hing": [126, 162, 165, 168], "twelv": 126, "cash": [126, 170], "eleven": 126, "tokens_a": [126, 127, 128], "tokens_b": [126, 127, 128], "bertencod": 126, "token_embed": 126, "segment_embed": 126, "ffn_num_input": 126, "seq": [126, 164, 165, 168, 176], "pred_posit": [126, 127], "num_pred_posit": 126, "batch_idx": 126, "masked_x": 126, "mlm_y_hat": [126, 128], "mlm": [126, 128], "mlm_posit": 126, "mlm_y": [126, 127, 128], "mlm_l": [126, 128], "nsp": [126, 128], "nsp_y_hat": [126, 128], "nsp_y": [126, 127, 128], "nsp_l": [126, 128], "bookcorpu": [126, 127], "meriti": [127, 186], "ptb": [127, 133, 135], "paragraph": [127, 176, 185], "delimit": [127, 132, 144, 176], "s3": 127, "metamind": 127, "3c914d17d80b1459be871a5039ac23e752a53cb": 127, "_read_wiki": 127, "wiki": [127, 131], "_get_next_sent": 127, "next_sent": 127, "is_next": 127, "_get_nsp_data_from_paragraph": 127, "nsp_data_from_paragraph": 127, "_replace_mlm_token": 127, "candidate_pred_posit": 127, "num_mlm_pr": 127, "mlm_input_token": 127, "pred_positions_and_label": 127, "mlm_pred_posit": 127, "masked_token": 127, "_get_mlm_data_from_token": 127, "mlm_pred_label": 127, "_pad_bert_input": 127, "max_num_mlm_pr": 127, "all_pred_posit": 127, "all_mlm_weight": 127, "all_mlm_label": 127, "nsp_label": 127, "mlm_pred_label_id": 127, "_wikitextdataset": 127, "wordpiec": 127, "30000": 127, "load_data_wiki": [127, 128], "pred_positions_x": [127, 128], "mlm_weights_x": [127, 128], "dateset": 127, "nltk": 127, "punkt": 127, "sent_token": 127, "_get_batch_loss_bert": 128, "shard": 128, "tokens_x_shard": 128, "segments_x_shard": 128, "valid_lens_x_shard": 128, "pred_positions_x_shard": 128, "mlm_weights_x_shard": 128, "mlm_y_shard": 128, "nsp_y_shard": 128, "train_bert": 128, "num_steps_reach": 128, "mlm_l_mean": 128, "nsp_l_mean": 128, "get_bert_encod": 128, "encoded_text": 128, "encoded_text_cl": 128, "encoded_text_cran": 128, "encoded_pair": 128, "encoded_pair_cl": 128, "encoded_pair_cran": 128, "ic": 129, "steam": 129, "q_": [129, 189, 190], "multiset": 129, "ji": [129, 146, 153], "asymmetr": 129, "00019": [129, 186], "000066": 129, "003": 129, "000017": 129, "p_2": [129, 177], "000022": 129, "00078": 129, "0022": 129, "000018": 129, "085": 129, "36": [129, 157], "redesign": [129, 149], "subword": [130, 186, 191], "upstream": 130, "cbow": 130, "subsampl": 130, "fasttext": [130, 131], "50d": 131, "0b8703943ccdb6eb788e6f091b8946e82231bc4d": 131, "cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a": 131, "300d": 131, "b5116e234e9eb9076672cfeabf5469f3eec904fa": 131, "c1816da3821ae9f43899be655002f6c723e91b88": 131, "embedding_nam": 131, "idx_to_vec": 131, "_load_embed": 131, "unknown_idx": 131, "unk": [131, 132, 133, 176, 185], "glove_6b50d": 131, "400000": 131, "3367": 131, "knn": 131, "topk": [131, 135], "ret_typ": [131, 135], "get_similar_token": [131, 135], "query_token": [131, 135], "son": [131, 134, 186], "daughter": 131, "get_analogi": 131, "token_a": 131, "token_b": 131, "token_c": 131, "male": 131, "femal": 131, "capit": [131, 153, 185], "beij": 131, "japan": 131, "superl": 131, "syntact": [131, 185], "tens": 131, "inflect": 132, "boi": 132, "boyfriend": 132, "girl": 132, "girlfriend": 132, "spanish": 132, "finnish": 132, "morphologi": 132, "morpholog": 132, "bojanowski": [132, 186], "whe": 132, "_w": 132, "_g": 132, "bpe": 132, "sennrich": [132, 186], "raw_token_freq": 132, "tall": [132, 157], "er_": 132, "token_freq": [132, 185], "fast_": 132, "faster_": 132, "tall_": 132, "taller_": 132, "freq": [132, 185], "get_max_freq_pair": 132, "merge_symbol": 132, "max_freq_pair": 132, "new_token_freq": 132, "new_token": 132, "tal": [132, 186], "num_merg": 132, "segment_bp": 132, "cur_output": 132, "tallest_": 132, "fatter_": 132, "journal": [133, 186], "319d85e578af0cdc590547f26231e4e31cdf1e42": 133, "read_ptb": 133, "raw_text": [133, 176, 185], "mikolov": [133, 134, 186], "shorten": [133, 150], "show_list_len_pair_hist": [133, 176], "compare_count": 133, "get_centers_and_context": 133, "max_window_s": [133, 135], "window_s": [133, 168], "tiny_dataset": 133, "all_cent": 133, "all_context": 133, "randomgener": 133, "unnorm": 133, "sampling_weight": 133, "get_neg": 133, "all_neg": 133, "n_i": [133, 185], "m_i": 133, "contexts_neg": 133, "max_i": 133, "batchifi": 133, "cur_len": 133, "load_data_ptb": [133, 135], "num_noise_word": [133, 135], "ptbdataset": 133, "collate_fn": 133, "batchify_fn": 133, "2m": [134, 153], "input_dim": [135, 160, 163], "output_dim": [135, 163], "num_embed": 135, "embedding_dim": 135, "embedding_weight": 135, "contexts_and_neg": 135, "skip_gram": 135, "embed_v": 135, "embed_u": 135, "binary_cross_entropy_with_logit": 135, "sigmd": 135, "context_neg": 135, "002": [135, 158, 163], "adher": [136, 149, 157], "indefinit": 136, "setminu": 136, "boolean": 136, "hadamard": [136, 153, 165, 173, 175], "_p": [136, 140, 153], "pdf": [136, 149, 186], "perp": [136, 157], "greek": 137, "rmsprop": [137, 139, 141, 142, 186, 191], "jour": 137, "init_adadelta_st": 137, "feature_dim": [137, 138, 139, 144, 145, 147], "s_b": [137, 138, 139, 147], "delta_w": 137, "delta_b": 137, "hyperparam": [137, 138, 139, 144, 145, 147], "get_data_ch11": [137, 138, 139, 144, 145, 147], "train_ch11": [137, 138, 139, 144, 145, 147], "liner": 137, "train_concise_ch11": [137, 138, 139, 144, 145, 147], "prop": 137, "hack": [138, 174, 183], "redress": 138, "eta_0": [138, 143, 148], "eta_i": [138, 148], "sparsiti": [138, 164, 167, 186], "qualifi": 138, "gentl": [138, 153], "kappa": 138, "couldn": 138, "impract": 138, "elus": 138, "adagrad_2d": 138, "s1": [138, 141, 145, 147, 148], "s2": [138, 141, 145, 147, 148], "g1": [138, 141, 147, 148], "f_2d": [138, 141, 145, 147], "show_trace_2d": [138, 141, 145, 147, 148], "train_2d": [138, 141, 145, 147, 148], "init_adagrad_st": 138, "uneven": 138, "gerschgorin": 138, "lambda_i": [138, 145, 178], "recap": [139, 153], "precondition": [139, 141, 147], "reddi": [139, 186], "hotfix": 139, "correspondingli": [139, 141, 144, 175], "anticlimact": 139, "debia": 139, "daunt": 139, "init_adam_st": 139, "v_w": [139, 145], "beta2": 139, "v_bias_corr": 139, "s_bias_corr": 139, "sgn": 139, "pointwis": [139, 166], "ewma": 139, "strengthen": 140, "cap_": 140, "emptyset": [140, 157], "parabola": 140, "alpha_i": [140, 148, 157], "unobserv": [140, 158, 165], "foremost": 140, "ast": [140, 186], "semidefinit": 140, "succeq": 140, "nondecreas": 140, "lemma": 140, "graviti": 140, "alpha_1": 140, "alpha_n": 140, "lagrang": 140, "satisfact": [140, 149, 159], "proj": 140, "diamond": 140, "lessapprox": 141, "declin": [141, 144, 184], "f_grad": [141, 148], "gd": [141, 144], "show_trac": 141, "f_line": 141, "overshoot": 141, "bigg": 141, "2x_2": [141, 147], "2x_1": 141, "4x_2": 141, "ff7f0e": 141, "1f77b4": 141, "f_2d_grad": 141, "gd_2d": [141, 145], "oscil": [141, 145], "curvatur": 141, "mimic": 141, "cosh": 141, "sinh": 141, "f_hess": 141, "spectacularli": [141, 184], "defeat": 141, "cautiou": [141, 145], "flatter": 141, "entireti": 141, "millimet": 141, "kilomet": 141, "meter": [141, 157], "terribl": 141, "conjunct": 141, "bewar": 141, "oneself": 142, "incant": 142, "primer": 142, "precondit": 142, "adadelta": [142, 186, 191], "secondli": 143, "bounc": 143, "pertain": [143, 162], "monik": 143, "cyclic": [143, 179], "maxpool": 143, "averagepool": 143, "train_loss": 143, "__module__": 143, "learningrateschedul": 143, "custom_callback": 143, "dummy_model": 143, "squarerootschedul": 143, "num_upd": 143, "stepsiz": 143, "gentli": 143, "eta_": 143, "eta_t": [143, 144, 145, 148], "factorschedul": 143, "stop_factor_lr": 143, "base_lr": 143, "multisteplr": 143, "mileston": 143, "get_lr": 143, "get_last_lr": 143, "multifactorschedul": 143, "loshchilov": [143, 186], "cosineschedul": 143, "max_upd": 143, "final_lr": 143, "warmup_step": 143, "warmup_begin_lr": 143, "base_lr_orig": 143, "max_step": 143, "get_warmup_lr": 143, "gotmar": [143, 186], "perplexingli": 143, "gluoncv": 143, "polyschedul": 143, "teh": [143, 186], "langevin": 143, "2ghz": 144, "avx": 144, "midrang": 144, "allevi": [144, 164, 167, 175, 176, 178], "tik": 144, "2mnp": 144, "gigaflop": 144, "nasa": 144, "wing": 144, "aircraft": 144, "airfoil": 144, "airfoil_self_nois": 144, "dat": 144, "76e5be1548fd8222e5074cf0faae75edff8cf93f": 144, "1500": [144, 186], "genfromtxt": 144, "from_numpi": [144, 155], "sub_": 144, "trainer_fn": 144, "35": [144, 186], "db": 144, "train_sgd": 144, "gd_re": 144, "sgd_re": 144, "mini1_r": 144, "mini2_r": 144, "tr_name": 144, "evil": 144, "geni": 144, "lenient": 145, "canyon": 145, "expositori": 145, "goh": [145, 186], "polyak": [145, 186], "nesterov": [145, 148, 186], "pleasant": 145, "ellipsoid": 145, "momentum_2d": 145, "v2": 145, "init_momentum_st": 145, "sgd_momentum": 145, "features_dim": 145, "train_momentum": 145, "contriv": [145, 150], "succ": 145, "eigensystem": 145, "eigenspac": 145, "v_0": [145, 190], "flammarion": [145, 186], "bach": [145, 186], "downweight": 145, "xytext": 146, "arrowprop": 146, "arrowstyl": 146, "nempir": 146, "77": [146, 186], "dislodg": 146, "rx": 146, "tick": 146, "set_ztick": 146, "nil": [146, 149], "0013": 146, "wigner": [146, 186], "1958": [146, 186], "tieleman": [147, 186], "1x_1": 147, "rmsprop_2d": 147, "init_rmsprop_st": 147, "gamma1": 147, "constant_lr": 148, "prematur": 148, "t_": 148, "exponential_lr": 148, "polynomial_lr": 148, "tibshirani": 148, "vial": [148, 186], "whichev": [148, 177], "telescop": 148, "loos": 148, "legion": 149, "newspap": 149, "outmod": 149, "biomed": 149, "catalyz": 149, "clarifi": 149, "player": 149, "astrophys": 149, "climat": [149, 184], "biomedicin": 149, "onboard": 149, "exemplar": 149, "entrepreneur": 149, "breadth": 149, "runnabl": 149, "sporad": 149, "clueless": 149, "paywal": 149, "latex": 149, "javascript": 149, "sphinx": 149, "thoroughli": 149, "outset": 149, "tast": [149, 150, 159, 168, 184], "esoter": 149, "organiz": 149, "taught": 149, "ammunit": 149, "curatori": 149, "tread": 149, "inquiri": 149, "kick": 149, "gear": 149, "eclips": 149, "matplotlib_inlin": [149, 151], "backend_inlin": [149, 151], "newest": [149, 164], "compliat": 149, "undergradu": 149, "happili": 149, "terrif": 149, "bollob": [149, 186], "wasserman": [149, 186], "joe": 149, "blitzstein": 149, "gem": 149, "indebt": 149, "draft": 149, "anirudh": 149, "dagar": 149, "yuan": [149, 186], "tang": [149, 168, 186], "juli": 149, "gaosheng": 149, "liujun": 149, "jiehang": 149, "baidu": 149, "paddlepaddl": 149, "shuai": [149, 162], "alxnorden": 149, "avinashingit": 149, "bowen0701": 149, "brettkoonc": 149, "chaitanya": 149, "bapat": 149, "cryptonaut": 149, "david": 149, "fiocco": 149, "edgarroman": 149, "gkutiel": 149, "mitro": 149, "liang": [149, 186], "pu": 149, "rahul": 149, "agarw": [149, 186], "moham": [149, 186], "jamaoui": 149, "michael": 149, "stu": 149, "stewart": 149, "mike": 149, "m\u00fcller": 149, "nrauschmayr": 149, "prakhar": 149, "srivastav": 149, "sad": 149, "sfermigi": 149, "sheng": 149, "zha": 149, "sundeepteki": 149, "topecongiro": 149, "tpdi": 149, "vermicelli": 149, "vishaal": 149, "kapoor": 149, "vishwesh": 149, "ravi": 149, "shrimali": 149, "yayab": 149, "yuhong": 149, "evgenii": 149, "smirnov": 149, "lgov": 149, "corston": 149, "oliv": [149, 186], "igor": 149, "dzreyev": 149, "nguyen": 149, "pmuen": 149, "andrei": 149, "lukovenko": 149, "senorcinco": 149, "vfdev": 149, "dsweet": 149, "mohammad": 149, "mahdi": 149, "abhishek": 149, "gupta": [149, 186], "uwsd": 149, "domkm": 149, "lisa": 149, "oaklei": 149, "bowen": 149, "aarush": 149, "ahuja": 149, "prasanth": 149, "buddareddygari": 149, "brianhende": 149, "mani2106": 149, "mtn": 149, "lkevinzc": 149, "caojilin": 149, "lakshya": 149, "fiet": 149, "l\u00fcer": 149, "surbhi": 149, "vijayvargeeya": 149, "muhyun": 149, "dennismalmgren": 149, "adursun": 149, "liqingnz": 149, "pedro": 149, "larroi": 149, "ozgur": 149, "jun": 149, "blume": 149, "geogunow": 149, "josh": 149, "maximilian": 149, "b\u00f6ther": 149, "rakib": 149, "islam": 149, "leonard": 149, "lausen": 149, "abhinav": 149, "upadhyai": 149, "rongruosong": 149, "steve": 149, "sedlmey": 149, "ruslan": 149, "baratov": 149, "rafael": 149, "schlatter": 149, "liusy182": 149, "gianni": 149, "pappa": 149, "qbaza": 149, "dchoi77": 149, "gerson": 149, "phuc": 149, "atwood": 149, "christabella": 149, "vn09": 149, "haibin": 149, "jjangga0214": 149, "richychen": 149, "noelo": 149, "hansent": 149, "giel": 149, "dop": 149, "dvincent1337": 149, "whited3vil": 149, "kulit": 149, "codypenta": 149, "joseppinilla": 149, "ahmaurya": 149, "karolszk": 149, "heytitl": 149, "goetz": 149, "rigtorp": 149, "tiep": 149, "vu": 149, "sfilip": 149, "mlxd": 149, "kale": [149, 186], "tessera": 149, "sanjar": 149, "adilov": 149, "matteoferrara": 149, "hsneto": 149, "katarzyna": 149, "biesialska": 149, "gregori": 149, "bruss": 149, "dui": 149, "thanh": 149, "doan": 149, "paulaurel": 149, "graytown": 149, "duc": 149, "pham": [149, 186], "sl7423": 149, "jaedong": 149, "hwang": 149, "yida": 149, "cys4": 149, "clhm": 149, "jean": 149, "kaddour": 149, "austinmw": 149, "trebeljahr": 149, "tbaum": 149, "cuong": 149, "pavelkomarov": 149, "vzlamal": 149, "notanothersystem": 149, "arun": 149, "jancio": 149, "eldarkurt": 149, "shazbot": 149, "doctorcolossu": 149, "gducharm": 149, "cclauss": 149, "daniel": 149, "mietchen": 149, "hoonos": 149, "biagiom": 149, "abhinavsp0730": 149, "jonathanhrandal": 149, "ysraell": 149, "nodar": 149, "okroshiashvili": 149, "ugurkap": 149, "jiyang": 149, "kang": 149, "stevenjok": 149, "tomer": 149, "kaftan": 149, "liweiwp": 149, "netyst": 149, "ypandya": 149, "nishanttharani": 149, "heiligerl": 149, "sportsthu": 149, "hoa": 149, "manuel": 149, "arno": 149, "korfmann": 149, "webentwicklung": 149, "aterzi": 149, "nxby": 149, "xiaot": 149, "josiah": 149, "yoder": 149, "mathresearch": 149, "mzz2017": 149, "jroberayala": 149, "iluu": 149, "ghejc": 149, "bsharmi": 149, "vkramdev": 149, "simonwardjon": 149, "lakshkd": 149, "talneoran": 149, "djliden": 149, "nikhil95": 149, "oren": 149, "barkan": 149, "guowei": 149, "haozhu233": 149, "pratikhack": 149, "yue": [149, 186], "ying": 149, "tayfunun": 149, "steinsag": 149, "charleybel": 149, "lumsdain": 149, "jiekui": 149, "deepak": 149, "pathak": 149, "florian": 149, "donhaus": 149, "tim": 149, "adriaan": 149, "tijssel": 149, "ron": 149, "medina": 149, "gaurav": 149, "saha": 149, "murat": 149, "semerci": 149, "lei": 149, "mao": [149, 186], "levi": [149, 186], "mcclenni": 149, "joshua": 149, "broyd": 149, "jake221": 149, "jonbal": 149, "zyhazwraith": 149, "brian": 149, "pulfer": 149, "nick": 149, "tomasino": 149, "lefan": 149, "hongshen": 149, "vinnei": 149, "cavallo": 149, "yuntai": 149, "yuanxiang": 149, "amarazov": 149, "pasricha": 149, "ben": 149, "greenawald": 149, "shivam": 149, "quanshangz": 149, "biswajit": 149, "sahoo": 149, "parth": 149, "pandit": 149, "ishan": 149, "kumar": [149, 186], "homunculusk": 149, "schwartz": 149, "varadgunj": 149, "jason": 149, "wiener": 149, "armin": 149, "gholampoor": 149, "shreshtha13": 149, "arnav": 149, "hyeonggyu": 149, "emilyong": 149, "b\u00e1lint": 149, "mucs\u00e1nyi": 149, "duboi": 149, "juntian": 149, "tao": 149, "wenxiang": 149, "xu": [149, 186], "lifu": 149, "filevich": 149, "quake2005": 149, "werner": 149, "marsel": 149, "khisamutdinov": 149, "francesco": 149, "fuma": 149, "fumag": 149, "peilin": 149, "vincent": [149, 186], "gurgul": 149, "qingfengtommi": 149, "janmei": 149, "shukla": 149, "mo": 149, "shan": 149, "kaan": 149, "sancak": 149, "regob": 149, "alexsau": 149, "gopalakrishna": 149, "ramachandra": 149, "tobia": 149, "uelwer": 149, "chao": [149, 163, 186], "tian": 149, "cao": [149, 186], "nicola": 149, "corthorn": 149, "akash5474": 149, "kxxt": 149, "zxydi1992": 149, "britton": 149, "shuangchi": 149, "zhmou": 149, "krahet": 149, "jie": 149, "han": 149, "atishai": 149, "marcel": 149, "flygar": 149, "adtygan": 149, "nik": 149, "vaessen": 149, "loui": 149, "schlessing": 149, "balaji": 149, "varatharajan": 149, "atgctg": 149, "kaixin": 149, "victor": 149, "barbaro": 149, "riccardo": 149, "musto": 149, "elizabeth": 149, "azimjonn": 149, "guilherm": 149, "miotto": 149, "alessandro": 149, "finamor": 149, "joji": 149, "joseph": 149, "anthoni": 149, "biel": 149, "zeme": 149, "shjustinbaek": 149, "gab": 149, "nantekoto": 149, "yutaro": 149, "nishiyama": 149, "amsalem": 149, "maomao": 149, "amin": 149, "allahyar": 149, "gij": 149, "tulder": 149, "mikhail": 149, "berkov": 149, "iamorphen": 149, "caser": [149, 168], "walsh": 149, "pggpl": 149, "rohankarthikeyan": 149, "ryan": 149, "choi": 149, "likun": 149, "wen": 149, "ming": 149, "karypi": [149, 186], "swami": 149, "sivasubramanian": 149, "desanti": 149, "selipski": 149, "jassi": 149, "cambridg": [149, 186], "commiss": 149, "tranah": 149, "prose": 149, "plate": 150, "wengert": [150, 186], "phd": 150, "thesi": [150, 175], "speelpen": [150, 186], "griewank": [150, 186], "julia": 150, "revel": [150, 157, 186], "buffer": 150, "overwritten": 150, "wipe": 150, "ancestor": 150, "maze": 150, "d_grad": 150, "booster": 150, "liber": 150, "expedi": [150, 153], "greec": 151, "archimed": 151, "inscrib": 151, "polygon": 151, "arc": 151, "secant": 151, "auc": [151, 165], "d_x": 151, "svg": 151, "crisper": 151, "set_matplotlib_format": 151, "rcparam": 151, "overlai": 151, "has_one_axi": 151, "u_1": 151, "u_2": 151, "u_m": 151, "3x_1": 151, "fluenci": 152, "vii": 152, "aptitud": 152, "palo": 153, "balmi": 153, "72": 153, "fahrenheit": 153, "celsiu": 153, "cholesterol": 153, "st": 153, "1n": 153, "m2": 153, "font": 153, "rd": 153, "operand": 153, "deserv": 153, "top_": 153, "top_m": 153, "top_i": [153, 163], "matvec": 153, "hang": [153, 179], "1k": 153, "2k": [153, 168], "n1": 153, "n2": 153, "nk": 153, "1m": 153, "k1": 153, "k2": 153, "top_n": 153, "school": [153, 156, 157], "hypotenus": 153, "manhattan": 153, "ord": 153, "revenu": [153, 159, 162, 167], "kolter": [153, 186], "cubic": 153, "__": 154, "hazard": 154, "breez": 155, "killer": 155, "numpy_extens": 155, "empow": 155, "alia": 155, "prepopul": 155, "reconfigur": 155, "outermost": [155, 183], "x_new_1": 155, "x_var": 155, "x_new_2": 155, "unari": 155, "derefer": 155, "referenc": [155, 157], "lest": 155, "spring": 155, "halt": 155, "device_get": 155, "comma": [156, 157], "spreadsheet": 156, "march": 156, "1879": 156, "ulm": 156, "feder": 156, "polytechn": 156, "gravit": 156, "house_tini": 156, "numroom": 156, "rooftyp": 156, "data_fil": 156, "127500": 156, "106000": 156, "slate": 156, "178100": 156, "140000": 156, "270000": 156, "bed": 156, "menac": 156, "imput": 156, "rooftype_sl": 156, "rooftype_nan": 156, "to_numpi": 156, "seaborn": 156, "bokeh": 156, "abalon": 156, "pillow": 156, "unsupervis": [157, 184, 186], "uncontroversi": 157, "frequentist": 157, "dam": [157, 186], "hunt": 157, "theses": 157, "depart": 157, "1000000": 157, "inextric": [157, 179], "num_toss": 157, "fair_prob": 157, "unfair": 157, "cum_count": 157, "axhlin": 157, "preoccupi": 157, "countabl": 157, "bigcup_": 157, "kolmogorov": [157, 186], "1933": [157, 186], "alarm": 157, "burgl": 157, "suspect": 157, "clunki": 157, "planet": 157, "801392782910287192": 157, "biologist": 157, "breath": 157, "smell": 157, "covid": 157, "sum_v": 157, "renorm": [157, 186], "lung": 157, "shoe": [157, 185], "doctor": [157, 186], "hiv": 157, "0015": 157, "011485": 157, "1306": 157, "06": 157, "terrifi": 157, "physician": 157, "clariti": 157, "requisit": 157, "0003": 157, "00176955": 157, "8307": 157, "dp": 157, "sum_x": 157, "economist": 157, "disutil": 157, "100k": [157, 158, 162, 164, 165], "rent": 157, "homeless": 157, "200k": 157, "genuin": 157, "der": [157, 186], "kiureghian": [157, 186], "ditlevsen": [157, 186], "quantif": 157, "tenfold": 157, "41": [157, 186], "z_m": 157, "venn": 157, "infect": 157, "asset": 157, "portfolio": [157, 186], "nobel": 157, "markovitz": 157, "mangram": [157, 186], "intric": [158, 165], "sedhain": [158, 186], "cf": [158, 167], "meantim": 158, "underset": [158, 163, 190], "parallel_": 158, "mx": [158, 163, 165, 168], "num_us": [158, 163, 164, 165, 168], "rmse": [158, 163], "inter_matrix": 158, "recon": 158, "sublist": [158, 165], "movielen": [158, 161, 162, 163, 165, 191], "num_item": [158, 163, 164, 165, 168], "read_data_ml100k": [158, 164, 165, 168], "split_data_ml100k": [158, 164, 165, 168], "train_inter_mat": 158, "load_data_ml100k": [158, 164, 165, 168], "test_inter_mat": 158, "rollov": [158, 160, 161, 164, 165, 168], "train_recsys_r": [158, 163], "inter_mat": [158, 163], "ctr": [159, 160, 161, 186], "mcmahan": [159, 186], "anonym": 159, "attract": [159, 163], "campaign": 159, "piqu": 159, "visitor": 159, "undisclos": 159, "privaci": 159, "e18327c48c8e8e5c23da714dd614e390d369843f": 159, "15000": 159, "ctrdataset": [159, 160, 161], "data_path": 159, "feat_mapp": [159, 160, 161], "min_threshold": 159, "num_feat": 159, "feat_cnt": 159, "field_dim": [159, 160, 161], "int64": [159, 177, 183], "setdefault": [159, 164, 168], "cnt": 159, "feat_v": 159, "feat_valu": 159, "fm": [159, 160, 161], "criteo": [159, 160, 161], "avazu": [159, 161], "guo": [160, 186], "dnn": [160, 186], "chua": [160, 186], "mlp_dim": 160, "num_factor": [160, 161, 163, 165, 168], "drop_rat": 160, "linear_lay": [160, 161], "embed_output_dim": 160, "embed_x": 160, "square_of_sum": [160, 161], "sum_of_squar": [160, 161], "pyramid": 160, "sigmoidbinarycrossentropyloss": [160, 161], "rendl": [161, 166, 186], "reminisc": [161, 166], "weaken": 161, "kd": [161, 168], "reorgan": 161, "reformul": 161, "bpr": [161, 166, 168, 186], "viabl": [161, 164], "yi": 162, "spotifi": 162, "delight": 162, "commonplac": [162, 163], "autorec": [162, 163, 165, 166, 186, 191], "neumf": [162, 168], "deepfm": [162, 186], "koren": [163, 186], "contest": 163, "rental": 163, "announc": 163, "cinematch": 163, "percent": 163, "usd": 163, "grand": [163, 186], "bellkor": 163, "pragmat": 163, "bigchao": [163, 186], "blend": 163, "scher": [163, 186], "_u": [163, 165, 166, 168], "genr": [163, 164], "pq": 163, "poorer": 163, "ui": [163, 165, 166], "b_u": 163, "2_f": 163, "user_bia": 163, "item_bia": 163, "user_id": [163, 164, 165, 168], "item_id": [163, 164, 165, 168], "p_u": 163, "q_i": 163, "gunawardana": [163, 186], "shani": [163, 186], "rmse_list": 163, "r_ui": 163, "r_hat": 163, "input_data": [163, 165], "train_feat": 163, "test_rms": 163, "split_and_load_ml100k": [163, 164], "test_ratio": [163, 164], "grouplen": 164, "minnesota": 164, "herlock": [164, 186], "943": 164, "1682": 164, "readm": 164, "org": [164, 186], "cd4dcac4241c8a4ad7badc7ca635da8a69dddb83": 164, "timestamp": [164, 167, 168], "interchang": [164, 166], "93": 164, "695": [164, 186], "ec": 164, "oldest": 164, "split_mod": 164, "train_item": 164, "test_item": 164, "train_list": 164, "itertupl": 164, "neg_mask": 164, "user_index": 164, "item_index": 164, "train_u": 164, "train_r": 164, "test_u": 164, "test_r": 164, "ncf": 165, "subnetwork": 165, "gmf": 165, "nums_hidden": 165, "prediction_lay": 165, "p_mf": 165, "q_mf": 165, "p_mlp": 165, "q_mlp": 165, "con_r": 165, "dislik": 165, "prdataset": 165, "cand": [165, 168], "neg_item": 165, "roc": 165, "rank_": 165, "g_u": 165, "backslash": [165, 166], "s_u": [165, 168], "discount": [165, 166, 187, 189, 190], "ndcg": [165, 166], "hit_and_auc": 165, "rankedlist": 165, "test_matrix": 165, "hits_k": 165, "hits_al": 165, "evaluate_rank": [165, 168], "test_input": 165, "ranked_list": 165, "ranked_item": 165, "hit_rat": 165, "all_item": [165, 168], "test_data_it": 165, "item_scor": 165, "train_rank": [165, 168], "test_seq_it": [165, 168], "eval_step": [165, 168], "p_po": 165, "p_neg": 165, "predict_mod": 165, "binar": 165, "users_train": [165, 168], "items_train": [165, 168], "ratings_train": [165, 168], "users_test": [165, 168], "items_test": [165, 168], "ratings_test": [165, 168], "bprloss": [165, 166, 168], "demerit": 166, "listwis": [166, 186], "uj": 166, "lambda_": [166, 178], "wedg": 166, "batch_axi": 166, "svm": [166, 186], "hingelossbrec": 166, "youtub": 167, "tapestri": [167, 186], "goldberg": [167, 186], "newsgroup": 167, "su": [167, 186], "khoshgoftaar": [167, 186], "sarwar": [167, 186], "reluct": 167, "mous": 167, "forth": 167, "stamp": 167, "quadrana": [167, 168, 186], "cold": [167, 186], "schein": [167, 186], "uncov": 168, "milk": 168, "butter": 168, "flour": 168, "transient": 168, "hconv": 168, "vconv": 168, "uit": 168, "d_prime": 168, "drop_ratio": 168, "conv_v": 168, "conv_h": 168, "maxpool1d": 168, "fc1_dim_v": 168, "fc1_dim_h": 168, "q_prime": 168, "item_emb": 168, "user_emb": 168, "out_h": 168, "out_v": 168, "maxp": 168, "conv_out": 168, "pool_out": 168, "q_prime_i": 168, "seqdataset": 168, "sort_idx": 168, "u_id": 168, "i_id": 168, "seq_item": 168, "seq_us": 168, "seq_tgt": 168, "test_seq": 168, "test_us": 168, "_uid": 168, "uid": [168, 186], "i_seq": 168, "_seq": 168, "_win": 168, "step_siz": 168, "stop_idx": 168, "target_num": 168, "train_seq_data": 168, "04": 168, "1h": [168, 171], "session": [168, 186], "hidasi": [168, 186], "overestim": [169, 185, 189], "undemand": 169, "bang": 169, "buck": 169, "greedili": 169, "048": 169, "054": 169, "miracul": 169, "times10": 169, "abd": 169, "ced": 169, "y_2": [169, 177], "y_3": 169, "leftward": [170, 172, 184], "shouldn": 170, "___": 170, "schuster": [170, 174, 186], "paliw": [170, 174, 186], "overrightarrow": 170, "overleftarrow": 170, "xh": [170, 171, 173, 181], "hh": [170, 171, 173, 178, 181], "2h": 170, "hq": [170, 171, 181], "rnnscratch": [170, 171, 183], "birnnscratch": 170, "f_rnn": 170, "b_rnn": 170, "f_h": 170, "b_h": [170, 173, 183], "f_output": 170, "b_output": 170, "bigru": 170, "phi_l": 171, "2056": 171, "stackedrnnscratch": 171, "timemachin": [171, 173, 175, 180, 182, 183, 185], "rnn_block": 171, "rnnlmscratch": [171, 173, 175, 182, 183], "new_stat": 171, "initialize_carri": [171, 173, 175], "variable_broadcast": [171, 173, 175], "in_ax": [171, 173, 175], "out_ax": [171, 173, 175], "split_rng": [171, 173, 175], "layer_i_st": 171, "out_stat": 171, "gru_cel": 171, "time_major": [171, 175, 182], "rnnlm": [171, 173, 175, 182], "enc_all_output": [172, 177], "encoderdecod": [172, 177], "cho": [173, 177, 186], "chung": [173, 186], "xr": 173, "hr": 173, "xz": 173, "hz": 173, "gruscratch": 173, "w_xz": 173, "w_hz": 173, "b_z": 173, "w_xr": 173, "w_hr": 173, "b_r": 173, "w_xh": [173, 181, 183], "w_hh": [173, 181, 183], "w_x": [173, 175], "w_h": [173, 175], "h_tild": 173, "scan_fn": [173, 175], "lighter": [173, 174, 186], "notori": 174, "typifi": 174, "cascad": 174, "phonem": [174, 186], "handwrit": [174, 179, 186], "beam": [174, 177, 191], "elman": [175, 186], "articul": 175, "ephemer": 175, "inclus": 175, "flush": 175, "xf": 175, "hf": 175, "xo": 175, "xc": 175, "forev": 175, "uninhibit": 175, "dictat": 175, "lstmscratch": 175, "w_xi": 175, "w_hi": 175, "w_xf": 175, "w_hf": 175, "b_f": 175, "w_xo": 175, "w_ho": 175, "b_o": 175, "w_xc": 175, "w_hc": 175, "b_c": 175, "h_c": 175, "c_tild": 175, "begin_st": [175, 182], "optimizedlstmcel": 175, "rose": [175, 179], "victori": 175, "tranform": 175, "lump": 176, "bilingu": [176, 177], "tatoeba": 176, "_download": [176, 180, 185], "_token": [176, 185], "max_exampl": 176, "src": [176, 177], "tgt": [176, 177], "xlist": 176, "ylist": 176, "set_hatch": 176, "_build_arrai": 176, "is_tgt": 176, "pad_or_trim": 176, "tgt_sentenc": 176, "salut": 176, "japanes": 176, "enc_stat": 177, "check_len": [177, 183], "seq2seqdecod": 177, "embs_and_context": 177, "dec_output": 177, "inter_enc_var": 177, "inter_dec_var": 177, "understudi": 177, "papineni": [177, 186], "p_3": 177, "p_4": 177, "pred_seq": 177, "label_seq": 177, "pred_token": 177, "label_token": 177, "len_pr": 177, "len_label": 177, "num_match": 177, "label_sub": 177, "rerun": 177, "destabil": 178, "werbo": [178, 186], "unrol": [178, 179], "feedforward": [178, 179, 186], "h_t": [178, 181, 184], "o_t": 178, "h_": [178, 181, 184], "trickier": 178, "a_t": [178, 188, 189, 190], "b_t": 178, "c_t": 178, "butterfli": 178, "backpropg": 178, "jaeger": [178, 186], "xi_t": 178, "pi_t": 178, "z_t": 178, "tallec": [178, 186], "ollivi": [178, 186], "hx": 178, "qh": 178, "protyp": 179, "synthesi": [179, 186], "unfold": [179, 184], "cede": 179, "abc": 179, "pave": 179, "exploratori": [179, 186], "wreck": 180, "beach": 180, "outlandish": 180, "worthwhil": 180, "bite": 180, "grandma": 180, "benign": 180, "unigram": [180, 185], "bigram": [180, 185], "trigram": [180, 185], "gutenberg": 180, "singleton": 180, "epsilon_3": 180, "wood": [180, 186], "felin": 180, "piouw": 180, "kcj": 180, "pwepoiut": 180, "nonsens": [180, 182], "tolstoi": 180, "magnum": 180, "opu": 180, "war": [180, 183], "peac": 180, "inevit": 180, "saint": 180, "exuperi": 180, "princ": 180, "achin": [181, 186], "heck": 182, "rnncell": 182, "simplernn": 182, "init_param": [182, 183], "output_lay": [182, 183], "rnn_output": [182, 183], "w_hq": 183, "b_q": 183, "46": 183, "ineleg": 183, "lipschitz": 183, "spike": 183, "bestow": 183, "grad_clip_v": 183, "grad_leav": 183, "tree_flatten": 183, "autocomplet": 183, "num_pr": 183, "whip": 183, "10th": [184, 186], "transpir": 184, "bother": 184, "imperfectli": 184, "recoveri": 184, "ftse": 184, "strateg": 184, "revolv": 184, "hebrew": 184, "hoyer": [184, 186], "onestep_pr": 184, "604": 184, "n_train": 184, "609": [184, 186], "605": 184, "601": 184, "602": [184, 186], "603": 184, "606": 184, "607": [184, 186], "608": 184, "multistep": 184, "multistep_pr": 184, "k_step_pr": 184, "investor": 184, "090b5e7e70c295757f55df93cb0a180b9691891a": 185, "za": 185, "atom": 185, "ascii": 185, "pronoun": 185, "preposit": 185, "zipfian": 185, "zipf": 185, "bigram_token": 185, "bigram_vocab": 185, "trigram_token": 185, "trigram_vocab": 185, "bigram_freq": 185, "trigram_freq": 185, "scrape": 185, "barham": 186, "davi": 186, "12th": 186, "usenix": 186, "ymposium": 186, "perat": 186, "ystem": 186, "esign": 186, "mplement": 186, "osdi": 186, "pp": 186, "265": 186, "jiang": 186, "ieee": 186, "acm": 186, "ransact": 186, "udio": 186, "peech": 186, "anguag": 186, "1545": 186, "gonzalez": 186, "proceed": 186, "ifth": 186, "nternat": 186, "onfer": 186, "eb": 186, "earch": 186, "ata": 186, "ining": 186, "123": 186, "132": 186, "sano": 186, "yanas": 186, "ohta": 186, "koyama": 186, "25th": 186, "sigkdd": 186, "nowledg": 186, "iscoveri": 186, "donahu": 186, "luc": 186, "miech": 186, "barr": 186, "hasson": 186, "2204": 186, "14198": 186, "kokhlikyan": 186, "miglani": 186, "reblitz": 186, "richardson": 186, "blind": 186, "02178": 186, "firat": 186, "johnson": 186, "lepikhin": 186, "passo": 186, "pa": 186, "lm": 186, "echnic": 186, "eport": 186, "2305": 186, "10403": 186, "regan": 186, "singer": 186, "09018": 186, "eproduc": 186, "ernel": 186, "merican": 186, "athemat": 186, "ocieti": 186, "68": 186, "337": 186, "404": 186, "kiro": 186, "1607": 186, "06450": 186, "1409": 186, "0473": 186, "kadavath": 186, "kundu": 186, "askel": 186, "kernion": 186, "jone": 186, "2212": 186, "08073": 186, "ayesian": 186, "35th": 186, "brendel": 186, "\u00e9": 186, "gl": 186, "sebag": 186, "30th": 186, "icml": 186, "tuytelaar": 186, "gool": 186, "peed": 186, "european": 186, "omput": 186, "ision": 186, "417": 186, "153": 186, "ation": 186, "cademi": 186, "cienc": 186, "716": 186, "719": 186, "1957a": 186, "arkovian": 186, "echan": 186, "679": 186, "684": 186, "jstor": 186, "24900506": 186, "1957b": 186, "dover": 186, "cohan": 186, "05150": 186, "ducharm": 186, "jauvin": 186, "ournal": 186, "esearch": 186, "feb": 186, "1137": 186, "1155": 186, "frasconi": 186, "eural": 186, "etwork": 186, "157": 186, "166": 186, "nformat": 186, "rocess": 186, "breuleux": 186, "bastien": 186, "lamblin": 186, "pascanu": 186, "desjardin": 186, "ython": 186, "proc": 186, "9th": 186, "murrai": 186, "faloutso": 186, "23rd": 186, "orld": 186, "108": 186, "ikhonov": 186, "ecognit": 186, "springer": 186, "liabil": 186, "olit": 186, "conomi": 186, "637": 186, "654": 186, "singh": 186, "chellappa": 186, "5561": 186, "5569": 186, "joulin": 186, "ssociat": 186, "inguist": 186, "135": 186, "146": 186, "bolloba": 186, "nalysi": 186, "nivers": 186, "ress": 186, "hudson": 186, "altman": 186, "arora": 186, "von": 186, "arx": 186, "2108": 186, "07258": 186, "compstat": 186, "177": 186, "186": 186, "connectionist": 186, "euro": 186, "im": 186, "371": 186, "382": 186, "nime": 186, "bousquet": 186, "lugosi": 186, "esaim": 186, "robabl": 186, "tatist": 186, "323": 186, "375": 186, "ang": 186, "pott": 186, "1508": 186, "05326": 186, "ptimiz": 186, "england": 186, "biometrika": 186, "324": 186, "345": 186, "ijcai": 186, "5226": 186, "5228": 186, "della": 186, "pietra": 186, "jelinek": 186, "lafferti": 186, "roossin": 186, "85": 186, "mercer": 186, "cole": 186, "udapest": 186, "olum": 186, "mann": 186, "ryder": 186, "subbiah": 186, "dhariw": 186, "1877": 186, "1901": 186, "iglovikov": 186, "khvedchenya": 186, "parinov": 186, "druzhinin": 186, "kalinin": 186, "albument": 186, "hoan": 186, "jr": 186, "hsu": 186, "ntellig": 186, "134": 186, "184": 186, "203": 186, "elsevi": 186, "diab": 186, "agirr": 186, "lopez": 186, "gazpio": 186, "specia": 186, "sem": 186, "crosslingu": 186, "11th": 186, "orkshop": 186, "emant": 186, "valuat": 186, "em": 186, "jaitli": 186, "vinyal": 186, "listen": 186, "01211": 186, "lu": 186, "rajeswaran": 186, "lee": 186, "grover": 186, "laskin": 186, "mordatch": 186, "15084": 186, "15097": 186, "heterogen": 186, "1512": 186, "01274": 186, "dong": 186, "lapata": 186, "mpiric": 186, "ethod": 186, "atur": 186, "551": 186, "woollei": 186, "vandermersch": 186, "cohen": 186, "catanzaro": 186, "shelham": 186, "cu": 186, "fficient": 186, "1410": 186, "0759": 186, "2014a": 186, "merri": 186, "\u00eb": 186, "nboer": 186, "ncoder": 186, "1259": 186, "2014b": 186, "gulcehr": 186, "bougar": 186, "schwenk": 186, "1406": 186, "1078": 186, "narang": 186, "bosma": 186, "mishra": 186, "robert": 186, "02311": 186, "1412": 186, "3555": 186, "luong": 186, "epresent": 186, "weston": 186, "karlen": 186, "kavukcuoglu": 186, "kuksa": 186, "2493": 186, "2537": 186, "louka": 186, "jaggi": 186, "heori": 186, "ilei": 186, "ons": 186, "csiszar": 186, "axiomat": 186, "261": 186, "273": 186, "superposit": 186, "ontrol": 186, "ignal": 186, "303": 186, "314": 186, "attern": 186, "cvpr": 186, "886": 186, "893": 186, "decock": 186, "owa": 186, "oston": 186, "semest": 186, "ducat": 186, "corrado": 186, "monga": 186, "devin": 186, "1223": 186, "1231": 186, "hastorun": 186, "jampani": 186, "kakulapati": 186, "lakshman": 186, "pilchin": 186, "vogel": 186, "mazon": 186, "sigop": 186, "eview": 186, "205": 186, "220": 186, "socher": 186, "fei": 186, "248": 186, "derkiureghian": 186, "aleatori": 186, "afeti": 186, "toutanova": 186, "1810": 186, "04805": 186, "krueger": 186, "8516": 186, "nvp": 186, "efro": 186, "1422": 186, "1430": 186, "beyer": 186, "kolesnikov": 186, "weissenborn": 186, "zhai": 186, "unterthin": 186, "hazan": 186, "subgradi": 186, "2121": 186, "2159": 186, "1603": 186, "07285": 186, "09699": 186, "feldman": 186, "hardt": 186, "pitassi": 186, "roth": 186, "47th": 186, "nnual": 186, "117": 186, "179": 186, "211": 186, "metzen": 186, "ssurvei": 186, "1808": 186, "05377": 186, "sychophysik": 186, "vol": 186, "breitkopf": 186, "h\u00e4": 186, "rtel": 186, "shazeer": 186, "rogram": 186, "echniqu": 186, "rick": 186, "eal": 186, "raphic": 186, "addison": 186, "eslei": 186, "halleng": 186, "letham": 186, "bakshi": 186, "1802": 186, "02219": 186, "cortic": 186, "josa": 186, "2379": 186, "2394": 186, "orker": 186, "oyd": 186, "658": 186, "bester": 186, "kean": 186, "oyal": 186, "hysic": 186, "ngineer": 186, "463": 186, "2088": 186, "3251": 186, "3269": 186, "donini": 186, "pontil": 186, "34th": 186, "lotteri": 186, "ticket": 186, "1803": 186, "03635": 186, "1807": 186, "02811": 186, "148": 186, "156": 186, "pursuit": 186, "82": 186, "397": 186, "249": 186, "266": 186, "leari": 186, "ooper": 186, "267": 186, "285": 186, "weinberg": 186, "bindel": 186, "blackbox": 186, "aussian": 186, "balakrishnan": 186, "ratt": 186, "3598": 186, "3609": 186, "ecker": 186, "bethg": 186, "2414": 186, "2423": 186, "theoria": 186, "motu": 186, "corporum": 186, "coelestum": 186, "werk": 186, "k\u00f6niglich": 186, "reussisch": 186, "kademi": 186, "issenschaften": 186, "rincipl": 186, "hanic": 186, "scribner": 186, "440": 186, "449": 186, "1440": 186, "1448": 186, "darrel": 186, "malik": 186, "587": 186, "13th": 186, "rtifici": 186, "pub": 186, "nichol": 186, "oki": 186, "weav": 186, "61": 186, "vanloan": 186, "opkin": 186, "courvil": 186, "mit": 186, "deeplearningbook": 186, "pouget": 186, "mirza": 186, "ward": 186, "farlei": 186, "ozair": 186, "2672": 186, "2680": 186, "keskar": 186, "13243": 186, "bochkovskii": 186, "koltun": 186, "2110": 186, "07641": 186, "6071": 186, "1308": 186, "0850": 186, "liwicki": 186, "fern": 186, "ndez": 186, "bertolami": 186, "bunk": 186, "855": 186, "868": 186, "framewis": 186, "610": 186, "ecent": 186, "evelop": 186, "pplicat": 186, "107": 186, "kluwer": 186, "chiu": 186, "parmar": 186, "nterspeech": 186, "5036": 186, "5040": 186, "andbook": 186, "308": 186, "26th": 186, "oint": 186, "1725": 186, "1731": 186, "gunn": 186, "nikravesh": 186, "zadeh": 186, "xtraction": 186, "oundat": 186, "mitliagka": 186, "omnivor": 186, "1606": 186, "04487": 186, "iew": 186, "eometri": 186, "doll": 186, "cvf": 186, "16000": 186, "16009": 186, "2017a": 186, "gkioxari": 186, "2961": 186, "2969": 186, "mage": 186, "1034": 186, "2016a": 186, "770": 186, "778": 186, "2016b": 186, "630": 186, "645": 186, "40th": 186, "sigir": 186, "etriev": 186, "355": 186, "364": 186, "2017b": 186, "liao": 186, "nie": 186, "173": 186, "182": 186, "rganiz": 186, "ehavior": 186, "wilei": 186, "08415": 186, "rchitectur": 186, "uantit": 186, "pproach": 186, "konstan": 186, "borcher": 186, "riedl": 186, "22nd": 186, "230": 186, "237": 186, "karatzogl": 186, "baltruna": 186, "tikk": 186, "1511": 186, "06939": 186, "jain": 186, "abbeel": 186, "6840": 186, "6851": 186, "ield": 186, "ynamic": 186, "ecurr": 186, "1735": 186, "1780": 186, "borgeaud": 186, "mensch": 186, "buchatskaya": 186, "cai": 186, "rutherford": 186, "2203": 186, "15556": 186, "sandler": 186, "chu": 186, "obil": 186, "1314": 186, "1324": 186, "janz": 186, "mooij": 186, "689": 186, "696": 186, "shen": 186, "7132": 186, "7141": 186, "volinski": 186, "8th": 186, "263": 186, "aggarw": 186, "xplor": 186, "ewsl": 186, "doi": 186, "1145": 186, "3544903": 186, "3544906": 186, "uszkoreit": 186, "hawthorn": 186, "eck": 186, "maaten": 186, "4700": 186, "4708": 186, "crf": 186, "01991": 186, "striat": 186, "hysiologi": 186, "574": 186, "591": 186, "binocular": 186, "106": 186, "154": 186, "195": 186, "215": 186, "243": 186, "hoo": 186, "leyton": 186, "lion": 186, "kotthoff": 186, "vanschoren": 186, "ed": 186, "1945": 186, "1953": 186, "1502": 186, "03167": 186, "podoprikhin": 186, "garipov": 186, "vetrov": 186, "05407": 186, "gabriel": 186, "hongler": 186, "bppt": 186, "rtrl": 186, "ekf": 186, "echo": 186, "gmd": 186, "orschungszentrum": 186, "nformationstechnik": 186, "onn": 186, "17th": 186, "gonz\u00e1lez": 186, "rong": 186, "11205": 186, "karayev": 186, "multimedia": 186, "675": 186, "678": 186, "weld": 186, "zettlemoy": 186, "patil": 186, "agraw": 186, "bajwa": 186, "datacent": 186, "44th": 186, "isca": 186, "grefenstett": 186, "blunsom": 186, "1404": 186, "2188": 186, "ijcnn": 186, "578": 186, "581": 186, "mccandlish": 186, "henighan": 186, "amodei": 186, "08361": 186, "somekh": 186, "aila": 186, "lain": 186, "lehtinen": 186, "1710": 186, "10196": 186, "el": 186, "khami": 186, "03360": 186, "1408": 186, "5882": 186, "chebycheffian": 186, "nal": 186, "6980": 186, "ay": 186, "iclr": 186, "1609": 186, "02907": 186, "gu": 186, "reid": 186, "matsuo": 186, "iwasawa": 186, "2205": 186, "11916": 186, "odel": 186, "sulla": 186, "determinazion": 186, "empirica": 186, "di": 186, "una": 186, "legg": 186, "distribuzion": 186, "inst": 186, "ttuari": 186, "iorn": 186, "cs229": 186, "1097": 186, "1105": 186, "rrai": 186, "rocessor": 186, "prentic": 186, "vicent": 186, "petton": 186, "lachaux": 186, "baciu": 186, "kahan": 186, "aru": 186, "band": 186, "iologi": 186, "goodman": 186, "sharma": 186, "soricut": 186, "1909": 186, "11942": 186, "4013": 186, "4021": 186, "coustic": 186, "8595": 186, "8598": 186, "1995a": 186, "3361": 186, "boser": 186, "denker": 186, "henderson": 186, "hubbard": 186, "jackel": 186, "541": 186, "1998a": 186, "orr": 186, "muller": 186, "rade": 186, "1998b": 186, "haffner": 186, "2278": 186, "2324": 186, "1995b": 186, "brunot": 186, "cort": 186, "moir": 186, "sur": 186, "ration": 186, "rigonom": 186, "triqu": 186, "dont": 186, "r\u00e9": 186, "sultat": 186, "d\u00e9": 186, "pendent": 186, "igur": 186, "idot": 186, "ghazvininejad": 186, "1910": 186, "13461": 186, "andreassen": 186, "dohan": 186, "dyer": 186, "michalewski": 186, "ramasesh": 186, "2206": 186, "14858": 186, "rostamizadeh": 186, "gonina": 186, "recht": 186, "05934": 186, "istribut": 186, "lgorithm": 186, "dissert": 186, "hesi": 186, "cmu": 186, "andersen": 186, "josifovski": 186, "583": 186, "598": 186, "20th": 186, "661": 186, "670": 186, "nishihara": 186, "moritz": 186, "stoica": 186, "05118": 186, "yan": 186, "1312": 186, "4400": 186, "2980": 186, "2988": 186, "lv": 186, "cour": 186, "feng": 186, "santo": 186, "xiang": 186, "1703": 186, "03130": 186, "berkowitz": 186, "elkan": 186, "1506": 186, "wetzel": 186, "scholarship": 186, "503": 186, "1806": 186, "09055": 186, "anguelov": 186, "erhan": 186, "fu": 186, "berg": 186, "ott": 186, "stoyanov": 186, "ro": 186, "robustli": 186, "1907": 186, "11692": 186, "10012": 186, "10022": 186, "feichtenhof": 186, "2201": 186, "03545": 186, "3431": 186, "3440": 186, "sgdr": 186, "1608": 186, "03983": 186, "keypoint": 186, "peng": 186, "00846": 186, "dali": 186, "49th": 186, "eet": 186, "uman": 186, "echnologi": 186, "142": 186, "zeitschrift": 186, "\u00fc": 186, "ahrscheinlichkeitstheori": 186, "und": 186, "verwandt": 186, "ebiet": 186, "405": 186, "415": 186, "nferenc": 186, "duvenaud": 186, "32nd": 186, "444": 186, "452": 186, "arkowitz": 186, "usi": 186, "59": 186, "rowland": 186, "hron": 186, "turner": 186, "ghahramani": 186, "1804": 186, "11271": 186, "bradburi": 186, "ontextu": 186, "6294": 186, "6305": 186, "imman": 186, "nervou": 186, "bulletin": 186, "biophys": 186, "133": 186, "holt": 186, "scullei": 186, "ebner": 186, "gradi": 186, "trench": 186, "1222": 186, "1230": 186, "iee": 186, "roceed": 186, "olid": 186, "tate": 186, "lectron": 186, "evic": 186, "sentinel": 186, "07843": 186, "pline": 186, "unction": 186, "143": 186, "145": 186, "2013a": 186, "1301": 186, "3781": 186, "2013b": 186, "composition": 186, "3111": 186, "3119": 186, "lexic": 186, "nglish": 186, "steiner": 186, "larsen": 186, "2430": 186, "2439": 186, "heess": 186, "antonogl": 186, "wierstra": 186, "riedmil": 186, "tari": 186, "5602": 186, "rusu": 186, "veness": 186, "bellemar": 186, "518": 186, "7540": 186, "529": 186, "533": 186, "zheng": 186, "intervalrank": 186, "isoton": 186, "3rd": 186, "151": 186, "hoekstra": 186, "rouder": 186, "wagenmak": 186, "psychonom": 186, "ulletin": 186, "103": 186, "olv": 186, "ncorrectli": 186, "os": 186, "roblem": 186, "141": 186, "oltzmann": 186, "kaplun": 186, "bansal": 186, "barak": 186, "xperiment": 186, "124003": 186, "ubi": 186, "ackoff": 186, "ryptologi": 186, "29": 186, "onvex": 186, "automatica": 186, "1559": 186, "1568": 186, "ondon": 186, "eri": 186, "236": 186, "767": 186, "333": 186, "380": 186, "fumero": 186, "maiorca": 186, "moschella": 186, "rodol": 186, "locatello": 186, "asif": 186, "unimod": 186, "2210": 186, "01738": 186, "bahri": 186, "05148": 186, "utomata": 186, "615": 186, "622": 186, "381": 186, "6583": 186, "williamson": 186, "hyperkernel": 186, "1043": 186, "1071": 186, "2303": 186, "08774": 186, "almeida": 186, "wainwright": 186, "mishkin": 186, "02155": 186, "rouko": 186, "311": 186, "318": 186, "\u00e4": 186, "ckstr": 186, "da": 186, "01933": 186, "2337": 186, "2346": 186, "nnal": 186, "329": 186, "348": 186, "gross": 186, "massa": 186, "lerer": 186, "chanan": 186, "orch": 186, "8026": 186, "8037": 186, "04304": 186, "malart": 186, "hesslow": 186, "cojocaru": 186, "cappelli": 186, "alobeidli": 186, "launai": 186, "efin": 186, "alcon": 186, "llm": 186, "2306": 186, "01116": 186, "schoenholz": 186, "ganguli": 186, "resurrect": 186, "isometri": 186, "4785": 186, "4795": 186, "glo": 186, "emnlp": 186, "1532": 186, "1543": 186, "ausal": 186, "ammar": 186, "bhagavatula": 186, "55th": 186, "1756": 186, "1765": 186, "neumann": 186, "iyyer": 186, "orth": 186, "hapter": 186, "2227": 186, "2237": 186, "cookbook": 186, "denmark": 186, "1707": 186, "06990": 186, "ussr": 186, "hasan": 186, "datla": 186, "qadir": 186, "farri": 186, "paraphras": 186, "1610": 186, "03098": 186, "yasunaga": 186, "2302": 186, "06476": 186, "cremonesi": 186, "jannach": 186, "urvei": 186, "51": 186, "hallaci": 186, "8748": 186, "8763": 186, "metz": 186, "chintala": 186, "06434": 186, "narasimhan": 186, "saliman": 186, "luan": 186, "1882": 186, "kosaraju": 186, "10428": 186, "10436": 186, "millican": 186, "2112": 186, "11446": 186, "matena": 186, "67": 186, "lopyrev": 186, "05250": 186, "bello": 186, "levskaya": 186, "shlen": 186, "05941": 186, "06125": 186, "cajal": 186, "santiago": 186, "ouvel": 186, "tructur": 186, "yst": 186, "\u00e8": 186, "erveux": 186, "omm": 186, "ert": 186, "br": 186, "einwald": 186, "ie": 186, "boureau": 186, "chopra": 186, "379": 186, "09237": 186, "divvala": 186, "779": 186, "788": 186, "olo": 186, "02767": 186, "defreita": 186, "06279": 186, "zolna": 186, "parisotto": 186, "colmenarejo": 186, "novikov": 186, "barth": 186, "maron": 186, "06175": 186, "995": 186, "freudenthal": 186, "gantner": 186, "schmidt": 186, "thiem": 186, "ncertainti": 186, "461": 186, "lubin": 186, "papamark": 186, "ulia": 186, "07892": 186, "1278": 186, "1286": 186, "eurosci": 186, "1019": 186, "princeton": 186, "veit": 186, "belongi": 186, "shavit": 186, "10694": 186, "mcgraw": 186, "avocado": 186, "zucchini": 186, "iccv": 186, "kraus": 186, "satheesh": 186, "ma": 186, "252": 186, "odern": 186, "saxena": 186, "whang": 186, "denton": 186, "11487": 186, "perron": 186, "un": 186, "utom": 186, "debut": 186, "chaumond": 186, "wolf": 186, "01108": 186, "webson": 186, "sutawika": 186, "alyafeai": 186, "08207": 186, "tsipra": 186, "madri": 186, "2483": 186, "295": 186, "akiki": 186, "pavlick": 186, "ili": 186, "\u0107": 186, "176": 186, "2211": 186, "05100": 186, "popescul": 186, "ungar": 186, "pennock": 186, "253": 186, "260": 186, "beaumont": 186, "vencu": 186, "wightman": 186, "cherti": 186, "08402": 186, "2673": 186, "2681": 186, "scholkopf": 186, "herbrich": 186, "helmbold": 186, "416": 186, "426": 186, "verlag": 186, "burg": 186, "upport": 186, "ector": 186, "egular": 186, "eyond": 186, "menon": 186, "sanner": 186, "24th": 186, "haddow": 186, "birch": 186, "07909": 186, "delbalso": 186, "ensor": 186, "05799": 186, "27": 186, "423": 186, "yao": 186, "abdelzah": 186, "vae": 186, "37th": 186, "patwari": 186, "puri": 186, "legreslei": 186, "casper": 186, "08053": 186, "maddison": 186, "guez": 186, "sifr": 186, "den": 186, "driessch": 186, "7587": 186, "484": 186, "stimat": 186, "chapman": 186, "victorri": 186, "239": 186, "274": 186, "1556": 186, "sainath": 186, "1510": 186, "01722": 186, "oogl": 186, "1470": 186, "norick": 186, "rajbhandari": 186, "eep": 186, "egatron": 186, "ur": 186, "11990": 186, "vldb": 186, "ndowment": 186, "703": 186, "710": 186, "larochel": 186, "2951": 186, "2959": 186, "weiss": 186, "maheswaranathan": 186, "nonequilibrium": 186, "2256": 186, "2265": 186, "rastogi": 186, "rao": 186, "shoeb": 186, "abid": 186, "fisch": 186, "04615": 186, "salakhutdinov": 186, "1929": 186, "greff": 186, "1505": 186, "00387": 186, "inear": 186, "lgebra": 186, "welleslei": 186, "ambridg": 186, "2440": 186, "2448": 186, "marten": 186, "dahl": 186, "1139": 186, "1147": 186, "3104": 186, "3112": 186, "vanhouck": 186, "alemi": 186, "v4": 186, "nception": 186, "31st": 186, "aaai": 186, "sermanet": 186, "rabinovich": 186, "wojna": 186, "rethink": 186, "2818": 186, "2826": 186, "08209": 186, "6105": 186, "6114": 186, "eleventh": 186, "565": 186, "573": 186, "guestrin": 186, "arkov": 186, "dehghani": 186, "metzler": 186, "06732": 186, "karda": 186, "cucurul": 186, "scialom": 186, "hartshorn": 186, "saravia": 186, "stojnic": 186, "09085": 186, "azizpour": 186, "06455": 186, "shamma": 186, "friedland": 186, "elizald": 186, "poland": 186, "yfcc100m": 186, "73": 186, "coursera": 186, "inston": 186, "houlsbi": 186, "mixer": 186, "freeman": 186, "douz": 186, "sablayrol": 186, "gou": 186, "10347": 186, "lavril": 186, "izacard": 186, "martinet": 186, "lacroix": 186, "13971": 186, "martin": 186, "stone": 186, "almahairi": 186, "babaei": 186, "2307": 186, "09288": 186, "areh": 186, "433": 186, "toscher": 186, "jahrer": 186, "etflix": 186, "sand": 186, "gever": 186, "smeulder": 186, "104": 186, "171": 186, "dokl": 186, "akad": 186, "nauk": 186, "sssr": 186, "181": 186, "915": 186, "918": 186, "probab": 186, "264": 186, "281": 186, "teoriya": 186, "veroyatnostei": 186, "ee": 186, "primeneniya": 186, "543": 186, "564": 186, "305": 186, "1226": 186, "1235": 186, "1403": 186, "831": 186, "838": 186, "levin": 186, "851": 186, "876": 186, "gomez": 186, "polosukhin": 186, "5998": 186, "6008": 186, "bservat": 186, "siam": 186, "hanazawa": 186, "shikano": 186, "lang": 186, "328": 186, "339": 186, "shi": 186, "23433": 186, "23445": 186, "wong": 186, "57th": 186, "1822": 186, "schuurman": 186, "davidson": 186, "pan": 186, "riffel": 186, "owen": 186, "sigplan": 186, "otic": 186, "judgment": 186, "625": 186, "641": 186, "oncis": 186, "ours": 186, "279": 186, "292": 186, "sankhi": 186, "\u0101": 186, "ndian": 186, "359": 186, "372": 186, "guu": 186, "lester": 186, "finetun": 186, "2109": 186, "01652": 186, "2022a": 186, "07682": 186, "2022b": 186, "11903": 186, "angevin": 186, "28th": 186, "681": 186, "688": 186, "464": 186, "78": 186, "1550": 186, "1560": 186, "ann": 186, "325": 186, "327": 186, "4697": 186, "rawat": 186, "pedapati": 186, "1905": 186, "01392": 186, "lg": 186, "schill": 186, "sfi": 186, "010": 186, "anta": 186, "nstitut": 186, "gasthau": 186, "memoiz": 186, "wan": 186, "jin": 186, "golmant": 186, "keutzer": 186, "9127": 186, "9135": 186, "norouzi": 186, "macherei": 186, "bridg": 186, "08144": 186, "rasul": 186, "vollgraf": 186, "1708": 186, "07747": 186, "5393": 186, "5402": 186, "tu": 186, "1492": 186, "xing": 186, "10524": 186, "10533": 186, "alleva": 186, "droppo": 186, "stolck": 186, "icrosoft": 186, "icassp": 186, "5934": 186, "5938": 186, "sakamoto": 186, "akaban": 186, "fujimoto": 186, "poken": 186, "05108": 186, "moczulski": 186, "denil": 186, "1476": 186, "1483": 186, "yin": 186, "334": 186, "gitman": 186, "ginsburg": 186, "03888": 186, "koh": 186, "baid": 186, "10789": 186, "sachan": 186, "9793": 186, "9803": 186, "1212": 186, "5701": 186, "3557": 186, "2021a": 186, "luu": 186, "hui": 186, "parameter": 186, "hypercomplex": 186, "2021b": 186, "roller": 186, "artetx": 186, "01068": 186, "tanida": 186, "itoh": 186, "ichioka": 186, "apan": 186, "ppli": 186, "2021c": 186, "06864": 186, "00923": 186, "3212": 186, "3232": 186, "rli": 186, "hou": 186, "isola": 186, "unpair": 186, "2223": 186, "2232": 186, "zemel": 186, "urtasun": 186, "fidler": 186, "1611": 186, "01578": 186, "pratik": 187, "chaudhari": 187, "pennsylvania": 187, "rasool": 187, "fakoor": 187, "kavosh": 187, "asadi": 187, "doorstep": 187, "warehous": 187, "citi": 187, "deliveri": 187, "datum": 187, "instant": [187, 190], "gridworld": 188, "timestep": [188, 189], "s_0": [188, 189, 190], "r_0": [188, 190], "s_t": [188, 189, 190], "r_t": 188, "gridwold": 188, "markovian": 188, "mountaincar": 188, "pong": 188, "max_": [189, 190], "q_k": [189, 190], "subvert": 189, "pi_e": 189, "min_q": 189, "nt": 189, "afteral": 189, "tie": [189, 190], "prob": 189, "dqn": 189, "chapet": 189, "epsilion": 189, "greadi": 189, "uparrow": [189, 190], "e_greedi": 189, "q_learn": 189, "next_stat": 189, "epicent": 189, "lake": 190, "equiv": 190, "mnemon": 190, "sate": 190, "richard": 190, "v_k": 190, "q_0": 190, "pi_0": 190, "pi_k": 190, "value_iter": 190, "prob_idx": 190, "pr": 190, "prefac": 191, "builder": 191}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"distribut": [0, 9, 44, 64, 94, 103], "bernoulli": 0, "discret": [0, 9], "uniform": 0, "continu": [0, 6, 9, 134], "binomi": 0, "poisson": 0, "gaussian": [0, 11, 78, 79, 80, 81], "exponenti": 0, "famili": 0, "summari": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 155, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 188, 189, 190], "exercis": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 88, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 188, 189, 190], "eigendecomposit": 1, "find": 1, "eigenvalu": 1, "an": [1, 4, 12, 18, 47, 92, 145, 157, 159, 161, 188, 189], "exampl": [1, 2, 4, 6, 11, 47, 78, 85, 92, 94, 133, 157], "decompos": 1, "matric": [1, 153], "oper": [1, 2, 22, 61, 72, 136, 155], "symmetr": 1, "gershgorin": 1, "circl": 1, "theorem": [1, 5], "A": [1, 5, 6, 7, 11, 35, 44, 45, 80, 92, 94, 150, 157], "us": [1, 12, 13, 17, 18, 70, 108, 120, 123, 124], "applic": [1, 4, 117, 118], "The": [1, 5, 6, 7, 8, 11, 15, 23, 29, 35, 49, 57, 59, 60, 64, 72, 80, 82, 86, 92, 93, 95, 96, 98, 100, 103, 119, 120, 121, 123, 127, 129, 132, 133, 134, 135, 137, 138, 139, 145, 147, 163, 164, 165, 172, 184, 189], "growth": 1, "iter": [1, 122, 190], "map": [1, 72], "eigenvector": 1, "long": [1, 175], "term": [1, 175], "behavior": 1, "random": [1, 9, 86, 88, 157, 178], "data": [1, 21, 44, 46, 47, 59, 62, 83, 92, 106, 107, 113, 122, 155, 156, 164, 185], "relat": 1, "back": 1, "observ": 1, "fix": [1, 176], "normal": [1, 29, 63, 103], "discuss": [1, 25, 30, 62, 63, 64, 65, 66, 69, 71, 75, 77, 98, 113, 114, 150, 151, 153, 156, 157, 180, 188], "geometri": [2, 7], "linear": [2, 10, 97, 98, 102, 103, 104, 105, 108, 114, 153], "algebra": [2, 153], "vector": [2, 41, 98, 103, 123, 124, 129, 131, 134, 144, 153], "dot": [2, 22, 153], "product": [2, 22, 153], "angl": 2, "cosin": [2, 143], "similar": [2, 21, 131], "hyperplan": 2, "transform": [2, 24, 25, 29, 30, 126, 127, 183], "depend": 2, "rank": [2, 165, 166], "invert": 2, "numer": [2, 6, 116, 136], "issu": 2, "determin": 2, "tensor": [2, 37, 38, 153, 156], "common": [2, 10, 41, 51], "from": [2, 9, 63, 65, 77, 78, 80, 100, 105, 108, 110, 111, 114, 115, 126, 129, 138, 144, 145, 147, 170, 171, 173, 175, 183], "express": 2, "code": [2, 11, 12, 17, 35, 91, 149], "appendix": [3, 16], "mathemat": [3, 7], "deep": [3, 16, 62, 63, 82, 91, 92, 111, 146, 160, 171, 191], "learn": [3, 16, 62, 72, 78, 91, 92, 94, 95, 111, 138, 141, 143, 146, 148, 149, 177, 180, 187, 189, 191], "inform": [4, 28, 98, 136], "theori": [4, 95, 98, 136], "self": [4, 28, 92, 94, 134, 189], "entropi": [4, 98, 100, 135], "motiv": [4, 92], "definit": [4, 11, 80, 140, 188], "interpret": [4, 5, 11, 42, 78, 129], "properti": [4, 140, 153, 189], "mutual": 4, "joint": [4, 9], "condit": [4, 145], "pointwis": 4, "kullback": 4, "leibler": 4, "diverg": 4, "kl": 4, "cross": [4, 72, 98, 100, 101, 113, 135], "formal": [4, 157], "object": [4, 48, 55, 57, 72, 86, 88, 89, 92, 106, 136, 148, 155], "function": [4, 9, 15, 20, 22, 53, 54, 56, 60, 62, 69, 80, 86, 88, 89, 92, 98, 103, 104, 105, 114, 127, 136, 140, 145, 150, 154, 177, 190], "multi": [4, 26, 46, 51, 66, 90, 143], "class": [4, 15, 20, 42, 47, 59, 60, 69, 93, 119, 154], "classif": [4, 8, 53, 92, 93, 95, 96, 97, 98, 117], "integr": 5, "calculu": [5, 7, 10, 136, 151], "geometr": 5, "fundament": 5, "chang": [5, 14, 51], "variabl": [5, 6, 9, 10, 150, 157], "comment": 5, "sign": [5, 18], "convent": 5, "multipl": [5, 22, 44, 45, 47, 51, 60, 61, 71, 76, 153, 157], "maximum": [6, 47, 76], "likelihood": [6, 98], "principl": [6, 190], "concret": 6, "optim": [6, 7, 85, 86, 87, 88, 89, 90, 92, 104, 105, 142, 146, 161, 189, 190], "neg": [6, 125, 133, 165, 168], "log": [6, 14, 98], "multivari": [7, 141], "higher": [7, 10], "dimension": [7, 108, 123, 141], "differenti": [7, 10, 150, 151], "gradient": [7, 103, 116, 141, 144, 146, 148, 150, 151, 178, 183], "descent": [7, 103, 141, 144, 148], "note": [7, 38], "chain": [7, 151], "rule": [7, 10, 151], "backpropag": [7, 109, 178], "algorithm": [7, 85, 92, 104, 105, 137, 138, 139, 142, 147, 189], "hessian": 7, "littl": 7, "matrix": [7, 22, 61, 153, 163], "naiv": 8, "bay": 8, "optic": 8, "charact": [8, 181], "recognit": [8, 50], "probabilist": 8, "model": [8, 23, 25, 26, 29, 30, 37, 49, 50, 53, 54, 60, 65, 66, 68, 69, 92, 93, 98, 99, 100, 101, 103, 104, 105, 106, 108, 110, 113, 114, 115, 120, 123, 124, 126, 127, 129, 132, 134, 135, 158, 160, 161, 163, 165, 168, 173, 175, 180, 181, 182, 183, 184], "classifi": [8, 53, 54, 93], "train": [8, 23, 29, 30, 44, 45, 46, 47, 49, 51, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69, 70, 74, 82, 83, 99, 100, 101, 104, 105, 106, 108, 109, 110, 115, 120, 123, 124, 125, 133, 134, 135, 158, 160, 161, 163, 165, 168, 173, 175, 177, 182, 183, 184], "probabl": [9, 129, 136, 157], "densiti": 9, "cumul": 9, "mean": [9, 11], "varianc": [9, 11], "standard": [9, 11], "deviat": [9, 11], "continuum": 9, "margin": 9, "covari": [9, 94], "correl": [9, 72], "singl": [10, 60, 117, 124], "deriv": [10, 140, 151], "approxim": [10, 114, 125], "order": [10, 184], "taylor": 10, "seri": 10, "statist": [11, 95, 129, 157, 164, 185], "evalu": [11, 60, 120, 123, 124, 158, 160, 163, 165, 177, 190], "compar": [11, 28, 85, 120, 178], "estim": 11, "squar": [11, 103], "error": [11, 101, 113], "bia": 11, "trade": 11, "off": 11, "conduct": 11, "hypothesi": 11, "test": [11, 53, 54, 95], "signific": 11, "power": 11, "p": 11, "valu": [11, 27, 46, 190], "One": [11, 123, 134, 141, 149, 183], "side": [11, 38], "two": 11, "gener": [11, 47, 82, 83, 84, 95, 101, 107, 111, 127], "step": [11, 50, 178], "construct": 11, "confid": 11, "interv": 11, "aw": 12, "ec2": 12, "instanc": [12, 18, 59], "creat": [12, 18, 120, 122], "run": [12, 17, 18, 91], "preset": 12, "locat": 12, "increas": 12, "limit": [12, 114], "launch": 12, "label": [12, 47, 86, 92, 94, 129], "tab_ec2": 12, "connect": [12, 29, 61, 63, 65, 77], "instal": [12, 14, 91], "cuda": 12, "librari": 12, "jupyt": [12, 17], "notebook": [12, 17, 18, 149], "remot": [12, 17], "close": 12, "unus": 12, "googl": 13, "colab": 13, "contribut": 14, "thi": [14, 149], "book": [14, 149], "submit": [14, 53, 54, 113], "minor": 14, "propos": 14, "major": 14, "git": 14, "github": [14, 149], "clone": 14, "repositori": 14, "edit": [14, 17], "push": 14, "pull": 14, "request": 14, "d2l": [15, 91], "api": [15, 85], "document": [15, 154], "tool": 16, "local": [17, 77, 140, 141, 146], "advanc": 17, "option": 17, "markdown": 17, "file": [17, 37], "server": [17, 19, 46], "time": [17, 71, 123, 178], "amazon": 18, "sagemak": 18, "up": 18, "stop": [18, 111], "updat": [18, 148, 173], "select": [19, 101, 113], "gpu": [19, 38, 40, 41, 44, 45, 51], "util": [20, 106, 151], "attent": [21, 22, 23, 24, 26, 28, 120], "pool": [21, 76, 123], "kernel": [21, 72, 78, 80], "via": [21, 39], "nadaraya": 21, "watson": 21, "regress": [21, 78, 92, 98, 99, 100, 102, 103, 104, 105, 107, 108, 117], "adapt": [21, 141], "score": 22, "conveni": 22, "mask": [22, 58, 126, 127, 177], "softmax": [22, 98, 99, 100, 125], "batch": [22, 63, 94], "scale": [22, 25, 60], "addit": 22, "bahdanau": 23, "mechan": [23, 24], "defin": [23, 50, 53, 54, 56, 60, 99, 104, 105, 108, 110, 119, 123, 127, 135, 173, 182], "decod": [23, 25, 29, 172, 177, 183, 184], "larg": 25, "pretrain": [25, 54, 121, 123, 124, 126, 127, 128, 130, 131, 133, 135], "encod": [25, 28, 29, 30, 126, 132, 172, 177, 183], "onli": 25, "bert": [25, 117, 121, 126, 127, 128], "fine": [25, 50, 54, 117, 121], "tune": [25, 50, 54, 117, 121], "t5": 25, "gpt": 25, "2": [25, 161], "3": 25, "beyond": [25, 116], "scalabl": 25, "languag": [25, 118, 119, 120, 121, 126, 127, 130, 180, 181, 183, 185], "head": 26, "implement": [26, 45, 63, 99, 100, 104, 105, 106, 107, 108, 110, 115, 137, 138, 139, 144, 145, 147, 158, 160, 161, 163, 165, 166, 168, 170, 171, 173, 175, 182, 183, 189, 190], "queri": 27, "kei": [27, 46, 92], "visual": [27, 88, 89, 96, 151], "posit": 28, "cnn": [28, 58], "rnn": [28, 124, 178, 181, 183], "absolut": 28, "rel": 28, "architectur": [29, 62, 64, 160, 168, 172], "positionwis": 29, "feed": 29, "forward": [29, 35, 109, 135], "network": [29, 38, 41, 44, 45, 49, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 80, 82, 83, 84, 85, 97, 102, 103, 109, 111, 123, 124, 170, 171, 174, 179, 181, 182, 183], "residu": [29, 69], "layer": [29, 31, 35, 49, 60, 63, 65, 71, 72, 77, 114, 135], "vision": [30, 52], "patch": 30, "embed": [30, 129, 132, 133, 134, 135], "put": [30, 59, 119, 120, 122, 126, 133, 172, 185], "It": [30, 59, 119, 120, 122, 126, 133, 185], "all": [30, 36, 59, 119, 120, 122, 126, 133, 185], "togeth": [30, 59, 119, 120, 122, 126, 133, 172, 185], "custom": [31, 33, 35, 59, 165], "without": [31, 108, 181], "paramet": [31, 33, 36, 37, 46, 64, 115, 116, 135, 173, 175], "builder": 32, "guid": 32, "initi": [33, 34, 45, 49, 50, 56, 60, 115, 116, 135, 173, 175], "built": 33, "lazi": 34, "modul": [35, 154], "sequenti": [35, 42, 168], "execut": 35, "propag": [35, 109, 135], "method": [35, 51, 56, 111, 141, 145], "manag": 36, "access": [36, 113], "target": [36, 149], "onc": 36, "ti": 36, "i": [37, 86], "o": 37, "load": [37, 96, 119, 121, 123, 124, 131, 133, 161, 164, 168, 176], "save": [37, 155], "comput": [38, 39, 40, 41, 43, 52, 109, 150, 178], "devic": 38, "storag": [38, 41], "copi": 38, "neural": [38, 56, 62, 67, 73, 74, 80, 85, 97, 102, 103, 109, 123, 124, 165, 170, 171, 174, 179, 181, 182, 183], "asynchron": [39, 88, 89], "asynchroni": 39, "backend": 39, "barrier": 39, "blocker": 39, "improv": 39, "automat": [40, 150], "parallel": [40, 44, 46], "commun": 40, "hardwar": [41, 62], "memori": [41, 155, 175], "hard": 41, "disk": 41, "drive": [41, 94], "solid": 41, "state": [41, 173, 175, 181], "cloud": 41, "cpu": 41, "microarchitectur": 41, "cach": [41, 144], "other": [41, 155], "acceler": [41, 42], "buse": 41, "more": [41, 94, 157], "latenc": 41, "number": 41, "nvidia": 41, "tesla": 41, "compil": 42, "symbol": 42, "program": [42, 190], "hybrid": 42, "serial": 42, "perform": [43, 85], "split": [44, 164], "problem": [44, 86, 92, 94, 143, 145, 189], "toi": [44, 45, 143], "synchron": [44, 46], "concis": [45, 63, 99, 104, 107, 108, 110, 115, 138, 144, 145, 147, 170, 171, 173, 175, 182], "ring": 46, "machin": [46, 92, 94, 160, 161, 176, 177], "store": 46, "anchor": [47, 55], "box": [47, 48, 55, 60], "intersect": 47, "over": [47, 123], "union": 47, "iou": 47, "assign": 47, "ground": 47, "truth": 47, "bound": [47, 48, 60], "offset": 47, "predict": [47, 49, 60, 63, 78, 100, 103, 113, 126, 127, 158, 175, 177, 182, 184], "non": [47, 150, 153], "suppress": 47, "detect": [48, 55, 57, 60, 72], "fulli": [49, 63, 77], "convolut": [49, 61, 62, 63, 64, 67, 71, 72, 73, 74, 77, 82, 85, 123], "transpos": [49, 61], "read": [49, 50, 53, 54, 56, 57, 59, 60, 96, 107, 113, 119, 120, 122, 133, 144, 156, 176, 185], "dataset": [49, 50, 53, 54, 57, 59, 60, 82, 96, 101, 107, 113, 119, 120, 121, 122, 127, 133, 144, 156, 159, 161, 164, 165, 168, 176, 185], "hot": [50, 134, 183], "dog": [50, 54], "imag": [51, 53, 54, 56, 59, 72, 96], "augment": [51, 53, 54], "flip": 51, "crop": 51, "color": 51, "combin": [51, 126, 149], "cifar": 53, "10": 53, "kaggl": [53, 54, 113], "obtain": [53, 54], "organ": [53, 54], "download": [53, 54, 57, 91, 113, 176], "valid": [53, 54, 101, 113], "set": [53, 54, 95, 136, 140], "result": [53, 54], "breed": 54, "identif": 54, "imagenet": 54, "multiscal": 55, "style": 56, "transfer": 56, "content": [56, 149], "preprocess": [56, 59, 62, 113, 122, 156, 176], "postprocess": 56, "extract": [56, 133], "featur": [56, 72, 138, 159], "loss": [56, 60, 98, 100, 103, 104, 105, 135, 166, 177], "total": 56, "variat": 56, "synthes": 56, "demonstr": 57, "region": 58, "base": [58, 60, 93, 181, 183], "r": 58, "fast": 58, "faster": 58, "semant": 59, "segment": 59, "pascal": 59, "voc2012": 59, "shot": 60, "multibox": 60, "concaten": 60, "downsampl": 60, "block": [60, 65, 66, 68, 69, 70], "complet": 60, "basic": [61, 98, 103, 145, 153], "pad": [61, 75, 76], "stride": [61, 75, 76], "channel": [61, 71, 76, 77], "transposit": 61, "alexnet": 62, "represent": [62, 126], "miss": 62, "ingredi": 62, "activ": [62, 114], "capac": 62, "control": [62, 94, 150], "dure": 63, "scratch": [63, 78, 100, 105, 108, 110, 115, 138, 144, 145, 147, 170, 171, 173, 175, 183], "lenet": [63, 74], "design": [64, 106], "anynet": 64, "space": [64, 80, 86], "regnet": 64, "dens": 65, "densenet": 65, "resnet": [65, 69], "transit": 65, "branch": 66, "googlenet": 66, "incept": 66, "modern": [67, 174], "nin": 68, "resnext": 69, "vgg": 70, "input": [71, 126, 175], "output": [71, 175, 183], "1": 71, "edg": 72, "recept": 72, "field": 72, "averag": [76, 145], "invari": 77, "constrain": 77, "mlp": 77, "translat": [77, 176, 177], "process": [78, 79, 80, 81, 88, 89, 118, 130, 188], "infer": [78, 119, 120, 121], "posterior": 78, "equat": 78, "make": 78, "hyperparamet": [78, 85, 86, 87, 90], "gp": 78, "work": [78, 184], "life": 78, "easi": 78, "gpytorch": 78, "introduct": [79, 92], "prior": 80, "simpl": [80, 150, 157], "weight": [80, 108, 145], "radial": 80, "basi": 80, "rbf": 80, "adversari": [82, 83, 84], "pokemon": 82, "discrimin": [82, 83], "some": 83, "real": 83, "searcher": 85, "schedul": [85, 88, 89, 143], "tuner": 85, "bookkeep": 85, "hpo": 85, "what": 86, "configur": 86, "tab_example_configspac": 86, "search": [86, 88, 92, 141, 169], "success": [89, 90, 92], "halv": [89, 90], "fidel": 90, "miniconda": 91, "framework": 91, "packag": 91, "compon": 92, "kind": 92, "supervis": [92, 134], "tag": [92, 117], "recommend": [92, 159, 162, 166, 167, 168], "system": [92, 159, 162, 166, 167, 168], "sequenc": [92, 117, 168, 176, 177, 180, 184, 185], "unsupervis": 92, "interact": 92, "environ": [92, 94], "reinforc": [92, 94, 187], "root": 92, "road": 92, "tab_intro_decad": 92, "stori": 92, "essenc": 92, "accuraci": 93, "shift": 94, "type": 94, "concept": 94, "medic": 94, "diagnost": 94, "car": 94, "nonstationari": 94, "anecdot": 94, "correct": [94, 189], "empir": 94, "risk": 94, "taxonomi": 94, "onlin": [94, 159], "bandit": 94, "consid": 94, "fair": 94, "account": 94, "transpar": 94, "reus": 95, "minibatch": [96, 103, 133, 144], "surpris": 98, "revisit": [98, 99, 111], "complex": 101, "underfit": 101, "overfit": [101, 111], "polynomi": 101, "curv": 101, "fit": 101, "size": 101, "analyt": 103, "solut": 103, "stochast": [103, 144, 148, 190], "speed": 103, "biologi": 103, "orient": 106, "synthet": 107, "loader": 107, "decai": 108, "norm": [108, 153], "high": 108, "ell_2": 108, "penalti": [108, 140], "regular": [108, 111], "backward": [109, 150], "graph": 109, "dropout": 110, "practic": [110, 145], "inspir": 111, "nonparametr": 111, "earli": 111, "classic": 111, "multilay": [112, 114, 115], "perceptron": [112, 114, 115], "hous": 113, "price": 113, "measur": [113, 163], "k": 113, "fold": 113, "hidden": [114, 173, 175, 181], "incorpor": 114, "nonlinear": 114, "univers": 114, "relu": 114, "sigmoid": 114, "tanh": 114, "stabil": 116, "vanish": [116, 146], "explod": 116, "break": 116, "symmetri": 116, "default": 116, "xavier": 116, "level": [117, 181], "token": [117, 176, 185], "text": [117, 124, 127, 128, 185], "pair": [117, 132], "question": 117, "answer": 117, "natur": [118, 119, 120, 121, 130], "stanford": 119, "snli": 119, "attend": 120, "aggreg": 120, "sentiment": [122, 123, 124], "analysi": [122, 123, 124, 141, 145, 148, 178], "max": 123, "textcnn": 123, "word": [123, 124, 129, 131, 133, 134, 135, 180], "recurr": [124, 170, 171, 173, 174, 179, 181, 182, 183], "repres": [124, 128], "sampl": [125, 133, 145, 148, 165, 168], "hierarch": 125, "bidirect": [126, 170], "context": [126, 133], "independ": 126, "sensit": 126, "task": [126, 127, 167], "specif": [126, 154], "agnost": 126, "best": 126, "both": 126, "world": 126, "next": [126, 127], "sentenc": [126, 127], "helper": 127, "global": [129, 140], "glove": 129, "skip": [129, 134, 135], "gram": [129, 134, 135, 180], "corpu": 129, "ratio": 129, "co": 129, "occurr": 129, "tab_glov": 129, "analogi": 131, "appli": [131, 135], "subword": 132, "fasttext": 132, "byte": 132, "subsampl": 133, "center": 133, "word2vec": [134, 135], "ar": [134, 140], "bad": 134, "choic": 134, "bag": 134, "cbow": 134, "binari": 135, "loop": 135, "notat": 136, "adadelta": 137, "adagrad": 138, "spars": 138, "rate": [138, 141, 143, 148, 158], "precondit": [138, 141], "adam": 139, "yogi": 139, "convex": [140, 145, 148], "jensen": 140, "": [140, 141], "inequ": 140, "minima": [140, 141, 146], "below": 140, "second": 140, "constraint": 140, "lagrangian": 140, "project": 140, "newton": 141, "converg": [141, 148], "line": 141, "polici": [143, 190], "factor": [143, 160, 161, 163, 188], "warmup": 143, "momentum": 145, "leaki": 145, "ill": 145, "effect": 145, "experi": 145, "theoret": 145, "quadrat": 145, "scalar": [145, 150, 153], "goal": 146, "challeng": 146, "saddl": 146, "point": 146, "rmsprop": 147, "dynam": [148, 190], "finit": 148, "prefac": 149, "about": 149, "medium": 149, "math": 149, "html": 149, "do": 149, "structur": 149, "audienc": 149, "websit": 149, "forum": 149, "acknowledg": 149, "detach": 150, "python": [150, 155], "flow": 150, "partial": 151, "preliminari": 152, "arithmet": 153, "reduct": 153, "sum": 153, "manipul": 155, "get": [155, 164], "start": 155, "index": 155, "slice": 155, "broadcast": 155, "convers": [155, 156], "prepar": 156, "format": 156, "toss": 157, "coin": 157, "treatment": 157, "expect": 157, "autorec": 158, "autoencod": 158, "reimplement": 158, "rich": 159, "advertis": [159, 161], "wrapper": 159, "deepfm": 160, "wai": 161, "effici": 161, "criterion": 161, "movielen": [164, 168], "collabor": [165, 167], "filter": [165, 167], "person": [165, 166], "neumf": 165, "bayesian": 166, "its": 166, "hing": 166, "overview": 167, "explicit": 167, "feedback": 167, "implicit": 167, "awar": 168, "100k": 168, "beam": 169, "greedi": 169, "exhaust": 169, "gate": [173, 175], "unit": 173, "gru": 173, "reset": 173, "candid": 173, "short": 175, "lstm": 175, "cell": 175, "forget": 175, "node": 175, "intern": 175, "length": 176, "teacher": 177, "forc": 177, "through": 178, "full": 178, "truncat": 178, "strategi": 178, "detail": 178, "markov": [180, 184, 188], "n": 180, "frequenc": 180, "laplac": 180, "smooth": 180, "perplex": 180, "partit": 180, "clip": 183, "autoregress": 184, "convert": 185, "raw": 185, "vocabulari": 185, "exploratori": 185, "refer": 186, "decis": 188, "mdp": 188, "return": 188, "discount": 188, "assumpt": 188, "q": 189, "underli": 189, "explor": 189, "action": 190, "dive": 191}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinxcontrib.bibtex": 9, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Dog Breed Identification (ImageNet Dogs) on Kaggle": [[54, "dog-breed-identification-imagenet-dogs-on-kaggle"]], "Obtaining and Organizing the Dataset": [[54, "obtaining-and-organizing-the-dataset"], [53, "obtaining-and-organizing-the-dataset"]], "Downloading the Dataset": [[54, "downloading-the-dataset"], [53, "downloading-the-dataset"], [57, "downloading-the-dataset"]], "Organizing the Dataset": [[54, "organizing-the-dataset"], [53, "organizing-the-dataset"]], "Image Augmentation": [[54, "image-augmentation"], [53, "image-augmentation"], [51, "image-augmentation"]], "Reading the Dataset": [[54, "reading-the-dataset"], [53, "reading-the-dataset"], [49, "reading-the-dataset"], [59, "reading-the-dataset"], [50, "reading-the-dataset"], [57, "reading-the-dataset"], [176, "reading-the-dataset"], [185, "reading-the-dataset"], [156, "reading-the-dataset"], [133, "reading-the-dataset"], [144, "reading-the-dataset"], [122, "reading-the-dataset"], [107, "reading-the-dataset"], [119, "reading-the-dataset"]], "Fine-Tuning a Pretrained Model": [[54, "fine-tuning-a-pretrained-model"]], "Defining the Training Function": [[54, "defining-the-training-function"], [53, "defining-the-training-function"]], "Training and Validating the Model": [[54, "training-and-validating-the-model"], [53, "training-and-validating-the-model"]], "Classifying the Testing Set and Submitting Results on Kaggle": [[54, "classifying-the-testing-set-and-submitting-results-on-kaggle"], [53, "classifying-the-testing-set-and-submitting-results-on-kaggle"]], "Summary": [[54, "summary"], [58, "summary"], [60, "summary"], [42, "summary"], [56, "summary"], [44, "summary"], [45, "summary"], [53, "summary"], [46, "summary"], [49, "summary"], [59, "summary"], [55, "summary"], [61, "summary"], [50, "summary"], [57, "summary"], [47, "summary"], [48, "summary"], [51, "summary"], [21, "summary"], [37, "summary"], [27, "summary"], [31, "summary"], [39, "summary"], [22, "summary"], [41, "summary"], [29, "summary"], [38, "summary"], [23, "summary"], [40, "summary"], [33, "summary"], [28, "summary"], [26, "summary"], [35, "summary"], [34, "summary"], [36, "summary"], [76, "summary"], [72, "summary"], [80, "summary"], [79, "summary"], [74, "summary"], [83, "summary"], [68, "summary"], [82, "summary"], [78, "summary"], [70, "summary"], [190, "summary"], [189, "summary"], [12, "summary"], [6, "summary"], [14, "summary"], [7, "summary"], [19, "summary"], [9, "summary"], [10, "summary"], [11, "summary"], [8, "summary"], [4, "summary"], [2, "summary"], [0, "summary"], [5, "summary"], [17, "summary"], [1, "summary"], [13, "summary"], [18, "summary"], [172, "summary"], [184, "summary"], [176, "summary"], [182, "summary"], [185, "summary"], [171, "summary"], [169, "summary"], [168, "summary"], [188, "summary"], [181, "summary"], [175, "summary"], [170, "summary"], [173, "summary"], [178, "summary"], [183, "summary"], [177, "summary"], [159, "summary"], [149, "summary"], [155, "summary"], [161, "summary"], [167, "summary"], [147, "summary"], [165, "summary"], [158, "summary"], [164, "summary"], [160, "summary"], [148, "summary"], [163, "summary"], [166, "summary"], [133, "summary"], [132, "summary"], [131, "summary"], [141, "summary"], [144, "summary"], [137, "summary"], [134, "summary"], [135, "summary"], [143, "summary"], [146, "summary"], [145, "summary"], [129, "summary"], [128, "summary"], [140, "summary"], [139, "summary"], [127, "summary"], [126, "summary"], [138, "summary"], [124, "summary"], [106, "summary"], [109, "summary"], [105, "summary"], [115, "summary"], [110, "summary"], [111, "summary"], [120, "summary"], [122, "summary"], [117, "summary"], [125, "summary"], [123, "summary"], [107, "summary"], [116, "summary"], [108, "summary"], [121, "summary"], [119, "summary"], [99, "summary"], [94, "summary"], [85, "summary"], [103, "summary"], [88, "summary"], [89, "summary"], [96, "summary"], [100, "summary"], [86, "summary"], [101, "summary"], [93, "summary"], [104, "summary"], [92, "summary"], [95, "summary"], [90, "summary"]], "Exercises": [[54, "exercises"], [58, "exercises"], [62, "exercises"], [60, "exercises"], [42, "exercises"], [56, "exercises"], [44, "exercises"], [45, "exercises"], [53, "exercises"], [46, "exercises"], [49, "exercises"], [59, "exercises"], [55, "exercises"], [61, "exercises"], [50, "exercises"], [57, "exercises"], [47, "exercises"], [48, "exercises"], [51, "exercises"], [21, "exercises"], [37, "exercises"], [27, "exercises"], [31, "exercises"], [39, "exercises"], [22, "exercises"], [41, "exercises"], [30, "exercises"], [29, "exercises"], [25, "exercises"], [38, "exercises"], [23, "exercises"], [40, "exercises"], [33, "exercises"], [28, "exercises"], [26, "exercises"], [35, "exercises"], [34, "exercises"], [36, "exercises"], [76, "exercises"], [77, "exercises"], [69, "exercises"], [65, "exercises"], [72, "exercises"], [80, "exercises"], [79, "exercises"], [74, "exercises"], [83, "exercises"], [64, "exercises"], [63, "exercises"], [66, "exercises"], [75, "exercises"], [68, "exercises"], [82, "exercises"], [78, "exercises"], [71, "exercises"], [70, "exercises"], [190, "exercises"], [189, "exercises"], [12, "exercises"], [6, "exercises"], [14, "exercises"], [7, "exercises"], [9, "exercises"], [10, "exercises"], [11, "exercises"], [8, "exercises"], [4, "exercises"], [2, "exercises"], [0, "exercises"], [5, "exercises"], [17, "exercises"], [1, "exercises"], [13, "exercises"], [18, "exercises"], [172, "exercises"], [184, "exercises"], [176, "exercises"], [182, "exercises"], [185, "exercises"], [171, "exercises"], [169, "exercises"], [180, "exercises"], [168, "exercises"], [188, "exercises"], [181, "exercises"], [175, "exercises"], [170, "exercises"], [173, "exercises"], [178, "exercises"], [183, "exercises"], [177, "exercises"], [156, "exercises"], [159, "exercises"], [149, "exercises"], [155, "exercises"], [161, "exercises"], [157, "exercises"], [167, "exercises"], [147, "exercises"], [165, "exercises"], [153, "exercises"], [151, "exercises"], [158, "exercises"], [164, "exercises"], [160, "exercises"], [150, "exercises"], [148, "exercises"], [163, "exercises"], [166, "exercises"], [133, "exercises"], [132, "exercises"], [131, "exercises"], [141, "exercises"], [144, "exercises"], [137, "exercises"], [134, "exercises"], [135, "exercises"], [143, "exercises"], [146, "exercises"], [145, "exercises"], [129, "exercises"], [128, "exercises"], [140, "exercises"], [139, "exercises"], [127, "exercises"], [126, "exercises"], [138, "exercises"], [124, "exercises"], [106, "exercises"], [109, "exercises"], [105, "exercises"], [113, "exercises"], [115, "exercises"], [110, "exercises"], [111, "exercises"], [120, "exercises"], [122, "exercises"], [117, "exercises"], [125, "exercises"], [123, "exercises"], [107, "exercises"], [116, "exercises"], [108, "exercises"], [121, "exercises"], [119, "exercises"], [114, "exercises"], [99, "exercises"], [94, "exercises"], [85, "exercises"], [103, "exercises"], [88, "exercises"], [96, "exercises"], [100, "exercises"], [86, "exercises"], [101, "exercises"], [93, "exercises"], [104, "exercises"], [92, "exercises"], [95, "exercises"], [98, "exercises"]], "Region-based CNNs (R-CNNs)": [[58, "region-based-cnns-r-cnns"]], "R-CNNs": [[58, "r-cnns"]], "Fast R-CNN": [[58, "fast-r-cnn"]], "Faster R-CNN": [[58, "faster-r-cnn"]], "Mask R-CNN": [[58, "mask-r-cnn"]], "Deep Convolutional Neural Networks (AlexNet)": [[62, "deep-convolutional-neural-networks-alexnet"]], "Representation Learning": [[62, "representation-learning"]], "Missing Ingredient: Data": [[62, "missing-ingredient-data"]], "Missing Ingredient: Hardware": [[62, "missing-ingredient-hardware"]], "AlexNet": [[62, "alexnet"]], "Architecture": [[62, "architecture"]], "Activation Functions": [[62, "activation-functions"], [114, "activation-functions"]], "Capacity Control and Preprocessing": [[62, "capacity-control-and-preprocessing"]], "Training": [[62, "training"], [60, "training"], [56, "training"], [44, "training"], [45, "training"], [49, "training"], [30, "training"], [29, "training"], [23, "training"], [69, "training"], [65, "training"], [74, "training"], [83, "training"], [64, "training"], [66, "training"], [68, "training"], [82, "training"], [70, "training"], [8, "training"], [184, "training"], [173, "training"], [183, "training"], [177, "training"], [134, "training"], [134, "id3"], [135, "training"], [106, "training"], [105, "training"], [115, "training"], [115, "id2"], [110, "training"], [99, "training"], [100, "training"], [104, "training"]], "Discussion": [[62, "discussion"], [64, "discussion"], [63, "discussion"], [66, "discussion"], [71, "discussion"], [1, "discussion"], [156, "discussion"], [157, "discussion"], [153, "discussion"], [151, "discussion"], [150, "discussion"]], "Single Shot Multibox Detection": [[60, "single-shot-multibox-detection"]], "Model": [[60, "model"], [30, "model"], [29, "model"], [23, "model"], [26, "model"], [158, "model"], [115, "model"], [115, "id1"], [103, "model"]], "Class Prediction Layer": [[60, "class-prediction-layer"]], "Bounding Box Prediction Layer": [[60, "bounding-box-prediction-layer"]], "Concatenating Predictions for Multiple Scales": [[60, "concatenating-predictions-for-multiple-scales"]], "Downsampling Block": [[60, "downsampling-block"]], "Base Network Block": [[60, "base-network-block"]], "The Complete Model": [[60, "the-complete-model"]], "Reading the Dataset and Initializing the Model": [[60, "reading-the-dataset-and-initializing-the-model"]], "Defining Loss and Evaluation Functions": [[60, "defining-loss-and-evaluation-functions"]], "Training the Model": [[60, "training-the-model"]], "Prediction": [[60, "prediction"], [49, "prediction"], [184, "prediction"], [177, "prediction"], [100, "prediction"]], "Compilers and Interpreters": [[42, "compilers-and-interpreters"]], "Symbolic Programming": [[42, "symbolic-programming"]], "Hybrid Programming": [[42, "hybrid-programming"]], "Hybridizing the Sequential Class": [[42, "hybridizing-the-sequential-class"]], "Acceleration by Hybridization": [[42, "acceleration-by-hybridization"]], "Serialization": [[42, "serialization"]], "Neural Style Transfer": [[56, "neural-style-transfer"]], "Method": [[56, "method"]], "Reading the Content and Style Images": [[56, "reading-the-content-and-style-images"]], "Preprocessing and Postprocessing": [[56, "preprocessing-and-postprocessing"]], "Extracting Features": [[56, "extracting-features"]], "Defining the Loss Function": [[56, "defining-the-loss-function"], [105, "defining-the-loss-function"], [104, "defining-the-loss-function"]], "Content Loss": [[56, "content-loss"]], "Style Loss": [[56, "style-loss"]], "Total Variation Loss": [[56, "total-variation-loss"]], "Loss Function": [[56, "loss-function"], [103, "loss-function"], [98, "loss-function"]], "Initializing the Synthesized Image": [[56, "initializing-the-synthesized-image"]], "Training on Multiple GPUs": [[44, "training-on-multiple-gpus"]], "Splitting the Problem": [[44, "splitting-the-problem"]], "Data Parallelism": [[44, "data-parallelism"]], "A Toy Network": [[44, "a-toy-network"], [45, "a-toy-network"]], "Data Synchronization": [[44, "data-synchronization"]], "Distributing Data": [[44, "distributing-data"]], "Concise Implementation for Multiple GPUs": [[45, "concise-implementation-for-multiple-gpus"]], "Network Initialization": [[45, "network-initialization"]], "Image Classification (CIFAR-10) on Kaggle": [[53, "image-classification-cifar-10-on-kaggle"]], "Defining the Model": [[53, "defining-the-model"], [182, "defining-the-model"], [173, "defining-the-model"], [105, "defining-the-model"], [110, "defining-the-model"], [123, "defining-the-model"], [108, "defining-the-model"], [99, "defining-the-model"], [104, "defining-the-model"]], "Parameter Servers": [[46, "parameter-servers"]], "Data-Parallel Training": [[46, "data-parallel-training"]], "Ring Synchronization": [[46, "ring-synchronization"]], "Multi-Machine Training": [[46, "multi-machine-training"]], "Key\u2013Value Stores": [[46, "keyvalue-stores"]], "Computational Performance": [[43, "computational-performance"]], "Fully Convolutional Networks": [[49, "fully-convolutional-networks"]], "The Model": [[49, "the-model"], [120, "the-model"], [100, "the-model"]], "Initializing Transposed Convolutional Layers": [[49, "initializing-transposed-convolutional-layers"]], "Semantic Segmentation and the Dataset": [[59, "semantic-segmentation-and-the-dataset"]], "Image Segmentation and Instance Segmentation": [[59, "image-segmentation-and-instance-segmentation"]], "The Pascal VOC2012 Semantic Segmentation Dataset": [[59, "the-pascal-voc2012-semantic-segmentation-dataset"]], "Data Preprocessing": [[59, "data-preprocessing"], [156, "data-preprocessing"], [113, "data-preprocessing"]], "Custom Semantic Segmentation Dataset Class": [[59, "custom-semantic-segmentation-dataset-class"]], "Putting It All Together": [[59, "putting-it-all-together"], [30, "putting-it-all-together"], [185, "putting-it-all-together"], [133, "putting-it-all-together"], [126, "putting-it-all-together"], [120, "putting-it-all-together"], [122, "putting-it-all-together"], [119, "putting-it-all-together"]], "Multiscale Object Detection": [[55, "multiscale-object-detection"]], "Multiscale Anchor Boxes": [[55, "multiscale-anchor-boxes"]], "Multiscale Detection": [[55, "multiscale-detection"]], "Transposed Convolution": [[61, "transposed-convolution"]], "Basic Operation": [[61, "basic-operation"]], "Padding, Strides, and Multiple Channels": [[61, "padding-strides-and-multiple-channels"]], "Connection to Matrix Transposition": [[61, "connection-to-matrix-transposition"]], "Fine-Tuning": [[50, "fine-tuning"]], "Steps": [[50, "steps"]], "Hot Dog Recognition": [[50, "hot-dog-recognition"]], "Defining and Initializing the Model": [[50, "defining-and-initializing-the-model"]], "Fine-Tuning the Model": [[50, "fine-tuning-the-model"]], "Computer Vision": [[52, "computer-vision"]], "The Object Detection Dataset": [[57, "the-object-detection-dataset"]], "Demonstration": [[57, "demonstration"]], "Anchor Boxes": [[47, "anchor-boxes"]], "Generating Multiple Anchor Boxes": [[47, "generating-multiple-anchor-boxes"]], "Intersection over Union (IoU)": [[47, "intersection-over-union-iou"]], "Labeling Anchor Boxes in Training Data": [[47, "labeling-anchor-boxes-in-training-data"]], "Assigning Ground-Truth Bounding Boxes to Anchor Boxes": [[47, "assigning-ground-truth-bounding-boxes-to-anchor-boxes"]], "Labeling Classes and Offsets": [[47, "labeling-classes-and-offsets"]], "An Example": [[47, "an-example"], [1, "an-example"], [157, "an-example"]], "Predicting Bounding Boxes with Non-Maximum Suppression": [[47, "predicting-bounding-boxes-with-non-maximum-suppression"]], "Object Detection and Bounding Boxes": [[48, "object-detection-and-bounding-boxes"]], "Bounding Boxes": [[48, "bounding-boxes"]], "Common Image Augmentation Methods": [[51, "common-image-augmentation-methods"]], "Flipping and Cropping": [[51, "flipping-and-cropping"]], "Changing Colors": [[51, "changing-colors"]], "Combining Multiple Image Augmentation Methods": [[51, "combining-multiple-image-augmentation-methods"]], "Training with Image Augmentation": [[51, "training-with-image-augmentation"]], "Multi-GPU Training": [[51, "multi-gpu-training"]], "Attention Pooling by Similarity": [[21, "attention-pooling-by-similarity"]], "Kernels and Data": [[21, "kernels-and-data"]], "Attention Pooling via Nadaraya\u2013Watson Regression": [[21, "attention-pooling-via-nadarayawatson-regression"]], "Adapting Attention Pooling": [[21, "adapting-attention-pooling"]], "File I/O": [[37, "file-i-o"]], "Loading and Saving Tensors": [[37, "loading-and-saving-tensors"]], "Loading and Saving Model Parameters": [[37, "loading-and-saving-model-parameters"]], "Queries, Keys, and Values": [[27, "queries-keys-and-values"]], "Visualization": [[27, "visualization"], [96, "visualization"]], "Custom Layers": [[31, "custom-layers"]], "Layers without Parameters": [[31, "layers-without-parameters"]], "Layers with Parameters": [[31, "layers-with-parameters"]], "Asynchronous Computation": [[39, "asynchronous-computation"]], "Asynchrony via Backend": [[39, "asynchrony-via-backend"]], "Barriers and Blockers": [[39, "barriers-and-blockers"]], "Improving Computation": [[39, "improving-computation"]], "Attention Scoring Functions": [[22, "attention-scoring-functions"]], "Dot Product Attention": [[22, "dot-product-attention"]], "Convenience Functions": [[22, "convenience-functions"]], "Masked Softmax Operation": [[22, "masked-softmax-operation"]], "Batch Matrix Multiplication": [[22, "batch-matrix-multiplication"]], "Scaled Dot Product Attention": [[22, "scaled-dot-product-attention"]], "Additive Attention": [[22, "additive-attention"]], "Hardware": [[41, "hardware"]], "Computers": [[41, "computers"]], "Memory": [[41, "memory"]], "Storage": [[41, "storage"]], "Hard Disk Drives": [[41, "hard-disk-drives"]], "Solid State Drives": [[41, "solid-state-drives"]], "Cloud Storage": [[41, "cloud-storage"]], "CPUs": [[41, "cpus"]], "Microarchitecture": [[41, "microarchitecture"]], "Vectorization": [[41, "vectorization"], [98, "vectorization"]], "Cache": [[41, "cache"]], "GPUs and other Accelerators": [[41, "gpus-and-other-accelerators"]], "Networks and Buses": [[41, "networks-and-buses"]], "More Latency Numbers": [[41, "more-latency-numbers"]], "Common Latency Numbers.": [[41, "id14"]], "Latency Numbers for NVIDIA Tesla GPUs.": [[41, "id15"]], "Transformers for Vision": [[30, "transformers-for-vision"]], "Patch Embedding": [[30, "patch-embedding"]], "Vision Transformer Encoder": [[30, "vision-transformer-encoder"]], "Summary and Discussion": [[30, "summary-and-discussion"], [25, "summary-and-discussion"], [77, "summary-and-discussion"], [69, "summary-and-discussion"], [65, "summary-and-discussion"], [75, "summary-and-discussion"], [180, "summary-and-discussion"], [113, "summary-and-discussion"], [114, "summary-and-discussion"], [98, "summary-and-discussion"]], "The Transformer Architecture": [[29, "the-transformer-architecture"]], "Positionwise Feed-Forward Networks": [[29, "positionwise-feed-forward-networks"]], "Residual Connection and Layer Normalization": [[29, "residual-connection-and-layer-normalization"]], "Encoder": [[29, "encoder"], [172, "encoder"], [177, "encoder"]], "Decoder": [[29, "decoder"], [172, "decoder"], [177, "decoder"]], "Large-Scale Pretraining with Transformers": [[25, "large-scale-pretraining-with-transformers"]], "Encoder-Only": [[25, "encoder-only"]], "Pretraining BERT": [[25, "pretraining-bert"], [128, "pretraining-bert"], [128, "id1"]], "Fine-Tuning BERT": [[25, "fine-tuning-bert"], [121, "fine-tuning-bert"]], "Encoder\u2013Decoder": [[25, "encoderdecoder"]], "Pretraining T5": [[25, "pretraining-t5"]], "Fine-Tuning T5": [[25, "fine-tuning-t5"]], "Decoder-Only": [[25, "decoder-only"]], "GPT and GPT-2": [[25, "gpt-and-gpt-2"]], "GPT-3 and Beyond": [[25, "gpt-3-and-beyond"]], "Scalability": [[25, "scalability"]], "Large Language Models": [[25, "large-language-models"]], "GPUs": [[38, "gpus"]], "Computing Devices": [[38, "computing-devices"]], "Tensors and GPUs": [[38, "tensors-and-gpus"]], "Storage on the GPU": [[38, "storage-on-the-gpu"]], "Copying": [[38, "copying"]], "Side Notes": [[38, "side-notes"]], "Neural Networks and GPUs": [[38, "neural-networks-and-gpus"]], "The Bahdanau Attention Mechanism": [[23, "the-bahdanau-attention-mechanism"]], "Defining the Decoder with Attention": [[23, "defining-the-decoder-with-attention"]], "Automatic Parallelism": [[40, "automatic-parallelism"]], "Parallel Computation on GPUs": [[40, "parallel-computation-on-gpus"]], "Parallel Computation and Communication": [[40, "parallel-computation-and-communication"]], "Attention Mechanisms and Transformers": [[24, "attention-mechanisms-and-transformers"]], "Parameter Initialization": [[33, "parameter-initialization"], [116, "parameter-initialization"]], "Built-in Initialization": [[33, "built-in-initialization"]], "Custom Initialization": [[33, "custom-initialization"]], "Self-Attention and Positional Encoding": [[28, "self-attention-and-positional-encoding"]], "Self-Attention": [[28, "self-attention"]], "Comparing CNNs, RNNs, and Self-Attention": [[28, "comparing-cnns-rnns-and-self-attention"]], "Positional Encoding": [[28, "positional-encoding"]], "Absolute Positional Information": [[28, "absolute-positional-information"]], "Relative Positional Information": [[28, "relative-positional-information"]], "Multi-Head Attention": [[26, "multi-head-attention"]], "Implementation": [[26, "implementation"], [137, "implementation"], [139, "implementation"]], "Layers and Modules": [[35, "layers-and-modules"]], "A Custom Module": [[35, "a-custom-module"]], "The Sequential Module": [[35, "the-sequential-module"]], "Executing Code in the Forward Propagation Method": [[35, "executing-code-in-the-forward-propagation-method"]], "Lazy Initialization": [[34, "lazy-initialization"]], "Builders\u2019 Guide": [[32, "builders-guide"]], "Parameter Management": [[36, "parameter-management"]], "Parameter Access": [[36, "parameter-access"]], "Targeted Parameters": [[36, "targeted-parameters"]], "All Parameters at Once": [[36, "all-parameters-at-once"]], "Tied Parameters": [[36, "tied-parameters"]], "Pooling": [[76, "pooling"]], "Maximum Pooling and Average Pooling": [[76, "maximum-pooling-and-average-pooling"]], "Padding and Stride": [[76, "padding-and-stride"], [75, "padding-and-stride"]], "Multiple Channels": [[76, "multiple-channels"]], "From Fully Connected Layers to Convolutions": [[77, "from-fully-connected-layers-to-convolutions"]], "Invariance": [[77, "invariance"]], "Constraining the MLP": [[77, "constraining-the-mlp"]], "Translation Invariance": [[77, "translation-invariance"]], "Locality": [[77, "locality"]], "Convolutions": [[77, "convolutions"]], "Channels": [[77, "channels"]], "Residual Networks (ResNet) and ResNeXt": [[69, "residual-networks-resnet-and-resnext"]], "Function Classes": [[69, "function-classes"]], "Residual Blocks": [[69, "residual-blocks"]], "ResNet Model": [[69, "resnet-model"]], "ResNeXt": [[69, "resnext"]], "Densely Connected Networks (DenseNet)": [[65, "densely-connected-networks-densenet"]], "From ResNet to DenseNet": [[65, "from-resnet-to-densenet"]], "Dense Blocks": [[65, "dense-blocks"]], "Transition Layers": [[65, "transition-layers"]], "DenseNet Model": [[65, "densenet-model"]], "Convolutions for Images": [[72, "convolutions-for-images"]], "The Cross-Correlation Operation": [[72, "the-cross-correlation-operation"]], "Convolutional Layers": [[72, "convolutional-layers"], [63, "convolutional-layers"]], "Object Edge Detection in Images": [[72, "object-edge-detection-in-images"]], "Learning a Kernel": [[72, "learning-a-kernel"]], "Cross-Correlation and Convolution": [[72, "cross-correlation-and-convolution"]], "Feature Map and Receptive Field": [[72, "feature-map-and-receptive-field"]], "Gaussian Process Priors": [[80, "gaussian-process-priors"]], "Definition": [[80, "definition"], [11, "definition"], [4, "definition"], [4, "id4"]], "A Simple Gaussian Process": [[80, "a-simple-gaussian-process"]], "From Weight Space to Function Space": [[80, "from-weight-space-to-function-space"]], "The Radial Basis Function (RBF) Kernel": [[80, "the-radial-basis-function-rbf-kernel"]], "The Neural Network Kernel": [[80, "the-neural-network-kernel"]], "Convolutional Neural Networks": [[73, "convolutional-neural-networks"]], "Introduction to Gaussian Processes": [[79, "introduction-to-gaussian-processes"]], "Convolutional Neural Networks (LeNet)": [[74, "convolutional-neural-networks-lenet"]], "LeNet": [[74, "lenet"]], "Generative Adversarial Networks": [[83, "generative-adversarial-networks"], [84, "generative-adversarial-networks"]], "Generate Some \u201cReal\u201d Data": [[83, "generate-some-real-data"]], "Generator": [[83, "generator"]], "Discriminator": [[83, "discriminator"], [82, "discriminator"]], "Designing Convolution Network Architectures": [[64, "designing-convolution-network-architectures"]], "The AnyNet Design Space": [[64, "the-anynet-design-space"]], "Distributions and Parameters of Design Spaces": [[64, "distributions-and-parameters-of-design-spaces"]], "RegNet": [[64, "regnet"]], "Gaussian Processes": [[81, "gaussian-processes"]], "Batch Normalization": [[63, "batch-normalization"]], "Training Deep Networks": [[63, "training-deep-networks"]], "Batch Normalization Layers": [[63, "batch-normalization-layers"]], "Fully Connected Layers": [[63, "fully-connected-layers"]], "Layer Normalization": [[63, "layer-normalization"]], "Batch Normalization During Prediction": [[63, "batch-normalization-during-prediction"]], "Implementation from Scratch": [[63, "implementation-from-scratch"], [171, "implementation-from-scratch"], [175, "implementation-from-scratch"], [170, "implementation-from-scratch"], [173, "implementation-from-scratch"], [147, "implementation-from-scratch"], [144, "implementation-from-scratch"], [145, "implementation-from-scratch"], [138, "implementation-from-scratch"], [115, "implementation-from-scratch"], [110, "implementation-from-scratch"], [108, "implementation-from-scratch"]], "LeNet with Batch Normalization": [[63, "lenet-with-batch-normalization"]], "Concise Implementation": [[63, "concise-implementation"], [171, "concise-implementation"], [175, "concise-implementation"], [170, "concise-implementation"], [173, "concise-implementation"], [147, "concise-implementation"], [144, "concise-implementation"], [145, "concise-implementation"], [138, "concise-implementation"], [115, "concise-implementation"], [110, "concise-implementation"], [108, "concise-implementation"]], "Modern Convolutional Neural Networks": [[67, "modern-convolutional-neural-networks"]], "Multi-Branch Networks (GoogLeNet)": [[66, "multi-branch-networks-googlenet"]], "Inception Blocks": [[66, "inception-blocks"]], "GoogLeNet Model": [[66, "googlenet-model"]], "Padding": [[75, "padding"]], "Stride": [[75, "stride"]], "Network in Network (NiN)": [[68, "network-in-network-nin"]], "NiN Blocks": [[68, "nin-blocks"]], "NiN Model": [[68, "nin-model"]], "Deep Convolutional Generative Adversarial Networks": [[82, "deep-convolutional-generative-adversarial-networks"]], "The Pokemon Dataset": [[82, "the-pokemon-dataset"]], "The Generator": [[82, "the-generator"]], "Gaussian Process Inference": [[78, "gaussian-process-inference"]], "Posterior Inference for Regression": [[78, "posterior-inference-for-regression"]], "Equations for Making Predictions and Learning Kernel Hyperparameters in GP Regression": [[78, "equations-for-making-predictions-and-learning-kernel-hyperparameters-in-gp-regression"]], "Interpreting Equations for Learning and Predictions": [[78, "interpreting-equations-for-learning-and-predictions"]], "Worked Example from Scratch": [[78, "worked-example-from-scratch"]], "Making Life Easy with GPyTorch": [[78, "making-life-easy-with-gpytorch"]], "Multiple Input and Multiple Output Channels": [[71, "multiple-input-and-multiple-output-channels"]], "Multiple Input Channels": [[71, "multiple-input-channels"]], "Multiple Output Channels": [[71, "multiple-output-channels"]], "1\\times 1 Convolutional Layer": [[71, "times-1-convolutional-layer"]], "Networks Using Blocks (VGG)": [[70, "networks-using-blocks-vgg"]], "VGG Blocks": [[70, "vgg-blocks"]], "VGG Network": [[70, "vgg-network"]], "Value Iteration": [[190, "value-iteration"], [190, "id2"]], "Stochastic Policy": [[190, "stochastic-policy"]], "Value Function": [[190, "value-function"]], "Action-Value Function": [[190, "action-value-function"]], "Optimal Stochastic Policy": [[190, "optimal-stochastic-policy"]], "Principle of Dynamic Programming": [[190, "principle-of-dynamic-programming"]], "Policy Evaluation": [[190, "policy-evaluation"]], "Implementation of Value Iteration": [[190, "implementation-of-value-iteration"]], "Dive into Deep Learning": [[191, "dive-into-deep-learning"]], "Q-Learning": [[189, "q-learning"]], "The Q-Learning Algorithm": [[189, "the-q-learning-algorithm"]], "An Optimization Problem Underlying Q-Learning": [[189, "an-optimization-problem-underlying-q-learning"]], "Exploration in Q-Learning": [[189, "exploration-in-q-learning"]], "The \u201cSelf-correcting\u201d Property of Q-Learning": [[189, "the-self-correcting-property-of-q-learning"]], "Implementation of Q-Learning": [[189, "implementation-of-q-learning"]], "Appendix: Tools for Deep Learning": [[16, "appendix-tools-for-deep-learning"]], "Using AWS EC2 Instances": [[12, "using-aws-ec2-instances"]], "Creating and Running an EC2 Instance": [[12, "creating-and-running-an-ec2-instance"]], "Presetting Location": [[12, "presetting-location"]], "Increasing Limits": [[12, "increasing-limits"]], "Launching an Instance": [[12, "launching-an-instance"]], "label:tab_ec2": [[12, "id5"]], "Connecting to the Instance": [[12, "connecting-to-the-instance"]], "Installing CUDA": [[12, "installing-cuda"]], "Installing Libraries for Running the Code": [[12, "installing-libraries-for-running-the-code"]], "Running the Jupyter Notebook remotely": [[12, "running-the-jupyter-notebook-remotely"]], "Closing Unused Instances": [[12, "closing-unused-instances"]], "Maximum Likelihood": [[6, "maximum-likelihood"]], "The Maximum Likelihood Principle": [[6, "the-maximum-likelihood-principle"]], "A Concrete Example": [[6, "a-concrete-example"]], "Numerical Optimization and the Negative Log-Likelihood": [[6, "numerical-optimization-and-the-negative-log-likelihood"]], "Maximum Likelihood for Continuous Variables": [[6, "maximum-likelihood-for-continuous-variables"]], "The d2l API Document": [[15, "the-d2l-api-document"]], "Classes": [[15, "classes"]], "Functions": [[15, "functions"]], "Contributing to This Book": [[14, "contributing-to-this-book"]], "Submitting Minor Changes": [[14, "submitting-minor-changes"]], "Proposing Major Changes": [[14, "proposing-major-changes"]], "Submitting Major Changes": [[14, "submitting-major-changes"]], "Installing Git": [[14, "installing-git"]], "Logging in to GitHub": [[14, "logging-in-to-github"]], "Cloning the Repository": [[14, "cloning-the-repository"]], "Editing and Pushing": [[14, "editing-and-pushing"]], "Submitting Pull Requests": [[14, "submitting-pull-requests"]], "Multivariable Calculus": [[7, "multivariable-calculus"]], "Higher-Dimensional Differentiation": [[7, "higher-dimensional-differentiation"]], "Geometry of Gradients and Gradient Descent": [[7, "geometry-of-gradients-and-gradient-descent"]], "A Note on Mathematical Optimization": [[7, "a-note-on-mathematical-optimization"]], "Multivariate Chain Rule": [[7, "multivariate-chain-rule"]], "The Backpropagation Algorithm": [[7, "the-backpropagation-algorithm"]], "Hessians": [[7, "hessians"]], "A Little Matrix Calculus": [[7, "a-little-matrix-calculus"]], "Selecting Servers and GPUs": [[19, "selecting-servers-and-gpus"]], "Selecting Servers": [[19, "selecting-servers"]], "Selecting GPUs": [[19, "selecting-gpus"]], "Random Variables": [[9, "random-variables"], [157, "random-variables"]], "Continuous Random Variables": [[9, "continuous-random-variables"]], "From Discrete to Continuous": [[9, "from-discrete-to-continuous"]], "Probability Density Functions": [[9, "probability-density-functions"]], "Cumulative Distribution Functions": [[9, "cumulative-distribution-functions"]], "Means": [[9, "means"]], "Variances": [[9, "variances"]], "Standard Deviations": [[9, "standard-deviations"]], "Means and Variances in the Continuum": [[9, "means-and-variances-in-the-continuum"]], "Joint Density Functions": [[9, "joint-density-functions"]], "Marginal Distributions": [[9, "marginal-distributions"]], "Covariance": [[9, "covariance"]], "Correlation": [[9, "correlation"]], "Single Variable Calculus": [[10, "single-variable-calculus"]], "Differential Calculus": [[10, "differential-calculus"]], "Rules of Calculus": [[10, "rules-of-calculus"]], "Common Derivatives": [[10, "common-derivatives"]], "Derivative Rules": [[10, "derivative-rules"]], "Linear Approximation": [[10, "linear-approximation"]], "Higher Order Derivatives": [[10, "higher-order-derivatives"]], "Taylor Series": [[10, "taylor-series"]], "Statistics": [[11, "statistics"]], "Evaluating and Comparing Estimators": [[11, "evaluating-and-comparing-estimators"]], "Mean Squared Error": [[11, "mean-squared-error"]], "Statistical Bias": [[11, "statistical-bias"]], "Variance and Standard Deviation": [[11, "variance-and-standard-deviation"]], "The Bias-Variance Trade-off": [[11, "the-bias-variance-trade-off"]], "Evaluating Estimators in Code": [[11, "evaluating-estimators-in-code"]], "Conducting Hypothesis Tests": [[11, "conducting-hypothesis-tests"]], "Statistical Significance": [[11, "statistical-significance"]], "Statistical Power": [[11, "statistical-power"]], "Test Statistic": [[11, "test-statistic"]], "p-value": [[11, "p-value"]], "One-side Test and Two-sided Test": [[11, "one-side-test-and-two-sided-test"]], "General Steps of Hypothesis Testing": [[11, "general-steps-of-hypothesis-testing"]], "Constructing Confidence Intervals": [[11, "constructing-confidence-intervals"]], "Interpretation": [[11, "interpretation"]], "A Gaussian Example": [[11, "a-gaussian-example"]], "Naive Bayes": [[8, "naive-bayes"]], "Optical Character Recognition": [[8, "optical-character-recognition"]], "The Probabilistic Model for Classification": [[8, "the-probabilistic-model-for-classification"]], "The Naive Bayes Classifier": [[8, "the-naive-bayes-classifier"]], "Information Theory": [[4, "information-theory"]], "Information": [[4, "information"]], "Self-information": [[4, "self-information"]], "Entropy": [[4, "entropy"], [98, "entropy"]], "Motivating Entropy": [[4, "motivating-entropy"]], "Interpretations": [[4, "interpretations"]], "Properties of Entropy": [[4, "properties-of-entropy"]], "Mutual Information": [[4, "mutual-information"], [4, "id3"]], "Joint Entropy": [[4, "joint-entropy"]], "Conditional Entropy": [[4, "conditional-entropy"]], "Properties of Mutual Information": [[4, "properties-of-mutual-information"]], "Pointwise Mutual Information": [[4, "pointwise-mutual-information"]], "Applications of Mutual Information": [[4, "applications-of-mutual-information"]], "Kullback\u2013Leibler Divergence": [[4, "kullbackleibler-divergence"]], "KL Divergence Properties": [[4, "kl-divergence-properties"]], "Example": [[4, "example"]], "Cross-Entropy": [[4, "cross-entropy"]], "Formal Definition": [[4, "formal-definition"]], "Properties": [[4, "properties"], [140, "properties"]], "Cross-Entropy as An Objective Function of Multi-class Classification": [[4, "cross-entropy-as-an-objective-function-of-multi-class-classification"]], "Geometry and Linear Algebraic Operations": [[2, "geometry-and-linear-algebraic-operations"]], "Geometry of Vectors": [[2, "geometry-of-vectors"]], "Dot Products and Angles": [[2, "dot-products-and-angles"]], "Cosine Similarity": [[2, "cosine-similarity"]], "Hyperplanes": [[2, "hyperplanes"]], "Geometry of Linear Transformations": [[2, "geometry-of-linear-transformations"]], "Linear Dependence": [[2, "linear-dependence"]], "Rank": [[2, "rank"]], "Invertibility": [[2, "invertibility"]], "Numerical Issues": [[2, "numerical-issues"]], "Determinant": [[2, "determinant"]], "Tensors and Common Linear Algebra Operations": [[2, "tensors-and-common-linear-algebra-operations"]], "Common Examples from Linear Algebra": [[2, "common-examples-from-linear-algebra"]], "Expressing in Code": [[2, "expressing-in-code"]], "Utility Functions and Classes": [[20, "utility-functions-and-classes"]], "Distributions": [[0, "distributions"]], "Bernoulli": [[0, "bernoulli"]], "Discrete Uniform": [[0, "discrete-uniform"]], "Continuous Uniform": [[0, "continuous-uniform"]], "Binomial": [[0, "binomial"]], "Poisson": [[0, "poisson"]], "Gaussian": [[0, "gaussian"]], "Exponential Family": [[0, "exponential-family"]], "Integral Calculus": [[5, "integral-calculus"]], "Geometric Interpretation": [[5, "geometric-interpretation"]], "The Fundamental Theorem of Calculus": [[5, "the-fundamental-theorem-of-calculus"]], "Change of Variables": [[5, "change-of-variables"]], "A Comment on Sign Conventions": [[5, "a-comment-on-sign-conventions"]], "Multiple Integrals": [[5, "multiple-integrals"]], "Change of Variables in Multiple Integrals": [[5, "change-of-variables-in-multiple-integrals"]], "Using Jupyter Notebooks": [[17, "using-jupyter-notebooks"]], "Editing and Running the Code Locally": [[17, "editing-and-running-the-code-locally"]], "Advanced Options": [[17, "advanced-options"]], "Markdown Files in Jupyter": [[17, "markdown-files-in-jupyter"]], "Running Jupyter Notebooks on a Remote Server": [[17, "running-jupyter-notebooks-on-a-remote-server"]], "Timing": [[17, "timing"]], "Eigendecompositions": [[1, "eigendecompositions"]], "Finding Eigenvalues": [[1, "finding-eigenvalues"]], "Decomposing Matrices": [[1, "decomposing-matrices"]], "Operations on Eigendecompositions": [[1, "operations-on-eigendecompositions"]], "Eigendecompositions of Symmetric Matrices": [[1, "eigendecompositions-of-symmetric-matrices"]], "Gershgorin Circle Theorem": [[1, "gershgorin-circle-theorem"]], "A Useful Application: The Growth of Iterated Maps": [[1, "a-useful-application-the-growth-of-iterated-maps"]], "Eigenvectors as Long Term Behavior": [[1, "eigenvectors-as-long-term-behavior"]], "Behavior on Random Data": [[1, "behavior-on-random-data"]], "Relating Back to Eigenvectors": [[1, "relating-back-to-eigenvectors"]], "An Observation": [[1, "an-observation"]], "Fixing the Normalization": [[1, "fixing-the-normalization"]], "Appendix: Mathematics for Deep Learning": [[3, "appendix-mathematics-for-deep-learning"]], "Using Google Colab": [[13, "using-google-colab"]], "Using Amazon SageMaker": [[18, "using-amazon-sagemaker"]], "Signing Up": [[18, "signing-up"]], "Creating a SageMaker Instance": [[18, "creating-a-sagemaker-instance"]], "Running and Stopping an Instance": [[18, "running-and-stopping-an-instance"]], "Updating Notebooks": [[18, "updating-notebooks"]], "The Encoder\u2013Decoder Architecture": [[172, "the-encoderdecoder-architecture"]], "Putting the Encoder and Decoder Together": [[172, "putting-the-encoder-and-decoder-together"]], "Reinforcement Learning": [[187, "reinforcement-learning"], [94, "reinforcement-learning"], [92, "reinforcement-learning"]], "References": [[186, "references"]], "Working with Sequences": [[184, "working-with-sequences"]], "Autoregressive Models": [[184, "autoregressive-models"]], "Sequence Models": [[184, "sequence-models"]], "Markov Models": [[184, "markov-models"]], "The Order of Decoding": [[184, "the-order-of-decoding"]], "Recurrent Neural Networks": [[179, "recurrent-neural-networks"], [181, "recurrent-neural-networks"]], "Machine Translation and the Dataset": [[176, "machine-translation-and-the-dataset"]], "Downloading and Preprocessing the Dataset": [[176, "downloading-and-preprocessing-the-dataset"]], "Tokenization": [[176, "tokenization"], [185, "tokenization"]], "Loading Sequences of Fixed Length": [[176, "loading-sequences-of-fixed-length"]], "Concise Implementation of Recurrent Neural Networks": [[182, "concise-implementation-of-recurrent-neural-networks"]], "Training and Predicting": [[182, "training-and-predicting"]], "Converting Raw Text into Sequence Data": [[185, "converting-raw-text-into-sequence-data"]], "Vocabulary": [[185, "vocabulary"]], "Exploratory Language Statistics": [[185, "exploratory-language-statistics"]], "Deep Recurrent Neural Networks": [[171, "deep-recurrent-neural-networks"]], "Beam Search": [[169, "beam-search"], [169, "id1"]], "Greedy Search": [[169, "greedy-search"]], "Exhaustive Search": [[169, "exhaustive-search"]], "Language Models": [[180, "language-models"]], "Learning Language Models": [[180, "learning-language-models"]], "Markov Models and n-grams": [[180, "markov-models-and-n-grams"]], "Word Frequency": [[180, "word-frequency"]], "Laplace Smoothing": [[180, "laplace-smoothing"]], "Perplexity": [[180, "perplexity"]], "Partitioning Sequences": [[180, "partitioning-sequences"]], "Sequence-Aware Recommender Systems": [[168, "sequence-aware-recommender-systems"]], "Model Architectures": [[168, "model-architectures"], [160, "model-architectures"]], "Model Implementation": [[168, "model-implementation"], [161, "model-implementation"], [165, "model-implementation"], [163, "model-implementation"]], "Sequential Dataset with Negative Sampling": [[168, "sequential-dataset-with-negative-sampling"]], "Load the MovieLens 100K dataset": [[168, "load-the-movielens-100k-dataset"]], "Train the Model": [[168, "train-the-model"], [161, "train-the-model"]], "Markov Decision Process (MDP)": [[188, "markov-decision-process-mdp"]], "Definition of an MDP": [[188, "definition-of-an-mdp"]], "Return and Discount Factor": [[188, "return-and-discount-factor"]], "Discussion of the Markov Assumption": [[188, "discussion-of-the-markov-assumption"]], "Neural Networks without Hidden States": [[181, "neural-networks-without-hidden-states"]], "Recurrent Neural Networks with Hidden States": [[181, "recurrent-neural-networks-with-hidden-states"]], "RNN-Based Character-Level Language Models": [[181, "rnn-based-character-level-language-models"]], "Long Short-Term Memory (LSTM)": [[175, "long-short-term-memory-lstm"]], "Gated Memory Cell": [[175, "gated-memory-cell"]], "Gated Hidden State": [[175, "gated-hidden-state"]], "Input Gate, Forget Gate, and Output Gate": [[175, "input-gate-forget-gate-and-output-gate"]], "Input Node": [[175, "input-node"]], "Memory Cell Internal State": [[175, "memory-cell-internal-state"]], "Hidden State": [[175, "hidden-state"], [173, "hidden-state"]], "Initializing Model Parameters": [[175, "initializing-model-parameters"], [173, "initializing-model-parameters"], [135, "initializing-model-parameters"], [115, "initializing-model-parameters"]], "Training and Prediction": [[175, "training-and-prediction"]], "Bidirectional Recurrent Neural Networks": [[170, "bidirectional-recurrent-neural-networks"]], "Gated Recurrent Units (GRU)": [[173, "gated-recurrent-units-gru"]], "Reset Gate and Update Gate": [[173, "reset-gate-and-update-gate"]], "Candidate Hidden State": [[173, "candidate-hidden-state"]], "Backpropagation Through Time": [[178, "backpropagation-through-time"]], "Analysis of Gradients in RNNs": [[178, "analysis-of-gradients-in-rnns"]], "Full Computation": [[178, "full-computation"]], "Truncating Time Steps": [[178, "truncating-time-steps"]], "Randomized Truncation": [[178, "randomized-truncation"]], "Comparing Strategies": [[178, "comparing-strategies"]], "Backpropagation Through Time in Detail": [[178, "backpropagation-through-time-in-detail"]], "Recurrent Neural Network Implementation from Scratch": [[183, "recurrent-neural-network-implementation-from-scratch"]], "RNN Model": [[183, "rnn-model"]], "RNN-Based Language Model": [[183, "rnn-based-language-model"]], "One-Hot Encoding": [[183, "one-hot-encoding"]], "Transforming RNN Outputs": [[183, "transforming-rnn-outputs"]], "Gradient Clipping": [[183, "gradient-clipping"]], "Decoding": [[183, "decoding"]], "Modern Recurrent Neural Networks": [[174, "modern-recurrent-neural-networks"]], "Sequence-to-Sequence Learning for Machine Translation": [[177, "sequence-to-sequence-learning-for-machine-translation"]], "Teacher Forcing": [[177, "teacher-forcing"]], "Encoder\u2013Decoder for Sequence-to-Sequence Learning": [[177, "encoderdecoder-for-sequence-to-sequence-learning"]], "Loss Function with Masking": [[177, "loss-function-with-masking"]], "Evaluation of Predicted Sequences": [[177, "evaluation-of-predicted-sequences"]], "Data Preparation": [[156, "data-preparation"]], "Conversion to the Tensor Format": [[156, "conversion-to-the-tensor-format"]], "Preliminaries": [[152, "preliminaries"]], "Feature-Rich Recommender Systems": [[159, "feature-rich-recommender-systems"]], "An Online Advertising Dataset": [[159, "an-online-advertising-dataset"]], "Dataset Wrapper": [[159, "dataset-wrapper"]], "Preface": [[149, "preface"]], "About This Book": [[149, "about-this-book"]], "One Medium Combining Code, Math, and HTML": [[149, "one-medium-combining-code-math-and-html"]], "Learning by Doing": [[149, "learning-by-doing"]], "Content and Structure": [[149, "content-and-structure"]], "Code": [[149, "code"]], "Target Audience": [[149, "target-audience"]], "Notebooks, Website, GitHub, and Forum": [[149, "notebooks-website-github-and-forum"]], "Acknowledgments": [[149, "acknowledgments"]], "Documentation": [[154, "documentation"]], "Functions and Classes in a Module": [[154, "functions-and-classes-in-a-module"]], "Specific Functions and Classes": [[154, "specific-functions-and-classes"]], "Data Manipulation": [[155, "data-manipulation"]], "Getting Started": [[155, "getting-started"]], "Indexing and Slicing": [[155, "indexing-and-slicing"]], "Operations": [[155, "operations"]], "Broadcasting": [[155, "broadcasting"]], "Saving Memory": [[155, "saving-memory"]], "Conversion to Other Python Objects": [[155, "conversion-to-other-python-objects"]], "Factorization Machines": [[161, "factorization-machines"]], "2-Way Factorization Machines": [[161, "way-factorization-machines"]], "An Efficient Optimization Criterion": [[161, "an-efficient-optimization-criterion"]], "Load the Advertising Dataset": [[161, "load-the-advertising-dataset"]], "Probability and Statistics": [[157, "probability-and-statistics"]], "A Simple Example: Tossing Coins": [[157, "a-simple-example-tossing-coins"]], "A More Formal Treatment": [[157, "a-more-formal-treatment"]], "Multiple Random Variables": [[157, "multiple-random-variables"]], "Expectations": [[157, "expectations"]], "Overview of Recommender Systems": [[167, "overview-of-recommender-systems"]], "Collaborative Filtering": [[167, "collaborative-filtering"]], "Explicit Feedback and Implicit Feedback": [[167, "explicit-feedback-and-implicit-feedback"]], "Recommendation Tasks": [[167, "recommendation-tasks"]], "RMSProp": [[147, "rmsprop"]], "The Algorithm": [[147, "the-algorithm"], [137, "the-algorithm"], [139, "the-algorithm"], [138, "the-algorithm"]], "Neural Collaborative Filtering for Personalized Ranking": [[165, "neural-collaborative-filtering-for-personalized-ranking"]], "The NeuMF model": [[165, "the-neumf-model"]], "Customized Dataset with Negative Sampling": [[165, "customized-dataset-with-negative-sampling"]], "Evaluator": [[165, "evaluator"]], "Training and Evaluating the Model": [[165, "training-and-evaluating-the-model"], [158, "training-and-evaluating-the-model"], [160, "training-and-evaluating-the-model"], [163, "training-and-evaluating-the-model"], [124, "training-and-evaluating-the-model"], [120, "training-and-evaluating-the-model"], [120, "id2"], [123, "training-and-evaluating-the-model"]], "Linear Algebra": [[153, "linear-algebra"]], "Scalars": [[153, "scalars"]], "Vectors": [[153, "vectors"]], "Matrices": [[153, "matrices"]], "Tensors": [[153, "tensors"]], "Basic Properties of Tensor Arithmetic": [[153, "basic-properties-of-tensor-arithmetic"]], "Reduction": [[153, "reduction"]], "Non-Reduction Sum": [[153, "non-reduction-sum"]], "Dot Products": [[153, "dot-products"]], "Matrix\u2013Vector Products": [[153, "matrixvector-products"]], "Matrix\u2013Matrix Multiplication": [[153, "matrixmatrix-multiplication"]], "Norms": [[153, "norms"]], "Calculus": [[151, "calculus"], [136, "calculus"]], "Derivatives and Differentiation": [[151, "derivatives-and-differentiation"]], "Visualization Utilities": [[151, "visualization-utilities"]], "Partial Derivatives and Gradients": [[151, "partial-derivatives-and-gradients"]], "Chain Rule": [[151, "chain-rule"]], "AutoRec: Rating Prediction with Autoencoders": [[158, "autorec-rating-prediction-with-autoencoders"]], "Implementing the Model": [[158, "implementing-the-model"]], "Reimplementing the Evaluator": [[158, "reimplementing-the-evaluator"]], "Recommender Systems": [[162, "recommender-systems"], [92, "recommender-systems"]], "The MovieLens Dataset": [[164, "the-movielens-dataset"]], "Getting the Data": [[164, "getting-the-data"]], "Statistics of the Dataset": [[164, "statistics-of-the-dataset"]], "Splitting the dataset": [[164, "splitting-the-dataset"]], "Loading the data": [[164, "loading-the-data"]], "Deep Factorization Machines": [[160, "deep-factorization-machines"]], "Implementation of DeepFM": [[160, "implementation-of-deepfm"]], "Automatic Differentiation": [[150, "automatic-differentiation"]], "A Simple Function": [[150, "a-simple-function"]], "Backward for Non-Scalar Variables": [[150, "backward-for-non-scalar-variables"]], "Detaching Computation": [[150, "detaching-computation"]], "Gradients and Python Control Flow": [[150, "gradients-and-python-control-flow"]], "Stochastic Gradient Descent": [[148, "stochastic-gradient-descent"]], "Stochastic Gradient Updates": [[148, "stochastic-gradient-updates"]], "Dynamic Learning Rate": [[148, "dynamic-learning-rate"]], "Convergence Analysis for Convex Objectives": [[148, "convergence-analysis-for-convex-objectives"]], "Stochastic Gradients and Finite Samples": [[148, "stochastic-gradients-and-finite-samples"]], "Matrix Factorization": [[163, "matrix-factorization"]], "The Matrix Factorization Model": [[163, "the-matrix-factorization-model"]], "Evaluation Measures": [[163, "evaluation-measures"]], "Personalized Ranking for Recommender Systems": [[166, "personalized-ranking-for-recommender-systems"]], "Bayesian Personalized Ranking Loss and its Implementation": [[166, "bayesian-personalized-ranking-loss-and-its-implementation"]], "Hinge Loss and its Implementation": [[166, "hinge-loss-and-its-implementation"]], "The Dataset for Pretraining Word Embeddings": [[133, "the-dataset-for-pretraining-word-embeddings"]], "Subsampling": [[133, "subsampling"]], "Extracting Center Words and Context Words": [[133, "extracting-center-words-and-context-words"]], "Negative Sampling": [[133, "negative-sampling"], [125, "negative-sampling"]], "Loading Training Examples in Minibatches": [[133, "loading-training-examples-in-minibatches"]], "Subword Embedding": [[132, "subword-embedding"]], "The fastText Model": [[132, "the-fasttext-model"]], "Byte Pair Encoding": [[132, "byte-pair-encoding"]], "Word Similarity and Analogy": [[131, "word-similarity-and-analogy"]], "Loading Pretrained Word Vectors": [[131, "loading-pretrained-word-vectors"], [124, "loading-pretrained-word-vectors"], [123, "loading-pretrained-word-vectors"]], "Applying Pretrained Word Vectors": [[131, "applying-pretrained-word-vectors"]], "Word Similarity": [[131, "word-similarity"]], "Word Analogy": [[131, "word-analogy"]], "Gradient Descent": [[141, "gradient-descent"]], "One-Dimensional Gradient Descent": [[141, "one-dimensional-gradient-descent"]], "Learning Rate": [[141, "learning-rate"]], "Local Minima": [[141, "local-minima"], [146, "local-minima"]], "Multivariate Gradient Descent": [[141, "multivariate-gradient-descent"]], "Adaptive Methods": [[141, "adaptive-methods"]], "Newton\u2019s Method": [[141, "newtons-method"]], "Convergence Analysis": [[141, "convergence-analysis"]], "Preconditioning": [[141, "preconditioning"], [138, "preconditioning"]], "Gradient Descent with Line Search": [[141, "gradient-descent-with-line-search"]], "Minibatch Stochastic Gradient Descent": [[144, "minibatch-stochastic-gradient-descent"], [103, "minibatch-stochastic-gradient-descent"]], "Vectorization and Caches": [[144, "vectorization-and-caches"]], "Minibatches": [[144, "minibatches"]], "Optimization Algorithms": [[142, "optimization-algorithms"], [92, "optimization-algorithms"]], "Natural Language Processing: Pretraining": [[130, "natural-language-processing-pretraining"]], "Adadelta": [[137, "adadelta"]], "Word Embedding (word2vec)": [[134, "word-embedding-word2vec"]], "One-Hot Vectors Are a Bad Choice": [[134, "one-hot-vectors-are-a-bad-choice"]], "Self-Supervised word2vec": [[134, "self-supervised-word2vec"]], "The Skip-Gram Model": [[134, "the-skip-gram-model"], [135, "the-skip-gram-model"]], "The Continuous Bag of Words (CBOW) Model": [[134, "the-continuous-bag-of-words-cbow-model"]], "Pretraining word2vec": [[135, "pretraining-word2vec"]], "Embedding Layer": [[135, "embedding-layer"]], "Defining the Forward Propagation": [[135, "defining-the-forward-propagation"]], "Binary Cross-Entropy Loss": [[135, "binary-cross-entropy-loss"]], "Defining the Training Loop": [[135, "defining-the-training-loop"]], "Applying Word Embeddings": [[135, "applying-word-embeddings"]], "Learning Rate Scheduling": [[143, "learning-rate-scheduling"]], "Toy Problem": [[143, "toy-problem"]], "Schedulers": [[143, "schedulers"]], "Policies": [[143, "policies"]], "Factor Scheduler": [[143, "factor-scheduler"]], "Multi Factor Scheduler": [[143, "multi-factor-scheduler"]], "Cosine Scheduler": [[143, "cosine-scheduler"]], "Warmup": [[143, "warmup"]], "Optimization and Deep Learning": [[146, "optimization-and-deep-learning"]], "Goal of Optimization": [[146, "goal-of-optimization"]], "Optimization Challenges in Deep Learning": [[146, "optimization-challenges-in-deep-learning"]], "Saddle Points": [[146, "saddle-points"]], "Vanishing Gradients": [[146, "vanishing-gradients"], [116, "vanishing-gradients"]], "Momentum": [[145, "momentum"]], "Basics": [[145, "basics"], [103, "basics"]], "Leaky Averages": [[145, "leaky-averages"]], "An Ill-conditioned Problem": [[145, "an-ill-conditioned-problem"]], "The Momentum Method": [[145, "the-momentum-method"]], "Effective Sample Weight": [[145, "effective-sample-weight"]], "Practical Experiments": [[145, "practical-experiments"]], "Theoretical Analysis": [[145, "theoretical-analysis"]], "Quadratic Convex Functions": [[145, "quadratic-convex-functions"]], "Scalar Functions": [[145, "scalar-functions"]], "Word Embedding with Global Vectors (GloVe)": [[129, "word-embedding-with-global-vectors-glove"]], "Skip-Gram with Global Corpus Statistics": [[129, "skip-gram-with-global-corpus-statistics"]], "The GloVe Model": [[129, "the-glove-model"]], "Interpreting GloVe from the Ratio of Co-occurrence Probabilities": [[129, "interpreting-glove-from-the-ratio-of-co-occurrence-probabilities"]], "label:tab_glove": [[129, "id4"]], "Representing Text with BERT": [[128, "representing-text-with-bert"]], "Convexity": [[140, "convexity"]], "Definitions": [[140, "definitions"]], "Convex Sets": [[140, "convex-sets"]], "Convex Functions": [[140, "convex-functions"]], "Jensen\u2019s Inequality": [[140, "jensens-inequality"]], "Local Minima Are Global Minima": [[140, "local-minima-are-global-minima"]], "Below Sets of Convex Functions Are Convex": [[140, "below-sets-of-convex-functions-are-convex"]], "Convexity and Second Derivatives": [[140, "convexity-and-second-derivatives"]], "Constraints": [[140, "constraints"]], "Lagrangian": [[140, "lagrangian"]], "Penalties": [[140, "penalties"]], "Projections": [[140, "projections"]], "Notation": [[136, "notation"]], "Numerical Objects": [[136, "numerical-objects"]], "Set Theory": [[136, "set-theory"]], "Functions and Operators": [[136, "functions-and-operators"]], "Probability and Information Theory": [[136, "probability-and-information-theory"]], "Adam": [[139, "adam"]], "Yogi": [[139, "yogi"]], "The Dataset for Pretraining BERT": [[127, "the-dataset-for-pretraining-bert"]], "Defining Helper Functions for Pretraining Tasks": [[127, "defining-helper-functions-for-pretraining-tasks"]], "Generating the Next Sentence Prediction Task": [[127, "generating-the-next-sentence-prediction-task"]], "Generating the Masked Language Modeling Task": [[127, "generating-the-masked-language-modeling-task"]], "Transforming Text into the Pretraining Dataset": [[127, "transforming-text-into-the-pretraining-dataset"]], "Bidirectional Encoder Representations from Transformers (BERT)": [[126, "bidirectional-encoder-representations-from-transformers-bert"]], "From Context-Independent to Context-Sensitive": [[126, "from-context-independent-to-context-sensitive"]], "From Task-Specific to Task-Agnostic": [[126, "from-task-specific-to-task-agnostic"]], "BERT: Combining the Best of Both Worlds": [[126, "bert-combining-the-best-of-both-worlds"]], "Input Representation": [[126, "input-representation"]], "Pretraining Tasks": [[126, "pretraining-tasks"]], "Masked Language Modeling": [[126, "masked-language-modeling"]], "Next Sentence Prediction": [[126, "next-sentence-prediction"]], "Adagrad": [[138, "adagrad"]], "Sparse Features and Learning Rates": [[138, "sparse-features-and-learning-rates"]], "Sentiment Analysis: Using Recurrent Neural Networks": [[124, "sentiment-analysis-using-recurrent-neural-networks"]], "Representing Single Text with RNNs": [[124, "representing-single-text-with-rnns"]], "Object-Oriented Design for Implementation": [[106, "object-oriented-design-for-implementation"]], "Utilities": [[106, "utilities"]], "Models": [[106, "models"], [92, "models"]], "Data": [[106, "data"], [92, "data"]], "Forward Propagation, Backward Propagation, and Computational Graphs": [[109, "forward-propagation-backward-propagation-and-computational-graphs"]], "Forward Propagation": [[109, "forward-propagation"]], "Computational Graph of Forward Propagation": [[109, "computational-graph-of-forward-propagation"]], "Backpropagation": [[109, "backpropagation"]], "Training Neural Networks": [[109, "training-neural-networks"]], "Linear Regression Implementation from Scratch": [[105, "linear-regression-implementation-from-scratch"]], "Defining the Optimization Algorithm": [[105, "defining-the-optimization-algorithm"], [104, "defining-the-optimization-algorithm"]], "Natural Language Processing: Applications": [[118, "natural-language-processing-applications"]], "Multilayer Perceptrons": [[112, "multilayer-perceptrons"], [114, "multilayer-perceptrons"]], "Predicting House Prices on Kaggle": [[113, "predicting-house-prices-on-kaggle"]], "Downloading Data": [[113, "downloading-data"]], "Kaggle": [[113, "kaggle"]], "Accessing and Reading the Dataset": [[113, "accessing-and-reading-the-dataset"]], "Error Measure": [[113, "error-measure"]], "K-Fold Cross-Validation": [[113, "k-fold-cross-validation"]], "Model Selection": [[113, "model-selection"], [101, "model-selection"]], "Submitting Predictions on Kaggle": [[113, "submitting-predictions-on-kaggle"]], "Implementation of Multilayer Perceptrons": [[115, "implementation-of-multilayer-perceptrons"]], "Dropout": [[110, "dropout"]], "Dropout in Practice": [[110, "dropout-in-practice"]], "Generalization in Deep Learning": [[111, "generalization-in-deep-learning"]], "Revisiting Overfitting and Regularization": [[111, "revisiting-overfitting-and-regularization"]], "Inspiration from Nonparametrics": [[111, "inspiration-from-nonparametrics"]], "Early Stopping": [[111, "early-stopping"]], "Classical Regularization Methods for Deep Networks": [[111, "classical-regularization-methods-for-deep-networks"]], "Natural Language Inference: Using Attention": [[120, "natural-language-inference-using-attention"]], "Attending": [[120, "attending"]], "Comparing": [[120, "comparing"]], "Aggregating": [[120, "aggregating"]], "Reading the dataset": [[120, "reading-the-dataset"]], "Creating the Model": [[120, "creating-the-model"]], "Using the Model": [[120, "using-the-model"]], "Sentiment Analysis and the Dataset": [[122, "sentiment-analysis-and-the-dataset"]], "Preprocessing the Dataset": [[122, "preprocessing-the-dataset"]], "Creating Data Iterators": [[122, "creating-data-iterators"]], "Fine-Tuning BERT for Sequence-Level and Token-Level Applications": [[117, "fine-tuning-bert-for-sequence-level-and-token-level-applications"]], "Single Text Classification": [[117, "single-text-classification"]], "Text Pair Classification or Regression": [[117, "text-pair-classification-or-regression"]], "Text Tagging": [[117, "text-tagging"]], "Question Answering": [[117, "question-answering"]], "Approximate Training": [[125, "approximate-training"]], "Hierarchical Softmax": [[125, "hierarchical-softmax"]], "Sentiment Analysis: Using Convolutional Neural Networks": [[123, "sentiment-analysis-using-convolutional-neural-networks"]], "One-Dimensional Convolutions": [[123, "one-dimensional-convolutions"]], "Max-Over-Time Pooling": [[123, "max-over-time-pooling"]], "The textCNN Model": [[123, "the-textcnn-model"]], "Synthetic Regression Data": [[107, "synthetic-regression-data"]], "Generating the Dataset": [[107, "generating-the-dataset"]], "Concise Implementation of the Data Loader": [[107, "concise-implementation-of-the-data-loader"]], "Numerical Stability and Initialization": [[116, "numerical-stability-and-initialization"]], "Vanishing and Exploding Gradients": [[116, "vanishing-and-exploding-gradients"]], "Exploding Gradients": [[116, "exploding-gradients"]], "Breaking the Symmetry": [[116, "breaking-the-symmetry"]], "Default Initialization": [[116, "default-initialization"]], "Xavier Initialization": [[116, "xavier-initialization"]], "Beyond": [[116, "beyond"]], "Weight Decay": [[108, "weight-decay"]], "Norms and Weight Decay": [[108, "norms-and-weight-decay"]], "High-Dimensional Linear Regression": [[108, "high-dimensional-linear-regression"]], "Defining \\ell_2 Norm Penalty": [[108, "defining-ell-2-norm-penalty"]], "Training without Regularization": [[108, "training-without-regularization"]], "Using Weight Decay": [[108, "using-weight-decay"]], "Natural Language Inference: Fine-Tuning BERT": [[121, "natural-language-inference-fine-tuning-bert"]], "Loading Pretrained BERT": [[121, "loading-pretrained-bert"]], "The Dataset for Fine-Tuning BERT": [[121, "the-dataset-for-fine-tuning-bert"]], "Natural Language Inference and the Dataset": [[119, "natural-language-inference-and-the-dataset"]], "Natural Language Inference": [[119, "natural-language-inference"]], "The Stanford Natural Language Inference (SNLI) Dataset": [[119, "the-stanford-natural-language-inference-snli-dataset"]], "Defining a Class for Loading the Dataset": [[119, "defining-a-class-for-loading-the-dataset"]], "Hidden Layers": [[114, "hidden-layers"]], "Limitations of Linear Models": [[114, "limitations-of-linear-models"]], "Incorporating Hidden Layers": [[114, "incorporating-hidden-layers"]], "From Linear to Nonlinear": [[114, "from-linear-to-nonlinear"]], "Universal Approximators": [[114, "universal-approximators"]], "ReLU Function": [[114, "relu-function"]], "Sigmoid Function": [[114, "sigmoid-function"]], "Tanh Function": [[114, "tanh-function"]], "Concise Implementation of Softmax Regression": [[99, "concise-implementation-of-softmax-regression"]], "Softmax Revisited": [[99, "softmax-revisited"]], "Environment and Distribution Shift": [[94, "environment-and-distribution-shift"]], "Types of Distribution Shift": [[94, "types-of-distribution-shift"]], "Covariate Shift": [[94, "covariate-shift"]], "Label Shift": [[94, "label-shift"]], "Concept Shift": [[94, "concept-shift"]], "Examples of Distribution Shift": [[94, "examples-of-distribution-shift"]], "Medical Diagnostics": [[94, "medical-diagnostics"]], "Self-Driving Cars": [[94, "self-driving-cars"]], "Nonstationary Distributions": [[94, "nonstationary-distributions"]], "More Anecdotes": [[94, "more-anecdotes"]], "Correction of Distribution Shift": [[94, "correction-of-distribution-shift"]], "Empirical Risk and Risk": [[94, "empirical-risk-and-risk"]], "Covariate Shift Correction": [[94, "covariate-shift-correction"]], "Label Shift Correction": [[94, "label-shift-correction"]], "Concept Shift Correction": [[94, "concept-shift-correction"]], "A Taxonomy of Learning Problems": [[94, "a-taxonomy-of-learning-problems"]], "Batch Learning": [[94, "batch-learning"]], "Online Learning": [[94, "online-learning"]], "Bandits": [[94, "bandits"]], "Control": [[94, "control"]], "Considering the Environment": [[94, "considering-the-environment"]], "Fairness, Accountability, and Transparency in Machine Learning": [[94, "fairness-accountability-and-transparency-in-machine-learning"]], "Hyperparameter Optimization API": [[85, "hyperparameter-optimization-api"]], "Searcher": [[85, "searcher"]], "Scheduler": [[85, "scheduler"]], "Tuner": [[85, "tuner"]], "Bookkeeping the Performance of HPO Algorithms": [[85, "bookkeeping-the-performance-of-hpo-algorithms"]], "Example: Optimizing the Hyperparameters of a Convolutional Neural Network": [[85, "example-optimizing-the-hyperparameters-of-a-convolutional-neural-network"]], "Comparing HPO Algorithms": [[85, "comparing-hpo-algorithms"]], "Linear Regression": [[103, "linear-regression"]], "Analytic Solution": [[103, "analytic-solution"]], "Predictions": [[103, "predictions"]], "Vectorization for Speed": [[103, "vectorization-for-speed"]], "The Normal Distribution and Squared Loss": [[103, "the-normal-distribution-and-squared-loss"]], "Linear Regression as a Neural Network": [[103, "linear-regression-as-a-neural-network"]], "Biology": [[103, "biology"]], "Asynchronous Random Search": [[88, "asynchronous-random-search"]], "Objective Function": [[88, "objective-function"], [89, "objective-function"]], "Asynchronous Scheduler": [[88, "asynchronous-scheduler"], [89, "asynchronous-scheduler"]], "Visualize the Asynchronous Optimization Process": [[88, "visualize-the-asynchronous-optimization-process"]], "Installation": [[91, "installation"]], "Installing Miniconda": [[91, "installing-miniconda"]], "Installing the Deep Learning Framework and the d2l Package": [[91, "installing-the-deep-learning-framework-and-the-d2l-package"]], "Downloading and Running the Code": [[91, "downloading-and-running-the-code"]], "Linear Neural Networks for Classification": [[97, "linear-neural-networks-for-classification"]], "Asynchronous Successive Halving": [[89, "asynchronous-successive-halving"]], "Visualize the Optimization Process": [[89, "visualize-the-optimization-process"]], "The Image Classification Dataset": [[96, "the-image-classification-dataset"]], "Loading the Dataset": [[96, "loading-the-dataset"]], "Reading a Minibatch": [[96, "reading-a-minibatch"]], "Linear Neural Networks for Regression": [[102, "linear-neural-networks-for-regression"]], "Hyperparameter Optimization": [[87, "hyperparameter-optimization"]], "Softmax Regression Implementation from Scratch": [[100, "softmax-regression-implementation-from-scratch"]], "The Softmax": [[100, "the-softmax"], [98, "the-softmax"]], "The Cross-Entropy Loss": [[100, "the-cross-entropy-loss"]], "What Is Hyperparameter Optimization?": [[86, "what-is-hyperparameter-optimization"]], "The Optimization Problem": [[86, "the-optimization-problem"]], "The Objective Function": [[86, "the-objective-function"]], "The Configuration Space": [[86, "the-configuration-space"]], "label:tab_example_configspace": [[86, "id11"]], "Random Search": [[86, "random-search"]], "Generalization": [[101, "generalization"]], "Training Error and Generalization Error": [[101, "training-error-and-generalization-error"]], "Model Complexity": [[101, "model-complexity"]], "Underfitting or Overfitting?": [[101, "underfitting-or-overfitting"]], "Polynomial Curve Fitting": [[101, "polynomial-curve-fitting"]], "Dataset Size": [[101, "dataset-size"]], "Cross-Validation": [[101, "cross-validation"]], "The Base Classification Model": [[93, "the-base-classification-model"]], "The Classifier Class": [[93, "the-classifier-class"]], "Accuracy": [[93, "accuracy"]], "Concise Implementation of Linear Regression": [[104, "concise-implementation-of-linear-regression"]], "Introduction": [[92, "introduction"]], "A Motivating Example": [[92, "a-motivating-example"]], "Key Components": [[92, "key-components"]], "Objective Functions": [[92, "objective-functions"]], "Kinds of Machine Learning Problems": [[92, "kinds-of-machine-learning-problems"]], "Supervised Learning": [[92, "supervised-learning"]], "Regression": [[92, "regression"]], "Classification": [[92, "classification"], [98, "classification"]], "Tagging": [[92, "tagging"]], "Search": [[92, "search"]], "Sequence Learning": [[92, "sequence-learning"]], "Unsupervised and Self-Supervised Learning": [[92, "unsupervised-and-self-supervised-learning"]], "Interacting with an Environment": [[92, "interacting-with-an-environment"]], "Roots": [[92, "roots"]], "The Road to Deep Learning": [[92, "the-road-to-deep-learning"]], "label:tab_intro_decade": [[92, "id59"]], "Success Stories": [[92, "success-stories"]], "The Essence of Deep Learning": [[92, "the-essence-of-deep-learning"]], "Generalization in Classification": [[95, "generalization-in-classification"]], "The Test Set": [[95, "the-test-set"]], "Test Set Reuse": [[95, "test-set-reuse"]], "Statistical Learning Theory": [[95, "statistical-learning-theory"]], "Multi-Fidelity Hyperparameter Optimization": [[90, "multi-fidelity-hyperparameter-optimization"]], "Successive Halving": [[90, "successive-halving"]], "Softmax Regression": [[98, "softmax-regression"]], "Linear Model": [[98, "linear-model"]], "Log-Likelihood": [[98, "log-likelihood"]], "Softmax and Cross-Entropy Loss": [[98, "softmax-and-cross-entropy-loss"]], "Information Theory Basics": [[98, "information-theory-basics"]], "Surprisal": [[98, "surprisal"]], "Cross-Entropy Revisited": [[98, "cross-entropy-revisited"]]}, "indexentries": {}})