<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>4.7. Environment and Distribution Shift &#8212; Dive into Deep Learning 1.0.3 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Multilayer Perceptrons" href="../chapter_multilayer-perceptrons/index.html" />
    <link rel="prev" title="4.6. Generalization in Classification" href="generalization-classification.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">4. </span>Linear Neural Networks for Classification</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">4.7. </span>Environment and Distribution Shift</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_linear-classification/environment-and-distribution-shift.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="http://preview.d2l.ai/d2l-en/master">
                  <i class="fas fa-book"></i>
                  Preview Version
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PyTorch
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en-mxnet.pdf">
                  <i class="fas fa-file-pdf"></i>
                  MXNet
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.zip">
                  <i class="fab fa-python"></i>
                  Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://courses.d2l.ai">
                  <i class="fas fa-user-graduate"></i>
                  Courses
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/d2l-ai/d2l-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://zh.d2l.ai">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Dive into Deep Learning"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">4. Linear Neural Networks for Classification</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-classification-dataset.html">4.2. The Image Classification Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification.html">4.3. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="softmax-regression-scratch.html">4.4. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="softmax-regression-concise.html">4.5. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="generalization-classification.html">4.6. Generalization in Classification</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4.7. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/lazy-init.html">6.4. Lazy Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.5. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.6. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.7. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg.html">8.2. Networks Using Blocks (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin.html">8.3. Network in Network (NiN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.4. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.5. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.6. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.7. Densely Connected Networks (DenseNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/cnn-design.html">8.8. Designing Convolution Network Architectures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn.html">10.4. Bidirectional Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.5. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.6. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.7. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.8. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index.html">13. Computational Performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize.html">13.1. Compilers and Interpreters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation.html">13.2. Asynchronous Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism.html">13.3. Automatic Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware.html">13.4. Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus.html">13.5. Training on Multiple GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise.html">13.6. Concise Implementation for Multiple GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver.html">13.7. Parameter Servers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">14. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">14.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">14.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">14.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">14.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">14.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">14.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">14.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">14.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">14.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">14.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">14.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">14.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">14.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">14.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">15. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">15.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">15.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">15.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">15.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">15.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">15.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">15.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">15.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">15.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">15.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">16. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">16.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html">16.2. Sentiment Analysis: Using Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">16.3. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">16.4. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">16.5. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">16.6. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html">16.7. Natural Language Inference: Fine-Tuning BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">17. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">17.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">17.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">17.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">18. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">18.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">18.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">18.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_hyperparameter-optimization/index.html">19. Hyperparameter Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/hyperopt-intro.html">19.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/hyperopt-api.html">19.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/rs-async.html">19.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/sh-intro.html">19.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/sh-async.html">19.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index.html">20. Generative Adversarial Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan.html">20.1. Generative Adversarial Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan.html">20.2. Deep Convolutional Generative Adversarial Networks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index.html">21. Recommender Systems</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro.html">21.1. Overview of Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens.html">21.2. The MovieLens Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf.html">21.3. Matrix Factorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec.html">21.4. AutoRec: Rating Prediction with Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking.html">21.5. Personalized Ranking for Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf.html">21.6. Neural Collaborative Filtering for Personalized Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec.html">21.7. Sequence-Aware Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr.html">21.8. Feature-Rich Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm.html">21.9. Factorization Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm.html">21.10. Deep Factorization Machines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index.html">22. Appendix: Mathematics for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html">22.1. Geometry and Linear Algebraic Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html">22.2. Eigendecompositions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html">22.3. Single Variable Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html">22.4. Multivariable Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html">22.5. Integral Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html">22.6. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html">22.7. Maximum Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions.html">22.8. Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html">22.9. Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics.html">22.10. Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html">22.11. Information Theory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">23. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter.html">23.1. Using Jupyter Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker.html">23.2. Using Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws.html">23.3. Using AWS EC2 Instances</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab.html">23.4. Using Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html">23.5. Selecting Servers and GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing.html">23.6. Contributing to This Book</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">23.7. Utility Functions and Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l.html">23.8. The <code class="docutils literal notranslate"><span class="pre">d2l</span></code> API Document</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">References</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="Dive into Deep Learning"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">Notation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. Preliminaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/ndarray.html">2.1. Data Manipulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/pandas.html">2.2. Data Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/linear-algebra.html">2.3. Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/calculus.html">2.4. Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/autograd.html">2.5. Automatic Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/probability.html">2.6. Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_preliminaries/lookup-api.html">2.7. Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_linear-regression/index.html">3. Linear Neural Networks for Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression.html">3.1. Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/oo-design.html">3.2. Object-Oriented Design for Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/synthetic-regression-data.html">3.3. Synthetic Regression Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-scratch.html">3.4. Linear Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/linear-regression-concise.html">3.5. Concise Implementation of Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/generalization.html">3.6. Generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_linear-regression/weight-decay.html">3.7. Weight Decay</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">4. Linear Neural Networks for Classification</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="softmax-regression.html">4.1. Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="image-classification-dataset.html">4.2. The Image Classification Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification.html">4.3. The Base Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="softmax-regression-scratch.html">4.4. Softmax Regression Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="softmax-regression-concise.html">4.5. Concise Implementation of Softmax Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="generalization-classification.html">4.6. Generalization in Classification</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4.7. Environment and Distribution Shift</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multilayer-perceptrons/index.html">5. Multilayer Perceptrons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp.html">5.1. Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/mlp-implementation.html">5.2. Implementation of Multilayer Perceptrons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/backprop.html">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/numerical-stability-and-init.html">5.4. Numerical Stability and Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/generalization-deep.html">5.5. Generalization in Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/dropout.html">5.6. Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_multilayer-perceptrons/kaggle-house-price.html">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_builders-guide/index.html">6. Builders’ Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/model-construction.html">6.1. Layers and Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/parameters.html">6.2. Parameter Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/init-param.html">6.3. Parameter Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/lazy-init.html">6.4. Lazy Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/custom-layer.html">6.5. Custom Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/read-write.html">6.6. File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_builders-guide/use-gpu.html">6.7. GPUs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-neural-networks/index.html">7. Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/why-conv.html">7.1. From Fully Connected Layers to Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/conv-layer.html">7.2. Convolutions for Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/padding-and-strides.html">7.3. Padding and Stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/channels.html">7.4. Multiple Input and Multiple Output Channels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/pooling.html">7.5. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-neural-networks/lenet.html">7.6. Convolutional Neural Networks (LeNet)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_convolutional-modern/index.html">8. Modern Convolutional Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/alexnet.html">8.1. Deep Convolutional Neural Networks (AlexNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/vgg.html">8.2. Networks Using Blocks (VGG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/nin.html">8.3. Network in Network (NiN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/googlenet.html">8.4. Multi-Branch Networks (GoogLeNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/batch-norm.html">8.5. Batch Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/resnet.html">8.6. Residual Networks (ResNet) and ResNeXt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/densenet.html">8.7. Densely Connected Networks (DenseNet)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_convolutional-modern/cnn-design.html">8.8. Designing Convolution Network Architectures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-neural-networks/index.html">9. Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/sequence.html">9.1. Working with Sequences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/text-sequence.html">9.2. Converting Raw Text into Sequence Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/language-model.html">9.3. Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn.html">9.4. Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-scratch.html">9.5. Recurrent Neural Network Implementation from Scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/rnn-concise.html">9.6. Concise Implementation of Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-neural-networks/bptt.html">9.7. Backpropagation Through Time</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recurrent-modern/index.html">10. Modern Recurrent Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/lstm.html">10.1. Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/gru.html">10.2. Gated Recurrent Units (GRU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/deep-rnn.html">10.3. Deep Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/bi-rnn.html">10.4. Bidirectional Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/machine-translation-and-dataset.html">10.5. Machine Translation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/encoder-decoder.html">10.6. The Encoder–Decoder Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/seq2seq.html">10.7. Sequence-to-Sequence Learning for Machine Translation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recurrent-modern/beam-search.html">10.8. Beam Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/index.html">11. Attention Mechanisms and Transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/queries-keys-values.html">11.1. Queries, Keys, and Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-pooling.html">11.2. Attention Pooling by Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/attention-scoring-functions.html">11.3. Attention Scoring Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/bahdanau-attention.html">11.4. The Bahdanau Attention Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/multihead-attention.html">11.5. Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html">11.6. Self-Attention and Positional Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/transformer.html">11.7. The Transformer Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/vision-transformer.html">11.8. Transformers for Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_attention-mechanisms-and-transformers/large-pretraining-transformers.html">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_optimization/index.html">12. Optimization Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/optimization-intro.html">12.1. Optimization and Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/convexity.html">12.2. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/gd.html">12.3. Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/sgd.html">12.4. Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/minibatch-sgd.html">12.5. Minibatch Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/momentum.html">12.6. Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adagrad.html">12.7. Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/rmsprop.html">12.8. RMSProp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adadelta.html">12.9. Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/adam.html">12.10. Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_optimization/lr-scheduler.html">12.11. Learning Rate Scheduling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational-performance/index.html">13. Computational Performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hybridize.html">13.1. Compilers and Interpreters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/async-computation.html">13.2. Asynchronous Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/auto-parallelism.html">13.3. Automatic Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/hardware.html">13.4. Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus.html">13.5. Training on Multiple GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/multiple-gpus-concise.html">13.6. Concise Implementation for Multiple GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational-performance/parameterserver.html">13.7. Parameter Servers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computer-vision/index.html">14. Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/image-augmentation.html">14.1. Image Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fine-tuning.html">14.2. Fine-Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/bounding-box.html">14.3. Object Detection and Bounding Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/anchor.html">14.4. Anchor Boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/multiscale-object-detection.html">14.5. Multiscale Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/object-detection-dataset.html">14.6. The Object Detection Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/ssd.html">14.7. Single Shot Multibox Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/rcnn.html">14.8. Region-based CNNs (R-CNNs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/semantic-segmentation-and-dataset.html">14.9. Semantic Segmentation and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/transposed-conv.html">14.10. Transposed Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/fcn.html">14.11. Fully Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/neural-style.html">14.12. Neural Style Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-cifar10.html">14.13. Image Classification (CIFAR-10) on Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computer-vision/kaggle-dog.html">14.14. Dog Breed Identification (ImageNet Dogs) on Kaggle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/index.html">15. Natural Language Processing: Pretraining</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec.html">15.1. Word Embedding (word2vec)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/approx-training.html">15.2. Approximate Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word-embedding-dataset.html">15.3. The Dataset for Pretraining Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/word2vec-pretraining.html">15.4. Pretraining word2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/glove.html">15.5. Word Embedding with Global Vectors (GloVe)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/subword-embedding.html">15.6. Subword Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/similarity-analogy.html">15.7. Word Similarity and Analogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert.html">15.8. Bidirectional Encoder Representations from Transformers (BERT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-dataset.html">15.9. The Dataset for Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-pretraining/bert-pretraining.html">15.10. Pretraining BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_natural-language-processing-applications/index.html">16. Natural Language Processing: Applications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">16.1. Sentiment Analysis and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-rnn.html">16.2. Sentiment Analysis: Using Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">16.3. Sentiment Analysis: Using Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">16.4. Natural Language Inference and the Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-attention.html">16.5. Natural Language Inference: Using Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/finetuning-bert.html">16.6. Fine-Tuning BERT for Sequence-Level and Token-Level Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_natural-language-processing-applications/natural-language-inference-bert.html">16.7. Natural Language Inference: Fine-Tuning BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement-learning/index.html">17. Reinforcement Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/mdp.html">17.1. Markov Decision Process (MDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/value-iter.html">17.2. Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement-learning/qlearning.html">17.3. Q-Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_gaussian-processes/index.html">18. Gaussian Processes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-intro.html">18.1. Introduction to Gaussian Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-priors.html">18.2. Gaussian Process Priors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_gaussian-processes/gp-inference.html">18.3. Gaussian Process Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_hyperparameter-optimization/index.html">19. Hyperparameter Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/hyperopt-intro.html">19.1. What Is Hyperparameter Optimization?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/hyperopt-api.html">19.2. Hyperparameter Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/rs-async.html">19.3. Asynchronous Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/sh-intro.html">19.4. Multi-Fidelity Hyperparameter Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hyperparameter-optimization/sh-async.html">19.5. Asynchronous Successive Halving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_generative-adversarial-networks/index.html">20. Generative Adversarial Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/gan.html">20.1. Generative Adversarial Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_generative-adversarial-networks/dcgan.html">20.2. Deep Convolutional Generative Adversarial Networks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender-systems/index.html">21. Recommender Systems</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/recsys-intro.html">21.1. Overview of Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/movielens.html">21.2. The MovieLens Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/mf.html">21.3. Matrix Factorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/autorec.html">21.4. AutoRec: Rating Prediction with Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ranking.html">21.5. Personalized Ranking for Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/neumf.html">21.6. Neural Collaborative Filtering for Personalized Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/seqrec.html">21.7. Sequence-Aware Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/ctr.html">21.8. Feature-Rich Recommender Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/fm.html">21.9. Factorization Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender-systems/deepfm.html">21.10. Deep Factorization Machines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/index.html">22. Appendix: Mathematics for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html">22.1. Geometry and Linear Algebraic Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html">22.2. Eigendecompositions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/single-variable-calculus.html">22.3. Single Variable Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html">22.4. Multivariable Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/integral-calculus.html">22.5. Integral Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/random-variables.html">22.6. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html">22.7. Maximum Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/distributions.html">22.8. Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/naive-bayes.html">22.9. Naive Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/statistics.html">22.10. Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-mathematics-for-deep-learning/information-theory.html">22.11. Information Theory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/index.html">23. Appendix: Tools for Deep Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/jupyter.html">23.1. Using Jupyter Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/sagemaker.html">23.2. Using Amazon SageMaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/aws.html">23.3. Using AWS EC2 Instances</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/colab.html">23.4. Using Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html">23.5. Selecting Servers and GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/contributing.html">23.6. Contributing to This Book</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/utils.html">23.7. Utility Functions and Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_appendix-tools-for-deep-learning/d2l.html">23.8. The <code class="docutils literal notranslate"><span class="pre">d2l</span></code> API Document</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">References</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="environment-and-distribution-shift">
<span id="sec-environment-and-distribution-shift"></span><h1><span class="section-number">4.7. </span>Environment and Distribution Shift<a class="headerlink" href="#environment-and-distribution-shift" title="Permalink to this heading">¶</a><div class="d2l-tabs" style="float:right"><div class="d2l-tabs__tab"><a href="https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb" onclick="captureOutboundLink('https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb'); return false;"> <button style="float:right", id="Colab_[pytorch]" class="mdl-button mdl-js-button mdl-button--primary mdl-js-ripple-effect"> <i class=" fas fa-external-link-alt"></i> Colab [pytorch] </button></a><div class="mdl-tooltip" data-mdl-for="Colab_[pytorch]"> Open the notebook in Colab</div></div><div class="d2l-tabs__tab"><a href="https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb" onclick="captureOutboundLink('https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb'); return false;"> <button style="float:right", id="Colab_[mxnet]" class="mdl-button mdl-js-button mdl-button--primary mdl-js-ripple-effect"> <i class=" fas fa-external-link-alt"></i> Colab [mxnet] </button></a><div class="mdl-tooltip" data-mdl-for="Colab_[mxnet]"> Open the notebook in Colab</div></div><div class="d2l-tabs__tab"><a href="https://colab.research.google.com/github/d2l-ai/d2l-jax-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb" onclick="captureOutboundLink('https://colab.research.google.com/github/d2l-ai/d2l-jax-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb'); return false;"> <button style="float:right", id="Colab_[jax]" class="mdl-button mdl-js-button mdl-button--primary mdl-js-ripple-effect"> <i class=" fas fa-external-link-alt"></i> Colab [jax] </button></a><div class="mdl-tooltip" data-mdl-for="Colab_[jax]"> Open the notebook in Colab</div></div><div class="d2l-tabs__tab"><a href="https://colab.research.google.com/github/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb" onclick="captureOutboundLink('https://colab.research.google.com/github/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_linear-classification/environment-and-distribution-shift.ipynb'); return false;"> <button style="float:right", id="Colab_[tensorflow]" class="mdl-button mdl-js-button mdl-button--primary mdl-js-ripple-effect"> <i class=" fas fa-external-link-alt"></i> Colab [tensorflow] </button></a><div class="mdl-tooltip" data-mdl-for="Colab_[tensorflow]"> Open the notebook in Colab</div></div></div></h1>
<p>In the previous sections, we worked through a number of hands-on
applications of machine learning, fitting models to a variety of
datasets. And yet, we never stopped to contemplate either where data
came from in the first place or what we ultimately plan to do with the
outputs from our models. Too often, machine learning developers in
possession of data rush to develop models without pausing to consider
these fundamental issues.</p>
<p>Many failed machine learning deployments can be traced back to this
failure. Sometimes models appear to perform marvelously as measured by
test set accuracy but fail catastrophically in deployment when the
distribution of data suddenly shifts. More insidiously, sometimes the
very deployment of a model can be the catalyst that perturbs the data
distribution. Say, for example, that we trained a model to predict who
will repay rather than default on a loan, finding that an applicant’s
choice of footwear was associated with the risk of default (Oxfords
indicate repayment, sneakers indicate default). We might be inclined
thereafter to grant a loan to any applicant wearing Oxfords and to deny
all applicants wearing sneakers.</p>
<p>In this case, our ill-considered leap from pattern recognition to
decision-making and our failure to critically consider the environment
might have disastrous consequences. For starters, as soon as we began
making decisions based on footwear, customers would catch on and change
their behavior. Before long, all applicants would be wearing Oxfords,
without any coincident improvement in credit-worthiness. Take a minute
to digest this because similar issues abound in many applications of
machine learning: by introducing our model-based decisions to the
environment, we might break the model.</p>
<p>While we cannot possibly give these topics a complete treatment in one
section, we aim here to expose some common concerns, and to stimulate
the critical thinking required to detect such situations early, mitigate
damage, and use machine learning responsibly. Some of the solutions are
simple (ask for the “right” data), some are technically difficult
(implement a reinforcement learning system), and others require that we
step outside the realm of statistical prediction altogether and grapple
with difficult philosophical questions concerning the ethical
application of algorithms.</p>
<div class="section" id="types-of-distribution-shift">
<h2><span class="section-number">4.7.1. </span>Types of Distribution Shift<a class="headerlink" href="#types-of-distribution-shift" title="Permalink to this heading">¶</a></h2>
<p>To begin, we stick with the passive prediction setting considering the
various ways that data distributions might shift and what might be done
to salvage model performance. In one classic setup, we assume that our
training data was sampled from some distribution
<span class="math notranslate nohighlight">\(p_S(\mathbf{x},y)\)</span> but that our test data will consist of
unlabeled examples drawn from some different distribution
<span class="math notranslate nohighlight">\(p_T(\mathbf{x},y)\)</span>. Already, we must confront a sobering reality.
Absent any assumptions on how <span class="math notranslate nohighlight">\(p_S\)</span> and <span class="math notranslate nohighlight">\(p_T\)</span> relate to each
other, learning a robust classifier is impossible.</p>
<p>Consider a binary classification problem, where we wish to distinguish
between dogs and cats. If the distribution can shift in arbitrary ways,
then our setup permits the pathological case in which the distribution
over inputs remains constant: <span class="math notranslate nohighlight">\(p_S(\mathbf{x}) = p_T(\mathbf{x})\)</span>,
but the labels are all flipped:
<span class="math notranslate nohighlight">\(p_S(y \mid \mathbf{x}) = 1 - p_T(y \mid \mathbf{x})\)</span>. In other
words, if God can suddenly decide that in the future all “cats” are now
dogs and what we previously called “dogs” are now cats—without any
change in the distribution of inputs <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>, then we
cannot possibly distinguish this setting from one in which the
distribution did not change at all.</p>
<p>Fortunately, under some restricted assumptions on the ways our data
might change in the future, principled algorithms can detect shift and
sometimes even adapt on the fly, improving on the accuracy of the
original classifier.</p>
<div class="section" id="covariate-shift">
<h3><span class="section-number">4.7.1.1. </span>Covariate Shift<a class="headerlink" href="#covariate-shift" title="Permalink to this heading">¶</a></h3>
<p>Among categories of distribution shift, covariate shift may be the most
widely studied. Here, we assume that while the distribution of inputs
may change over time, the labeling function, i.e., the conditional
distribution <span class="math notranslate nohighlight">\(P(y \mid \mathbf{x})\)</span> does not change. Statisticians
call this <em>covariate shift</em> because the problem arises due to a shift in
the distribution of the covariates (features). While we can sometimes
reason about distribution shift without invoking causality, we note that
covariate shift is the natural assumption to invoke in settings where we
believe that <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> causes <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Consider the challenge of distinguishing cats and dogs. Our training
data might consist of images of the kind in
<a class="reference internal" href="#fig-cat-dog-train"><span class="std std-numref">Fig. 4.7.1</span></a>.</p>
<div class="figure align-default" id="id2">
<span id="fig-cat-dog-train"></span><img alt="../_images/cat-dog-train.png" src="../_images/cat-dog-train.png" />
<p class="caption"><span class="caption-number">Fig. 4.7.1 </span><span class="caption-text">Training data for distinguishing cats and dogs (illustrations: Lafeez
Hossain / 500px / Getty Images; ilkermetinkursova / iStock / Getty
Images Plus; GlobalP / iStock / Getty Images Plus; Musthafa
Aboobakuru / 500px / Getty Images).</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<p>At test time we are asked to classify the images in
<a class="reference internal" href="#fig-cat-dog-test"><span class="std std-numref">Fig. 4.7.2</span></a>.</p>
<div class="figure align-default" id="id3">
<span id="fig-cat-dog-test"></span><img alt="../_images/cat-dog-test.png" src="../_images/cat-dog-test.png" />
<p class="caption"><span class="caption-number">Fig. 4.7.2 </span><span class="caption-text">Test data for distinguishing cats and dogs (illustrations:
SIBAS_minich / iStock / Getty Images Plus; Ghrzuzudu / iStock / Getty
Images Plus; id-work / DigitalVision Vectors / Getty Images; Yime /
iStock / Getty Images Plus).</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>The training set consists of photos, while the test set contains only
cartoons. Training on a dataset with substantially different
characteristics from the test set can spell trouble absent a coherent
plan for how to adapt to the new domain.</p>
</div>
<div class="section" id="label-shift">
<h3><span class="section-number">4.7.1.2. </span>Label Shift<a class="headerlink" href="#label-shift" title="Permalink to this heading">¶</a></h3>
<p><em>Label shift</em> describes the converse problem. Here, we assume that the
label marginal <span class="math notranslate nohighlight">\(P(y)\)</span> can change but the class-conditional
distribution <span class="math notranslate nohighlight">\(P(\mathbf{x} \mid y)\)</span> remains fixed across domains.
Label shift is a reasonable assumption to make when we believe that
<span class="math notranslate nohighlight">\(y\)</span> causes <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. For example, we may want to predict
diagnoses given their symptoms (or other manifestations), even as the
relative prevalence of diagnoses are changing over time. Label shift is
the appropriate assumption here because diseases cause symptoms. In some
degenerate cases the label shift and covariate shift assumptions can
hold simultaneously. For example, when the label is deterministic, the
covariate shift assumption will be satisfied, even when <span class="math notranslate nohighlight">\(y\)</span> causes
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Interestingly, in these cases, it is often
advantageous to work with methods that flow from the label shift
assumption. That is because these methods tend to involve manipulating
objects that look like labels (often low-dimensional), as opposed to
objects that look like inputs, which tend to be high-dimensional in deep
learning.</p>
</div>
<div class="section" id="concept-shift">
<h3><span class="section-number">4.7.1.3. </span>Concept Shift<a class="headerlink" href="#concept-shift" title="Permalink to this heading">¶</a></h3>
<p>We may also encounter the related problem of <em>concept shift</em>, which
arises when the very definitions of labels can change. This sounds
weird—a <em>cat</em> is a <em>cat</em>, no? However, other categories are subject to
changes in usage over time. Diagnostic criteria for mental illness, what
passes for fashionable, and job titles, are all subject to considerable
amounts of concept shift. It turns out that if we navigate around the
United States, shifting the source of our data by geography, we will
find considerable concept shift regarding the distribution of names for
<em>soft drinks</em> as shown in <a class="reference internal" href="#fig-popvssoda"><span class="std std-numref">Fig. 4.7.3</span></a>.</p>
<div class="figure align-default" id="id4">
<span id="fig-popvssoda"></span><a class="reference internal image-reference" href="../_images/popvssoda.png"><img alt="../_images/popvssoda.png" src="../_images/popvssoda.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 4.7.3 </span><span class="caption-text">Concept shift for soft drink names in the United States (CC-BY: Alan
McConchie, PopVsSoda.com).</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>If we were to build a machine translation system, the distribution
<span class="math notranslate nohighlight">\(P(y \mid \mathbf{x})\)</span> might be different depending on our
location. This problem can be tricky to spot. We might hope to exploit
knowledge that shift only takes place gradually either in a temporal or
geographic sense.</p>
</div>
</div>
<div class="section" id="examples-of-distribution-shift">
<h2><span class="section-number">4.7.2. </span>Examples of Distribution Shift<a class="headerlink" href="#examples-of-distribution-shift" title="Permalink to this heading">¶</a></h2>
<p>Before delving into formalism and algorithms, we can discuss some
concrete situations where covariate or concept shift might not be
obvious.</p>
<div class="section" id="medical-diagnostics">
<h3><span class="section-number">4.7.2.1. </span>Medical Diagnostics<a class="headerlink" href="#medical-diagnostics" title="Permalink to this heading">¶</a></h3>
<p>Imagine that you want to design an algorithm to detect cancer. You
collect data from healthy and sick people and you train your algorithm.
It works fine, giving you high accuracy and you conclude that you are
ready for a successful career in medical diagnostics. <em>Not so fast.</em></p>
<p>The distributions that gave rise to the training data and those you will
encounter in the wild might differ considerably. This happened to an
unfortunate startup that some of we authors worked with years ago. They
were developing a blood test for a disease that predominantly affects
older men and hoped to study it using blood samples that they had
collected from patients. However, it is considerably more difficult to
obtain blood samples from healthy men than from sick patients already in
the system. To compensate, the startup solicited blood donations from
students on a university campus to serve as healthy controls in
developing their test. Then they asked whether we could help them to
build a classifier for detecting the disease.</p>
<p>As we explained to them, it would indeed be easy to distinguish between
the healthy and sick cohorts with near-perfect accuracy. However, that
is because the test subjects differed in age, hormone levels, physical
activity, diet, alcohol consumption, and many more factors unrelated to
the disease. This was unlikely to be the case with real patients. Due to
their sampling procedure, we could expect to encounter extreme covariate
shift. Moreover, this case was unlikely to be correctable via
conventional methods. In short, they wasted a significant sum of money.</p>
</div>
<div class="section" id="self-driving-cars">
<h3><span class="section-number">4.7.2.2. </span>Self-Driving Cars<a class="headerlink" href="#self-driving-cars" title="Permalink to this heading">¶</a></h3>
<p>Say a company wanted to leverage machine learning for developing
self-driving cars. One key component here is a roadside detector. Since
real annotated data is expensive to get, they had the (smart and
questionable) idea to use synthetic data from a game rendering engine as
additional training data. This worked really well on “test data” drawn
from the rendering engine. Alas, inside a real car it was a disaster. As
it turned out, the roadside had been rendered with a very simplistic
texture. More importantly, <em>all</em> the roadside had been rendered with the
<em>same</em> texture and the roadside detector learned about this “feature”
very quickly.</p>
<p>A similar thing happened to the US Army when they first tried to detect
tanks in the forest. They took aerial photographs of the forest without
tanks, then drove the tanks into the forest and took another set of
pictures. The classifier appeared to work <em>perfectly</em>. Unfortunately, it
had merely learned how to distinguish trees with shadows from trees
without shadows—the first set of pictures was taken in the early
morning, the second set at noon.</p>
</div>
<div class="section" id="nonstationary-distributions">
<h3><span class="section-number">4.7.2.3. </span>Nonstationary Distributions<a class="headerlink" href="#nonstationary-distributions" title="Permalink to this heading">¶</a></h3>
<p>A much more subtle situation arises when the distribution changes slowly
(also known as <em>nonstationary distribution</em>) and the model is not
updated adequately. Below are some typical cases.</p>
<ul class="simple">
<li><p>We train a computational advertising model and then fail to update it
frequently (e.g., we forget to incorporate that an obscure new device
called an iPad was just launched).</p></li>
<li><p>We build a spam filter. It works well at detecting all spam that we
have seen so far. But then the spammers wise up and craft new
messages that look unlike anything we have seen before.</p></li>
<li><p>We build a product recommendation system. It works throughout the
winter but then continues to recommend Santa hats long after
Christmas.</p></li>
</ul>
</div>
<div class="section" id="more-anecdotes">
<h3><span class="section-number">4.7.2.4. </span>More Anecdotes<a class="headerlink" href="#more-anecdotes" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>We build a face detector. It works well on all benchmarks.
Unfortunately it fails on test data—the offending examples are
close-ups where the face fills the entire image (no such data was in
the training set).</p></li>
<li><p>We build a web search engine for the US market and want to deploy it
in the UK.</p></li>
<li><p>We train an image classifier by compiling a large dataset where each
among a large set of classes is equally represented in the dataset,
say 1000 categories, represented by 1000 images each. Then we deploy
the system in the real world, where the actual label distribution of
photographs is decidedly non-uniform.</p></li>
</ul>
</div>
</div>
<div class="section" id="correction-of-distribution-shift">
<h2><span class="section-number">4.7.3. </span>Correction of Distribution Shift<a class="headerlink" href="#correction-of-distribution-shift" title="Permalink to this heading">¶</a></h2>
<p>As we have discussed, there are many cases where training and test
distributions <span class="math notranslate nohighlight">\(P(\mathbf{x}, y)\)</span> are different. In some cases, we
get lucky and the models work despite covariate, label, or concept
shift. In other cases, we can do better by employing principled
strategies to cope with the shift. The remainder of this section grows
considerably more technical. The impatient reader could continue on to
the next section as this material is not prerequisite to subsequent
concepts.</p>
<div class="section" id="empirical-risk-and-risk">
<span id="subsec-empirical-risk-and-risk"></span><h3><span class="section-number">4.7.3.1. </span>Empirical Risk and Risk<a class="headerlink" href="#empirical-risk-and-risk" title="Permalink to this heading">¶</a></h3>
<p>Let’s first reflect on what exactly is happening during model training:
we iterate over features and associated labels of training data
<span class="math notranslate nohighlight">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span> and update
the parameters of a model <span class="math notranslate nohighlight">\(f\)</span> after every minibatch. For
simplicity we do not consider regularization, so we largely minimize the
loss on the training:</p>
<div class="math notranslate nohighlight" id="equation-eq-empirical-risk-min">
<span class="eqno">(4.7.1)<a class="headerlink" href="#equation-eq-empirical-risk-min" title="Permalink to this equation">¶</a></span>\[\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(l\)</span> is the loss function measuring “how bad” the prediction
<span class="math notranslate nohighlight">\(f(\mathbf{x}_i)\)</span> is given the associated label <span class="math notranslate nohighlight">\(y_i\)</span>.
Statisticians call the term in <a class="reference internal" href="#equation-eq-empirical-risk-min">(4.7.1)</a>
<em>empirical risk</em>. The <em>empirical risk</em> is an average loss over the
training data for approximating the <em>risk</em>, which is the expectation of
the loss over the entire population of data drawn from their true
distribution <span class="math notranslate nohighlight">\(p(\mathbf{x},y)\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-true-risk">
<span class="eqno">(4.7.2)<a class="headerlink" href="#equation-eq-true-risk" title="Permalink to this equation">¶</a></span>\[E_{p(\mathbf{x}, y)} [l(f(\mathbf{x}), y)] = \int\int l(f(\mathbf{x}), y) p(\mathbf{x}, y) \;d\mathbf{x}dy.\]</div>
<p>However, in practice we typically cannot obtain the entire population of
data. Thus, <em>empirical risk minimization</em>, which is minimizing the
empirical risk in <a class="reference internal" href="#equation-eq-empirical-risk-min">(4.7.1)</a>, is a practical
strategy for machine learning, with the hope of approximately minimizing
the risk.</p>
</div>
<div class="section" id="covariate-shift-correction">
<span id="subsec-covariate-shift-correction"></span><h3><span class="section-number">4.7.3.2. </span>Covariate Shift Correction<a class="headerlink" href="#covariate-shift-correction" title="Permalink to this heading">¶</a></h3>
<p>Assume that we want to estimate some dependency
<span class="math notranslate nohighlight">\(P(y \mid \mathbf{x})\)</span> for which we have labeled data
<span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span>. Unfortunately, the observations
<span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> are drawn from some <em>source distribution</em>
<span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span> rather than the <em>target distribution</em>
<span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>. Fortunately, the dependency assumption means that
the conditional distribution does not change:
<span class="math notranslate nohighlight">\(p(y \mid \mathbf{x}) = q(y \mid \mathbf{x})\)</span>. If the source
distribution <span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span> is “wrong”, we can correct for that
by using the following simple identity in the risk:</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-0">
<span class="eqno">(4.7.3)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-0" title="Permalink to this equation">¶</a></span>\[\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}\]</div>
<p>In other words, we need to reweigh each data example by the ratio of the
probability that it would have been drawn from the correct distribution
to that from the wrong one:</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-1">
<span class="eqno">(4.7.4)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-1" title="Permalink to this equation">¶</a></span>\[\beta_i \stackrel{\textrm{def}}{=} \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}.\]</div>
<p>Plugging in the weight <span class="math notranslate nohighlight">\(\beta_i\)</span> for each data example
<span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span> we can train our model using <em>weighted
empirical risk minimization</em>:</p>
<div class="math notranslate nohighlight" id="equation-eq-weighted-empirical-risk-min">
<span class="eqno">(4.7.5)<a class="headerlink" href="#equation-eq-weighted-empirical-risk-min" title="Permalink to this equation">¶</a></span>\[\mathop{\mathrm{minimize}}_f \frac{1}{n} \sum_{i=1}^n \beta_i l(f(\mathbf{x}_i), y_i).\]</div>
<p>Alas, we do not know that ratio, so before we can do anything useful we
need to estimate it. Many methods are available, including some fancy
operator-theoretic approaches that attempt to recalibrate the
expectation operator directly using a minimum-norm or a maximum entropy
principle. Note that for any such approach, we need samples drawn from
both distributions—the “true” <span class="math notranslate nohighlight">\(p\)</span>, e.g., by access to test data,
and the one used for generating the training set <span class="math notranslate nohighlight">\(q\)</span> (the latter
is trivially available). Note however, that we only need features
<span class="math notranslate nohighlight">\(\mathbf{x} \sim p(\mathbf{x})\)</span>; we do not need to access labels
<span class="math notranslate nohighlight">\(y \sim p(y)\)</span>.</p>
<p>In this case, there exists a very effective approach that will give
almost as good results as the original: namely, logistic regression,
which is a special case of softmax regression (see
<a class="reference internal" href="softmax-regression.html#sec-softmax"><span class="std std-numref">Section 4.1</span></a>) for binary classification. This is all that is
needed to compute estimated probability ratios. We learn a classifier to
distinguish between data drawn from <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> and data drawn
from <span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span>. If it is impossible to distinguish between
the two distributions then it means that the associated instances are
equally likely to come from either one of those two distributions. On
the other hand, any instances that can be well discriminated should be
significantly overweighted or underweighted accordingly.</p>
<p>For simplicity’s sake assume that we have an equal number of instances
from both distributions <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> and <span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span>,
respectively. Now denote by <span class="math notranslate nohighlight">\(z\)</span> labels that are <span class="math notranslate nohighlight">\(1\)</span> for data
drawn from <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(-1\)</span> for data drawn from <span class="math notranslate nohighlight">\(q\)</span>. Then
the probability in a mixed dataset is given by</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-2">
<span class="eqno">(4.7.6)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-2" title="Permalink to this equation">¶</a></span>\[P(z=1 \mid \mathbf{x}) = \frac{p(\mathbf{x})}{p(\mathbf{x})+q(\mathbf{x})} \textrm{ and hence } \frac{P(z=1 \mid \mathbf{x})}{P(z=-1 \mid \mathbf{x})} = \frac{p(\mathbf{x})}{q(\mathbf{x})}.\]</div>
<p>Thus, if we use a logistic regression approach, where
<span class="math notranslate nohighlight">\(P(z=1 \mid \mathbf{x})=\frac{1}{1+\exp(-h(\mathbf{x}))}\)</span>
(<span class="math notranslate nohighlight">\(h\)</span> is a parametrized function), it follows that</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-3">
<span class="eqno">(4.7.7)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-3" title="Permalink to this equation">¶</a></span>\[\beta_i = \frac{1/(1 + \exp(-h(\mathbf{x}_i)))}{\exp(-h(\mathbf{x}_i))/(1 + \exp(-h(\mathbf{x}_i)))} = \exp(h(\mathbf{x}_i)).\]</div>
<p>As a result, we need to solve two problems: the first, to distinguish
between data drawn from both distributions, and then a weighted
empirical risk minimization problem in
<a class="reference internal" href="#equation-eq-weighted-empirical-risk-min">(4.7.5)</a> where we weigh terms by
<span class="math notranslate nohighlight">\(\beta_i\)</span>.</p>
<p>Now we are ready to describe a correction algorithm. Suppose that we
have a training set
<span class="math notranslate nohighlight">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span> and an
unlabeled test set <span class="math notranslate nohighlight">\(\{\mathbf{u}_1, \ldots, \mathbf{u}_m\}\)</span>. For
covariate shift, we assume that <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> for all
<span class="math notranslate nohighlight">\(1 \leq i \leq n\)</span> are drawn from some source distribution and
<span class="math notranslate nohighlight">\(\mathbf{u}_i\)</span> for all <span class="math notranslate nohighlight">\(1 \leq i \leq m\)</span> are drawn from the
target distribution. Here is a prototypical algorithm for correcting
covariate shift:</p>
<ol class="arabic simple">
<li><p>Create a binary-classification training set:
<span class="math notranslate nohighlight">\(\{(\mathbf{x}_1, -1), \ldots, (\mathbf{x}_n, -1), (\mathbf{u}_1, 1), \ldots, (\mathbf{u}_m, 1)\}\)</span>.</p></li>
<li><p>Train a binary classifier using logistic regression to get the
function <span class="math notranslate nohighlight">\(h\)</span>.</p></li>
<li><p>Weigh training data using <span class="math notranslate nohighlight">\(\beta_i = \exp(h(\mathbf{x}_i))\)</span> or
better <span class="math notranslate nohighlight">\(\beta_i = \min(\exp(h(\mathbf{x}_i)), c)\)</span> for some
constant <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
<li><p>Use weights <span class="math notranslate nohighlight">\(\beta_i\)</span> for training on
<span class="math notranslate nohighlight">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span> in
<a class="reference internal" href="#equation-eq-weighted-empirical-risk-min">(4.7.5)</a>.</p></li>
</ol>
<p>Note that the above algorithm relies on a crucial assumption. For this
scheme to work, we need that each data example in the target (e.g., test
time) distribution had nonzero probability of occurring at training
time. If we find a point where <span class="math notranslate nohighlight">\(p(\mathbf{x}) &gt; 0\)</span> but
<span class="math notranslate nohighlight">\(q(\mathbf{x}) = 0\)</span>, then the corresponding importance weight
should be infinity.</p>
</div>
<div class="section" id="label-shift-correction">
<h3><span class="section-number">4.7.3.3. </span>Label Shift Correction<a class="headerlink" href="#label-shift-correction" title="Permalink to this heading">¶</a></h3>
<p>Assume that we are dealing with a classification task with <span class="math notranslate nohighlight">\(k\)</span>
categories. Using the same notation in
<a class="reference internal" href="#subsec-covariate-shift-correction"><span class="std std-numref">Section 4.7.3.2</span></a>, <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(p\)</span>
are the source distribution (e.g., training time) and target
distribution (e.g., test time), respectively. Assume that the
distribution of labels shifts over time: <span class="math notranslate nohighlight">\(q(y) \neq p(y)\)</span>, but the
class-conditional distribution stays the same:
<span class="math notranslate nohighlight">\(q(\mathbf{x} \mid y)=p(\mathbf{x} \mid y)\)</span>. If the source
distribution <span class="math notranslate nohighlight">\(q(y)\)</span> is “wrong”, we can correct for that according
to the following identity in the risk as defined in
<a class="reference internal" href="#equation-eq-true-risk">(4.7.2)</a>:</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-4">
<span class="eqno">(4.7.8)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-4" title="Permalink to this equation">¶</a></span>\[\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}\]</div>
<p>Here, our importance weights will correspond to the label likelihood
ratios:</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-5">
<span class="eqno">(4.7.9)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-5" title="Permalink to this equation">¶</a></span>\[\beta_i \stackrel{\textrm{def}}{=} \frac{p(y_i)}{q(y_i)}.\]</div>
<p>One nice thing about label shift is that if we have a reasonably good
model on the source distribution, then we can get consistent estimates
of these weights without ever having to deal with the ambient dimension.
In deep learning, the inputs tend to be high-dimensional objects like
images, while the labels are often simpler objects like categories.</p>
<p>To estimate the target label distribution, we first take our reasonably
good off-the-shelf classifier (typically trained on the training data)
and compute its “confusion” matrix using the validation set (also from
the training distribution). The <em>confusion matrix</em>, <span class="math notranslate nohighlight">\(\mathbf{C}\)</span>,
is simply a <span class="math notranslate nohighlight">\(k \times k\)</span> matrix, where each column corresponds to
the label category (ground truth) and each row corresponds to our
model’s predicted category. Each cell’s value <span class="math notranslate nohighlight">\(c_{ij}\)</span> is the
fraction of total predictions on the validation set where the true label
was <span class="math notranslate nohighlight">\(j\)</span> and our model predicted <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Now, we cannot calculate the confusion matrix on the target data
directly because we do not get to see the labels for the examples that
we see in the wild, unless we invest in a complex real-time annotation
pipeline. What we can do, however, is average all of our model’s
predictions at test time together, yielding the mean model outputs
<span class="math notranslate nohighlight">\(\mu(\hat{\mathbf{y}}) \in \mathbb{R}^k\)</span>, where the
<span class="math notranslate nohighlight">\(i^\textrm{th}\)</span> element <span class="math notranslate nohighlight">\(\mu(\hat{y}_i)\)</span> is the fraction of
the total predictions on the test set where our model predicted
<span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>It turns out that under some mild conditions—if our classifier was
reasonably accurate in the first place, and if the target data contains
only categories that we have seen before, and if the label shift
assumption holds in the first place (the strongest assumption here)—we
can estimate the test set label distribution by solving a simple linear
system</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-6">
<span class="eqno">(4.7.10)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-6" title="Permalink to this equation">¶</a></span>\[\mathbf{C} p(\mathbf{y}) = \mu(\hat{\mathbf{y}}),\]</div>
<p>because as an estimate
<span class="math notranslate nohighlight">\(\sum_{j=1}^k c_{ij} p(y_j) = \mu(\hat{y}_i)\)</span> holds for all
<span class="math notranslate nohighlight">\(1 \leq i \leq k\)</span>, where <span class="math notranslate nohighlight">\(p(y_j)\)</span> is the
<span class="math notranslate nohighlight">\(j^\textrm{th}\)</span> element of the <span class="math notranslate nohighlight">\(k\)</span>-dimensional label
distribution vector <span class="math notranslate nohighlight">\(p(\mathbf{y})\)</span>. If our classifier is
sufficiently accurate to begin with, then the confusion matrix
<span class="math notranslate nohighlight">\(\mathbf{C}\)</span> will be invertible, and we get a solution
<span class="math notranslate nohighlight">\(p(\mathbf{y}) = \mathbf{C}^{-1} \mu(\hat{\mathbf{y}})\)</span>.</p>
<p>Because we observe the labels on the source data, it is easy to estimate
the distribution <span class="math notranslate nohighlight">\(q(y)\)</span>. Then, for any training example <span class="math notranslate nohighlight">\(i\)</span>
with label <span class="math notranslate nohighlight">\(y_i\)</span>, we can take the ratio of our estimated
<span class="math notranslate nohighlight">\(p(y_i)/q(y_i)\)</span> to calculate the weight <span class="math notranslate nohighlight">\(\beta_i\)</span>, and plug
this into weighted empirical risk minimization in
<a class="reference internal" href="#equation-eq-weighted-empirical-risk-min">(4.7.5)</a>.</p>
</div>
<div class="section" id="concept-shift-correction">
<h3><span class="section-number">4.7.3.4. </span>Concept Shift Correction<a class="headerlink" href="#concept-shift-correction" title="Permalink to this heading">¶</a></h3>
<p>Concept shift is much harder to fix in a principled manner. For
instance, in a situation where suddenly the problem changes from
distinguishing cats from dogs to one of distinguishing white from black
animals, it will be unreasonable to assume that we can do much better
than just collecting new labels and training from scratch. Fortunately,
in practice, such extreme shifts are rare. Instead, what usually happens
is that the task keeps on changing slowly. To make things more concrete,
here are some examples:</p>
<ul class="simple">
<li><p>In computational advertising, new products are launched, old products
become less popular. This means that the distribution over ads and
their popularity changes gradually and any click-through rate
predictor needs to change gradually with it.</p></li>
<li><p>Traffic camera lenses degrade gradually due to environmental wear,
affecting image quality progressively.</p></li>
<li><p>News content changes gradually (i.e., most of the news remains
unchanged but new stories appear).</p></li>
</ul>
<p>In such cases, we can use the same approach that we used for training
networks to make them adapt to the change in the data. In other words,
we use the existing network weights and simply perform a few update
steps with the new data rather than training from scratch.</p>
</div>
</div>
<div class="section" id="a-taxonomy-of-learning-problems">
<h2><span class="section-number">4.7.4. </span>A Taxonomy of Learning Problems<a class="headerlink" href="#a-taxonomy-of-learning-problems" title="Permalink to this heading">¶</a></h2>
<p>Armed with knowledge about how to deal with changes in distributions, we
can now consider some other aspects of machine learning problem
formulation.</p>
<div class="section" id="batch-learning">
<h3><span class="section-number">4.7.4.1. </span>Batch Learning<a class="headerlink" href="#batch-learning" title="Permalink to this heading">¶</a></h3>
<p>In <em>batch learning</em>, we have access to training features and labels
<span class="math notranslate nohighlight">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span>, which we
use to train a model <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>. Later on, we deploy this
model to score new data <span class="math notranslate nohighlight">\((\mathbf{x}, y)\)</span> drawn from the same
distribution. This is the default assumption for any of the problems
that we discuss here. For instance, we might train a cat detector based
on lots of pictures of cats and dogs. Once we have trained it, we ship
it as part of a smart catdoor computer vision system that lets only cats
in. This is then installed in a customer’s home and is never updated
again (barring extreme circumstances).</p>
</div>
<div class="section" id="online-learning">
<h3><span class="section-number">4.7.4.2. </span>Online Learning<a class="headerlink" href="#online-learning" title="Permalink to this heading">¶</a></h3>
<p>Now imagine that the data <span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span> arrives one sample
at a time. More specifically, assume that we first observe
<span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>, then we need to come up with an estimate
<span class="math notranslate nohighlight">\(f(\mathbf{x}_i)\)</span>. Only once we have done this do we observe
<span class="math notranslate nohighlight">\(y_i\)</span> and so receive a reward or incur a loss, given our decision.
Many real problems fall into this category. For example, we need to
predict tomorrow’s stock price, which allows us to trade based on that
estimate and at the end of the day we find out whether our estimate made
us a profit. In other words, in <em>online learning</em>, we have the following
cycle where we are continuously improving our model given new
observations:</p>
<div class="math notranslate nohighlight" id="equation-chapter-linear-classification-environment-and-distribution-shift-7">
<span class="eqno">(4.7.11)<a class="headerlink" href="#equation-chapter-linear-classification-environment-and-distribution-shift-7" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}&amp;\textrm{model } f_t \longrightarrow \textrm{data }  \mathbf{x}_t \longrightarrow \textrm{estimate } f_t(\mathbf{x}_t) \longrightarrow\\ \textrm{obs}&amp;\textrm{ervation } y_t \longrightarrow \textrm{loss } l(y_t, f_t(\mathbf{x}_t)) \longrightarrow \textrm{model } f_{t+1}\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="bandits">
<h3><span class="section-number">4.7.4.3. </span>Bandits<a class="headerlink" href="#bandits" title="Permalink to this heading">¶</a></h3>
<p><em>Bandits</em> are a special case of the problem above. While in most
learning problems we have a continuously parametrized function <span class="math notranslate nohighlight">\(f\)</span>
where we want to learn its parameters (e.g., a deep network), in a
<em>bandit</em> problem we only have a finite number of arms that we can pull,
i.e., a finite number of actions that we can take. It is not very
surprising that for this simpler problem stronger theoretical guarantees
in terms of optimality can be obtained. We list it mainly since this
problem is often (confusingly) treated as if it were a distinct learning
setting.</p>
</div>
<div class="section" id="control">
<h3><span class="section-number">4.7.4.4. </span>Control<a class="headerlink" href="#control" title="Permalink to this heading">¶</a></h3>
<p>In many cases the environment remembers what we did. Not necessarily in
an adversarial manner but it will just remember and the response will
depend on what happened before. For instance, a coffee boiler controller
will observe different temperatures depending on whether it was heating
the boiler previously. PID (proportional-integral-derivative) controller
algorithms are a popular choice there. Likewise, a user’s behavior on a
news site will depend on what we showed them previously (e.g., they will
read most news only once). Many such algorithms form a model of the
environment in which they act so as to make their decisions appear less
random. Recently, control theory (e.g., PID variants) has also been used
to automatically tune hyperparameters to achieve better disentangling
and reconstruction quality, and improve the diversity of generated text
and the reconstruction quality of generated images
<span id="id1">(<a class="reference internal" href="../chapter_references/zreferences.html#id257" title="Shao, H., Yao, S., Sun, D., Zhang, A., Liu, S., Liu, D., … Abdelzaher, T. (2020). ControlVAE: controllable variational autoencoder. Proceedings of the 37th International Conference on Machine Learning.">Shao <em>et al.</em>, 2020</a>)</span>.</p>
</div>
<div class="section" id="reinforcement-learning">
<h3><span class="section-number">4.7.4.5. </span>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this heading">¶</a></h3>
<p>In the more general case of an environment with memory, we may encounter
situations where the environment is trying to cooperate with us
(cooperative games, in particular for non-zero-sum games), or others
where the environment will try to win. Chess, Go, Backgammon, or
StarCraft are some of the cases in <em>reinforcement learning</em>. Likewise,
we might want to build a good controller for autonomous cars. Other cars
are likely to respond to the autonomous car’s driving style in
nontrivial ways, e.g., trying to avoid it, trying to cause an accident,
or trying to cooperate with it.</p>
</div>
<div class="section" id="considering-the-environment">
<h3><span class="section-number">4.7.4.6. </span>Considering the Environment<a class="headerlink" href="#considering-the-environment" title="Permalink to this heading">¶</a></h3>
<p>One key distinction between the different situations above is that a
strategy that might have worked throughout in the case of a stationary
environment, might not work throughout in an environment that can adapt.
For instance, an arbitrage opportunity discovered by a trader is likely
to disappear once it is exploited. The speed and manner at which the
environment changes determines to a large extent the type of algorithms
that we can bring to bear. For instance, if we know that things may only
change slowly, we can force any estimate to change only slowly, too. If
we know that the environment might change instantaneously, but only very
infrequently, we can make allowances for that. These types of knowledge
are crucial for the aspiring data scientist in dealing with concept
shift, i.e., when the problem that is being solved can change over time.</p>
</div>
</div>
<div class="section" id="fairness-accountability-and-transparency-in-machine-learning">
<h2><span class="section-number">4.7.5. </span>Fairness, Accountability, and Transparency in Machine Learning<a class="headerlink" href="#fairness-accountability-and-transparency-in-machine-learning" title="Permalink to this heading">¶</a></h2>
<p>Finally, it is important to remember that when you deploy machine
learning systems you are not merely optimizing a predictive model—you
are typically providing a tool that will be used to (partially or fully)
automate decisions. These technical systems can impact the lives of
individuals who are subject to the resulting decisions. The leap from
considering predictions to making decisions raises not only new
technical questions, but also a slew of ethical questions that must be
carefully considered. If we are deploying a medical diagnostic system,
we need to know for which populations it may work and for which it may
not. Overlooking foreseeable risks to the welfare of a subpopulation
could cause us to administer inferior care. Moreover, once we
contemplate decision-making systems, we must step back and reconsider
how we evaluate our technology. Among other consequences of this change
of scope, we will find that <em>accuracy</em> is seldom the right measure. For
instance, when translating predictions into actions, we will often want
to take into account the potential cost sensitivity of erring in various
ways. If one way of misclassifying an image could be perceived as a
racial sleight of hand, while misclassification to a different category
would be harmless, then we might want to adjust our thresholds
accordingly, accounting for societal values in designing the
decision-making protocol. We also want to be careful about how
prediction systems can lead to feedback loops. For example, consider
predictive policing systems, which allocate patrol officers to areas
with high forecasted crime. It is easy to see how a worrying pattern can
emerge:</p>
<ol class="arabic simple">
<li><p>Neighborhoods with more crime get more patrols.</p></li>
<li><p>Consequently, more crimes are discovered in these neighborhoods,
entering the training data available for future iterations.</p></li>
<li><p>Exposed to more positives, the model predicts yet more crime in these
neighborhoods.</p></li>
<li><p>In the next iteration, the updated model targets the same
neighborhood even more heavily leading to yet more crimes discovered,
etc.</p></li>
</ol>
<p>Often, the various mechanisms by which a model’s predictions become
coupled to its training data are unaccounted for in the modeling
process. This can lead to what researchers call <em>runaway feedback
loops</em>. Additionally, we want to be careful about whether we are
addressing the right problem in the first place. Predictive algorithms
now play an outsize role in mediating the dissemination of information.
Should the news that an individual encounters be determined by the set
of Facebook pages they have <em>Liked</em>? These are just a few among the many
pressing ethical dilemmas that you might encounter in a career in
machine learning.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">4.7.6. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">¶</a></h2>
<p>In many cases training and test sets do not come from the same
distribution. This is called distribution shift. The risk is the
expectation of the loss over the entire population of data drawn from
their true distribution. However, this entire population is usually
unavailable. Empirical risk is an average loss over the training data to
approximate the risk. In practice, we perform empirical risk
minimization.</p>
<p>Under the corresponding assumptions, covariate and label shift can be
detected and corrected for at test time. Failure to account for this
bias can become problematic at test time. In some cases, the environment
may remember automated actions and respond in surprising ways. We must
account for this possibility when building models and continue to
monitor live systems, open to the possibility that our models and the
environment will become entangled in unanticipated ways.</p>
</div>
<div class="section" id="exercises">
<h2><span class="section-number">4.7.7. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>What could happen when we change the behavior of a search engine?
What might the users do? What about the advertisers?</p></li>
<li><p>Implement a covariate shift detector. Hint: build a classifier.</p></li>
<li><p>Implement a covariate shift corrector.</p></li>
<li><p>Besides distribution shift, what else could affect how the empirical
risk approximates the risk?</p></li>
</ol>
<p><a class="reference external" href="https://discuss.d2l.ai/t/105">Discussions</a></p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">4.7. Environment and Distribution Shift</a><ul>
<li><a class="reference internal" href="#types-of-distribution-shift">4.7.1. Types of Distribution Shift</a><ul>
<li><a class="reference internal" href="#covariate-shift">4.7.1.1. Covariate Shift</a></li>
<li><a class="reference internal" href="#label-shift">4.7.1.2. Label Shift</a></li>
<li><a class="reference internal" href="#concept-shift">4.7.1.3. Concept Shift</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-of-distribution-shift">4.7.2. Examples of Distribution Shift</a><ul>
<li><a class="reference internal" href="#medical-diagnostics">4.7.2.1. Medical Diagnostics</a></li>
<li><a class="reference internal" href="#self-driving-cars">4.7.2.2. Self-Driving Cars</a></li>
<li><a class="reference internal" href="#nonstationary-distributions">4.7.2.3. Nonstationary Distributions</a></li>
<li><a class="reference internal" href="#more-anecdotes">4.7.2.4. More Anecdotes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#correction-of-distribution-shift">4.7.3. Correction of Distribution Shift</a><ul>
<li><a class="reference internal" href="#empirical-risk-and-risk">4.7.3.1. Empirical Risk and Risk</a></li>
<li><a class="reference internal" href="#covariate-shift-correction">4.7.3.2. Covariate Shift Correction</a></li>
<li><a class="reference internal" href="#label-shift-correction">4.7.3.3. Label Shift Correction</a></li>
<li><a class="reference internal" href="#concept-shift-correction">4.7.3.4. Concept Shift Correction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-taxonomy-of-learning-problems">4.7.4. A Taxonomy of Learning Problems</a><ul>
<li><a class="reference internal" href="#batch-learning">4.7.4.1. Batch Learning</a></li>
<li><a class="reference internal" href="#online-learning">4.7.4.2. Online Learning</a></li>
<li><a class="reference internal" href="#bandits">4.7.4.3. Bandits</a></li>
<li><a class="reference internal" href="#control">4.7.4.4. Control</a></li>
<li><a class="reference internal" href="#reinforcement-learning">4.7.4.5. Reinforcement Learning</a></li>
<li><a class="reference internal" href="#considering-the-environment">4.7.4.6. Considering the Environment</a></li>
</ul>
</li>
<li><a class="reference internal" href="#fairness-accountability-and-transparency-in-machine-learning">4.7.5. Fairness, Accountability, and Transparency in Machine Learning</a></li>
<li><a class="reference internal" href="#summary">4.7.6. Summary</a></li>
<li><a class="reference internal" href="#exercises">4.7.7. Exercises</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="generalization-classification.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>4.6. Generalization in Classification</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_multilayer-perceptrons/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>5. Multilayer Perceptrons</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>